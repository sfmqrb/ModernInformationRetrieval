[{
    "id": "2981549002",
    "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes.",
    "abstract": "Wide neural networks with random weights and biases are Gaussian processes, as originally observed by Neal (1995) and more recently by Lee et al. (2018) and Matthews et al. (2018) for deep fully-connected networks, as well as by Novak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional networks. We show that this Neural Network-Gaussian Process correspondence surprisingly extends to all modern feedforward or recurrent neural networks composed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph) convolution, pooling, skip connection, attention, batch normalization, and/or layer normalization. More generally, we introduce a language for expressing neural network computations, and our result encompasses all such expressible neural networks. This work serves as a tutorial on the *tensor programs* technique formulated in Yang (2019) and elucidates the Gaussian Process results obtained there. We provide open-source implementations of the Gaussian Process kernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at this http URL.",
    "date": "2019",
    "authors": [
        "Greg Yang"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Artificial neural network",
        "Multilayer perceptron"
    ],
    "citation_count": "27",
    "reference_count": "55",
    "references": [
        "2194775991",
        "2963403868",
        "1836465849",
        "2964308564",
        "2963446712",
        "1677182931",
        "2157331557",
        "2310919327",
        "2064675550",
        "1533861849"
    ]
},{
    "id": "3105081694",
    "title": "COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images.",
    "abstract": "The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.",
    "date": "2020",
    "authors": [
        "Linda Wang",
        "Zhong Qiu Lin",
        "Alexander Wong"
    ],
    "related_topics": [
        "Deep learning",
        "Convolutional neural network",
        "Image processing"
    ],
    "citation_count": "704",
    "reference_count": "46",
    "references": [
        "2194775991",
        "3001118548",
        "2962835968",
        "3008827533",
        "2919115771",
        "2108598243",
        "2963446712",
        "3007497549",
        "3010604545",
        "3008985036"
    ]
},{
    "id": "2950893734",
    "title": "Self-Attention Generative Adversarial Networks",
    "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.",
    "date": "2018",
    "authors": [
        "Han Zhang",
        "Ian Goodfellow",
        "Dimitris Metaxas",
        "Augustus Odena"
    ],
    "related_topics": [
        "Boosting (machine learning)",
        "Visualization",
        "Normalization (statistics)"
    ],
    "citation_count": "1,493",
    "reference_count": "52",
    "references": [
        "2964121744",
        "2963403868",
        "2117539524",
        "2099471712",
        "2964308564",
        "2963073614",
        "2962793481",
        "2963684088",
        "2963373786",
        "2963470893"
    ]
},{
    "id": "3119786062",
    "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
    "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
    "date": "2021",
    "authors": [
        "Alexey Dosovitskiy",
        "Lucas Beyer",
        "Alexander Kolesnikov",
        "Dirk Weissenborn",
        "Xiaohua Zhai",
        "Thomas Unterthiner",
        "Mostafa Dehghani",
        "Matthias Minderer",
        "Georg Heigold",
        "Sylvain Gelly",
        "Jakob Uszkoreit",
        "Neil Houlsby"
    ],
    "related_topics": [
        "Transformer (machine learning model)",
        "Contextual image classification",
        "Computer vision"
    ],
    "citation_count": "290",
    "reference_count": "49",
    "references": [
        "2194775991",
        "2618530766",
        "2964121744",
        "2963341956",
        "2963403868",
        "1836465849",
        "2108598243",
        "3118608800",
        "2963091558",
        "3034978746"
    ]
},{
    "id": "2145339207",
    "title": "Human-level control through deep reinforcement learning",
    "abstract": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.",
    "date": "2015",
    "authors": [
        "Volodymyr Mnih",
        "Koray Kavukcuoglu",
        "David Silver",
        "Andrei A. Rusu",
        "Joel Veness",
        "Marc G. Bellemare",
        "Alex Graves",
        "Martin Riedmiller",
        "Andreas K. Fidjeland",
        "Georg Ostrovski",
        "Stig Petersen",
        "Charles Beattie",
        "Amir Sadik",
        "Ioannis Antonoglou",
        "Helen King",
        "Dharshan Kumaran",
        "Daan Wierstra",
        "Shane Legg",
        "Demis Hassabis"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Temporal difference learning",
        "Artificial neural network"
    ],
    "citation_count": "14,732",
    "reference_count": "33",
    "references": [
        "2618530766",
        "2310919327",
        "2100495367",
        "2187089797",
        "1665214252",
        "2072128103",
        "2546302380",
        "2121863487",
        "2952509347",
        "1652505363"
    ]
},{
    "id": "2153579005",
    "title": "Distributed Representations of Words and Phrases and their Compositionality",
    "abstract": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.",
    "date": "2013",
    "authors": [
        "Tomas Mikolov",
        "Ilya Sutskever",
        "Kai Chen",
        "Greg S Corrado",
        "Jeff Dean"
    ],
    "related_topics": [
        "Word2vec",
        "Word embedding",
        "Word order"
    ],
    "citation_count": "25,751",
    "reference_count": "19",
    "references": [
        "1614298861",
        "2141599568",
        "2117130368",
        "2132339004",
        "2158139315",
        "1423339008",
        "1498436455",
        "1662133657",
        "1889268436",
        "2131462252"
    ]
},{
    "id": "2194775991",
    "title": "Deep Residual Learning for Image Recognition",
    "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\u20148\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
    "date": "2016",
    "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
    ],
    "related_topics": [
        "Deep learning",
        "Residual",
        "Convolutional neural network"
    ],
    "citation_count": "77,931",
    "reference_count": "52",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "639708223",
        "1836465849",
        "2102605133",
        "2117539524",
        "1903029394",
        "2155893237",
        "1536680647"
    ]
},{
    "id": "2963403868",
    "title": "Attention is All You Need",
    "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.",
    "date": "2017",
    "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N. Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
    ],
    "related_topics": [
        "Machine translation",
        "Encoder",
        "BLEU"
    ],
    "citation_count": "18,855",
    "reference_count": "0",
    "references": []
},{
    "id": "1836465849",
    "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
    "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.",
    "date": "2015",
    "authors": [
        "Sergey Ioffe",
        "Christian Szegedy"
    ],
    "related_topics": [
        "Normalization (statistics)",
        "Initialization",
        "Contextual image classification"
    ],
    "citation_count": "25,868",
    "reference_count": "23",
    "references": [
        "2097117768",
        "2117539524",
        "2095705004",
        "1677182931",
        "2146502635",
        "2310919327",
        "1665214252",
        "2168231600",
        "1533861849",
        "104184427"
    ]
},{
    "id": "2964308564",
    "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
    "abstract": "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "date": "2014",
    "authors": [
        "Dzmitry Bahdanau",
        "Kyunghyun Cho",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Machine translation",
        "Artificial neural network",
        "Phrase"
    ],
    "citation_count": "17,406",
    "reference_count": "25",
    "references": [
        "2157331557",
        "2064675550",
        "6908809",
        "2132339004",
        "1753482797",
        "2294059674",
        "1810943226",
        "2964199361",
        "1815076433",
        "2153653739"
    ]
},{
    "id": "2963446712",
    "title": "Densely Connected Convolutional Networks",
    "abstract": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections&#x2014;one between each layer and its subsequent layer&#x2014;our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.",
    "date": "2017",
    "authors": [
        "Gao Huang",
        "Zhuang Liu",
        "Laurens van der Maaten",
        "Kilian Q. Weinberger"
    ],
    "related_topics": [
        "Convolutional code",
        "Network architecture",
        "Vanishing gradient problem"
    ],
    "citation_count": "16,054",
    "reference_count": "39",
    "references": [
        "2194775991",
        "2618530766",
        "2097117768",
        "1836465849",
        "2117539524",
        "1903029394",
        "2095705004",
        "2108598243",
        "1677182931",
        "2183341477"
    ]
},{
    "id": "1677182931",
    "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",
    "abstract": "Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.",
    "date": "2015",
    "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
    ],
    "related_topics": [
        "Rectifier (neural networks)",
        "Initialization",
        "Overfitting"
    ],
    "citation_count": "11,535",
    "reference_count": "35",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "1836465849",
        "2102605133",
        "2117539524",
        "2095705004",
        "2108598243",
        "2155893237",
        "1536680647"
    ]
},{
    "id": "2157331557",
    "title": "Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "date": "2013",
    "authors": [
        "Kyunghyun Cho",
        "Bart van Merrienboer",
        "Caglar Gulcehre",
        "Dzmitry Bahdanau",
        "Fethi Bougares",
        "Holger Schwenk",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Encoder",
        "Recurrent neural network",
        "Artificial neural network"
    ],
    "citation_count": "13,344",
    "reference_count": "31",
    "references": [
        "2618530766",
        "2153579005",
        "2064675550",
        "2147768505",
        "6908809",
        "2132339004",
        "1753482797",
        "2294059674",
        "2156387975",
        "2963504252"
    ]
},{
    "id": "2310919327",
    "title": "Gradient-based learning applied to document recognition",
    "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.",
    "date": "2000",
    "authors": [
        "Yann Lecun",
        "Leon Bottou",
        "Yoshua Bengio",
        "Patrick Haffner"
    ],
    "related_topics": [
        "Artificial neural network",
        "Convolutional neural network",
        "Handwriting recognition"
    ],
    "citation_count": "37,429",
    "reference_count": "0",
    "references": []
},{
    "id": "1533861849",
    "title": "Understanding the difficulty of training deep feedforward neural networks",
    "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).",
    "date": "2010",
    "authors": [
        "Xavier Glorot",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Deep learning",
        "Vanishing gradient problem",
        "Initialization"
    ],
    "citation_count": "12,845",
    "reference_count": "17",
    "references": [
        "2136922672",
        "2310919327",
        "2072128103",
        "2117130368",
        "2025768430",
        "2110798204",
        "1498436455",
        "1994197834",
        "2131462252",
        "2172174689"
    ]
},{
    "id": "3001118548",
    "title": "Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China",
    "abstract": "A recent cluster of pneumonia cases in Wuhan, China, was caused by a novel betacoronavirus, the 2019 novel coronavirus (2019-nCoV). We report the epidemiological, clinical, laboratory, and radiological characteristics and treatment and clinical outcomes of these patients. All patients with suspected 2019-nCoV were admitted to a designated hospital in Wuhan. We prospectively collected and analysed data on patients with laboratory-confirmed 2019-nCoV infection by real-time RT-PCR and next-generation sequencing. Data were obtained with standardised data collection forms shared by the International Severe Acute Respiratory and Emerging Infection Consortium from electronic medical records. Researchers also directly communicated with patients or their families to ascertain epidemiological and symptom data. Outcomes were also compared between patients who had been admitted to the intensive care unit (ICU) and those who had not.",
    "date": "2020",
    "authors": [
        "Chaolin Huang",
        "Yeming Wang",
        "Xingwang Li",
        "Lili Ren",
        "Jianping Zhao",
        "Yi Hu",
        "Li Zhang",
        "Guohui Fan",
        "Jiuyang Xu",
        "Xiaoying Gu",
        "Zhenshun Cheng",
        "Ting Yu",
        "Jiaan Xia",
        "Yuan Wei",
        "Wenjuan Wu",
        "Xuelei Xie",
        "Wen Yin",
        "Hui Li",
        "Min Liu",
        "Yan Xiao",
        "Hong Gao",
        "Li Guo",
        "Jungang Xie",
        "Guangfa Wang",
        "Rongmeng Jiang",
        "Zhancheng Gao",
        "Qi Jin",
        "Jianwei Wang",
        "Bin Cao"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Intensive care unit",
        "Viral pneumonia"
    ],
    "citation_count": "26,659",
    "reference_count": "34",
    "references": [
        "2903899730",
        "2166867592",
        "3000413850",
        "2132260239",
        "2026274122",
        "2104548316",
        "2131262274",
        "2006434809",
        "3017468735",
        "2725497285"
    ]
},{
    "id": "2962835968",
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
    "date": "2014",
    "authors": [
        "Karen Simonyan",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Convolution",
        "Computer vision",
        "Scale (map)"
    ],
    "citation_count": "83,614",
    "reference_count": "0",
    "references": []
},{
    "id": "3008827533",
    "title": "Clinical Characteristics of Coronavirus Disease 2019 in China",
    "abstract": "Abstract Background Since December 2019, when coronavirus disease 2019 (Covid-19) emerged in Wuhan city and rapidly spread throughout China, data have been needed on the clinical characteristics of...",
    "date": "2020",
    "authors": [
        "Wei-jie Guan",
        "Zheng-yi Ni",
        "Yu Hu",
        "Wenhua Liang",
        "Chun-quan Ou",
        "Jianxing He",
        "Lei Liu",
        "Hong Shan",
        "Chunliang Lei",
        "David S.C. Hui",
        "Bin Du",
        "Lan-juan Li",
        "Guang Zeng",
        "Kwok-Yung Yuen",
        "Ruchong Chen",
        "Chun-Li Tang",
        "Tao Wang",
        "Ping-yan Chen",
        "Jie Xiang",
        "Shiyue Li",
        "Jinlin Wang",
        "Zi Jing Liang",
        "Yi-xiang Peng",
        "Li Wei",
        "Yong Liu",
        "Ya-hua Hu",
        "Peng Peng",
        "Jian-ming Wang",
        "Ji-yang Liu",
        "Zhong Chen",
        "Gang Li",
        "Zhi-jian Zheng",
        "Shao-qin Qiu",
        "Jie Luo",
        "Chang-jiang Ye",
        "Shao-yong Zhu",
        "Nanshan Zhong"
    ],
    "related_topics": [
        "Pandemic",
        "Betacoronavirus",
        "Viral Epidemiology"
    ],
    "citation_count": "17,855",
    "reference_count": "19",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3003668884",
        "3002539152",
        "3004318991",
        "3003465021",
        "3004239190",
        "3003573988"
    ]
},{
    "id": "2919115771",
    "title": "Deep learning",
    "abstract": "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.",
    "date": "2015",
    "authors": [
        "Yann LeCun",
        "Yoshua Bengio",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Deep learning",
        "Object detection",
        "Cognitive neuroscience of visual object recognition"
    ],
    "citation_count": "39,561",
    "reference_count": "33",
    "references": [
        "2145339207",
        "2136922672",
        "2310919327",
        "2100495367",
        "2064675550",
        "2163922914",
        "2160815625",
        "2022508996",
        "2025768430",
        "1993882792"
    ]
},{
    "id": "2108598243",
    "title": "ImageNet: A large-scale hierarchical image database",
    "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.",
    "date": "2009",
    "authors": [
        "Jia Deng",
        "Wei Dong",
        "Richard Socher",
        "Li-Jia Li",
        "Kai Li",
        "Li Fei-Fei"
    ],
    "related_topics": [
        "WordNet",
        "Image retrieval",
        "Contextual image classification"
    ],
    "citation_count": "28,435",
    "reference_count": "24",
    "references": [
        "2151103935",
        "2038721957",
        "2128017662",
        "2110764733",
        "1782590233",
        "1576445103",
        "2145607950",
        "2141282920",
        "2115733720",
        "1528789833"
    ]
},{
    "id": "3007497549",
    "title": "Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases.",
    "abstract": "Chest CT had higher sensitivity for diagnosis of COVID-19 as compared with initial reverse-transcription polymerase chain reaction from swab samples in the epidemic area of China.",
    "date": "2020",
    "authors": [
        "Tao Ai",
        "Zhenlu Yang",
        "Hongyan Hou",
        "Chenao Zhan",
        "Chong Chen",
        "Wenzhi Lv",
        "Qian Tao",
        "Ziyong Sun",
        "Liming Xia"
    ],
    "related_topics": [
        "Real-time polymerase chain reaction",
        "Reverse transcription polymerase chain reaction",
        "Pneumonia"
    ],
    "citation_count": "3,787",
    "reference_count": "9",
    "references": [
        "3001118548",
        "3008818676",
        "3004906315",
        "3006643024",
        "3006110666",
        "3006354146",
        "3003901880",
        "3005656138",
        "3004511262"
    ]
},{
    "id": "3010604545",
    "title": "Detection of SARS-CoV-2 in Different Types of Clinical Specimens.",
    "abstract": "This study describes results of PCR and viral RNA testing for SARS-CoV-2 in bronchoalveolar fluid, sputum, feces, blood, and urine specimens from patients with COVID-19 infection in China to identify possible means of non-respiratory transmission.",
    "date": "2020",
    "authors": [
        "Wenling Wang",
        "Yanli Xu",
        "Ruqin Gao",
        "Roujian Lu",
        "Kai Han",
        "Guizhen Wu",
        "Wenjie Tan"
    ],
    "related_topics": [
        "Sputum",
        "Viral load",
        "Feces"
    ],
    "citation_count": "3,735",
    "reference_count": "13",
    "references": [
        "3005079553",
        "3008962515",
        "3008452791",
        "3033453353",
        "3034408674",
        "3035275617",
        "3034059415",
        "3033952286",
        "3036958556",
        "3035464429"
    ]
},{
    "id": "3008985036",
    "title": "Sensitivity of Chest CT for COVID-19: Comparison to RT-PCR",
    "abstract": "In a series of 51 patients with chest CT and real-time polymerase chain reaction assay (RT-PCR) performed within 3 days, the sensitivity of CT for 2019 novel coronavirus infection was 98% and that ...",
    "date": "2020",
    "authors": [
        "Yicheng Fang",
        "Huangqi Zhang",
        "Jicheng Xie",
        "Minjie Lin",
        "Lingjun Ying",
        "Peipei Pang",
        "Wenbin Ji"
    ],
    "related_topics": [
        "Real-time polymerase chain reaction",
        "Polymerase chain reaction",
        "Pneumonia"
    ],
    "citation_count": "2,086",
    "reference_count": "7",
    "references": [
        "3002108456",
        "3006643024",
        "3006110666",
        "3028749392",
        "3032185657",
        "3042098369",
        "3037255629"
    ]
},{
    "id": "2964121744",
    "title": "Adam: A Method for Stochastic Optimization",
    "abstract": "Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",
    "date": "2014",
    "authors": [
        "Diederik P. Kingma",
        "Jimmy Lei Ba"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Convex optimization",
        "Rate of convergence"
    ],
    "citation_count": "68,547",
    "reference_count": "0",
    "references": []
},{
    "id": "2117539524",
    "title": "ImageNet Large Scale Visual Recognition Challenge",
    "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.",
    "date": "2015",
    "authors": [
        "Olga Russakovsky",
        "Jia Deng",
        "Hao Su",
        "Jonathan Krause",
        "Sanjeev Satheesh",
        "Sean Ma",
        "Zhiheng Huang",
        "Andrej Karpathy",
        "Aditya Khosla",
        "Michael Bernstein",
        "Alexander C. Berg",
        "Li Fei-Fei"
    ],
    "related_topics": [
        "Object detection",
        "Cognitive neuroscience of visual object recognition",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "23,365",
    "reference_count": "97",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "2151103935",
        "2102605133",
        "1614298861",
        "2108598243",
        "2155893237",
        "2168356304",
        "1849277567"
    ]
},{
    "id": "2099471712",
    "title": "Generative Adversarial Nets",
    "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
    "date": "2014",
    "authors": [
        "Ian Goodfellow",
        "Jean Pouget-Abadie",
        "Mehdi Mirza",
        "Bing Xu",
        "David Warde-Farley",
        "Sherjil Ozair",
        "Aaron Courville",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Generative model",
        "Discriminative model",
        "Approximate inference"
    ],
    "citation_count": "27,329",
    "reference_count": "34",
    "references": [
        "2618530766",
        "2136922672",
        "1959608418",
        "3118608800",
        "2310919327",
        "1904365287",
        "2964153729",
        "2072128103",
        "2546302380",
        "2025768430"
    ]
},{
    "id": "2963073614",
    "title": "Image-to-Image Translation with Conditional Adversarial Networks",
    "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.",
    "date": "2017",
    "authors": [
        "Phillip Isola",
        "Jun-Yan Zhu",
        "Tinghui Zhou",
        "Alexei A. Efros"
    ],
    "related_topics": [
        "Image translation",
        "Image (mathematics)",
        "Machine learning"
    ],
    "citation_count": "9,065",
    "reference_count": "52",
    "references": [
        "2964121744",
        "1836465849",
        "2117539524",
        "1901129140",
        "1903029394",
        "2099471712",
        "2133665775",
        "2963684088",
        "2100495367",
        "2340897893"
    ]
},{
    "id": "2962793481",
    "title": "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks",
    "abstract": "Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X \u2192 Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y \u2192 X and introduce a cycle consistency loss to push F(G(X)) \u2248 X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.",
    "date": "2017",
    "authors": [
        "Jun-Yan Zhu",
        "Taesung Park",
        "Phillip Isola",
        "Alexei A. Efros"
    ],
    "related_topics": [
        "Image translation",
        "Image (category theory)",
        "Translation (geometry)"
    ],
    "citation_count": "8,237",
    "reference_count": "54",
    "references": [
        "2194775991",
        "2962835968",
        "2117539524",
        "1903029394",
        "2099471712",
        "1959608418",
        "2963684088",
        "2100495367",
        "2340897893",
        "2963373786"
    ]
},{
    "id": "2963684088",
    "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
    "abstract": "Abstract: In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.",
    "date": "2015",
    "authors": [
        "Alec Radford",
        "Luke Metz",
        "Soumith Chintala"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Supervised learning",
        "Feature learning"
    ],
    "citation_count": "8,789",
    "reference_count": "0",
    "references": []
},{
    "id": "2963373786",
    "title": "Improved techniques for training GANs",
    "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
    "date": "2016",
    "authors": [
        "Tim Salimans",
        "Ian Goodfellow",
        "Wojciech Zaremba",
        "Vicki Cheung",
        "Alec Radford",
        "Xi Chen"
    ],
    "related_topics": [
        "MNIST database",
        "Pattern recognition",
        "Turing test"
    ],
    "citation_count": "4,633",
    "reference_count": "20",
    "references": [
        "1836465849",
        "2183341477",
        "2963684088",
        "2964153729",
        "2271840356",
        "648143168",
        "2963685250",
        "2949416428",
        "830076066",
        "1487641199"
    ]
},{
    "id": "2963470893",
    "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
    "abstract": "Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.",
    "date": "2017",
    "authors": [
        "Christian Ledig",
        "Lucas Theis",
        "Ferenc Huszar",
        "Jose Caballero",
        "Andrew Cunningham",
        "Alejandro Acosta",
        "Andrew Aitken",
        "Alykhan Tejani",
        "Johannes Totz",
        "Zehan Wang",
        "Wenzhe Shi"
    ],
    "related_topics": [
        "Image texture",
        "Image resolution",
        "Convolutional neural network"
    ],
    "citation_count": "5,564",
    "reference_count": "68",
    "references": [
        "2194775991",
        "2618530766",
        "2962835968",
        "2964121744",
        "2097117768",
        "1836465849",
        "2117539524",
        "2099471712",
        "1677182931",
        "2133665775"
    ]
},{
    "id": "2618530766",
    "title": "ImageNet classification with deep convolutional neural networks",
    "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
    "date": "2017",
    "authors": [
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Dropout (neural networks)",
        "Overfitting"
    ],
    "citation_count": "165,784",
    "reference_count": "31",
    "references": [
        "2194775991",
        "2097117768",
        "2108598243",
        "2911964244",
        "3118608800",
        "1904365287",
        "1665214252",
        "2546302380",
        "2110764733",
        "2130325614"
    ]
},{
    "id": "2963341956",
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
    "date": "2018",
    "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina N. Toutanova"
    ],
    "related_topics": [
        "Question answering",
        "Language model",
        "Natural language understanding"
    ],
    "citation_count": "26,395",
    "reference_count": "52",
    "references": [
        "2963403868",
        "2153579005",
        "2250539671",
        "2108598243",
        "2962739339",
        "2131744502",
        "2251939518",
        "2963748441",
        "2117130368",
        "2025768430"
    ]
},{
    "id": "3118608800",
    "title": "Learning Multiple Layers of Features from Tiny Images",
    "abstract": "In this work we describe how to train a multi-layer generative model of natural images. We use a dataset of millions of tiny colour images, described in the next section. This has been attempted by several groups but without success. The models on which we focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These models learn interesting-looking filters, which we show are more useful to a classifier than the raw pixels. We train the classifier on a labeled subset that we have collected and call the CIFAR-10 dataset.",
    "date": "2008",
    "authors": [
        "Alex Krizhevsky"
    ],
    "related_topics": [
        "Deep belief network",
        "Generative model",
        "Boltzmann machine"
    ],
    "citation_count": "11,848",
    "reference_count": "3",
    "references": [
        "2096192494",
        "2081580037",
        "2165225968"
    ]
},{
    "id": "2963091558",
    "title": "Non-local Neural Networks",
    "abstract": "Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.",
    "date": "2018",
    "authors": [
        "Xiaolong Wang",
        "Ross Girshick",
        "Abhinav Gupta",
        "Kaiming He"
    ],
    "related_topics": [
        "Pose",
        "Object detection",
        "Image segmentation"
    ],
    "citation_count": "2,840",
    "reference_count": "53",
    "references": [
        "2194775991",
        "2962835968",
        "639708223",
        "2963403868",
        "1836465849",
        "2117539524",
        "1677182931",
        "2806070179",
        "1861492603",
        "2565639579"
    ]
},{
    "id": "3034978746",
    "title": "A Simple Framework for Contrastive Learning of Visual Representations",
    "abstract": "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels.",
    "date": "2020",
    "authors": [
        "Ting Chen",
        "Simon Kornblith",
        "Mohammad Norouzi",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Supervised learning",
        "Linear classifier",
        "Machine learning"
    ],
    "citation_count": "1,354",
    "reference_count": "0",
    "references": []
},{
    "id": "2100495367",
    "title": "Reducing the Dimensionality of Data with Neural Networks",
    "abstract": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \"autoencoder\" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.",
    "date": "2006",
    "authors": [
        "G. E. Hinton",
        "R. R. Salakhutdinov"
    ],
    "related_topics": [
        "Autoencoder",
        "Dimensionality reduction",
        "Restricted Boltzmann machine"
    ],
    "citation_count": "15,298",
    "reference_count": "7",
    "references": [
        "2136922672",
        "2053186076",
        "2001141328",
        "2293063825",
        "2121122425",
        "2032647857",
        "2021774695"
    ]
},{
    "id": "2187089797",
    "title": "Visualizing Data using t-SNE",
    "abstract": "We present a new technique called \u201ct-SNE\u201d that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.",
    "date": "2007",
    "authors": [
        "Laurens van der Maaten",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Sammon mapping",
        "t-distributed stochastic neighbor embedding",
        "Isomap"
    ],
    "citation_count": "20,095",
    "reference_count": "36",
    "references": [
        "2100495367",
        "2072128103",
        "2053186076",
        "2001141328",
        "2156718197",
        "2125637308",
        "2139823104",
        "2137570937",
        "2157444450",
        "1742512077"
    ]
},{
    "id": "1665214252",
    "title": "Rectified Linear Units Improve Restricted Boltzmann Machines",
    "abstract": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.",
    "date": "2010",
    "authors": [
        "Vinod Nair",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Binary number",
        "Sigmoid function"
    ],
    "citation_count": "13,478",
    "reference_count": "21",
    "references": [
        "2136922672",
        "2100495367",
        "2546302380",
        "2116064496",
        "1782590233",
        "2134557905",
        "2099866409",
        "1994197834",
        "2536626143",
        "2157364932"
    ]
},{
    "id": "2072128103",
    "title": "Learning Deep Architectures for AI",
    "abstract": "Can machine learning deliver AI? Theoretical results, inspiration from the brain and cognition, as well as machine learning experiments suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one would need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers, graphical models with many levels of latent variables, or in complicated propositional formulae re-using many sub-formulae. Each level of the architecture represents features at a different level of abstraction, defined as a composition of lower-level features. Searching the parameter space of deep architectures is a difficult task, but new algorithms have been discovered and a new sub-area has emerged in the machine learning community since 2006, following these discoveries. Learning algorithms such as those for Deep Belief Networks and other related unsupervised learning algorithms have recently been proposed to train deep architectures, yielding exciting results and beating the state-of-the-art in certain areas. Learning Deep Architectures for AI discusses the motivations for and principles of learning algorithms for deep architectures. By analyzing and comparing recent results with different learning algorithms for deep architectures, explanations for their success are proposed and discussed, highlighting challenges and suggesting avenues for future explorations in this area.",
    "date": "2008",
    "authors": [
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Deep belief network",
        "Unsupervised learning",
        "Instance-based learning"
    ],
    "citation_count": "9,705",
    "reference_count": "227",
    "references": [
        "2156909104",
        "2911964244",
        "2136922672",
        "2296616510",
        "2310919327",
        "2100495367",
        "2187089797",
        "2129131372",
        "2119821739",
        "2053186076"
    ]
},{
    "id": "2546302380",
    "title": "What is the best multi-stage architecture for object recognition?",
    "abstract": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%).",
    "date": "2009",
    "authors": [
        "Kevin Jarrett",
        "Koray Kavukcuoglu",
        "Marc'Aurelio Ranzato",
        "Yann LeCun"
    ],
    "related_topics": [
        "Feature extraction",
        "Feature (machine learning)",
        "Unsupervised learning"
    ],
    "citation_count": "2,425",
    "reference_count": "54",
    "references": [
        "2151103935",
        "2161969291",
        "2310919327",
        "2100495367",
        "2162915993",
        "2110798204",
        "2130325614",
        "2097018403",
        "2166049352",
        "2134557905"
    ]
},{
    "id": "2121863487",
    "title": "Reinforcement Learning: An Introduction",
    "abstract": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.",
    "date": "1987",
    "authors": [
        "R.S. Sutton",
        "A.G. Barto"
    ],
    "related_topics": [
        "Learning classifier system",
        "Reinforcement learning",
        "Apprenticeship learning"
    ],
    "citation_count": "44,042",
    "reference_count": "84",
    "references": [
        "1639032689",
        "2154642048",
        "3017143921",
        "2100677568",
        "1535810436",
        "1603765807",
        "3011120880",
        "1569320505",
        "94523489",
        "2178806388"
    ]
},{
    "id": "2952509347",
    "title": "The arcade learning environment: an evaluation platform for general agents",
    "abstract": "In this extended abstract we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by presenting a benchmark set of domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. We conclude with a brief update on the latest ALE developments. All of the software, including the benchmark agents, is publicly available.",
    "date": "2015",
    "authors": [
        "Marc G. Bellemare",
        "Yavar Naddaf",
        "Joel Veness",
        "Michael Bowling"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Learning environment",
        "Transfer of learning"
    ],
    "citation_count": "1,837",
    "reference_count": "26",
    "references": [
        "2145339207",
        "2952509347",
        "2126316555",
        "1515851193",
        "1625390266",
        "1502916507",
        "2099587183",
        "2013391942",
        "2101355568",
        "2132622533"
    ]
},{
    "id": "1652505363",
    "title": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations",
    "abstract": "The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system.",
    "date": "1986",
    "authors": [
        "David E. Rumelhart",
        "James L. McClelland"
    ],
    "related_topics": [
        "Competitive learning",
        "Connectionism",
        "Parallel processing (DSP implementation)"
    ],
    "citation_count": "24,210",
    "reference_count": "0",
    "references": []
},{
    "id": "1614298861",
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.",
    "date": "2013",
    "authors": [
        "Tomas Mikolov",
        "Kai Chen",
        "Greg S. Corrado",
        "Jeffrey Dean"
    ],
    "related_topics": [
        "Word2vec",
        "Word embedding",
        "Word (computer architecture)"
    ],
    "citation_count": "15,670",
    "reference_count": "0",
    "references": []
},{
    "id": "2141599568",
    "title": "Linguistic Regularities in Continuous Space Word Representations",
    "abstract": "Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, \u201cKing Man + Woman\u201d results in a vector very close to \u201cQueen.\u201d We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.",
    "date": "2013",
    "authors": [
        "Tomas Mikolov",
        "Wen-tau Yih",
        "Geoffrey Zweig"
    ],
    "related_topics": [
        "Syntax",
        "Language model",
        "Analogy"
    ],
    "citation_count": "3,564",
    "reference_count": "22",
    "references": [
        "1614298861",
        "2100495367",
        "2117130368",
        "179875071",
        "2132339004",
        "2158139315",
        "2147152072",
        "1632114991",
        "2131462252",
        "1970689298"
    ]
},{
    "id": "2117130368",
    "title": "A unified architecture for natural language processing: deep neural networks with multitask learning",
    "abstract": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.",
    "date": "2008",
    "authors": [
        "Ronan Collobert",
        "Jason Weston"
    ],
    "related_topics": [
        "Multi-task learning",
        "Semi-supervised learning",
        "Language identification"
    ],
    "citation_count": "5,697",
    "reference_count": "24",
    "references": [
        "2310919327",
        "2132339004",
        "2130903752",
        "2158847908",
        "2107008379",
        "2914746235",
        "2173629880",
        "2885050925",
        "2158823144",
        "2163568299"
    ]
},{
    "id": "2132339004",
    "title": "A neural probabilistic language model",
    "abstract": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.",
    "date": "2003",
    "authors": [
        "Yoshua Bengio",
        "R\u00e9jean Ducharme",
        "Pascal Vincent",
        "Christian Janvin"
    ],
    "related_topics": [
        "Language model",
        "Cache language model",
        "Word embedding"
    ],
    "citation_count": "7,567",
    "reference_count": "33",
    "references": [
        "2038721957",
        "2116064496",
        "2147152072",
        "1631260214",
        "2096175520",
        "2110485445",
        "1575350781",
        "2158195707",
        "2121227244",
        "2914484425"
    ]
},{
    "id": "2158139315",
    "title": "Word Representations: A Simple and General Method for Semi-Supervised Learning",
    "abstract": "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/",
    "date": "2010",
    "authors": [
        "Joseph Turian",
        "Lev-Arie Ratinov",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Word (computer architecture)",
        "Semi-supervised learning",
        "Chunking (psychology)"
    ],
    "citation_count": "2,492",
    "reference_count": "47",
    "references": [
        "1880262756",
        "2117130368",
        "2132339004",
        "1662133657",
        "168564468",
        "2131462252",
        "2296073425",
        "2158997610",
        "2004763266",
        "2156515921"
    ]
},{
    "id": "1423339008",
    "title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks",
    "abstract": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%.",
    "date": "2011",
    "authors": [
        "Richard Socher",
        "Cliff C. Lin",
        "Chris Manning",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Parsing",
        "Parse tree",
        "Treebank"
    ],
    "citation_count": "1,478",
    "reference_count": "25",
    "references": [
        "2100495367",
        "2162915993",
        "2067191022",
        "2117130368",
        "2132339004",
        "2130325614",
        "1574901103",
        "1566135517",
        "1528789833",
        "2536208356"
    ]
},{
    "id": "1498436455",
    "title": "Learning representations by back-propagating errors",
    "abstract": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.",
    "date": "1987",
    "authors": [
        "David E. Rumelhart",
        "Geoffrey E. Hinton",
        "Ronald J. Williams"
    ],
    "related_topics": [
        "Domain (software engineering)",
        "Task (project management)",
        "Measure (mathematics)"
    ],
    "citation_count": "23,793",
    "reference_count": "2",
    "references": [
        "1652505363",
        "2322002063"
    ]
},{
    "id": "1662133657",
    "title": "From frequency to meaning: vector space models of semantics",
    "abstract": "Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.",
    "date": "2009",
    "authors": [
        "Peter D. Turney",
        "Patrick Pantel"
    ],
    "related_topics": [
        "Statistical semantics",
        "Distributional semantics",
        "Semantics"
    ],
    "citation_count": "3,199",
    "reference_count": "178",
    "references": [
        "2173213060",
        "1880262756",
        "1532325895",
        "3013264884",
        "2038721957",
        "2117130368",
        "2024165284",
        "1660390307",
        "2166706824",
        "1992419399"
    ]
},{
    "id": "1889268436",
    "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces",
    "abstract": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.",
    "date": "2012",
    "authors": [
        "Richard Socher",
        "Brody Huval",
        "Christopher D. Manning",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Parse tree",
        "Principle of compositionality",
        "Natural language"
    ],
    "citation_count": "1,444",
    "reference_count": "39",
    "references": [
        "2251939518",
        "2117130368",
        "1423339008",
        "71795751",
        "1662133657",
        "2097606805",
        "2103305545",
        "2163455955",
        "1984052055",
        "2151048449"
    ]
},{
    "id": "2131462252",
    "title": "A Scalable Hierarchical Distributed Language Model",
    "abstract": "Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the non-hierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models.",
    "date": "2008",
    "authors": [
        "Andriy Mnih",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Cache language model",
        "Language model",
        "Binary tree"
    ],
    "citation_count": "1,130",
    "reference_count": "12",
    "references": [
        "2038721957",
        "2132339004",
        "36903255",
        "2091812280",
        "2158195707",
        "2121227244",
        "2127314673",
        "2056590938",
        "2111305191",
        "1558797106"
    ]
},{
    "id": "2097117768",
    "title": "Going deeper with convolutions",
    "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.",
    "date": "2015",
    "authors": [
        "Christian Szegedy",
        "Wei Liu",
        "Yangqing Jia",
        "Pierre Sermanet",
        "Scott Reed",
        "Dragomir Anguelov",
        "Dumitru Erhan",
        "Vincent Vanhoucke",
        "Andrew Rabinovich"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Artificial neural network",
        "Contextual image classification"
    ],
    "citation_count": "30,642",
    "reference_count": "21",
    "references": [
        "2618530766",
        "2102605133",
        "1849277567",
        "2963542991",
        "2310919327",
        "1904365287",
        "2963911037",
        "2168231600",
        "2068730032",
        "104184427"
    ]
},{
    "id": "639708223",
    "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
    "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features\u2014using the recently popular terminology of neural networks with \u2019attention\u2019 mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.",
    "date": "2017",
    "authors": [
        "Shaoqing Ren",
        "Kaiming He",
        "Ross Girshick",
        "Jian Sun"
    ],
    "related_topics": [
        "Object detection",
        "Convolutional neural network",
        "Deep learning"
    ],
    "citation_count": "27,093",
    "reference_count": "39",
    "references": [
        "2194775991",
        "2618530766",
        "2962835968",
        "2097117768",
        "2102605133",
        "2117539524",
        "1903029394",
        "2155893237",
        "1536680647",
        "2168356304"
    ]
},{
    "id": "2102605133",
    "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
    "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
    "date": "2014",
    "authors": [
        "Ross Girshick",
        "Jeff Donahue",
        "Trevor Darrell",
        "Jitendra Malik"
    ],
    "related_topics": [
        "Object detection",
        "Feature (computer vision)",
        "Convolutional neural network"
    ],
    "citation_count": "19,440",
    "reference_count": "46",
    "references": [
        "2618530766",
        "2151103935",
        "2108598243",
        "2161969291",
        "2168356304",
        "3118608800",
        "2310919327",
        "2031489346",
        "2088049833",
        "2155541015"
    ]
},{
    "id": "1903029394",
    "title": "Fully convolutional networks for semantic segmentation",
    "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
    "date": "2015",
    "authors": [
        "Jonathan Long",
        "Evan Shelhamer",
        "Trevor Darrell"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Segmentation",
        "Inference"
    ],
    "citation_count": "23,063",
    "reference_count": "42",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "2102605133",
        "2155893237",
        "1663973292",
        "1849277567",
        "2963542991",
        "2109255472",
        "2155541015"
    ]
},{
    "id": "2155893237",
    "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
    "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
    "date": "2014",
    "authors": [
        "Yangqing Jia",
        "Evan Shelhamer",
        "Jeff Donahue",
        "Sergey Karayev",
        "Jonathan Long",
        "Ross Girshick",
        "Sergio Guadarrama",
        "Trevor Darrell"
    ],
    "related_topics": [
        "Deep learning",
        "Theano",
        "CUDA"
    ],
    "citation_count": "14,849",
    "reference_count": "10",
    "references": [
        "2618530766",
        "2102605133",
        "2963542991",
        "2088049833",
        "2155541015",
        "753012316",
        "1825604117",
        "2147414309",
        "1872489089",
        "2962883796"
    ]
},{
    "id": "1536680647",
    "title": "Fast R-CNN",
    "abstract": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.",
    "date": "2015",
    "authors": [
        "Ross Girshick"
    ],
    "related_topics": [
        "Object detection",
        "Python (programming language)",
        "Pascal (programming language)"
    ],
    "citation_count": "14,299",
    "reference_count": "25",
    "references": [
        "2618530766",
        "2962835968",
        "2102605133",
        "2108598243",
        "2155893237",
        "2168356304",
        "1861492603",
        "2963542991",
        "2109255472",
        "2164598857"
    ]
},{
    "id": "2095705004",
    "title": "Dropout: a simple way to prevent neural networks from overfitting",
    "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.",
    "date": "2013",
    "authors": [
        "Nitish Srivastava",
        "Geoffrey Hinton",
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Ruslan Salakhutdinov"
    ],
    "related_topics": [
        "Overfitting",
        "Deep learning",
        "Convolutional neural network"
    ],
    "citation_count": "28,363",
    "reference_count": "36",
    "references": [
        "2618530766",
        "2136922672",
        "3118608800",
        "2100495367",
        "2135046866",
        "2546302380",
        "2025768430",
        "2145094598",
        "2131241448",
        "2335728318"
    ]
},{
    "id": "2146502635",
    "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization",
    "abstract": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.",
    "date": "2011",
    "authors": [
        "John Duchi",
        "Elad Hazan",
        "Yoram Singer"
    ],
    "related_topics": [
        "Subgradient method",
        "Online machine learning",
        "Empirical risk minimization"
    ],
    "citation_count": "8,784",
    "reference_count": "48",
    "references": [
        "2296319761",
        "2108598243",
        "3120740533",
        "2798766386",
        "2610857016",
        "2150102617",
        "2167732364",
        "1992208280",
        "2160218441",
        "1978394996"
    ]
},{
    "id": "2168231600",
    "title": "Large Scale Distributed Deep Networks",
    "abstract": "Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.",
    "date": "2012",
    "authors": [
        "Jeffrey Dean",
        "Greg Corrado",
        "Rajat Monga",
        "Kai Chen",
        "Matthieu Devin",
        "Mark Mao",
        "Marc'aurelio Ranzato",
        "Andrew Senior",
        "Paul Tucker",
        "Ke Yang",
        "Quoc V. Le",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Deep learning",
        "Artificial neural network",
        "Feature learning"
    ],
    "citation_count": "3,316",
    "reference_count": "33",
    "references": [
        "2108598243",
        "2173213060",
        "3118608800",
        "2146502635",
        "2117130368",
        "2147768505",
        "2132339004",
        "2141125852",
        "2184045248",
        "2118858186"
    ]
},{
    "id": "104184427",
    "title": "On the importance of initialization and momentum in deep learning",
    "abstract": "Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.",
    "date": "2013",
    "authors": [
        "Ilya Sutskever",
        "James Martens",
        "George Dahl",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Initialization",
        "Stochastic gradient descent",
        "Recurrent neural network"
    ],
    "citation_count": "3,585",
    "reference_count": "28",
    "references": [
        "2618530766",
        "2136922672",
        "2100495367",
        "2064675550",
        "1533861849",
        "2147768505",
        "2110798204",
        "1993882792",
        "3141595720",
        "2184045248"
    ]
},{
    "id": "6908809",
    "title": "ADADELTA: An Adaptive Learning Rate Method",
    "abstract": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.",
    "date": "2012",
    "authors": [
        "Matthew D. Zeiler"
    ],
    "related_topics": [
        "Stochastic gradient descent",
        "Gradient descent",
        "Online machine learning"
    ],
    "citation_count": "6,485",
    "reference_count": "6",
    "references": [
        "2168231600",
        "2147768505",
        "1498436455",
        "2120420045",
        "19621276",
        "1994616650"
    ]
},{
    "id": "1753482797",
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "date": "2013",
    "authors": [
        "Nal Kalchbrenner",
        "Phil Blunsom"
    ],
    "related_topics": [
        "Rule-based machine translation",
        "Transfer-based machine translation",
        "Dynamic and formal equivalence"
    ],
    "citation_count": "1,269",
    "reference_count": "18",
    "references": [
        "2146502635",
        "2117130368",
        "179875071",
        "2132339004",
        "1889268436",
        "2171928131",
        "2251222643",
        "2103305545",
        "2006969979",
        "196214544"
    ]
},{
    "id": "2294059674",
    "title": "Maxout Networks",
    "abstract": "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",
    "date": "2013",
    "authors": [
        "Ian Goodfellow",
        "David Warde-Farley",
        "Mehdi Mirza",
        "Aaron Courville",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "MNIST database",
        "Leverage (statistics)",
        "Machine learning"
    ],
    "citation_count": "2,215",
    "reference_count": "23",
    "references": [
        "2618530766",
        "3118608800",
        "2310919327",
        "1904365287",
        "2546302380",
        "2912934387",
        "2131241448",
        "2335728318",
        "2156387975",
        "189596042"
    ]
},{
    "id": "1810943226",
    "title": "Generating Sequences With Recurrent Neural Networks",
    "abstract": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.",
    "date": "2013",
    "authors": [
        "Alex Graves"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Handwriting",
        "Sequence"
    ],
    "citation_count": "3,285",
    "reference_count": "30",
    "references": [
        "2064675550",
        "1554663460",
        "2143612262",
        "44815768",
        "1632114991",
        "2131462252",
        "196214544",
        "2108677974",
        "2120861206",
        "3023071679"
    ]
},{
    "id": "2964199361",
    "title": "On the Properties of Neural Machine Translation: Encoder--Decoder Approaches",
    "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder\u2010Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",
    "date": "2014",
    "authors": [
        "Kyunghyun Cho",
        "Bart van Merrienboer",
        "Dzmitry Bahdanau",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Machine translation",
        "Convolutional neural network",
        "Artificial neural network"
    ],
    "citation_count": "3,605",
    "reference_count": "11",
    "references": [
        "2130942839",
        "2157331557",
        "6908809",
        "1753482797",
        "1810943226",
        "2153653739",
        "2395935897",
        "1828163288",
        "1905522558",
        "2341457423"
    ]
},{
    "id": "1815076433",
    "title": "On the difficulty of training recurrent neural networks",
    "abstract": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.",
    "date": "2013",
    "authors": [
        "Razvan Pascanu",
        "Tomas Mikolov",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Dynamical systems theory",
        "Artificial intelligence"
    ],
    "citation_count": "3,975",
    "reference_count": "23",
    "references": [
        "2146502635",
        "2064675550",
        "1498436455",
        "1606347560",
        "196214544",
        "2110485445",
        "2171865010",
        "2122585011",
        "2118706537",
        "2107878631"
    ]
},{
    "id": "2153653739",
    "title": "Statistical phrase-based translation",
    "abstract": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models out-perform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems.",
    "date": "2003",
    "authors": [
        "Philipp Koehn",
        "Franz Josef Och",
        "Daniel Marcu"
    ],
    "related_topics": [
        "Noun phrase",
        "Phrase",
        "Determiner phrase"
    ],
    "citation_count": "3,415",
    "reference_count": "15",
    "references": [
        "2101105183",
        "2006969979",
        "1508165687",
        "1973923101",
        "1986543644",
        "2116316001",
        "1517947178",
        "2161792612",
        "1549285799",
        "2158388102"
    ]
},{
    "id": "2183341477",
    "title": "Rethinking the Inception Architecture for Computer Vision",
    "abstract": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.",
    "date": "2016",
    "authors": [
        "Christian Szegedy",
        "Vincent Vanhoucke",
        "Sergey Ioffe",
        "Jon Shlens",
        "Zbigniew Wojna"
    ],
    "related_topics": [
        "Test set",
        "Set (abstract data type)",
        "Machine learning"
    ],
    "citation_count": "13,450",
    "reference_count": "20",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "1836465849",
        "2102605133",
        "2117539524",
        "1903029394",
        "1677182931",
        "2096733369",
        "2016053056"
    ]
},{
    "id": "2147768505",
    "title": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition",
    "abstract": "We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.",
    "date": "2011",
    "authors": [
        "G. E. Dahl",
        "Dong Yu",
        "Li Deng",
        "A. Acero"
    ],
    "related_topics": [
        "Deep belief network",
        "Hidden Markov model",
        "Word error rate"
    ],
    "citation_count": "3,161",
    "reference_count": "84",
    "references": [
        "2136922672",
        "2100495367",
        "1533861849",
        "2072128103",
        "2546302380",
        "2116064496",
        "2117130368",
        "2025768430",
        "1993882792",
        "1498436455"
    ]
},{
    "id": "2156387975",
    "title": "Deep Sparse Rectifier Neural Networks",
    "abstract": "While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-dierentiabil ity",
    "date": "2011",
    "authors": [
        "Xavier Glorot",
        "Antoine Bordes",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Rectifier (neural networks)",
        "Winner-take-all",
        "Artificial neural network"
    ],
    "citation_count": "6,910",
    "reference_count": "36",
    "references": [
        "2136922672",
        "3118608800",
        "2310919327",
        "1665214252",
        "1533861849",
        "2072128103",
        "2129131372",
        "2546302380",
        "2097726431",
        "2025768430"
    ]
},{
    "id": "2963504252",
    "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
    "abstract": "Abstract: Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.",
    "date": "2013",
    "authors": [
        "Andrew M. Saxe",
        "James L. McClelland",
        "Surya Ganguli"
    ],
    "related_topics": [
        "Artificial neural network",
        "Deep learning",
        "Nonlinear system"
    ],
    "citation_count": "984",
    "reference_count": "22",
    "references": [
        "2618530766",
        "2100495367",
        "1533861849",
        "2072128103",
        "2117130368",
        "104184427",
        "2110798204",
        "2141125852",
        "1993882792",
        "1815076433"
    ]
},{
    "id": "2136922672",
    "title": "A fast learning algorithm for deep belief nets",
    "abstract": "We show how to use \"complementary priors\" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.",
    "date": "2006",
    "authors": [
        "Geoffrey E. Hinton",
        "Simon Osindero",
        "Yee-Whye Teh"
    ],
    "related_topics": [
        "Deep belief network",
        "Convolutional Deep Belief Networks",
        "Generative model"
    ],
    "citation_count": "15,667",
    "reference_count": "30",
    "references": [
        "2310919327",
        "2116064496",
        "2057175746",
        "2159080219",
        "2156163116",
        "2131686571",
        "2158778629",
        "2567948266",
        "2159737176",
        "2124914669"
    ]
},{
    "id": "2025768430",
    "title": "Extracting and composing robust features with denoising autoencoders",
    "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.",
    "date": "2008",
    "authors": [
        "Pascal Vincent",
        "Hugo Larochelle",
        "Yoshua Bengio",
        "Pierre-Antoine Manzagol"
    ],
    "related_topics": [
        "Deep belief network",
        "Unsupervised learning",
        "Generative model"
    ],
    "citation_count": "5,631",
    "reference_count": "23",
    "references": [
        "2136922672",
        "2100495367",
        "2072128103",
        "2110798204",
        "2153663612",
        "1652505363",
        "1498436455",
        "1994197834",
        "2293063825",
        "2172174689"
    ]
},{
    "id": "2110798204",
    "title": "Greedy Layer-Wise Training of Deep Networks",
    "abstract": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.",
    "date": "2006",
    "authors": [
        "Yoshua Bengio",
        "Pascal Lamblin",
        "Dan Popovici",
        "Hugo Larochelle"
    ],
    "related_topics": [
        "Deep belief network",
        "Convolutional Deep Belief Networks",
        "Deep learning"
    ],
    "citation_count": "5,516",
    "reference_count": "16",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2613634265",
        "2124914669",
        "1993845689",
        "2109779438",
        "2103626435",
        "2125569215",
        "2167967601"
    ]
},{
    "id": "1994197834",
    "title": "An empirical evaluation of deep architectures on problems with many factors of variation",
    "abstract": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks.",
    "date": "2007",
    "authors": [
        "Hugo Larochelle",
        "Dumitru Erhan",
        "Aaron Courville",
        "James Bergstra",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Online machine learning",
        "Instance-based learning",
        "Computational learning theory"
    ],
    "citation_count": "1,060",
    "reference_count": "13",
    "references": [
        "2153635508",
        "2136922672",
        "2100495367",
        "2116064496",
        "2110798204",
        "2134557905",
        "2147800946",
        "2613634265",
        "2159737176",
        "2124914669"
    ]
},{
    "id": "2172174689",
    "title": "Efficient Learning of Sparse Representations with an Energy-Based Model",
    "abstract": "We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces \"stroke detectors\" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.",
    "date": "2006",
    "authors": [
        "Marc'aurelio Ranzato",
        "Christopher Poultney",
        "Sumit Chopra",
        "Yann L. Cun"
    ],
    "related_topics": [
        "Encoder",
        "Sparse approximation",
        "MNIST database"
    ],
    "citation_count": "1,541",
    "reference_count": "14",
    "references": [
        "2136922672",
        "2310919327",
        "2116064496",
        "1902027874",
        "2156163116",
        "2105464873",
        "1802356529",
        "2075187489",
        "2102409316",
        "11828546"
    ]
},{
    "id": "2166867592",
    "title": "Isolation of a Novel Coronavirus from a Man with Pneumonia in Saudi Arabia",
    "abstract": "A previously unknown coronavirus was isolated from the sputum of a 60-year-old man who presented with acute pneumonia and subsequent renal failure with a fatal outcome in Saudi Arabia. The virus (called HCoV-EMC) replicated readily in cell culture, producing cytopathic effects of rounding, detachment, and syncytium formation. The virus represents a novel betacoronavirus species. The closest known relatives are bat coronaviruses HKU4 and HKU5. Here, the clinical data, virus isolation, and molecular identification are presented. The clinical picture was remarkably similar to that of the severe acute respiratory syndrome (SARS) outbreak in 2003 and reminds us that animal coronaviruses can cause severe disease in humans.",
    "date": "2012",
    "authors": [
        "Ali Moh Zaki",
        "Sander Van Boheemen",
        "Theo M. Bestebroer",
        "Albert D.M.E. Osterhaus",
        "Ron A.M. Fouchier"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "4,493",
    "reference_count": "24",
    "references": [
        "2132260239",
        "2025170735",
        "2129542667",
        "1703839189",
        "2116586125",
        "1987783718",
        "2111412754",
        "1963953102",
        "2170933940",
        "2126707939"
    ]
},{
    "id": "3000413850",
    "title": "Comparative therapeutic efficacy of remdesivir and combination lopinavir, ritonavir, and interferon beta against MERS-CoV.",
    "abstract": "Middle East respiratory syndrome coronavirus (MERS-CoV) is the causative agent of a severe respiratory disease associated with more than 2468 human infections and over 851 deaths in 27 countries since 2012. There are no approved treatments for MERS-CoV infection although a combination of lopinavir, ritonavir and interferon beta (LPV/RTV-IFNb) is currently being evaluated in humans in the Kingdom of Saudi Arabia. Here, we show that remdesivir (RDV) and IFNb have superior antiviral activity to LPV and RTV in vitro. In mice, both prophylactic and therapeutic RDV improve pulmonary function and reduce lung viral loads and severe lung pathology. In contrast, prophylactic LPV/RTV-IFNb slightly reduces viral loads without impacting other disease parameters. Therapeutic LPV/RTV-IFNb improves pulmonary function but does not reduce virus replication or severe lung pathology. Thus, we provide in vivo evidence of the potential for RDV to treat MERS-CoV infections.",
    "date": "2020",
    "authors": [
        "Timothy P. Sheahan",
        "Amy C. Sims",
        "Sarah R. Leist",
        "Alexandra Sch\u00e4fer",
        "John Won",
        "Ariane J. Brown",
        "Stephanie A. Montgomery",
        "Alison Hogg",
        "Darius Babusis",
        "Michael O. Clarke",
        "Jamie E. Spahn",
        "Laura Bauer",
        "Scott Sellers",
        "Danielle Porter",
        "Joy Y. Feng",
        "Tomas Cihlar",
        "Robert Jordan",
        "Mark R. Denison",
        "Ralph S. Baric"
    ],
    "related_topics": [
        "Lopinavir/ritonavir",
        "Lopinavir",
        "Lung injury"
    ],
    "citation_count": "1,327",
    "reference_count": "53",
    "references": [
        "2107277218",
        "2470646526",
        "2725497285",
        "1993577573",
        "2565805236",
        "2791599184",
        "2255243349",
        "2292021561",
        "2290466312",
        "2793022939"
    ]
},{
    "id": "2132260239",
    "title": "Identification of a novel coronavirus in patients with severe acute respiratory syndrome.",
    "abstract": "BACKGROUND: The severe acute respiratory syndrome (SARS) has recently been identified as a new clinical entity. SARS is thought to be caused by an unknown infectious agent. METHODS: Clinical specimens from patients with SARS were searched for unknown viruses with the use of cell cultures and molecular techniques. RESULTS: A novel coronavirus was identified in patients with SARS. The virus was isolated in cell culture, and a sequence 300 nucleotides in length was obtained by a polymerase-chain-reaction (PCR)-based random-amplification procedure. Genetic characterization indicated that the virus is only distantly related to known coronaviruses (identical in 50 to 60 percent of the nucleotide sequence). On the basis of the obtained sequence, conventional and real-time PCR assays for specific and sensitive detection of the novel virus were established. Virus was detected in a variety of clinical specimens from patients with SARS but not in controls. High concentrations of viral RNA of up to 100 million molecules per milliliter were found in sputum. Viral RNA was also detected at extremely low concentrations in plasma during the acute phase and in feces during the late convalescent phase. Infected patients showed seroconversion on the Vero cells in which the virus was isolated. CONCLUSIONS: The novel coronavirus might have a role in causing SARS.",
    "date": "2003",
    "authors": [
        "Christian Drosten",
        "Stephan G\u00fcnther",
        "Wolfgang Preiser",
        "Sylvie van der Werf",
        "Hans-Reinhard Brodt",
        "Stephan Becker",
        "Holger Rabenau",
        "Marcus Panning",
        "Larissa Kolesnikova",
        "Ron A.M. Fouchier",
        "Annemarie Berger",
        "Ana-Maria Burgui\u00e8re",
        "Jindrich Cinatl",
        "Markus Eickmann",
        "Nicolas Escriou",
        "Klaus Grywna",
        "Stefanie Kramme",
        "Jean-Claude Manuguerra",
        "Stefanie M\u00fcller",
        "Volker Rickerts",
        "Martin St\u00fcrmer",
        "Simon Vieth",
        "Hans-Dieter Klenk",
        "Albert D.M.E. Osterhaus",
        "Herbert Schmitz",
        "Hans Wilhelm Doerr"
    ],
    "related_topics": [
        "Coronavirus",
        "Severe acute respiratory syndrome",
        "Human coronavirus OC43"
    ],
    "citation_count": "5,038",
    "reference_count": "9",
    "references": [
        "2100820722",
        "2125251240",
        "2107922358",
        "2127062009",
        "2084994773",
        "2149579937",
        "2090060897",
        "2004869546",
        "2030133843"
    ]
},{
    "id": "2026274122",
    "title": "KDIGO clinical practice guidelines for acute kidney injury.",
    "abstract": "tion\u2019, implying that most patients \u2018should\u2019 receive a particular action. In contrast, level 2 guidelines are essentially \u2018suggestions\u2019 and are deemed to be \u2018weak\u2019 or discretionary, recognising that management decisions may vary in different clinical contexts. Each recommendation was further graded from A to D by the quality of evidence underpinning them, with grade A referring to a high quality of evidence whilst grade D recognised a \u2018very low\u2019 evidence base. The overall strength and quality of the supporting evidence is summarised in table 1 . The guidelines focused on 4 key domains: (1) AKI definition, (2) prevention and treatment of AKI, (3) contrastinduced AKI (CI-AKI) and (4) dialysis interventions for the treatment of AKI. The full summary of clinical practice statements is available at www.kdigo.org, but a few key recommendation statements will be highlighted here.",
    "date": "2012",
    "authors": [
        "Arif Khwaja"
    ],
    "related_topics": [
        "Renal angina",
        "Psychological intervention",
        "Intensive care medicine"
    ],
    "citation_count": "5,067",
    "reference_count": "23",
    "references": [
        "1967300023",
        "2131419242",
        "2143432233",
        "2117958746",
        "1531106656",
        "2157775267",
        "2028701043",
        "2111704803",
        "2135163018",
        "2042074736"
    ]
},{
    "id": "2104548316",
    "title": "A novel coronavirus associated with severe acute respiratory syndrome.",
    "abstract": "background A worldwide outbreak of severe acute respiratory syndrome (SARS) has been associated with exposures originating from a single ill health care worker from Guangdong Province, China. We conducted studies to identify the etiologic agent of this outbreak. methods We received clinical specimens from patients in six countries and tested them, using virus isolation techniques, electron-microscopical and histologic studies, and molecular and serologic assays, in an attempt to identify a wide range of potential pathogens. results No classic respiratory or bacterial respiratory pathogen was consistently identified. However, a novel coronavirus was isolated from patients who met the case definition of SARS. Cytopathological features were noted microscopically in Vero E6 cells inoculated with a throat-swab specimen. Electron-microscopical examination of cultures revealed ultrastructural features characteristic of coronaviruses. Immunohistochemical and immunofluorescence staining revealed reactivity with group I coronavirus polyclonal antibodies. Consensus coronavirus primers designed to amplify a fragment of the polymerase gene by reverse transcription\u2013polymerase chain reaction (RT-PCR) were used to obtain a sequence that clearly identified the isolate as a unique coronavirus only distantly related to previously sequenced coronaviruses. With specific diagnostic RT-PCR primers we identified several identical nucleotide sequences in 12 patients from several locations, a finding consistent with a point source outbreak. Indirect fluorescent antibody tests and enzyme-linked immunosorbent assays made with the new coronavirus isolate have been used to demonstrate a virus-specific serologic response. Preliminary studies suggest that this virus may never before have infected the U.S. population. conclusions A novel coronavirus is associated with this outbreak, and the evidence indicates that this virus has an etiologic role in SARS. The name Urbani SARS-associated coronavirus is proposed for the virus.",
    "date": "2003",
    "authors": [
        "Ksiazek Tg",
        "Erdman D",
        "Goldsmith Cs",
        "Zaki",
        "Peret T",
        "Emery S",
        "Tong S",
        "Urbani C",
        "Comer Ja",
        "Lim W",
        "Rollin Pe",
        "Dowell Sf",
        "Ling Ae",
        "Humphrey Cd",
        "Shieh Wj",
        "Guarner J",
        "Paddock Cd",
        "Rota P",
        "Fields B",
        "DeRisi J",
        "Yang Jy",
        "Cox N",
        "Hughes Jm",
        "LeDuc Jw",
        "Bellini Wj",
        "Anderson Lj"
    ],
    "related_topics": [
        "Human coronavirus OC43",
        "Coronavirus",
        "Human coronavirus 229E"
    ],
    "citation_count": "5,166",
    "reference_count": "31",
    "references": [
        "2106882534",
        "2131262274",
        "2100820722",
        "2125251240",
        "2463755683",
        "2398786667",
        "2127949919",
        "1576737979",
        "2128788856",
        "2076620790"
    ]
},{
    "id": "2006434809",
    "title": "Epidemiological, demographic, and clinical characteristics of 47 cases of Middle East respiratory syndrome coronavirus disease from Saudi Arabia: a descriptive study",
    "abstract": "Summary Background Middle East respiratory syndrome (MERS) is a new human disease caused by a novel coronavirus (CoV). Clinical data on MERS-CoV infections are scarce. We report epidemiological, demographic, clinical, and laboratory characteristics of 47 cases of MERS-CoV infections, identify knowledge gaps, and define research priorities. Methods We abstracted and analysed epidemiological, demographic, clinical, and laboratory data from confirmed cases of sporadic, household, community, and health-care-associated MERS-CoV infections reported from Saudi Arabia between Sept 1, 2012, and June 15, 2013. Cases were confirmed as having MERS-CoV by real-time RT-PCR. Findings 47 individuals (46 adults, one child) with laboratory-confirmed MERS-CoV disease were identified; 36 (77%) were male (male:female ratio 3\u00b73:1). 28 patients died, a 60% case-fatality rate. The case-fatality rate rose with increasing age. Only two of the 47 cases were previously healthy; most patients (45 [96%]) had underlying comorbid medical disorders, including diabetes (32 [68%]), hypertension (16 [34%]), chronic cardiac disease (13 [28%]), and chronic renal disease (23 [49%]). Common symptoms at presentation were fever (46 [98%]), fever with chills or rigors (41 [87%]), cough (39 [83%]), shortness of breath (34 [72%]), and myalgia (15 [32%]). Gastrointestinal symptoms were also frequent, including diarrhoea (12 [26%]), vomiting (ten [21%]), and abdominal pain (eight [17%]). All patients had abnormal findings on chest radiography, ranging from subtle to extensive unilateral and bilateral abnormalities. Laboratory analyses showed raised concentrations of lactate dehydrogenase (23 [49%]) and aspartate aminotransferase (seven [15%]) and thrombocytopenia (17 [36%]) and lymphopenia (16 [34%]). Interpretation Disease caused by MERS-CoV presents with a wide range of clinical manifestations and is associated with substantial mortality in admitted patients who have medical comorbidities. Major gaps in our knowledge of the epidemiology, community prevalence, and clinical spectrum of infection and disease need urgent definition. Funding None.",
    "date": "2013",
    "authors": [
        "Abdullah Assiri",
        "Jaffar A Al-Tawfiq",
        "Abdullah A Al-Rabeeah",
        "Fahad A Al-Rabiah",
        "Sami Al-Hajjar",
        "Ali Al-Barrak",
        "Hesham Flemban",
        "Wafa N Al-Nassir",
        "Hanan H Balkhy",
        "Rafat F Al-Hakeem",
        "Hatem Q Makhdoom",
        "Alimuddin I Zumla",
        "Ziad A Memish"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Epidemiology",
        "myalgia"
    ],
    "citation_count": "1,309",
    "reference_count": "31",
    "references": [
        "2166867592",
        "2107053896",
        "2131262274",
        "1703839189",
        "2112147913",
        "2045002682",
        "1852588318",
        "2163627712",
        "2140143765",
        "2119775949"
    ]
},{
    "id": "3017468735",
    "title": "A Novel Coronavirus Genome Identified in a Cluster of Pneumonia Cases \u2014 Wuhan, China 2019\u22122020",
    "abstract": "",
    "date": "2019",
    "authors": [
        "Wenjie Tan",
        "Xiang Zhao",
        "Xuejun Ma",
        "Wenling Wang",
        "Peihua Niu",
        "Wenbo Xu",
        "George F. Gao",
        "Guizhen Wu"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Disease cluster"
    ],
    "citation_count": "368",
    "reference_count": "0",
    "references": []
},{
    "id": "2725497285",
    "title": "Broad-spectrum antiviral GS-5734 inhibits both epidemic and zoonotic coronaviruses.",
    "abstract": "Emerging viral infections are difficult to control because heterogeneous members periodically cycle in and out of humans and zoonotic hosts, complicating the development of specific antiviral therapies and vaccines. Coronaviruses (CoVs) have a proclivity to spread rapidly into new host species causing severe disease. Severe acute respiratory syndrome CoV (SARS-CoV) and Middle East respiratory syndrome CoV (MERS-CoV) successively emerged, causing severe epidemic respiratory disease in immunologically naive human populations throughout the globe. Broad-spectrum therapies capable of inhibiting CoV infections would address an immediate unmet medical need and could be invaluable in the treatment of emerging and endemic CoV infections. We show that a nucleotide prodrug, GS-5734, currently in clinical development for treatment of Ebola virus disease, can inhibit SARS-CoV and MERS-CoV replication in multiple in vitro systems, including primary human airway epithelial cell cultures with submicromolar IC50 values. GS-5734 was also effective against bat CoVs, prepandemic bat CoVs, and circulating contemporary human CoV in primary human lung cells, thus demonstrating broad-spectrum anti-CoV activity. In a mouse model of SARS-CoV pathogenesis, prophylactic and early therapeutic administration of GS-5734 significantly reduced lung viral load and improved clinical signs of disease as well as respiratory function. These data provide substantive evidence that GS-5734 may prove effective against endemic MERS-CoV in the Middle East, circulating human CoV, and, possibly most importantly, emerging CoV of the future.",
    "date": "2017",
    "authors": [
        "Timothy P. Sheahan",
        "Amy C. Sims",
        "Rachel L. Graham",
        "Vineet D. Menachery",
        "Lisa E. Gralinski",
        "James B. Case",
        "Sarah R. Leist",
        "Krzysztof Pyrc",
        "Joy Y. Feng",
        "Iva Trantcheva",
        "Roy Bannister",
        "Yeojin Park",
        "Darius Babusis",
        "Michael O. Clarke",
        "Richard L. Mackman",
        "Jamie E. Spahn",
        "Christopher A. Palmiotti",
        "Dustin Siegel",
        "Adrian S. Ray",
        "Tomas Cihlar",
        "Robert Jordan",
        "Mark R. Denison",
        "Ralph S. Baric"
    ],
    "related_topics": [
        "Respiratory function",
        "Middle East respiratory syndrome",
        "Coronavirus"
    ],
    "citation_count": "1,073",
    "reference_count": "34",
    "references": [
        "2470646526",
        "2129542667",
        "2195009776",
        "2255243349",
        "2292021561",
        "2115555188",
        "2298153446",
        "2525468044",
        "1945961678",
        "2099941783"
    ]
},{
    "id": "3001897055",
    "title": "A Novel Coronavirus from Patients with Pneumonia in China, 2019.",
    "abstract": "In December 2019, a cluster of patients with pneumonia of unknown cause was linked to a seafood wholesale market in Wuhan, China. A previously unknown betacoronavirus was discovered through the use of unbiased sequencing in samples from patients with pneumonia. Human airway epithelial cells were used to isolate a novel coronavirus, named 2019-nCoV, which formed a clade within the subgenus sarbecovirus, Orthocoronavirinae subfamily. Different from both MERS-CoV and SARS-CoV, 2019-nCoV is the seventh member of the family of coronaviruses that infect humans. Enhanced surveillance and further investigation are ongoing. (Funded by the National Key Research and Development Program of China and the National Major Project for Control and Prevention of Infectious Disease in China.).",
    "date": "2020",
    "authors": [
        "Na Zhu",
        "Dingyu Zhang",
        "Wenling Wang",
        "Xingwang Li",
        "Bo Yang",
        "Jingdong Song",
        "Xiang Zhao",
        "Baoying Huang",
        "Weifeng Shi",
        "Roujian Lu",
        "Peihua Niu",
        "Faxian Zhan",
        "Xuejun Ma",
        "Dayan Wang",
        "Wenbo Xu",
        "Guizhen Wu",
        "George F. Gao",
        "Wenjie Tan"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Infectious disease (medical specialty)"
    ],
    "citation_count": "15,031",
    "reference_count": "12",
    "references": [
        "2903899730",
        "2166867592",
        "2132260239",
        "2104548316",
        "2306794997",
        "1909499787",
        "3027518954",
        "2792024998",
        "2955025503",
        "2257005270"
    ]
},{
    "id": "3005079553",
    "title": "Clinical Characteristics of 138 Hospitalized Patients With 2019 Novel Coronavirus-Infected Pneumonia in Wuhan, China.",
    "abstract": "Importance In December 2019, novel coronavirus (2019-nCoV)\u2013infected pneumonia (NCIP) occurred in Wuhan, China. The number of cases has increased rapidly but information on the clinical characteristics of affected patients is limited. Objective To describe the epidemiological and clinical characteristics of NCIP. Design, Setting, and Participants Retrospective, single-center case series of the 138 consecutive hospitalized patients with confirmed NCIP at Zhongnan Hospital of Wuhan University in Wuhan, China, from January 1 to January 28, 2020; final date of follow-up was February 3, 2020. Exposures Documented NCIP. Main Outcomes and Measures Epidemiological, demographic, clinical, laboratory, radiological, and treatment data were collected and analyzed. Outcomes of critically ill patients and noncritically ill patients were compared. Presumed hospital-related transmission was suspected if a cluster of health professionals or hospitalized patients in the same wards became infected and a possible source of infection could be tracked. Results Of 138 hospitalized patients with NCIP, the median age was 56 years (interquartile range, 42-68; range, 22-92 years) and 75 (54.3%) were men. Hospital-associated transmission was suspected as the presumed mechanism of infection for affected health professionals (40 [29%]) and hospitalized patients (17 [12.3%]). Common symptoms included fever (136 [98.6%]), fatigue (96 [69.6%]), and dry cough (82 [59.4%]). Lymphopenia (lymphocyte count, 0.8\u2009\u00d7\u2009109/L [interquartile range {IQR}, 0.6-1.1]) occurred in 97 patients (70.3%), prolonged prothrombin time (13.0 seconds [IQR, 12.3-13.7]) in 80 patients (58%), and elevated lactate dehydrogenase (261 U/L [IQR, 182-403]) in 55 patients (39.9%). Chest computed tomographic scans showed bilateral patchy shadows or ground glass opacity in the lungs of all patients. Most patients received antiviral therapy (oseltamivir, 124 [89.9%]), and many received antibacterial therapy (moxifloxacin, 89 [64.4%]; ceftriaxone, 34 [24.6%]; azithromycin, 25 [18.1%]) and glucocorticoid therapy (62 [44.9%]). Thirty-six patients (26.1%) were transferred to the intensive care unit (ICU) because of complications, including acute respiratory distress syndrome (22 [61.1%]), arrhythmia (16 [44.4%]), and shock (11 [30.6%]). The median time from first symptom to dyspnea was 5.0 days, to hospital admission was 7.0 days, and to ARDS was 8.0 days. Patients treated in the ICU (n\u2009=\u200936), compared with patients not treated in the ICU (n\u2009=\u2009102), were older (median age, 66 years vs 51 years), were more likely to have underlying comorbidities (26 [72.2%] vs 38 [37.3%]), and were more likely to have dyspnea (23 [63.9%] vs 20 [19.6%]), and anorexia (24 [66.7%] vs 31 [30.4%]). Of the 36 cases in the ICU, 4 (11.1%) received high-flow oxygen therapy, 15 (41.7%) received noninvasive ventilation, and 17 (47.2%) received invasive ventilation (4 were switched to extracorporeal membrane oxygenation). As of February 3, 47 patients (34.1%) were discharged and 6 died (overall mortality, 4.3%), but the remaining patients are still hospitalized. Among those discharged alive (n\u2009=\u200947), the median hospital stay was 10 days (IQR, 7.0-14.0). Conclusions and Relevance In this single-center case series of 138 hospitalized patients with confirmed NCIP in Wuhan, China, presumed hospital-related transmission of 2019-nCoV was suspected in 41% of patients, 26% of patients received ICU care, and mortality was 4.3%.",
    "date": "2020",
    "authors": [
        "Dawei Wang",
        "Bo Hu",
        "Chang Hu",
        "Fangfang Zhu",
        "Xing Liu",
        "Jing Zhang",
        "Binbin Wang",
        "Hui Xiang",
        "Zhenshun Cheng",
        "Yong Xiong",
        "Yan Zhao",
        "Yirong Li",
        "Xinghuan Wang",
        "Zhiyong Peng"
    ],
    "related_topics": [
        "Interquartile range",
        "Intensive care unit",
        "Pneumonia"
    ],
    "citation_count": "15,854",
    "reference_count": "25",
    "references": [
        "3001118548",
        "3001897055",
        "3002108456",
        "3003668884",
        "3002539152",
        "3000834295",
        "3003951199",
        "2999409984",
        "2999318660",
        "1803784511"
    ]
},{
    "id": "3002108456",
    "title": "Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: a descriptive study",
    "abstract": "In December, 2019, a pneumonia associated with the 2019 novel coronavirus (2019-nCoV) emerged in Wuhan, China. We aimed to further clarify the epidemiological and clinical characteristics of 2019-nCoV pneumonia. In this retrospective, single-centre study, we included all confirmed cases of 2019-nCoV in Wuhan Jinyintan Hospital from Jan 1 to Jan 20, 2020. Cases were confirmed by real-time RT-PCR and were analysed for epidemiological, demographic, clinical, and radiological features and laboratory data. Outcomes were followed up until Jan 25, 2020.",
    "date": "2020",
    "authors": [
        "Nanshan Chen",
        "Min Zhou",
        "Xuan Dong",
        "Jieming Qu",
        "Fengyun Gong",
        "Yang Han",
        "Yang Qiu",
        "Jingli Wang",
        "Ying Liu",
        "Yuan Wei",
        "Jia'an Xia",
        "Ting Yu",
        "Xinxin Zhang",
        "Li Zhang"
    ],
    "related_topics": [
        "Pneumonia",
        "Epidemiology",
        "Coronavirus"
    ],
    "citation_count": "12,942",
    "reference_count": "28",
    "references": [
        "3001118548",
        "2903899730",
        "2166867592",
        "2999409984",
        "2999318660",
        "2132260239",
        "2999364275",
        "2909194930",
        "2991899552",
        "2775086803"
    ]
},{
    "id": "3003668884",
    "title": "Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus-Infected Pneumonia.",
    "abstract": "Abstract Background The initial cases of novel coronavirus (2019-nCoV)\u2013infected pneumonia (NCIP) occurred in Wuhan, Hubei Province, China, in December 2019 and January 2020. We analyzed data on the...",
    "date": "2020",
    "authors": [
        "Qun Li",
        "Xuhua Guan",
        "Peng Wu",
        "Xiaoye Wang",
        "Lei Zhou",
        "Yeqing Tong",
        "Ruiqi Ren",
        "Kathy S.M. Leung",
        "Eric H.Y. Lau",
        "Jessica Y. Wong",
        "Xuesen Xing",
        "Nijuan Xiang",
        "Yang Wu",
        "Chao Li",
        "Qi Chen",
        "Dan Li",
        "Tian Liu",
        "Jing Zhao",
        "Man Liu",
        "Wenxiao Tu",
        "Chuding Chen",
        "Lianmei Jin",
        "Rui Yang",
        "Qi Wang",
        "Suhua Zhou",
        "Rui Wang",
        "Hui Liu",
        "Yingbo Luo",
        "Yuan Liu",
        "Ge Shao",
        "Huan Li",
        "Zhongfa Tao",
        "Yang Yang",
        "Zhiqiang Deng",
        "Boxi Liu",
        "Zhitao Ma",
        "Yanping Zhang",
        "Guoqing Shi",
        "Tommy T.Y. Lam",
        "Joseph T. Wu",
        "George F. Gao",
        "Benjamin J. Cowling",
        "Bo Yang",
        "Gabriel M. Leung",
        "Zijian Feng"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Betacoronavirus"
    ],
    "citation_count": "11,678",
    "reference_count": "18",
    "references": [
        "3001897055",
        "3002539152",
        "3000834295",
        "3002533507",
        "2470646526",
        "3002715510",
        "1909499787",
        "3001971765",
        "2147166346",
        "2149508011"
    ]
},{
    "id": "3002539152",
    "title": "A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster.",
    "abstract": "Summary Background An ongoing outbreak of pneumonia associated with a novel coronavirus was reported in Wuhan city, Hubei province, China. Affected patients were geographically linked with a local wet market as a potential source. No data on person-to-person or nosocomial transmission have been published to date. Methods In this study, we report the epidemiological, clinical, laboratory, radiological, and microbiological findings of five patients in a family cluster who presented with unexplained pneumonia after returning to Shenzhen, Guangdong province, China, after a visit to Wuhan, and an additional family member who did not travel to Wuhan. Phylogenetic analysis of genetic sequences from these patients were done. Findings From Jan 10, 2020, we enrolled a family of six patients who travelled to Wuhan from Shenzhen between Dec 29, 2019 and Jan 4, 2020. Of six family members who travelled to Wuhan, five were identified as infected with the novel coronavirus. Additionally, one family member, who did not travel to Wuhan, became infected with the virus after several days of contact with four of the family members. None of the family members had contacts with Wuhan markets or animals, although two had visited a Wuhan hospital. Five family members (aged 36\u201366 years) presented with fever, upper or lower respiratory tract symptoms, or diarrhoea, or a combination of these 3\u20136 days after exposure. They presented to our hospital (The University of Hong Kong-Shenzhen Hospital, Shenzhen) 6\u201310 days after symptom onset. They and one asymptomatic child (aged 10 years) had radiological ground-glass lung opacities. Older patients (aged >60 years) had more systemic symptoms, extensive radiological ground-glass lung changes, lymphopenia, thrombocytopenia, and increased C-reactive protein and lactate dehydrogenase levels. The nasopharyngeal or throat swabs of these six patients were negative for known respiratory microbes by point-of-care multiplex RT-PCR, but five patients (four adults and the child) were RT-PCR positive for genes encoding the internal RNA-dependent RNA polymerase and surface Spike protein of this novel coronavirus, which were confirmed by Sanger sequencing. Phylogenetic analysis of these five patients' RT-PCR amplicons and two full genomes by next-generation sequencing showed that this is a novel coronavirus, which is closest to the bat severe acute respiatory syndrome (SARS)-related coronaviruses found in Chinese horseshoe bats. Interpretation Our findings are consistent with person-to-person transmission of this novel coronavirus in hospital and family settings, and the reports of infected travellers in other geographical regions. Funding The Shaw Foundation Hong Kong, Michael Seak-Kan Tong, Respiratory Viral Research Foundation Limited, Hui Ming, Hui Hoy and Chow Sin Lan Charity Fund Limited, Marina Man-Wai Lee, the Hong Kong Hainan Commercial Association South China Microbiology Research Fund, Sanming Project of Medicine (Shenzhen), and High Level-Hospital Program (Guangdong Health Commission).",
    "date": "2020",
    "authors": [
        "Jasper Fuk Woo Chan",
        "Shuofeng Yuan",
        "Kin Hang Kok",
        "Kelvin Kai Wang To",
        "Hin Chu",
        "Jin Yang",
        "Fanfan Xing",
        "Jieling Liu",
        "Cyril Chik Yan Yip",
        "Rosana Wing Shan Poon",
        "Hoi Wah Tsoi",
        "Simon Kam Fai Lo",
        "Kwok Hung Chan",
        "Vincent Kwok Man Poon",
        "Wan Mui Chan",
        "Jonathan Daniel Ip",
        "Jian Piao Cai",
        "Vincent Chi Chung Cheng",
        "Honglin Chen",
        "Christopher Kim Ming Hui",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Epidemiology"
    ],
    "citation_count": "6,856",
    "reference_count": "31",
    "references": [
        "2025170735",
        "2129542667",
        "2103503670",
        "2115555188",
        "2807736175",
        "2105637133",
        "2889758689",
        "2769543984",
        "2140338292",
        "2170933940"
    ]
},{
    "id": "3004318991",
    "title": "Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding.",
    "abstract": "Summary Background In late December, 2019, patients presenting with viral pneumonia due to an unidentified microbial agent were reported in Wuhan, China. A novel coronavirus was subsequently identified as the causative pathogen, provisionally named 2019 novel coronavirus (2019-nCoV). As of Jan 26, 2020, more than 2000 cases of 2019-nCoV infection have been confirmed, most of which involved people living in or visiting Wuhan, and human-to-human transmission has been confirmed. Methods We did next-generation sequencing of samples from bronchoalveolar lavage fluid and cultured isolates from nine inpatients, eight of whom had visited the Huanan seafood market in Wuhan. Complete and partial 2019-nCoV genome sequences were obtained from these individuals. Viral contigs were connected using Sanger sequencing to obtain the full-length genomes, with the terminal regions determined by rapid amplification of cDNA ends. Phylogenetic analysis of these 2019-nCoV genomes and those of other coronaviruses was used to determine the evolutionary history of the virus and help infer its likely origin. Homology modelling was done to explore the likely receptor-binding properties of the virus. Findings The ten genome sequences of 2019-nCoV obtained from the nine patients were extremely similar, exhibiting more than 99\u00b798% sequence identity. Notably, 2019-nCoV was closely related (with 88% identity) to two bat-derived severe acute respiratory syndrome (SARS)-like coronaviruses, bat-SL-CoVZC45 and bat-SL-CoVZXC21, collected in 2018 in Zhoushan, eastern China, but were more distant from SARS-CoV (about 79%) and MERS-CoV (about 50%). Phylogenetic analysis revealed that 2019-nCoV fell within the subgenus Sarbecovirus of the genus Betacoronavirus, with a relatively long branch length to its closest relatives bat-SL-CoVZC45 and bat-SL-CoVZXC21, and was genetically distinct from SARS-CoV. Notably, homology modelling revealed that 2019-nCoV had a similar receptor-binding domain structure to that of SARS-CoV, despite amino acid variation at some key residues. Interpretation 2019-nCoV is sufficiently divergent from SARS-CoV to be considered a new human-infecting betacoronavirus. Although our phylogenetic analysis suggests that bats might be the original host of this virus, an animal sold at the seafood market in Wuhan might represent an intermediate host facilitating the emergence of the virus in humans. Importantly, structural analysis suggests that 2019-nCoV might be able to bind to the angiotensin-converting enzyme 2 receptor in humans. The future evolution, adaptation, and spread of this virus warrant urgent investigation. Funding National Key Research and Development Program of China, National Major Project for Control and Prevention of Infectious Disease in China, Chinese Academy of Sciences, Shandong First Medical University.",
    "date": "2020",
    "authors": [
        "Roujian Lu",
        "Xiang Zhao",
        "Juan Li",
        "Peihua Niu",
        "Bo Yang",
        "Honglong Wu",
        "Wenling Wang",
        "Hao Song",
        "Baoying Huang",
        "Na Zhu",
        "Yuhai Bi",
        "Xuejun Ma",
        "Faxian Zhan",
        "Liang Wang",
        "Tao Hu",
        "Hong Zhou",
        "Zhenhong Hu",
        "Weimin Zhou",
        "Li Zhao",
        "Jing Chen",
        "Yao Meng",
        "Ji Wang",
        "Yang Lin",
        "Jianying Yuan",
        "Zhihao Xie",
        "Jinmin Ma",
        "William J Liu",
        "Dayan Wang",
        "Wenbo Xu",
        "Edward C Holmes",
        "George F Gao",
        "Guizhen Wu",
        "Weijun Chen",
        "Weifeng Shi",
        "Wenjie Tan"
    ],
    "related_topics": [
        "Betacoronavirus",
        "Coronavirus",
        "Phylogenetics"
    ],
    "citation_count": "7,668",
    "reference_count": "36",
    "references": [
        "3001118548",
        "3001897055",
        "3002539152",
        "3004280078",
        "2103441770",
        "2141052558",
        "2166867592",
        "2306794997",
        "3017468735",
        "2804822363"
    ]
},{
    "id": "3003465021",
    "title": "First Case of 2019 Novel Coronavirus in the United States.",
    "abstract": "An outbreak of novel coronavirus (2019-nCoV) that began in Wuhan, China, has spread rapidly, with cases now confirmed in multiple countries. We report the first case of 2019-nCoV infection confirmed in the United States and describe the identification, diagnosis, clinical course, and management of the case, including the patient's initial mild symptoms at presentation with progression to pneumonia on day 9 of illness. This case highlights the importance of close coordination between clinicians and public health authorities at the local, state, and federal levels, as well as the need for rapid dissemination of clinical information related to the care of patients with this emerging infection.",
    "date": "2020",
    "authors": [
        "Michelle L Holshue",
        "Chas DeBolt",
        "Scott Lindquist",
        "Kathy H Lofy",
        "John Wiesman",
        "Hollianne Bruce",
        "Christopher Spitters",
        "Keith Ericson",
        "Sara Wilkerson",
        "Ahmet Tural",
        "George Diaz",
        "Amanda Cohn",
        "LeAnne Fox",
        "Anita Patel",
        "Susan I Gerber",
        "Lindsay Kim",
        "Suxiang Tong",
        "Xiaoyan Lu",
        "Steve Lindstrom",
        "Mark A Pallansch",
        "William C Weldon",
        "Holly M Biggs",
        "Timothy M Uyeki",
        "Satish K Pillai"
    ],
    "related_topics": [
        "Public health",
        "Coronavirus",
        "Pneumonia"
    ],
    "citation_count": "4,627",
    "reference_count": "7",
    "references": [
        "3001118548",
        "3001897055",
        "3002539152",
        "3003951199",
        "3000413850",
        "2991491848",
        "2605343262"
    ]
},{
    "id": "3003573988",
    "title": "Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study.",
    "abstract": "Summary Background Since Dec 31, 2019, the Chinese city of Wuhan has reported an outbreak of atypical pneumonia caused by the 2019 novel coronavirus (2019-nCoV). Cases have been exported to other Chinese cities, as well as internationally, threatening to trigger a global outbreak. Here, we provide an estimate of the size of the epidemic in Wuhan on the basis of the number of cases exported from Wuhan to cities outside mainland China and forecast the extent of the domestic and global public health risks of epidemics, accounting for social and non-pharmaceutical prevention interventions. Methods We used data from Dec 31, 2019, to Jan 28, 2020, on the number of cases exported from Wuhan internationally (known days of symptom onset from Dec 25, 2019, to Jan 19, 2020) to infer the number of infections in Wuhan from Dec 1, 2019, to Jan 25, 2020. Cases exported domestically were then estimated. We forecasted the national and global spread of 2019-nCoV, accounting for the effect of the metropolitan-wide quarantine of Wuhan and surrounding cities, which began Jan 23\u201324, 2020. We used data on monthly flight bookings from the Official Aviation Guide and data on human mobility across more than 300 prefecture-level cities in mainland China from the Tencent database. Data on confirmed cases were obtained from the reports published by the Chinese Center for Disease Control and Prevention. Serial interval estimates were based on previous studies of severe acute respiratory syndrome coronavirus (SARS-CoV). A susceptible-exposed-infectious-recovered metapopulation model was used to simulate the epidemics across all major cities in China. The basic reproductive number was estimated using Markov Chain Monte Carlo methods and presented using the resulting posterior mean and 95% credibile interval (CrI). Findings In our baseline scenario, we estimated that the basic reproductive number for 2019-nCoV was 2\u00b768 (95% CrI 2\u00b747\u20132\u00b786) and that 75\u2008815 individuals (95% CrI 37\u2008304\u2013130\u2008330) have been infected in Wuhan as of Jan 25, 2020. The epidemic doubling time was 6\u00b74 days (95% CrI 5\u00b78\u20137\u00b71). We estimated that in the baseline scenario, Chongqing, Beijing, Shanghai, Guangzhou, and Shenzhen had imported 461 (95% CrI 227\u2013805), 113 (57\u2013193), 98 (49\u2013168), 111 (56\u2013191), and 80 (40\u2013139) infections from Wuhan, respectively. If the transmissibility of 2019-nCoV were similar everywhere domestically and over time, we inferred that epidemics are already growing exponentially in multiple major cities of China with a lag time behind the Wuhan outbreak of about 1\u20132 weeks. Interpretation Given that 2019-nCoV is no longer contained within Wuhan, other major Chinese cities are probably sustaining localised outbreaks. Large cities overseas with close transport links to China could also become outbreak epicentres, unless substantial public health interventions at both the population and personal levels are implemented immediately. Independent self-sustaining outbreaks in major cities globally could become inevitable because of substantial exportation of presymptomatic cases and in the absence of large-scale public health interventions. Preparedness plans and mitigation interventions should be readied for quick deployment globally. Funding Health and Medical Research Fund (Hong Kong, China).",
    "date": "2020",
    "authors": [
        "Joseph T Wu",
        "Kathy Leung",
        "Gabriel M Leung"
    ],
    "related_topics": [
        "Population",
        "Mainland China",
        "China"
    ],
    "citation_count": "3,227",
    "reference_count": "44",
    "references": [
        "3003668884",
        "3004397688",
        "3002764620",
        "2147166346",
        "3002533591",
        "1815575713",
        "2069251911",
        "2096145431",
        "2104595316",
        "1968393246"
    ]
},{
    "id": "2163922914",
    "title": "Representation Learning: A Review and New Perspectives",
    "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.",
    "date": "2013",
    "authors": [
        "Y. Bengio",
        "A. Courville",
        "P. Vincent"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Active learning (machine learning)"
    ],
    "citation_count": "9,032",
    "reference_count": "237",
    "references": [
        "2618530766",
        "2136922672",
        "3118608800",
        "2310919327",
        "2100495367",
        "2158899491",
        "2187089797",
        "1665214252",
        "2162915993",
        "2160815625"
    ]
},{
    "id": "2160815625",
    "title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups",
    "abstract": "Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.",
    "date": "2012",
    "authors": [
        "G. Hinton",
        "Li Deng",
        "Dong Yu",
        "G. E. Dahl",
        "A. Mohamed",
        "N. Jaitly",
        "Andrew Senior",
        "V. Vanhoucke",
        "P. Nguyen",
        "T. N. Sainath",
        "B. Kingsbury"
    ],
    "related_topics": [
        "Acoustic model",
        "Time delay neural network",
        "FMLLR"
    ],
    "citation_count": "9,951",
    "reference_count": "63",
    "references": [
        "2136922672",
        "2100495367",
        "1533861849",
        "2116064496",
        "2145094598",
        "2147768505",
        "1993882792",
        "44815768",
        "1498436455",
        "1994197834"
    ]
},{
    "id": "2022508996",
    "title": "Learning Hierarchical Features for Scene Labeling",
    "abstract": "Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320\u00d7240 image labeling in less than a second, including feature extraction.",
    "date": "2013",
    "authors": [
        "C. Farabet",
        "C. Couprie",
        "L. Najman",
        "Y. LeCun"
    ],
    "related_topics": [
        "Image segmentation",
        "Image texture",
        "Feature vector"
    ],
    "citation_count": "2,757",
    "reference_count": "48",
    "references": [
        "2310919327",
        "2110158442",
        "2546302380",
        "2130325614",
        "1999478155",
        "2143516773",
        "1423339008",
        "2156163116",
        "2169551590",
        "2031342017"
    ]
},{
    "id": "1993882792",
    "title": "Acoustic Modeling Using Deep Belief Networks",
    "abstract": "Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.",
    "date": "2011",
    "authors": [
        "A. Mohamed",
        "G. E. Dahl",
        "G. Hinton"
    ],
    "related_topics": [
        "Generative model",
        "Hidden Markov model",
        "Deep belief network"
    ],
    "citation_count": "1,894",
    "reference_count": "41",
    "references": [
        "2136922672",
        "3118608800",
        "2100495367",
        "2116064496",
        "2147768505",
        "2159080219",
        "44815768",
        "1994197834",
        "2913932916",
        "2103359087"
    ]
},{
    "id": "2151103935",
    "title": "Distinctive Image Features from Scale-Invariant Keypoints",
    "abstract": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
    "date": "2004",
    "authors": [
        "David G. Lowe"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Haar-like features",
        "Feature (computer vision)"
    ],
    "citation_count": "63,331",
    "reference_count": "42",
    "references": [
        "2033819227",
        "2124386111",
        "2154422044",
        "2012778485",
        "2124404372",
        "1676552347",
        "2124087378",
        "2111308925",
        "2165497495",
        "1949116567"
    ]
},{
    "id": "2038721957",
    "title": "WordNet : an electronic lexical database",
    "abstract": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet.",
    "date": "2000",
    "authors": [
        "Christiane Fellbaum"
    ],
    "related_topics": [
        "eXtended WordNet",
        "EuroWordNet",
        "WordNet"
    ],
    "citation_count": "21,240",
    "reference_count": "0",
    "references": []
},{
    "id": "2128017662",
    "title": "Scalable Recognition with a Vocabulary Tree",
    "abstract": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u0092s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.",
    "date": "2006",
    "authors": [
        "D. Nister",
        "H. Stewenius"
    ],
    "related_topics": [
        "Vocabulary",
        "Bag-of-words model in computer vision",
        "Search engine indexing"
    ],
    "citation_count": "4,708",
    "reference_count": "19",
    "references": [
        "2151103935",
        "2177274842",
        "2131846894",
        "1980911747",
        "2104978738",
        "2172188317",
        "2124404372",
        "2147717514",
        "2162006472",
        "2165497495"
    ]
},{
    "id": "2110764733",
    "title": "LabelMe: A Database and Web-Based Tool for Image Annotation",
    "abstract": "We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.",
    "date": "2008",
    "authors": [
        "Bryan C. Russell",
        "Antonio Torralba",
        "Kevin P. Murphy",
        "William T. Freeman"
    ],
    "related_topics": [
        "Image retrieval",
        "LabelMe",
        "Automatic image annotation"
    ],
    "citation_count": "3,307",
    "reference_count": "44",
    "references": [
        "2156909104",
        "2164598857",
        "2038721957",
        "2138451337",
        "2154422044",
        "2107034620",
        "1566135517",
        "2166049352",
        "2134557905",
        "2156598602"
    ]
},{
    "id": "1782590233",
    "title": "Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments",
    "abstract": "Most face databases have been created under controlled conditions to facilitate the study of specific parameters on the face recognition problem. These parameters include such variables as position, pose, lighting, background, camera quality, and gender. While there are many applications for face recognition technology in which one can control the parameters of image acquisition, there are also many applications in which the practitioner has little or no control over such parameters. This database, Labeled Faces in the Wild, is provided as an aid in studying the latter, unconstrained, recognition problem. The database contains labeled face photographs spanning the range of conditions typically encountered in everyday life. The database exhibits \u201cnatural\u201d variability in factors such as pose, lighting, race, accessories, occlusions, and background. In addition to describing the details of the database, we provide specific experimental paradigms for which the database is suitable. This is done in an effort to make research performed with the database as consistent and comparable as possible. We provide baseline results, including results of a state of the art face recognition system combined with a face alignment system. To facilitate experimentation on the database, we provide several parallel databases, including an aligned version.",
    "date": "2008",
    "authors": [
        "Gary B. Huang",
        "Marwan Mattar",
        "Tamara Berg",
        "Eric Learned-Miller"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face detection",
        "Facial recognition system"
    ],
    "citation_count": "5,170",
    "reference_count": "40",
    "references": [
        "3097096317",
        "2121647436",
        "1999478155",
        "2033419168",
        "2123921160",
        "2137659841",
        "2098693229",
        "2125310925",
        "2994340921",
        "2006793117"
    ]
},{
    "id": "1576445103",
    "title": "Caltech-256 Object Category Dataset",
    "abstract": "We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions.",
    "date": "2007",
    "authors": [
        "Gregory Griffin",
        "Alex Holub",
        "Pietro Perona"
    ],
    "related_topics": [
        "Caltech 101",
        "Pyramid (image processing)",
        "Set (abstract data type)"
    ],
    "citation_count": "2,342",
    "reference_count": "0",
    "references": []
},{
    "id": "2145607950",
    "title": "80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition",
    "abstract": "With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.",
    "date": "2008",
    "authors": [
        "A. Torralba",
        "R. Fergus",
        "W.T. Freeman"
    ],
    "related_topics": [
        "WordNet",
        "Object detection",
        "Image processing"
    ],
    "citation_count": "1,893",
    "reference_count": "54",
    "references": [
        "2164598857",
        "2162915993",
        "2124386111",
        "2038721957",
        "2128017662",
        "2110764733",
        "1576445103",
        "2107034620",
        "1566135517",
        "2111993661"
    ]
},{
    "id": "2141282920",
    "title": "Labeling images with a computer game",
    "abstract": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.",
    "date": "2004",
    "authors": [
        "Luis von Ahn",
        "Laura Dabbish"
    ],
    "related_topics": [
        "Computer game",
        "Game design",
        "Game development tool"
    ],
    "citation_count": "2,874",
    "reference_count": "10",
    "references": [
        "1666447063",
        "1934863104",
        "2166770390",
        "1587328194",
        "2293605478",
        "2970081408",
        "2055225264",
        "2050457084",
        "181417509",
        "2612148268"
    ]
},{
    "id": "2115733720",
    "title": "One-shot learning of object categories",
    "abstract": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.",
    "date": "2006",
    "authors": [
        "Li Fei-Fei",
        "R. Fergus",
        "P. Perona"
    ],
    "related_topics": [
        "One-shot learning",
        "Supervised learning",
        "Maximum a posteriori estimation"
    ],
    "citation_count": "2,025",
    "reference_count": "44",
    "references": [
        "2164598857",
        "2310919327",
        "2124386111",
        "2217896605",
        "2154422044",
        "2045656233",
        "2166049352",
        "2134557905",
        "2130416410",
        "2030536784"
    ]
},{
    "id": "1528789833",
    "title": "TextonBoost : joint appearance, shape and context modeling for multi-class object recognition and segmentation",
    "abstract": "This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. High classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow).",
    "date": "2006",
    "authors": [
        "Jamie Shotton",
        "John Winn",
        "Carsten Rother",
        "Antonio Criminisi"
    ],
    "related_topics": [
        "Image segmentation",
        "One-class classification",
        "Conditional random field"
    ],
    "citation_count": "1,510",
    "reference_count": "25",
    "references": [
        "2164598857",
        "2147880316",
        "2057175746",
        "2154422044",
        "2124351162",
        "2169551590",
        "2024046085",
        "1666447063",
        "2168002178",
        "1484228140"
    ]
},{
    "id": "3008818676",
    "title": "The epidemiological characteristics of an outbreak of 2019 novel coronavirus diseases (COVID-19) in China",
    "abstract": "Objective An outbreak of 2019 novel coronavirus diseases (COVID-19) in Wuhan, China has spread quickly nationwide. Here, we report results of a descriptive, exploratory analysis of all cases diagnosed as of February 11, 2020. Methods All COVID-19 cases reported through February 11, 2020 were extracted from China\u2019s Infectious Disease Information System. Analyses included: 1) summary of patient characteristics; 2) examination of age distributions and sex ratios; 3) calculation of case fatality and mortality rates; 4) geo-temporal analysis of viral spread; 5) epidemiological curve construction; and 6) subgroup analysis. Results A total of 72 314 patient records-44 672 (61.8%) confirmed cases, 16 186 (22.4%) suspected cases, 10567 (14.6%) clinical diagnosed cases (Hubei only), and 889 asymptomatic cases (1.2%)-contributed data for the analysis. Among confirmed cases, most were aged 30-79 years (86.6%), diagnosed in Hubei (74.7%), and considered mild/mild pneumonia (80.9%). A total of 1 023 deaths occurred among confirmed cases for an overall case-fatality rate of 2.3%. The COVID-19 spread outward from Hubei sometime after December 2019 and by February 11, 2020, 1 386 counties across all 31 provinces were affected. The epidemic curve of onset of symptoms peaked in January 23-26, then began to decline leading up to February 11. A total of 1 716 health workers have become infected and 5 have died (0.3%). Conclusions The COVID-19 epidemic has spread very quickly. It only took 30 days to expand from Hubei to the rest of Mainland China. With many people returning from a long holiday, China needs to prepare for the possible rebound of the epidemic. Key words: 2019 Novel Coronavirus; Outbreak; Epidemiological characteristics",
    "date": "2020",
    "authors": [
        "Novel Coronavirus Pneumonia Emergency Response Epidemiology Team"
    ],
    "related_topics": [
        "Case fatality rate",
        "Outbreak",
        "Mortality rate"
    ],
    "citation_count": "2,789",
    "reference_count": "9",
    "references": [
        "3033453353",
        "3035018050",
        "3037451072",
        "3034593359",
        "3033301213",
        "3021916232",
        "3031029566",
        "3037552531",
        "3037851904"
    ]
},{
    "id": "3006643024",
    "title": "Time Course of Lung Changes at Chest CT during Recovery from Coronavirus Disease 2019 (COVID-19).",
    "abstract": "Background Chest CT is used to assess the severity of lung involvement in coronavirus disease 2019 (COVID-19). Purpose To determine the changes in chest CT findings associated with COVID-19 from initial diagnosis until patient recovery. Materials and Methods This retrospective review included patients with real-time polymerase chain reaction-confirmed COVID-19 who presented between January 12, 2020, and February 6, 2020. Patients with severe respiratory distress and/or oxygen requirement at any time during the disease course were excluded. Repeat chest CT was performed at approximately 4-day intervals. Each of the five lung lobes was visually scored on a scale of 0 to 5, with 0 indicating no involvement and 5 indicating more than 75% involvement. The total CT score was determined as the sum of lung involvement, ranging from 0 (no involvement) to 25 (maximum involvement). Results Twenty-one patients (six men and 15 women aged 25-63 years) with confirmed COVID-19 were evaluated. A total of 82 chest CT scans were obtained in these patients, with a mean interval (\u00b1standard deviation) of 4 days \u00b1 1 (range, 1-8 days). All patients were discharged after a mean hospitalization period of 17 days \u00b1 4 (range, 11-26 days). Maximum lung involved peaked at approximately 10 days (with a calculated total CT score of 6) from the onset of initial symptoms (R2 = 0.25, P < .001). Based on quartiles of chest CT scans from day 0 to day 26 involvement, four stages of lung CT findings were defined. CT scans obtained in stage 1 (0-4 days) showed ground-glass opacities (18 of 24 scans [75%]), with a mean total CT score of 2 \u00b1 2; scans obtained in stage 2 (5-8 days) showed an increase in both the crazy-paving pattern (nine of 17 scans [53%]) and total CT score (mean, 6 \u00b1 4; P = .002); scans obtained in stage 3 (9-13 days) showed consolidation (19 of 21 scans [91%]) and a peak in the total CT score (mean, 7 \u00b1 4); and scans obtained in stage 4 (\u226514 days) showed gradual resolution of consolidation (15 of 20 scans [75%]) and a decrease in the total CT score (mean, 6 \u00b1 4) without crazy-paving pattern. Conclusion In patients recovering from coronavirus disease 2019 (without severe respiratory distress during the disease course), lung abnormalities on chest CT scans showed greatest severity approximately 10 days after initial onset of symptoms. \u00a9 RSNA, 2020.",
    "date": "2020",
    "authors": [
        "Feng Pan",
        "Tianhe Ye",
        "Peng Sun",
        "Shan Gui",
        "Bo Liang",
        "Lingli Li",
        "Dandan Zheng",
        "Jiazheng Wang",
        "Richard L Hesketh",
        "Lian Yang",
        "Chuansheng Zheng"
    ],
    "related_topics": [
        "Lung",
        "Respiratory distress",
        "Pneumonia"
    ],
    "citation_count": "1,289",
    "reference_count": "12",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3003668884",
        "3004906315",
        "2102634410",
        "2800783955",
        "3004802901",
        "2092969802",
        "2056155046"
    ]
},{
    "id": "3006110666",
    "title": "Chest CT for Typical Coronavirus Disease 2019 (COVID-19) Pneumonia: Relationship to Negative RT-PCR Testing.",
    "abstract": "Some patients with positive chest CT findings may present with negative results of real-time reverse-transcription polymerase chain reaction (RT-PCR) tests for coronavirus disease 2019 (COVID-19). In this study, the authors present chest CT findings from five patients with COVID-19 infection who had initial negative RT-PCR results. All five patients had typical imaging findings, including ground-glass opacity (five patients) and/or mixed ground-glass opacity and mixed consolidation (two patients). After isolation for presumed COVID-19 pneumonia, all patients were eventually confirmed to have COVID-19 infection by means of repeated swab tests. A combination of repeated swab tests and CT scanning may be helpful for individuals with a high clinical suspicion of COVID-19 infection but negative findings at RT-PCR screening.",
    "date": "2020",
    "authors": [
        "Xingzhi Xie",
        "Zheng Zhong",
        "Wei Zhao",
        "Chao Zheng",
        "Fei Wang",
        "Jun Liu"
    ],
    "related_topics": [
        "False Negative Reactions",
        "Radiology",
        "Real-time polymerase chain reaction"
    ],
    "citation_count": "1,468",
    "reference_count": "5",
    "references": [
        "3001897055",
        "3004906315",
        "3005272159",
        "2112136274",
        "2056155046"
    ]
},{
    "id": "3006354146",
    "title": "Initial CT findings and temporal changes in patients with the novel coronavirus pneumonia (2019-nCoV): a study of 63 patients in Wuhan, China.",
    "abstract": "The purpose of this study was to observe the imaging characteristics of the novel coronavirus pneumonia. Sixty-three confirmed patients were enrolled from December 30, 2019 to January 31, 2020. High-resolution CT (HRCT) of the chest was performed. The number of affected lobes, ground glass nodules (GGO), patchy/punctate ground glass opacities, patchy consolidation, fibrous stripes and irregular solid nodules in each patient's chest CT image were recorded. Additionally, we performed imaging follow-up of these patients. CT images of 63 confirmed patients were collected. M/F ratio: 33/30. The mean age was 44.9 \u00b1 15.2 years. The mean number of affected lobes was 3.3 \u00b1 1.8. Nineteen (30.2%) patients had one affected lobe, five (7.9%) patients had two affected lobes, four (6.3%) patients had three affected lobes, seven (11.1%) patients had four affected lobes while 28 (44.4%) patients had 5 affected lobes. Fifty-four (85.7%) patients had patchy/punctate ground glass opacities, 14 (22.2%) patients had GGO, 12 (19.0%) patients had patchy consolidation, 11 (17.5%) patients had fibrous stripes and 8 (12.7%) patients had irregular solid nodules. Fifty-four (85.7%) patients progressed, including single GGO increased, enlarged and consolidated; fibrous stripe enlarged, while solid nodules increased and enlarged. Imaging changes in novel viral pneumonia are rapid. The manifestations of the novel coronavirus pneumonia are diverse. Imaging changes of typical viral pneumonia and some specific imaging features were observed. Therefore, we need to strengthen the recognition of image changes to help clinicians to diagnose quickly and accurately. \u2022 High-resolution CT (HRCT) of the chest is critical for early detection, evaluation of disease severity and follow-up of patients with the novel coronavirus pneumonia. \u2022 The manifestations of the novel coronavirus pneumonia are diverse and change rapidly. \u2022 Radiologists should be aware of the various features of the disease and temporal changes.",
    "date": "2020",
    "authors": [
        "Yueying Pan",
        "Hanxiong Guan",
        "Shuchang Zhou",
        "Yujin Wang",
        "Qian Li",
        "Tingting Zhu",
        "Qiongjie Hu",
        "Liming Xia"
    ],
    "related_topics": [
        "Viral pneumonia",
        "Neuroradiology",
        "Radiology"
    ],
    "citation_count": "692",
    "reference_count": "5",
    "references": [
        "3001118548",
        "3002539152",
        "3001465255",
        "3017468735",
        "3001456238"
    ]
},{
    "id": "3003901880",
    "title": "CT Imaging of the 2019 Novel Coronavirus (2019-nCoV) Pneumonia.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Junqiang Lei",
        "Junfeng Li",
        "Xun Li",
        "Xiaolong Qi"
    ],
    "related_topics": [
        "Pneumonia",
        "Respiratory sounds",
        "Tomography"
    ],
    "citation_count": "475",
    "reference_count": "1",
    "references": [
        "3002533507"
    ]
},{
    "id": "3005656138",
    "title": "Use of Chest CT in Combination with Negative RT-PCR Assay for the 2019 Novel Coronavirus but High Clinical Suspicion.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Peikai Huang",
        "Tianzhu Liu",
        "Lesheng Huang",
        "Hailong Liu",
        "Ming Lei",
        "Wangdong Xu",
        "Xiaolu Hu",
        "Jun Chen",
        "Bo Liu"
    ],
    "related_topics": [
        "Real-time polymerase chain reaction",
        "Pneumonia",
        "False Negative Reactions"
    ],
    "citation_count": "350",
    "reference_count": "2",
    "references": [
        "3001897055",
        "3004668429"
    ]
},{
    "id": "3004511262",
    "title": "Evolution of CT Manifestations in a Patient Recovered from 2019 Novel Coronavirus (2019-nCoV) Pneumonia in Wuhan, China.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Heshui Shi",
        "Xiaoyu Han",
        "Chuansheng Zheng"
    ],
    "related_topics": [
        "Pneumonia",
        "Medicine",
        "Virology"
    ],
    "citation_count": "189",
    "reference_count": "0",
    "references": []
},{
    "id": "3008962515",
    "title": "Molecular and serological investigation of 2019-nCoV infected patients: implication of multiple shedding routes.",
    "abstract": "In December 2019, a novel coronavirus (2019-nCoV) caused an outbreak in Wuhan, China, and soon spread to other parts of the world. It was believed that 2019-nCoV was transmitted through respiratory tract and then induced pneumonia, thus molecular diagnosis based on oral swabs was used for confirmation of this disease. Likewise, patient will be released upon two times of negative detection from oral swabs. However, many coronaviruses can also be transmitted through oral-fecal route by infecting intestines. Whether 2019-nCoV infected patients also carry virus in other organs like intestine need to be tested. We conducted investigation on patients in a local hospital who were infected with this virus. We found the presence of 2019-nCoV in anal swabs and blood as well, and more anal swab positives than oral swab positives in a later stage of infection, suggesting shedding and thereby transmitted through oral-fecal route. We also showed serology test can improve detection positive rate thus should be used in future epidemiology. Our report provides a cautionary warning that 2019-nCoV may be shed through multiple routes.",
    "date": "2020",
    "authors": [
        "Wei Zhang",
        "Rong-Hui Du",
        "Bei Li",
        "Xiao-Shuang Zheng",
        "Xing-Lou Yang",
        "Ben Hu",
        "Yan-Yi Wang",
        "Geng-Fu Xiao",
        "Bing Yan",
        "Zheng-Li Shi",
        "Peng Zhou"
    ],
    "related_topics": [
        "Viral shedding",
        "Coronavirus",
        "Serology"
    ],
    "citation_count": "1,372",
    "reference_count": "13",
    "references": [
        "3001118548",
        "3001897055",
        "3003668884",
        "3004280078",
        "2786098272",
        "2769543984",
        "2021442163",
        "3025232310",
        "3028321619",
        "3027541845"
    ]
},{
    "id": "3008452791",
    "title": "Viral load of SARS-CoV-2 in clinical samples.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Yang Pan",
        "Daitao Zhang",
        "Peng Yang",
        "Leo L M Poon",
        "Quanyi Wang"
    ],
    "related_topics": [
        "Feces analysis",
        "Viral load",
        "Pneumonia"
    ],
    "citation_count": "850",
    "reference_count": "3",
    "references": [
        "3004318991",
        "3003637715",
        "2129542667"
    ]
},{
    "id": "3033453353",
    "title": "Recent Understandings Toward Coronavirus Disease 2019 (COVID-19): From Bench to Bedside",
    "abstract": "In late December 2019, an unprecedented outbreak of coronavirus disease 2019 (COVID-19) caused by SARS coronavirus 2 (SARS-CoV-2) (previously named 2019-nCoV) in Wuhan became the most challenging health emergency. Since its rapid spread in China and many other countries, the World Health Organization (WHO) declared COVID-19 a public health emergency of international concern (PHEIC) on 30th January 2020 and a pandemic on 11th March 2020. Thousands of people have died, and there are currently no vaccines or specific antiviral drugs for COVID-19. Therefore, it is critical to have a comprehensive understanding of the virus. In this review, we highlight the etiology, epidemiology, pathogenesis and pathology, clinical characteristics, diagnosis, clinical management, prognosis, infection control and prevention of COVID-19 based on recent studies.",
    "date": "2020",
    "authors": [
        "Jie Yu",
        "Peiwei Chai",
        "Shengfang Ge",
        "Xianqun Fan"
    ],
    "related_topics": [
        "Pandemic",
        "Public health",
        "Epidemiology"
    ],
    "citation_count": "13",
    "reference_count": "116",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3003668884",
        "3009885589",
        "3004280078",
        "3004318991",
        "3003465021",
        "3004239190"
    ]
},{
    "id": "3034408674",
    "title": "Risk assessment of mixed and displacement ventilation (LAF) during orthopedic and trauma surgery on COVID-19 patients with increased release of infectious aerosols",
    "abstract": "No abstract available Keywords: Displacement ventilation; SARS-CoV-2 spread; laminar air flow; mixed ventilation; negative pressure; no ventilation.",
    "date": "2020",
    "authors": [
        "Axel Kramer",
        "R\u00fcdiger K\u00fclpmann",
        "Arnold Brunner",
        "Michael M\u00fcller",
        "Georgi Wassilew"
    ],
    "related_topics": [
        "Ventilation (architecture)",
        "Displacement ventilation",
        "Trauma surgery"
    ],
    "citation_count": "4",
    "reference_count": "0",
    "references": []
},{
    "id": "3035275617",
    "title": "Recreational waters - A potential transmission route for SARS-CoV-2 to humans?",
    "abstract": "Coronavirus disease 2019 (COVID-19), the respiratory illness caused by the novel virus, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which has lead to high morbidity and mortality rates worldwide, has been causing major public health concerns since first detected in late 2019. Following identification of novel pathogens, questions in relation to dissemination of the pathogen and transmission routes begin to emerge. This rapidly spreading SARS-CoV-2 virus has been detected in both faecal and wastewater samples across the globe, highlighting the potential for faecal-oral transmission of the virus. As a result, concerns regarding the transmission of the virus in the environment and the risk associated with contracting the virus in recreational waters, particularly where inadequately treated wastewater is discharged, have been emerging in recent weeks. This paper highlights the need for further research to be carried out to investigate the presence, infectivity and viability of this newly identified SARS-CoV-2 virus in wastewater effluent and receiving recreational waters.",
    "date": "2020",
    "authors": [
        "Niamh Cahill",
        "Dearbh\u00e1ile Morris"
    ],
    "related_topics": [
        "Novel virus",
        "Coronavirus",
        "Transmission (medicine)"
    ],
    "citation_count": "22",
    "reference_count": "34",
    "references": [
        "3004280078",
        "3003465021",
        "3013893137",
        "3010604545",
        "3004824173",
        "3003464757",
        "3009834387",
        "3011863580",
        "3010096538",
        "3006846061"
    ]
},{
    "id": "3034059415",
    "title": "Impact of Lockdown on the Epidemic Dynamics of COVID-19 in France",
    "abstract": "The COVID-19 epidemic was reported in the Hubei province in China in December 2019 and then spread around the world reaching the pandemic stage at the beginning of March 2020. Since then, several countries went into lockdown. Using a mechanistic-statistical formalism, we estimate the effect of the lockdown in France on the contact rate and the effective reproduction number Re of the COVID-19. We obtain a reduction by a factor 7 (Re=0.47, 95%-CI: 0.45-0.50), compared to the estimates carried out in France at the early stage of the epidemic. We also estimate the fraction of the population that would be infected by the beginning of May, at the official date at which the lockdown should be relaxed. We find a fraction of 3.7% (95%-CI: 3.0-4.8%) of the total French population, without taking into account the number of recovered individuals before April 1st, which is not known. This proportion is seemingly too low to reach herd immunity. Thus, even if the lockdown strongly mitigated the first epidemic wave, keeping a low value of Re is crucial to avoid an uncontrolled second wave (initiated with much more infectious cases than the first wave) and to hence avoid the saturation of hospital facilities.",
    "date": "2020",
    "authors": [
        "Lionel Roques",
        "Etienne K. Klein",
        "Julien Papa\u00efx",
        "Antoine Sar",
        "Samuel Soubeyrand"
    ],
    "related_topics": [
        "Population",
        "Epidemic model",
        "Herd immunity"
    ],
    "citation_count": "37",
    "reference_count": "27",
    "references": [
        "3003668884",
        "3009885589",
        "3008443627",
        "3010604545",
        "3013967887",
        "3015571324",
        "3006642361",
        "3004397688",
        "3013594674",
        "3012789146"
    ]
},{
    "id": "3033952286",
    "title": "Real-time reverse transcription loop-mediated isothermal amplification for rapid detection of SARS-CoV-2",
    "abstract": "Background Highly sensitive real-time reverse transcription polymerase chain reaction (RT-qPCR) methods have been developed for the detection of SARS-CoV-2. However, they are costly. Loop-mediated isothermal amplification (LAMP) assay has emerged as a novel alternative isothermal amplification method for the detection of nucleic acid. Methods A rapid, sensitive and specific real-time reverse transcription LAMP (RT-LAMP) assay was developed for SARS-CoV-2 detection. Results This assay detected one copy/reaction of SARS-CoV-2 RNA in 30 min. Both the clinical sensitivity and specificity of this assay were 100%. The RT-LAMP showed comparable performance with RT-qPCR. Combining simplicity and cost-effectiveness, this assay is therefore recommended for use in resource resource-limited settings.",
    "date": "2020",
    "authors": [
        "Yee Ling Lau",
        "Ilyiana Ismail",
        "Nur Izati Mustapa",
        "Meng Yee Lai",
        "Tuan Suhaila Tuan Soh",
        "Afifah Hassan",
        "Kalaiarasu M Peariasamy",
        "Yee Leng Lee",
        "Yoong Min Chong",
        "I-Ching Sam",
        "Pik Pin Goh"
    ],
    "related_topics": [
        "Reverse Transcription Loop-mediated Isothermal Amplification",
        "Loop-mediated isothermal amplification",
        "Reverse transcription polymerase chain reaction"
    ],
    "citation_count": "9",
    "reference_count": "14",
    "references": [
        "3001195213",
        "3010604545",
        "2105275554",
        "3011969828",
        "2770752141",
        "2263084061",
        "2175815746",
        "1991420168",
        "2073600962",
        "2084576921"
    ]
},{
    "id": "3036958556",
    "title": "Involvement of digestive system in COVID-19: manifestations, pathology, management and challenges",
    "abstract": "The pandemic of novel coronavirus disease (COVID-19) has developed as a tremendous threat to global health. Although most COVID-19 patients present with respiratory symptoms, some present with gastrointestinal (GI) symptoms like diarrhoea, loss of appetite, nausea/vomiting and abdominal pain as the major complaints. These features may be attributable to the following facts: (a) COVID-19 is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and its receptor angiotensin converting enzyme 2 (ACE2) was found to be highly expressed in GI epithelial cells, providing a prerequisite for SARS-CoV-2 infection; (b) SARS-CoV-2 viral RNA has been found in stool specimens of infected patients, and 20% of patients showed prolonged presence of SARS-CoV-2 RNA in faecal samples after the virus converting to negative in the respiratory system. These findings suggest that SARS-CoV-2 may be able to actively infect and replicate in the GI tract. Moreover, GI infection could be the first manifestation antedating respiratory symptoms; patients suffering only digestive symptoms but no respiratory symptoms as clinical manifestation have also been reported. Thus, the implications of digestive symptoms in patients with COVID-19 is of great importance. In this review, we summarise recent findings on the epidemiology of GI tract involvement, potential mechanisms of faecal-oral transmission, GI and liver manifestation, pathological/histological features in patients with COVID-19 and the diagnosis, management of patients with pre-existing GI and liver diseases as well as precautions for preventing SARS-CoV-2 infection during GI endoscopy procedures.",
    "date": "2020",
    "authors": [
        "Song Su",
        "Jun Shen",
        "Liangru Zhu",
        "Yun Qiu",
        "Jin-Shen He",
        "Jin-Yu Tan",
        "Marietta Iacucci",
        "Siew C Ng",
        "Subrata Ghosh",
        "Ren Mao",
        "Jie Liang"
    ],
    "related_topics": [
        "Coronavirus",
        "Vomiting",
        "Disease"
    ],
    "citation_count": "20",
    "reference_count": "47",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3002539152",
        "3003465021",
        "3008090866",
        "3007940623",
        "3010604545",
        "3011242477"
    ]
},{
    "id": "3035464429",
    "title": "Sampling and detection of corona viruses in air: A mini review.",
    "abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a strain of coronaviruses that causes coronavirus disease 2019 (COVID-19). In these days, the spread of the SARS-CoV-2 virus through the air has become a controversial topic among scientists. Various organizations provide standard methods for monitoring biological agents in the air. Nevertheless, there has been no standard recommended method for sampling and determination of viruses in air. This manuscript aimed at reviewing published papers for sampling and detection of corona viruses, especially SARS-Cov-2 as a global health concern. It was found that SARS-Cov 2 was present in some air samples that were collected from patient's rooms in hospitals. This result warrants its airborne transmission potential. However, due to the fact that in the most reviewed studies, sampling was performed in the patient's room, it seems difficult to discriminate whether it is airborne or is transmitted through respiratory droplets. Moreover, some other disrupting factors such as patient distance from the sampler, using protective or oxygen masks by patients, patient activities, coughing and sneezing during sampling time, air movement, air conditioning, sampler type, sampling conditions, storage and transferring conditions, can affect the results. About the sampling methods, most of the used samplers such as PTFE filters, gelatin filers and cyclones showed suitable performance for trapping SARS-Co and MERS-Cov viruses followed by PCR analysis.",
    "date": "2020",
    "authors": [
        "Ali Reza Rahmani",
        "Mostafa Leili",
        "Ghasem Azarian",
        "Ali Poormohammadi"
    ],
    "related_topics": [
        "Airborne transmission",
        "Sampling (statistics)",
        "Air conditioning"
    ],
    "citation_count": "22",
    "reference_count": "41",
    "references": [
        "3010604545",
        "2132260239",
        "3010449299",
        "3018334611",
        "2103503670",
        "3015704123",
        "3030968929",
        "2158121945",
        "3015636815",
        "3018724240"
    ]
},{
    "id": "3028749392",
    "title": "A Collaborative Multidisciplinary Approach to the Management of Coronavirus Disease 2019 in the Hospital Setting.",
    "abstract": "The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes coronavirus disease 2019 (COVID-19), which presents an unprecedented challenge to medical providers worldwide. Although most SARS-CoV-2-infected individuals manifest with a self-limited mild disease that resolves with supportive care in the outpatient setting, patients with moderate to severe COVID-19 will require a multidisciplinary collaborative management approach for optimal care in the hospital setting. Laboratory and radiologic studies provide critical information on disease severity, management options, and overall prognosis. Medical management is mostly supportive with antipyretics, hydration, oxygen supplementation, and other measures as dictated by clinical need. Among its medical complications is a characteristic proinflammatory cytokine storm often associated with end-organ dysfunction, including respiratory failure, liver and renal insufficiency, cardiac injury, and coagulopathy. Specific recommendations for the management of these medical complications are discussed. Despite the issuance of emergency use authorization for remdesivir, there are still no proven effective antiviral and immunomodulatory therapies, and their use in COVID-19 management should be guided by clinical trial protocols or treatment registries. The medical care of patients with COVID-19 extends beyond their hospitalization. Postdischarge follow-up and monitoring should be performed, preferably using telemedicine, until the patients have fully recovered from their illness and are released from home quarantine protocols.",
    "date": "2020",
    "authors": [
        "Raymund R. Razonable",
        "Kelly M. Pennington",
        "Anne M. Meehan",
        "John W. Wilson",
        "Adam T. Froemming",
        "Courtney E. Bennett",
        "Ariela L. Marshall",
        "Abinash Virk",
        "Eva M. Carmona"
    ],
    "related_topics": [
        "Clinical trial",
        "Intensive care unit",
        "Telemedicine"
    ],
    "citation_count": "15",
    "reference_count": "136",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3009885589",
        "3008028633",
        "3002539152",
        "3004318991"
    ]
},{
    "id": "3032185657",
    "title": "Trajectory of the COVID-19 pandemic: chasing a moving target",
    "abstract": "The spread of COVID-19 has already taken a pandemic form, affecting over 180 countries in a matter of three months. The full continuum of disease ranges from mild, self-limiting illness to severe progressive COVID-19 pneumonia, multiorgan failure, cytokine storm and death. Younger and healthy population is now getting affected than before. Possibilities of airborne and fecal oral routes of transmission has increased the concern. In the absence of any specific therapeutic agent for coronavirus infections, the most effective manner to contain this pandemic is probably the non-pharmacological interventions (NPIs). The damage due to the pandemic disease is multifaceted and crippling to economy, trade, and health of the citizens of the countries. The extent of damage in such scenarios is something that is beyond calculation by Gross Domestic Product rate or currency value of the country. Unfortunately, unlike many other diseases, we are still away from the target antiviral drug and vaccine for severe acute respiratory syndrome (SARS-CoV-2) infection. The prime importance of NPIs like social distancing, staying in home, work from home, self-monitoring, public awareness, self-quarantine, etc. are constantly being emphasized by CDC, WHO, health ministries of all countries and social media houses. This is time of introspection and learning from our mistakes. Countries like China and South Korea who were initially the most hit countries could contain the disease spread by liberal testing of their population, stringent quarantine of people under investigation and isolation of the positive cases. Rest of the countries need to act urgently as well to bring an immediate halt in the community transmission.",
    "date": "2020",
    "authors": [
        "Kamal Kant Sahu",
        "Ajay Kumar Mishra",
        "Amos Lal"
    ],
    "related_topics": [
        "Population",
        "Pandemic",
        "Isolation (health care)"
    ],
    "citation_count": "18",
    "reference_count": "75",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3003668884",
        "3009885589",
        "3008028633",
        "3008090866",
        "3007497549",
        "3010930696",
        "3014294089"
    ]
},{
    "id": "3042098369",
    "title": "Laboratory Tests for COVID-19: A Review of Peer-Reviewed Publications and Implications for Clinical Use",
    "abstract": "Diagnostic tests for the coronavirus infection 2019 (COVID-19) are critical for prompt diagnosis, treatment and isolation to break the cycle of transmission. A positive real-time reverse-transcriptase polymerase chain reaction (RT-PCR), in conjunction with clinical and epidemiologic data, is the current standard for diagnosis, but several challenges still exist. Serological assays help to understand epidemiology better and to evaluate vaccine responses but they are unreliable for diagnosis in the acute phase of illness or assuming protective immunity. Serology is gaining attention, mainly because of convalescent plasma gaining importance as treatment for clinically worsening COVID-19 patients. We provide a narrative review of peer-reviewed research studies on RT-PCR, serology and antigen immune-assays for COVID-19, briefly describe their lab methods and discuss their limitations for clinical practice.",
    "date": "2020",
    "authors": [
        "Daniel Shyu",
        "James Dorroh",
        "Caleb Holtmeyer",
        "Detlef Ritter",
        "Anandhi Upendran",
        "Raghuraman Kannan",
        "Dima Dandachi",
        "Christian Rojas-Moreno",
        "Stevan P Whitt",
        "Hariharan Regunath"
    ],
    "related_topics": [
        "Serology",
        "Peer review",
        "Epidemiology"
    ],
    "citation_count": "10",
    "reference_count": "70",
    "references": [
        "3001118548",
        "3005079553",
        "3003668884",
        "3009885589",
        "3002539152",
        "3004280078",
        "3001195213",
        "3007497549",
        "3013893137",
        "3010604545"
    ]
},{
    "id": "3037255629",
    "title": "COVID-19 in children: An ample review",
    "abstract": "The aim of this review was to describe the current knowledge about coronavirus disease 2019 (COVID-19, which is caused by severe acute respiratory syndrome coronavirus 2 [SARS-CoV-2]) in children, from epidemiological, clinical, and laboratory perspectives, including knowledge on the disease course, treatment, and prognosis. An extensive literature search was performed to identify papers on COVID-19 (SARS-CoV-2 infection) in children, published between January 1, 2020 and April 1, 2020. There were 44 relevant papers on COVID-19 in children. The results showed that COVID-19 occurs in 0.39\u201312.3% of children. Clinical signs and symptoms are comparable to those in adults, but milder forms and a large percentage of asymptomatic carriers are found among children. Elevated inflammatory markers are associated with complications and linked to various co-infections. Chest computed tomography (CT) scans in children revealed structural changes similar to those found in adults, with consolidations surrounded by halos being somewhat specific for children with COVID-19. The recommended treatment includes providing symptomatic therapy, with no specific drug recommendations for children. The prognosis is much better for children compared to adults. This review highlights that COVID-19 in children is similar to the disease in the adult population, but with particularities regarding clinical manifestations, laboratory test results, chest imaging, and treatment. The prognosis is much better for children compared to adults, but with the progression of the pandemic; the cases in children might change in the future.",
    "date": "2020",
    "authors": [
        "Ioana M Ciuca"
    ],
    "related_topics": [
        "Epidemiology",
        "Asymptomatic carrier",
        "Disease"
    ],
    "citation_count": "12",
    "reference_count": "63",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3005079553",
        "3002108456",
        "3008028633",
        "3007940623",
        "3007497549",
        "3010604545",
        "3010930696"
    ]
},{
    "id": "2168356304",
    "title": "Object Detection with Discriminatively Trained Part-Based Models",
    "abstract": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.",
    "date": "2010",
    "authors": [
        "P F Felzenszwalb",
        "R B Girshick",
        "D McAllester",
        "D Ramanan"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent variable",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "10,895",
    "reference_count": "46",
    "references": [
        "2151103935",
        "2161969291",
        "3097096317",
        "2154422044",
        "2120419212",
        "2152826865",
        "2145072179",
        "1576520375",
        "2030536784",
        "2115763357"
    ]
},{
    "id": "1849277567",
    "title": "Visualizing and Understanding Convolutional Networks",
    "abstract": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
    "date": "2014",
    "authors": [
        "Matthew D. Zeiler",
        "Rob Fergus"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Softmax function",
        "Classifier (UML)"
    ],
    "citation_count": "12,255",
    "reference_count": "24",
    "references": [
        "2618530766",
        "2102605133",
        "2108598243",
        "2136922672",
        "1904365287",
        "2155541015",
        "2546302380",
        "2025768430",
        "2110798204",
        "2161381512"
    ]
},{
    "id": "1959608418",
    "title": "Auto-Encoding Variational Bayes",
    "abstract": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.",
    "date": "2013",
    "authors": [
        "Diederik P Kingma",
        "Max Welling"
    ],
    "related_topics": [
        "Approximate inference",
        "Inference",
        "Estimator"
    ],
    "citation_count": "13,251",
    "reference_count": "15",
    "references": [
        "2146502635",
        "2163922914",
        "2145094598",
        "2166851633",
        "2097268041",
        "2963173382",
        "2951493172",
        "2171490498",
        "2119196781",
        "3104819538"
    ]
},{
    "id": "1904365287",
    "title": "Improving neural networks by preventing co-adaptation of feature detectors",
    "abstract": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.",
    "date": "2012",
    "authors": [
        "Geoffrey E. Hinton",
        "Nitish Srivastava",
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Ruslan R. Salakhutdinov"
    ],
    "related_topics": [
        "Dropout (neural networks)",
        "Feature (computer vision)",
        "Overfitting"
    ],
    "citation_count": "8,094",
    "reference_count": "18",
    "references": [
        "2108598243",
        "2911964244",
        "3118608800",
        "2310919327",
        "2100495367",
        "2912934387",
        "2116064496",
        "2147768505",
        "1993882792",
        "4919037"
    ]
},{
    "id": "2964153729",
    "title": "Intriguing properties of neural networks",
    "abstract": "Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
    "date": "2013",
    "authors": [
        "Christian Szegedy",
        "Wojciech Zaremba",
        "Ilya Sutskever",
        "Joan Bruna",
        "Dumitru Erhan",
        "Ian Goodfellow",
        "Rob Fergus"
    ],
    "related_topics": [
        "Artificial neural network",
        "Adversarial machine learning",
        "Pattern recognition"
    ],
    "citation_count": "8,962",
    "reference_count": "11",
    "references": [
        "2618530766",
        "2102605133",
        "1614298861",
        "2108598243",
        "2160815625",
        "2072128103",
        "2206858481",
        "2120419212",
        "2120480077",
        "2150165932"
    ]
},{
    "id": "1901129140",
    "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
    "abstract": "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
    "date": "2015",
    "authors": [
        "Olaf Ronneberger",
        "Philipp Fischer",
        "Thomas Brox"
    ],
    "related_topics": [
        "Brain segmentation",
        "Deep learning",
        "Segmentation"
    ],
    "citation_count": "26,451",
    "reference_count": "13",
    "references": [
        "2618530766",
        "2962835968",
        "1903029394",
        "2155893237",
        "1677182931",
        "1948751323",
        "2167510172",
        "1893585201",
        "2148349024",
        "2147800946"
    ]
},{
    "id": "2133665775",
    "title": "Image quality assessment: from error visibility to structural similarity",
    "abstract": "Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.",
    "date": "2004",
    "authors": [
        "Zhou Wang",
        "A.C. Bovik",
        "H.R. Sheikh",
        "E.P. Simoncelli"
    ],
    "related_topics": [
        "Image quality",
        "Subjective video quality",
        "Human visual system model"
    ],
    "citation_count": "32,918",
    "reference_count": "53",
    "references": [
        "2159269332",
        "2142276208",
        "2118217749",
        "2053691921",
        "2153777140",
        "2912116903",
        "2107790757",
        "2158564760",
        "2124731682",
        "2115838129"
    ]
},{
    "id": "2340897893",
    "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
    "abstract": "Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications. Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning. For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling. Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities. 5000 of these images have high quality pixel-level annotations, 20 000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data. Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity. Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.",
    "date": "2016",
    "authors": [
        "Marius Cordts",
        "Mohamed Omran",
        "Sebastian Ramos",
        "Timo Rehfeld",
        "Markus Enzweiler",
        "Rodrigo Benenson",
        "Uwe Franke",
        "Stefan Roth",
        "Bernt Schiele"
    ],
    "related_topics": [
        "Object detection",
        "Deep learning",
        "Machine learning"
    ],
    "citation_count": "4,675",
    "reference_count": "81",
    "references": [
        "2618530766",
        "2962835968",
        "639708223",
        "2919115771",
        "2102605133",
        "2117539524",
        "1903029394",
        "1536680647",
        "2168356304",
        "1861492603"
    ]
},{
    "id": "2271840356",
    "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
    "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
    "date": "2014",
    "authors": [
        "Mart\u00edn Abadi",
        "Ashish Agarwal",
        "Paul Barham",
        "Eugene Brevdo",
        "Zhifeng Chen",
        "Craig Citro",
        "Gregory S. Corrado",
        "Andy Davis",
        "Jeffrey Dean",
        "Matthieu Devin",
        "Sanjay Ghemawat",
        "Ian J. Goodfellow",
        "Andrew Harp",
        "Geoffrey Irving",
        "Michael Isard",
        "Yangqing Jia",
        "Rafal J\u00f3zefowicz",
        "Lukasz Kaiser",
        "Manjunath Kudlur",
        "Josh Levenberg",
        "Dan Man\u00e9",
        "Rajat Monga",
        "Sherry Moore",
        "Derek Gordon Murray",
        "Chris Olah",
        "Mike Schuster",
        "Jonathon Shlens",
        "Benoit Steiner",
        "Ilya Sutskever",
        "Kunal Talwar",
        "Paul A. Tucker",
        "Vincent Vanhoucke",
        "Vijay Vasudevan",
        "Fernanda B. Vi\u00e9gas",
        "Oriol Vinyals",
        "Pete Warden",
        "Martin Wattenberg",
        "Martin Wicke",
        "Yuan Yu",
        "Xiaoqiang Zheng"
    ],
    "related_topics": [
        "Interface (computing)",
        "Deep learning",
        "Information extraction"
    ],
    "citation_count": "9,248",
    "reference_count": "42",
    "references": [
        "2097117768",
        "1836465849",
        "1614298861",
        "2130942839",
        "2155893237",
        "2064675550",
        "2160815625",
        "2168231600",
        "2016053056",
        "2131975293"
    ]
},{
    "id": "648143168",
    "title": "Deep generative image models using a Laplacian pyramid of adversarial networks",
    "abstract": "In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convolutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative convnet model is trained using the Generative Adversarial Nets (GAN) approach [11]. Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 samples were mistaken for real images around 40% of the time, compared to 10% for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset.",
    "date": "2015",
    "authors": [
        "Emily Denton",
        "Soumith Chintala",
        "Arthur Szlam",
        "Rob Fergus"
    ],
    "related_topics": [
        "Pyramid",
        "Real image",
        "Parametric model"
    ],
    "citation_count": "1,923",
    "reference_count": "31",
    "references": [
        "1836465849",
        "2099471712",
        "2108598243",
        "1959608418",
        "3118608800",
        "2100495367",
        "2025768430",
        "2125389028",
        "2118858186",
        "189596042"
    ]
},{
    "id": "2963685250",
    "title": "Weight normalization: a simple reparameterization to accelerate training of deep neural networks",
    "abstract": "We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.",
    "date": "2016",
    "authors": [
        "Tim Salimans",
        "Diederik P. Kingma"
    ],
    "related_topics": [
        "Normalization (statistics)",
        "Artificial neural network",
        "Stochastic gradient descent"
    ],
    "citation_count": "1,061",
    "reference_count": "26",
    "references": [
        "2194775991",
        "1836465849",
        "2145339207",
        "1959608418",
        "3118608800",
        "2064675550",
        "2963911037",
        "1533861849",
        "104184427",
        "2962897886"
    ]
},{
    "id": "2949416428",
    "title": "Semi-Supervised Learning with Deep Generative Models",
    "abstract": "The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.",
    "date": "2014",
    "authors": [
        "Diederik P. Kingma",
        "Danilo J. Rezende",
        "Shakir Mohamed",
        "Max Welling"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Bayesian inference",
        "Generative grammar"
    ],
    "citation_count": "1,679",
    "reference_count": "20",
    "references": [
        "1959608418",
        "2146502635",
        "2962897886",
        "2335728318",
        "2136504847",
        "2107008379",
        "1676820704",
        "2407712691",
        "2158049734",
        "2122457239"
    ]
},{
    "id": "830076066",
    "title": "Semi-supervised learning with Ladder networks",
    "abstract": "We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on top of the Ladder network proposed by Valpola [1] which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels.",
    "date": "2015",
    "authors": [
        "Antti Rasmus",
        "Harri Valpola",
        "Mikko Honkala",
        "Mathias Berglund",
        "Tapani Raiko"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Semi-supervised learning",
        "Deep learning"
    ],
    "citation_count": "927",
    "reference_count": "39",
    "references": [
        "2964121744",
        "1836465849",
        "2095705004",
        "2963207607",
        "2100495367",
        "2145094598",
        "2294059674",
        "2963382180",
        "1479807131",
        "1606347560"
    ]
},{
    "id": "1487641199",
    "title": "Generative Moment Matching Networks",
    "abstract": "We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.",
    "date": "2015",
    "authors": [
        "Yujia Li",
        "Kevin Swersky",
        "Rich Zemel"
    ],
    "related_topics": [
        "Generative model",
        "Generative topographic map",
        "Multilayer perceptron"
    ],
    "citation_count": "532",
    "reference_count": "48",
    "references": [
        "2618530766",
        "2097117768",
        "2099471712",
        "2130942839",
        "2157331557",
        "2963542991",
        "1959608418",
        "2310919327",
        "1904365287",
        "1665214252"
    ]
},{
    "id": "2911964244",
    "title": "Random Forests",
    "abstract": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.",
    "date": "2001",
    "authors": [
        "Leo Breiman"
    ],
    "related_topics": [
        "Random forest",
        "Multivariate random variable",
        "Random subspace method"
    ],
    "citation_count": "74,573",
    "reference_count": "12",
    "references": [
        "2912934387",
        "2112076978",
        "1975846642",
        "2152761983",
        "2113242816",
        "1605688901",
        "2120240539",
        "2099968818",
        "2067885219",
        "1580948147"
    ]
},{
    "id": "2130325614",
    "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
    "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.",
    "date": "2009",
    "authors": [
        "Honglak Lee",
        "Roger Grosse",
        "Rajesh Ranganath",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Convolutional Deep Belief Networks",
        "Deep belief network",
        "Deep learning"
    ],
    "citation_count": "2,975",
    "reference_count": "26",
    "references": [
        "2136922672",
        "2100495367",
        "2162915993",
        "2116064496",
        "2110798204",
        "2166049352",
        "2147800946",
        "2145889472",
        "2122922389",
        "2139427956"
    ]
},{
    "id": "2250539671",
    "title": "Glove: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "date": "2014",
    "authors": [
        "Jeffrey Pennington",
        "Richard Socher",
        "Christopher Manning"
    ],
    "related_topics": [
        "Word2vec",
        "Word embedding",
        "Sparse matrix"
    ],
    "citation_count": "21,265",
    "reference_count": "28",
    "references": [
        "2153579005",
        "1614298861",
        "2146502635",
        "2158899491",
        "2072128103",
        "2141599568",
        "2117130368",
        "2132339004",
        "2118020653",
        "2158139315"
    ]
},{
    "id": "2962739339",
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "date": "2018",
    "authors": [
        "Matthew E. Peters",
        "Mark Neumann",
        "Mohit Iyyer",
        "Matt Gardner",
        "Christopher Clark",
        "Kenton Lee",
        "Luke Zettlemoyer"
    ],
    "related_topics": [
        "Textual entailment",
        "Text corpus",
        "Syntax"
    ],
    "citation_count": "6,430",
    "reference_count": "55",
    "references": [
        "2964121744",
        "2153579005",
        "2095705004",
        "2250539671",
        "2064675550",
        "2158899491",
        "2493916176",
        "2251939518",
        "2147880316",
        "2963748441"
    ]
},{
    "id": "2131744502",
    "title": "Distributed Representations of Sentences and Documents",
    "abstract": "Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.",
    "date": "2014",
    "authors": [
        "Quoc Le",
        "Tomas Mikolov"
    ],
    "related_topics": [
        "Topic model",
        "Feature vector",
        "Feature (machine learning)"
    ],
    "citation_count": "7,019",
    "reference_count": "41",
    "references": [
        "2153579005",
        "1614298861",
        "2158899491",
        "2131744502",
        "2251939518",
        "2141599568",
        "2117130368",
        "2132339004",
        "2158139315",
        "2113459411"
    ]
},{
    "id": "2251939518",
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "date": "2013",
    "authors": [
        "Richard Socher",
        "Alex Perelygin",
        "Jean Wu",
        "Jason Chuang",
        "Christopher D. Manning",
        "Andrew Ng",
        "Christopher Potts"
    ],
    "related_topics": [
        "Treebank",
        "Principle of compositionality",
        "Parsing"
    ],
    "citation_count": "5,158",
    "reference_count": "42",
    "references": [
        "2146502635",
        "2097726431",
        "2117130368",
        "2132339004",
        "1423339008",
        "71795751",
        "1662133657",
        "1889268436",
        "2164019165",
        "2097606805"
    ]
},{
    "id": "2963748441",
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at this https URL",
    "date": "2016",
    "authors": [
        "Pranav Rajpurkar",
        "Jian Zhang",
        "Konstantin Lopyrev",
        "Percy Liang"
    ],
    "related_topics": [
        "Question answering",
        "Reading comprehension",
        "Reading (process)"
    ],
    "citation_count": "2,862",
    "reference_count": "27",
    "references": [
        "2108598243",
        "1544827683",
        "1632114991",
        "2125436846",
        "2964267515",
        "2962809918",
        "2171278097",
        "2962790689",
        "2251818205",
        "2251349042"
    ]
},{
    "id": "2096192494",
    "title": "On the quantitative analysis of deep belief networks",
    "abstract": "Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data.",
    "date": "2008",
    "authors": [
        "Ruslan Salakhutdinov",
        "Iain Murray"
    ],
    "related_topics": [
        "Deep belief network",
        "Restricted Boltzmann machine",
        "Approximate inference"
    ],
    "citation_count": "493",
    "reference_count": "14",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2099866409",
        "2169415915",
        "2158164339",
        "66838807",
        "2064630666",
        "1513873506",
        "2135094946"
    ]
},{
    "id": "2081580037",
    "title": "WordNet: a lexical database for English",
    "abstract": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].",
    "date": "1995",
    "authors": [
        "George A. Miller"
    ],
    "related_topics": [
        "WordNet",
        "Lexical database",
        "eXtended WordNet"
    ],
    "citation_count": "21,849",
    "reference_count": "7",
    "references": [
        "2102381086",
        "2103318667",
        "2065157922",
        "1483126227",
        "2017668967",
        "1518768680",
        "13823885"
    ]
},{
    "id": "2165225968",
    "title": "Unsupervised learning of distributions on binary vectors using two layer networks",
    "abstract": "We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model can be represented by a particular type of Boltzmann machine with a bipartite graph structure that we call the combination machine. This machine is closely related to the Harmonium model defined by Smolensky. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first learning algorithm is the standard gradient ascent heuristic for computing maximum likelihood estimates for the parameters of the model. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images.",
    "date": "1991",
    "authors": [
        "Yoav Freund",
        "David Haussler"
    ],
    "related_topics": [
        "Wake-sleep algorithm",
        "Feature learning",
        "Stability (learning theory)"
    ],
    "citation_count": "401",
    "reference_count": "11",
    "references": [
        "2159080219",
        "1652505363",
        "1997063559",
        "2049633694",
        "2293063825",
        "1507849272",
        "1964724001",
        "2121407732",
        "2725061391",
        "2315016682"
    ]
},{
    "id": "2806070179",
    "title": "Mask R-CNN",
    "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron .",
    "date": "2020",
    "authors": [
        "Kaiming He",
        "Georgia Gkioxari",
        "Piotr Dollar",
        "Ross Girshick"
    ],
    "related_topics": [
        "Object detection",
        "Image segmentation",
        "Minimum bounding box"
    ],
    "citation_count": "14,729",
    "reference_count": "42",
    "references": [
        "2194775991",
        "2618530766",
        "639708223",
        "2102605133",
        "1903029394",
        "1536680647",
        "2806070179",
        "1861492603",
        "2109255472",
        "2565639579"
    ]
},{
    "id": "1861492603",
    "title": "Microsoft COCO: Common Objects in Context",
    "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
    "date": "2014",
    "authors": [
        "Tsung-Yi Lin",
        "Michael Maire",
        "Serge J. Belongie",
        "James Hays",
        "Pietro Perona",
        "Deva Ramanan",
        "Piotr Doll\u00e1r",
        "C. Lawrence Zitnick"
    ],
    "related_topics": [
        "Object detection",
        "Cognitive neuroscience of visual object recognition",
        "Minimum bounding box"
    ],
    "citation_count": "16,063",
    "reference_count": "46",
    "references": [
        "2618530766",
        "2102605133",
        "2108598243",
        "2161969291",
        "2168356304",
        "2963542991",
        "3118608800",
        "2031489346",
        "2110158442",
        "2038721957"
    ]
},{
    "id": "2565639579",
    "title": "Feature Pyramid Networks for Object Detection",
    "abstract": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.",
    "date": "2017",
    "authors": [
        "Tsung-Yi Lin",
        "Piotr Dollar",
        "Ross Girshick",
        "Kaiming He",
        "Bharath Hariharan",
        "Serge Belongie"
    ],
    "related_topics": [
        "Feature (computer vision)",
        "Pyramid",
        "Object detection"
    ],
    "citation_count": "7,099",
    "reference_count": "41",
    "references": [
        "2194775991",
        "2618530766",
        "2962835968",
        "639708223",
        "2151103935",
        "2102605133",
        "2117539524",
        "1901129140",
        "1903029394",
        "2161969291"
    ]
},{
    "id": "2053186076",
    "title": "Nonlinear dimensionality reduction by locally linear embedding.",
    "abstract": "Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.",
    "date": "2000",
    "authors": [
        "Sam T. Roweis",
        "Lawrence K. Saul"
    ],
    "related_topics": [
        "Diffusion map",
        "Dimensionality reduction",
        "t-distributed stochastic neighbor embedding"
    ],
    "citation_count": "16,281",
    "reference_count": "12",
    "references": [
        "1902027874",
        "2610857016",
        "1991848143",
        "2107636931",
        "2121122425",
        "2122538988",
        "2047870719",
        "2070320140",
        "1513400187",
        "2019020850"
    ]
},{
    "id": "2001141328",
    "title": "A Global Geometric Framework for Nonlinear Dimensionality Reduction",
    "abstract": "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.",
    "date": "2000",
    "authors": [
        "J. B. Tenenbaum",
        "V. de Silva",
        "J. C. Langford"
    ],
    "related_topics": [
        "Diffusion map",
        "Dimensionality reduction",
        "Nonlinear dimensionality reduction"
    ],
    "citation_count": "14,796",
    "reference_count": "22",
    "references": [
        "2138451337",
        "2099741732",
        "2108384452",
        "2123977795",
        "2587818897",
        "2107636931",
        "2122538988",
        "2047870719",
        "2070320140",
        "2032647857"
    ]
},{
    "id": "2121122425",
    "title": "Dimension reduction by local principal component analysis",
    "abstract": "Reducing or eliminating statistical redundancy between the components of high-dimensional vector data enables a lower-dimensional representation without significant loss of information. Recognizing the limitations of principal component analysis (PCA), researchers in the statistics and neural network communities have developed nonlinear extensions of PCA. This article develops a local linear approach to dimension reduction that provides accurate representations and is fast to compute. We exercise the algorithms on speech and image data, and compare performance with PCA and with neural network implementations of nonlinear PCA. We find that both nonlinear techniques can provide more accurate representations than PCA and show that the local linear techniques outperform neural network implementations.",
    "date": "1997",
    "authors": [
        "Nandakishore Kambhatla",
        "Todd K. Leen"
    ],
    "related_topics": [
        "Sparse PCA",
        "Principal component analysis",
        "Dimensionality reduction"
    ],
    "citation_count": "787",
    "reference_count": "36",
    "references": [
        "2137983211",
        "3004157836",
        "2140196014",
        "1634005169",
        "3146803896",
        "1971735090",
        "2913399920",
        "2122538988",
        "2096710051",
        "2017977879"
    ]
},{
    "id": "2032647857",
    "title": "Replicator neural networks for universal optimal source coding.",
    "abstract": "Replicator neural networks self-organize by using their inputs as desired outputs; they internally form a compressed representation for the input data. A theorem shows that a class of replicator networks can, through the minimization of mean squared reconstruction error (for instance, by training on raw data examples), carry out optimal data compression for arbitrary data vector sources. Data manifolds, a new general model of data sources, are then introduced and a second theorem shows that, in a practically important limiting case, optimal-compression replicator networks operate by creating an essentially unique natural coordinate system for the manifold.",
    "date": "1995",
    "authors": [
        "Robert Hecht-Nielsen"
    ],
    "related_topics": [
        "Artificial neural network",
        "Data compression",
        "Manifold"
    ],
    "citation_count": "179",
    "reference_count": "14",
    "references": [
        "2137983211",
        "2166116275",
        "1993845689",
        "2122538988",
        "5731987",
        "2142228262",
        "2063971957",
        "2079782346",
        "2089419199",
        "2162604518"
    ]
},{
    "id": "2021774695",
    "title": "Learning sets of filters using back-propagation",
    "abstract": "Abstract A learning procedure, called back-propagation, for layered networks of deterministic, neuron-like units has been described previously. The ability of the procedure automatically to discover useful internal representations makes it a powerful tool for attacking difficult problems like speech recognition. This paper describes further research on the learning procedure and presents an example in which a network learns a set of filters that enable it to discriminate formant-like patterns in the presence of noise. The generality of the learning procedure is illustrated by a second example in which a similar network learns an edge detection task. The speed of learning is strongly dependent on the shape of the surface formed by the error measure in \u201cweight space\u201d. Examples are given of the error surface for a simple task and an acceleration method that speeds up descent in weight space is illustrated. The main drawback of the learning procedure is the way it scales as the size of the task and the network increases. Some preliminary results on scaling are reported and it is shown how the magnitude of the optimal weight changes depends on the fan-in of the units. Additional results show how the amount of interaction between the weights affects the learning speed. The paper is concluded with a discussion of the difficulties that are likely to be encounted in applying back-propagation to more realistic problems in speech recognition, and some promising approaches to overcoming these difficulties.",
    "date": "1987",
    "authors": [
        "David C. Plaut",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Multi-task learning",
        "Active learning (machine learning)",
        "Semi-supervised learning"
    ],
    "citation_count": "156",
    "reference_count": "8",
    "references": [
        "2154642048",
        "1652505363",
        "1498436455",
        "1507849272",
        "2155487652",
        "1995169133",
        "2591802459",
        "2010581677"
    ]
},{
    "id": "2156718197",
    "title": "Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering",
    "abstract": "Drawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered.",
    "date": "2001",
    "authors": [
        "Mikhail Belkin",
        "Partha Niyogi"
    ],
    "related_topics": [
        "Spectral clustering",
        "Manifold alignment",
        "Laplacian matrix"
    ],
    "citation_count": "4,960",
    "reference_count": "5",
    "references": [
        "2053186076",
        "2121947440",
        "2001141328",
        "1578099820",
        "108654854"
    ]
},{
    "id": "2125637308",
    "title": "Random Walks for Image Segmentation",
    "abstract": "A novel method is proposed for performing multilabel, interactive image segmentation. Given a small number of pixels with user-defined (or predefined) labels, one can analytically and quickly determine the probability that a random walker starting at each unlabeled pixel will first reach one of the prelabeled pixels. By assigning each pixel to the label for which the greatest probability is calculated, a high-quality image segmentation may be obtained. Theoretical properties of this algorithm are developed along with the corresponding connections to discrete potential theory and electrical circuits. This algorithm is formulated in discrete space (i.e., on a graph) using combinatorial analogues of standard operators and principles from continuous potential theory, allowing it to be applied in arbitrary dimension on arbitrary graphs",
    "date": "2006",
    "authors": [
        "L. Grady"
    ],
    "related_topics": [
        "Random walker algorithm",
        "Image segmentation",
        "Scale-space segmentation"
    ],
    "citation_count": "2,812",
    "reference_count": "76",
    "references": [
        "2296319761",
        "3029645440",
        "2177274842",
        "2121947440",
        "2124351162",
        "2143516773",
        "2104095591",
        "1578099820",
        "2169551590",
        "2150134853"
    ]
},{
    "id": "2139823104",
    "title": "Semi-supervised learning using Gaussian fields and harmonic functions",
    "abstract": "An approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm's ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.",
    "date": "2003",
    "authors": [
        "Xiaojin Zhu",
        "Zoubin Ghahramani",
        "John Lafferty"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Empirical risk minimization"
    ],
    "citation_count": "4,300",
    "reference_count": "21",
    "references": [
        "2121947440",
        "2143516773",
        "2165874743",
        "2154579312",
        "2122837498",
        "1511160855",
        "1585385982",
        "1979711143",
        "2113592823",
        "200434350"
    ]
},{
    "id": "2137570937",
    "title": "Dimensionality Reduction: A Comparative Review",
    "abstract": "In recent years, a variety of nonlinear dimensionality reduction techniques have been proposed that aim to address the limitations of traditional techniques such as PCA and classical scaling. The paper presents a review and systematic comparison of these techniques. The performances of the nonlinear techniques are investigated on artificial and natural tasks. The results of the experiments reveal that nonlinear techniques perform well on selected artificial tasks, but that this strong performance does not necessarily extend to real-world tasks. The paper explains these results by identifying weaknesses of current nonlinear techniques, and suggests how the performance of nonlinear dimensionality reduction techniques may be improved.",
    "date": "2008",
    "authors": [
        "Laurens van der Maaten",
        "Eric Postma",
        "Jaap van den Herik"
    ],
    "related_topics": [
        "Dimensionality reduction",
        "Nonlinear dimensionality reduction",
        "Nonlinear system"
    ],
    "citation_count": "1,358",
    "reference_count": "160",
    "references": [
        "2296319761",
        "2136922672",
        "1880262756",
        "2100495367",
        "2187089797",
        "1497256448",
        "2072128103",
        "2053186076",
        "2121947440",
        "2116064496"
    ]
},{
    "id": "2157444450",
    "title": "Stochastic Neighbor Embedding",
    "abstract": "We describe a probabilistic approach to the task of placing objects, described by high-dimensional vectors or by pairwise dissimilarities, in a low-dimensional space in a way that preserves neighbor identities. A Gaussian is centered on each object in the high-dimensional space and the densities under this Gaussian (or the given dissimilarities) are used to define a probability distribution over all the potential neighbors of the object. The aim of the embedding is to approximate this distribution as well as possible when the same operation is performed on the low-dimensional \"images\" of the objects. A natural cost function is a sum of Kullback-Leibler divergences, one per object, which leads to a simple gradient for adjusting the positions of the low-dimensional images. Unlike other dimensionality reduction methods, this probabilistic framework makes it easy to represent each object by a mixture of widely separated low-dimensional images. This allows ambiguous objects, like the document count vector for the word \"bank\", to have versions close to the images of both \"river\" and \"finance\" without forcing the images of outdoor concepts to be located close to those of corporate concepts.",
    "date": "2001",
    "authors": [
        "Geoffrey E. Hinton",
        "Sam T. Roweis"
    ],
    "related_topics": [
        "t-distributed stochastic neighbor embedding",
        "Dimensionality reduction",
        "Object (grammar)"
    ],
    "citation_count": "1,538",
    "reference_count": "9",
    "references": [
        "2053186076",
        "2001141328",
        "2148694408",
        "1991848143",
        "2107636931",
        "23758216",
        "2100659887",
        "2159174312",
        "2106346128"
    ]
},{
    "id": "1742512077",
    "title": "Nonlinear Dimensionality Reduction",
    "abstract": "Methods of dimensionality reduction provide a way to understand and visualize the structure of complex data sets. Traditional methods like principal component analysis and classical metric multidimensional scaling suffer from being based on linear models. Until recently, very few methods were able to reduce the data dimensionality in a nonlinear way. However, since the late nineties, many new methods have been developed and nonlinear dimensionality reduction, also called manifold learning, has become a hot topic. New advances that account for this rapid growth are, e.g. the use of graphs to represent the manifold topology, and the use of new metrics like the geodesic distance. In addition, new optimization schemes, based on kernel techniques and spectral decomposition, have lead to spectral embedding, which encompasses many of the recently developed methods. This book describes existing and advanced methods to reduce the dimensionality of numerical databases. For each method, the description starts from intuitive ideas, develops the necessary mathematical details, and ends by outlining the algorithmic implementation. Methods are compared with each other with the help of different illustrative examples. The purpose of the book is to summarize clear facts and ideas about well-known methods as well as recent developments in the topic of nonlinear dimensionality reduction. With this goal in mind, methods are all described from a unifying point of view, in order to highlight their respective strengths and shortcomings. The book is primarily intended for statisticians, computer scientists and data analysts. It is also accessible to other practitioners having a basic background in statistics and/or computational learning, like psychologists (in psychometry) and economists.",
    "date": "2007",
    "authors": [
        "John A. Lee",
        "Michel Verleysen"
    ],
    "related_topics": [
        "Dimensionality reduction",
        "Nonlinear dimensionality reduction",
        "Curse of dimensionality"
    ],
    "citation_count": "1,682",
    "reference_count": "0",
    "references": []
},{
    "id": "2116064496",
    "title": "Training products of experts by minimizing contrastive divergence",
    "abstract": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual \"expert\" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called \"contrastive divergence\" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.",
    "date": "2002",
    "authors": [
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Product of experts",
        "Deep belief network",
        "Conditional independence"
    ],
    "citation_count": "5,168",
    "reference_count": "23",
    "references": [
        "1652505363",
        "1997063559",
        "2096175520",
        "1746680969",
        "1993845689",
        "2165225968",
        "2083380015",
        "2114153178",
        "1547224907",
        "2101706260"
    ]
},{
    "id": "2134557905",
    "title": "Learning methods for generic object recognition with invariance to pose and lighting",
    "abstract": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second.",
    "date": "2004",
    "authors": [
        "Y. LeCun",
        "Fu Jie Huang",
        "L. Bottou"
    ],
    "related_topics": [
        "Object detection",
        "Image segmentation",
        "Support vector machine"
    ],
    "citation_count": "1,463",
    "reference_count": "28",
    "references": [
        "2164598857",
        "2310919327",
        "2217896605",
        "2124087378",
        "2124351082",
        "2123977795",
        "2155511848",
        "2160225842",
        "2295106276",
        "2141376824"
    ]
},{
    "id": "2099866409",
    "title": "Restricted Boltzmann machines for collaborative filtering",
    "abstract": "Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system.",
    "date": "2007",
    "authors": [
        "Ruslan Salakhutdinov",
        "Andriy Mnih",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Restricted Boltzmann machine",
        "Boltzmann machine",
        "Collaborative filtering"
    ],
    "citation_count": "2,063",
    "reference_count": "15",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2147152072",
        "1612003148",
        "2122090912",
        "2158164339",
        "2124914669",
        "205159212",
        "2165395308"
    ]
},{
    "id": "2536626143",
    "title": "Attribute and simile classifiers for face verification",
    "abstract": "We present two novel methods for face verification. Our first method - \u201cattribute\u201d classifiers - uses binary classifiers trained to recognize the presence or absence of describable aspects of visual appearance (e.g., gender, race, and age). Our second method - \u201csimile\u201d classifiers - removes the manual labeling required for attribute classification and instead learns the similarity of faces, or regions of faces, to specific reference people. Neither method requires costly, often brittle, alignment between image pairs; yet, both methods produce compact visual descriptions, and work on real-world images. Furthermore, both the attribute and simile classifiers improve on the current state-of-the-art for the LFW data set, reducing the error rates compared to the current best by 23.92% and 26.34%, respectively, and 31.68% when combined. For further testing across pose, illumination, and expression, we introduce a new data set - termed PubFig - of real-world images of public figures (celebrities and politicians) acquired from the internet. This data set is both larger (60,000 images) and deeper (300 images per individual) than existing data sets of its kind. Finally, we present an evaluation of human performance.",
    "date": "2009",
    "authors": [
        "Neeraj Kumar",
        "Alexander C. Berg",
        "Peter N. Belhumeur",
        "Shree K. Nayar"
    ],
    "related_topics": [
        "Feature extraction",
        "Facial recognition system",
        "Face (geometry)"
    ],
    "citation_count": "1,675",
    "reference_count": "32",
    "references": [
        "2151103935",
        "2119821739",
        "1782590233",
        "1989702938",
        "2112076978",
        "2033419168",
        "2123921160",
        "2098947662",
        "2905573712",
        "2155759509"
    ]
},{
    "id": "2157364932",
    "title": "Learning a similarity metric discriminatively, with application to face verification",
    "abstract": "We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the \"semantic\" distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.",
    "date": "2005",
    "authors": [
        "S. Chopra",
        "R. Hadsell",
        "Y. LeCun"
    ],
    "related_topics": [
        "Facial recognition system",
        "Norm (mathematics)",
        "Discriminative model"
    ],
    "citation_count": "2,924",
    "reference_count": "17",
    "references": [
        "2310919327",
        "2053186076",
        "2138451337",
        "2121647436",
        "2095757522",
        "2994340921",
        "2144354855",
        "2107369107",
        "1802356529",
        "10021998"
    ]
},{
    "id": "2156909104",
    "title": "The Nature of Statistical Learning Theory",
    "abstract": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.",
    "date": "1994",
    "authors": [
        "Vladimir N. Vapnik"
    ],
    "related_topics": [
        "Algorithmic learning theory",
        "Statistical learning theory",
        "Computational learning theory"
    ],
    "citation_count": "67,838",
    "reference_count": "0",
    "references": []
},{
    "id": "2296616510",
    "title": "Compressed sensing",
    "abstract": "Suppose x is an unknown vector in Ropfm (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m1/4log5/2(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscrp ball for 0<ples1. The N most important coefficients in that expansion allow reconstruction with lscr2 error O(N1/2-1p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscrp balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces",
    "date": "2003",
    "authors": [
        "D.L. Donoho"
    ],
    "related_topics": [
        "Basis pursuit",
        "Orthonormal basis",
        "Linear combination"
    ],
    "citation_count": "17,696",
    "reference_count": "20",
    "references": [
        "2145096794",
        "2078204800",
        "2116148865",
        "2099641086",
        "2097323375",
        "2136235822",
        "2147656689",
        "2012365979",
        "2096613063",
        "2050880896"
    ]
},{
    "id": "2129131372",
    "title": "Decoding by linear programming",
    "abstract": "This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.",
    "date": "2005",
    "authors": [
        "E.J. Candes",
        "T. Tao"
    ],
    "related_topics": [
        "Underdetermined system",
        "Linear code",
        "Sigma"
    ],
    "citation_count": "7,866",
    "reference_count": "29",
    "references": [
        "2296319761",
        "2296616510",
        "2145096794",
        "2129638195",
        "2078204800",
        "2116148865",
        "2099641086",
        "2050834445",
        "2154332973",
        "2136235822"
    ]
},{
    "id": "2119821739",
    "title": "Support-Vector Networks",
    "abstract": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.",
    "date": "1995",
    "authors": [
        "Corinna Cortes",
        "Vladimir Vapnik"
    ],
    "related_topics": [
        "Feature learning",
        "Active learning (machine learning)",
        "Feature vector"
    ],
    "citation_count": "48,415",
    "reference_count": "14",
    "references": [
        "2154642048",
        "1498436455",
        "2087347434",
        "2154579312",
        "1530699444",
        "2168228682",
        "2504871398",
        "1568787085",
        "5594912",
        "2322002063"
    ]
},{
    "id": "2161969291",
    "title": "Histograms of oriented gradients for human detection",
    "abstract": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.",
    "date": "2005",
    "authors": [
        "N. Dalal",
        "B. Triggs"
    ],
    "related_topics": [
        "Histogram of oriented gradients",
        "Local binary patterns",
        "GLOH"
    ],
    "citation_count": "36,483",
    "reference_count": "22",
    "references": [
        "2151103935",
        "2177274842",
        "2145072179",
        "1576520375",
        "2172188317",
        "2152473410",
        "1992825118",
        "1608462934",
        "2295106276",
        "2156539399"
    ]
},{
    "id": "2162915993",
    "title": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories",
    "abstract": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u0092s \"gist\" and Lowe\u0092s SIFT descriptors.",
    "date": "2006",
    "authors": [
        "S. Lazebnik",
        "C. Schmid",
        "J. Ponce"
    ],
    "related_topics": [
        "Pyramid (image processing)",
        "Pyramid",
        "Bag-of-words model in computer vision"
    ],
    "citation_count": "9,928",
    "reference_count": "28",
    "references": [
        "1880262756",
        "2154422044",
        "2107034620",
        "1566135517",
        "2166049352",
        "2104978738",
        "2914885528",
        "2168002178",
        "2134731454",
        "2165828254"
    ]
},{
    "id": "2097018403",
    "title": "Linear spatial pyramid matching using sparse coding for image classification",
    "abstract": "Recently SVMs using spatial pyramid matching (SPM) kernel have been highly successful in image classification. Despite its popularity, these nonlinear SVMs have a complexity O(n2 ~ n3) in training and O(n) in testing, where n is the training size, implying that it is nontrivial to scaleup the algorithms to handle more than thousands of training images. In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and propose a linear SPM kernel based on SIFT sparse codes. This new approach remarkably reduces the complexity of SVMs to O(n) in training and a constant in testing. In a number of image categorization experiments, we find that, in terms of classification accuracy, the suggested linear SPM based on sparse coding of SIFT descriptors always significantly outperforms the linear SPM kernel on histograms, and is even better than the nonlinear SPM kernels, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors.",
    "date": "2009",
    "authors": [
        "Jianchao Yang",
        "Kai Yu",
        "Yihong Gong",
        "Thomas Huang"
    ],
    "related_topics": [
        "Support vector machine",
        "Kernel (image processing)",
        "Contextual image classification"
    ],
    "citation_count": "3,781",
    "reference_count": "28",
    "references": [
        "2153635508",
        "2162915993",
        "1576445103",
        "2153663612",
        "2107034620",
        "1566135517",
        "2166049352",
        "2113606819",
        "2161516371",
        "1624854622"
    ]
},{
    "id": "2166049352",
    "title": "Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories",
    "abstract": "Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.",
    "date": "2007",
    "authors": [
        "Li Fei-Fei",
        "Rob Fergus",
        "Pietro Perona"
    ],
    "related_topics": [
        "Generative model",
        "Learning object",
        "Caltech 101"
    ],
    "citation_count": "8,240",
    "reference_count": "18",
    "references": [
        "2164598857",
        "2124386111",
        "2154422044",
        "2124087378",
        "2155511848",
        "1516111018",
        "1949116567",
        "1746680969",
        "2567948266",
        "1699734612"
    ]
},{
    "id": "1639032689",
    "title": "Genetic algorithms in search, optimization, and machine learning",
    "abstract": "From the Publisher: This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.",
    "date": "1988",
    "authors": [
        "David E. Goldberg"
    ],
    "related_topics": [
        "Genetic representation",
        "Genetic programming",
        "Pascal (programming language)"
    ],
    "citation_count": "108,858",
    "reference_count": "0",
    "references": []
},{
    "id": "2154642048",
    "title": "Learning internal representations by error propagation",
    "abstract": "This chapter contains sections titled: The Problem, The Generalized Delta Rule, Simulation Results, Some Further Generalizations, Conclusion",
    "date": "1987",
    "authors": [
        "D. E. Rumelhart",
        "G. E. Hinton",
        "R. J. Williams"
    ],
    "related_topics": [
        "Delta rule",
        "Semi-supervised learning",
        "Backpropagation"
    ],
    "citation_count": "31,294",
    "reference_count": "23",
    "references": [
        "2154642048",
        "1652505363",
        "1535810436",
        "1507849272",
        "2101926813",
        "2073257493",
        "2021878536",
        "1490454746",
        "2115647291",
        "1505136099"
    ]
},{
    "id": "3017143921",
    "title": "Pattern classification and scene analysis",
    "abstract": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis.",
    "date": "1972",
    "authors": [
        "Richard O. Duda",
        "Peter E. Hart"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Cluster analysis",
        "Linear discriminant analysis"
    ],
    "citation_count": "21,861",
    "reference_count": "0",
    "references": []
},{
    "id": "2100677568",
    "title": "Learning to Predict by the Methods of Temporal Differences",
    "abstract": "This article introduces a class of incremental learning procedures specialized for prediction \u2013 that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.",
    "date": "1988",
    "authors": [
        "Richard S. Sutton"
    ],
    "related_topics": [
        "Temporal difference learning",
        "Supervised learning",
        "Heuristic"
    ],
    "citation_count": "6,363",
    "reference_count": "33",
    "references": [
        "2154642048",
        "1652505363",
        "2895674046",
        "1535810436",
        "1507849272",
        "2178806388",
        "1596324102",
        "1583833196",
        "1569296262",
        "2075379212"
    ]
},{
    "id": "1535810436",
    "title": "Adaptive switching circuits",
    "abstract": "",
    "date": "1987",
    "authors": [
        "Bernard Widrow",
        "Marcian E. Hoff"
    ],
    "related_topics": [
        "Computer science",
        "Electronic circuit",
        "Electronic engineering"
    ],
    "citation_count": "5,028",
    "reference_count": "0",
    "references": []
},{
    "id": "1603765807",
    "title": "Parallel and Distributed Computation: Numerical Methods",
    "abstract": "",
    "date": "1988",
    "authors": [
        "Dimitri P. Bertsekas",
        "John N. Tsitsiklis"
    ],
    "related_topics": [
        "Distributed design patterns",
        "Distributed algorithm",
        "Computation"
    ],
    "citation_count": "8,462",
    "reference_count": "0",
    "references": []
},{
    "id": "3011120880",
    "title": "Learning from delayed rewards",
    "abstract": "",
    "date": "1988",
    "authors": [
        "C. J. C. H. Watkins"
    ],
    "related_topics": [
        "Computer science",
        "Cognitive psychology",
        "Q learning algorithm"
    ],
    "citation_count": "8,088",
    "reference_count": "0",
    "references": []
},{
    "id": "1569320505",
    "title": "Adaptive filtering prediction and control",
    "abstract": "This unified survey focuses on linear discrete-time systems and explores the natural extensions to nonlinear systems. In keeping with the importance of computers to practical applications, the authors emphasize discrete-time systems. Their approach summarizes the theoretical and practical aspects of a large class of adaptive algorithms.1984 edition.",
    "date": "1983",
    "authors": [
        "Graham C. Goodwin",
        "Kwai Sang Sin"
    ],
    "related_topics": [
        "Control theory",
        "Adaptive filter",
        "Nonlinear system"
    ],
    "citation_count": "6,699",
    "reference_count": "0",
    "references": []
},{
    "id": "94523489",
    "title": "Radial Basis Functions, Multi-Variable Functional Interpolation and Adaptive Networks",
    "abstract": "Abstract : The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed. This leads naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks. A class of adaptive networks is identified which makes the interpolation scheme explicit. This class has the property that learning is equivalent to the solution of a set of linear equations. These networks thus represent nonlinear relationships while having a guaranteed learning rule. Great Britain.",
    "date": "1988",
    "authors": [
        "David S. Broomhead",
        "David Lowe"
    ],
    "related_topics": [
        "Interpolation",
        "Linear interpolation",
        "Bilinear interpolation"
    ],
    "citation_count": "5,007",
    "reference_count": "0",
    "references": []
},{
    "id": "2178806388",
    "title": "Some studies in machine learning using the game of checkers",
    "abstract": "Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done by verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.",
    "date": "1995",
    "authors": [
        "Arthur L. Samuel"
    ],
    "related_topics": [
        "Rote learning",
        "Artificial intelligence",
        "Period (music)"
    ],
    "citation_count": "3,436",
    "reference_count": "0",
    "references": []
},{
    "id": "2126316555",
    "title": "A Survey of Monte Carlo Tree Search Methods",
    "abstract": "Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.",
    "date": "2012",
    "authors": [
        "C. B. Browne",
        "E. Powley",
        "D. Whitehouse",
        "S. M. Lucas",
        "P. I. Cowling",
        "P. Rohlfshagen",
        "S. Tavener",
        "D. Perez",
        "S. Samothrakis",
        "S. Colton"
    ],
    "related_topics": [
        "Monte Carlo tree search",
        "Computer Go",
        "General game playing"
    ],
    "citation_count": "2,344",
    "reference_count": "214",
    "references": [
        "2122410182",
        "2168405694",
        "1625390266",
        "1714211023",
        "131069610",
        "2171084228",
        "2020135152",
        "1888434271",
        "1510812122",
        "1500868819"
    ]
},{
    "id": "1515851193",
    "title": "Introduction to Reinforcement Learning",
    "abstract": "From the Publisher: In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.",
    "date": "1998",
    "authors": [
        "Richard S. Sutton",
        "Andrew G. Barto"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Temporal difference learning",
        "Q-learning"
    ],
    "citation_count": "6,402",
    "reference_count": "0",
    "references": []
},{
    "id": "1625390266",
    "title": "Bandit based monte-carlo planning",
    "abstract": "For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.",
    "date": "2006",
    "authors": [
        "Levente Kocsis",
        "Csaba Szepesv\u00e1ri"
    ],
    "related_topics": [
        "Monte Carlo tree search",
        "Monte Carlo method",
        "Decision problem"
    ],
    "citation_count": "3,101",
    "reference_count": "12",
    "references": [
        "2168405694",
        "2077902449",
        "2101861158",
        "2009551863",
        "1512919909",
        "1551466210",
        "1863869622",
        "2016647253",
        "1562282139",
        "2135997697"
    ]
},{
    "id": "1502916507",
    "title": "Similarity Search in High Dimensions via Hashing",
    "abstract": "The nearestor near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately, all known techniques for solving this problem fall prey to the \\curse of dimensionality.\" That is, the data structures scale poorly with data dimensionality; in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should su ce for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points Supported by NAVY N00014-96-1-1221 grant and NSF Grant IIS-9811904. Supported by Stanford Graduate Fellowship and NSF NYI Award CCR-9357849. Supported by ARO MURI Grant DAAH04-96-1-0007, NSF Grant IIS-9811904, and NSF Young Investigator Award CCR9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 25th VLDB Conference, Edinburgh, Scotland, 1999. from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our method gives signi cant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition. Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50).",
    "date": "1999",
    "authors": [
        "Aristides Gionis",
        "Piotr Indyk",
        "Rajeev Motwani"
    ],
    "related_topics": [
        "Nearest neighbor search",
        "Locality-sensitive hashing",
        "Very large database"
    ],
    "citation_count": "4,138",
    "reference_count": "39",
    "references": [
        "2147152072",
        "2147717514",
        "1634005169",
        "2295428206",
        "1956559956",
        "2125148312",
        "2160066518",
        "3017143921",
        "2074429597",
        "1541459201"
    ]
},{
    "id": "2099587183",
    "title": "General Game Playing: Overview of the AAAI Competition",
    "abstract": "A general game playing system is one that can accept a formal description of a game and play the game effectively without human intervention. Unlike specialized game players, such as Deep Blue, general game players do not rely on algorithms designed in advance for specific games; and, unlike Deep Blue, they are able to play different kinds of games. In order to promote work in this area, the AAAI is sponsoring an open competition at this summer's Twentieth National Conference on Artificial Intelligence. This article is an overview of the technical issues and logistics associated with this summer's competition, as well as the relevance of general game playing to the long range-goals of artificial intelligence.",
    "date": "2005",
    "authors": [
        "Michael R. Genesereth",
        "Nathaniel Love",
        "Barney Pell"
    ],
    "related_topics": [
        "General game playing",
        "General video game playing",
        "Game design"
    ],
    "citation_count": "616",
    "reference_count": "4",
    "references": [
        "1981627423",
        "1572038152",
        "2119409989",
        "3025398977"
    ]
},{
    "id": "2013391942",
    "title": "Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability",
    "abstract": "This book presents sequential decision theory from a novel algorithmic information theory perspective. While the former is suited for active agents in known environment, the latter is suited for passive prediction in unknown environment. The book introduces these two well-known but very different ideas and removes the limitations by unifying them to one parameter-free theory of an optimal reinforcement learning agent embedded in an arbitrary unknown environment. Most AI problems can easily be formulated within this theory, which reduces the conceptual problems to pure computational problems. Considered problem classes include sequence prediction, strategic games, function minimization, reinforcement and supervised learning. The discussion includes formal definitions of intelligence order relations, the horizon problem and relations to other approaches to AI. One intention of this book is to excite a broader AI audience about abstract algorithmic information theory concepts, and conversely to inform theorists about exciting applications to AI.",
    "date": "2004",
    "authors": [
        "Marcus Hutter"
    ],
    "related_topics": [
        "Algorithmic learning theory",
        "Reinforcement learning",
        "Algorithmic probability"
    ],
    "citation_count": "709",
    "reference_count": "0",
    "references": []
},{
    "id": "2101355568",
    "title": "An object-oriented representation for efficient reinforcement learning",
    "abstract": "Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the well-known Taxi domain, plus a real-life videogame.",
    "date": "2008",
    "authors": [
        "Carlos Diuk",
        "Andre Cohen",
        "Michael L. Littman"
    ],
    "related_topics": [
        "Learning classifier system",
        "Reinforcement learning",
        "Robot learning"
    ],
    "citation_count": "270",
    "reference_count": "102",
    "references": [
        "2122410182",
        "1506806321",
        "2121863487",
        "2168405694",
        "1515851193",
        "1625390266",
        "2119567691",
        "2107726111",
        "1576452626",
        "2168359464"
    ]
},{
    "id": "2132622533",
    "title": "Horde: a scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction",
    "abstract": "Maintaining accurate world knowledge in a complex and changing environment is a perennial problem for robots and other artificial intelligence systems. Our architecture for addressing this problem, called Horde, consists of a large number of independent reinforcement learning sub-agents, or demons. Each demon is responsible for answering a single predictive or goal-oriented question about the world, thereby contributing in a factored, modular way to the system's overall knowledge. The questions are in the form of a value function, but each demon has its own policy, reward function, termination function, and terminal-reward function unrelated to those of the base problem. Learning proceeds in parallel by all demons simultaneously so as to extract the maximal training information from whatever actions are taken by the system as a whole. Gradient-based temporal-difference learning methods are used to learn efficiently and reliably with function approximation in this off-policy setting. Horde runs in constant time and memory per time step, and is thus suitable for learning online in real-time applications such as robotics. We present results using Horde on a multi-sensored mobile robot to successfully learn goal-oriented behaviors and long-term predictions from off-policy experience. Horde is a significant incremental step towards a real-time architecture for efficient learning of general knowledge from unsupervised sensorimotor interaction.",
    "date": "2011",
    "authors": [
        "Richard S. Sutton",
        "Joseph Modayil",
        "Michael Delp",
        "Thomas Degris",
        "Patrick M. Pilarski",
        "Adam White",
        "Doina Precup"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Robot learning",
        "Reinforcement learning"
    ],
    "citation_count": "368",
    "reference_count": "24",
    "references": [
        "2121863487",
        "1515851193",
        "2100677568",
        "2109910161",
        "2075268401",
        "2062937587",
        "1491843047",
        "2149390907",
        "2134042548",
        "13294968"
    ]
},{
    "id": "179875071",
    "title": "Recurrent neural network based language model",
    "abstract": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition",
    "date": "2009",
    "authors": [
        "Tomas Mikolov",
        "Martin Karafi\u00e1t",
        "Luk\u00e1s Burget",
        "Jan Cernock\u00fd",
        "Sanjeev Khudanpur"
    ],
    "related_topics": [
        "Time delay neural network",
        "Language model",
        "Recurrent neural network"
    ],
    "citation_count": "5,539",
    "reference_count": "14",
    "references": [
        "2132339004",
        "2110485445",
        "2107878631",
        "36903255",
        "2096072088",
        "2468573742",
        "2152808281",
        "2292896937",
        "2027499299",
        "2437096199"
    ]
},{
    "id": "2147152072",
    "title": "Indexing by Latent Semantic Analysis",
    "abstract": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.",
    "date": "1990",
    "authors": [
        "Scott Deerwester",
        "Susan T. Dumais",
        "George W. Furnas",
        "Thomas K. Landauer",
        "Richard Harshman"
    ],
    "related_topics": [
        "Document-term matrix",
        "Latent semantic analysis",
        "Vector space model"
    ],
    "citation_count": "17,225",
    "reference_count": "26",
    "references": [
        "1956559956",
        "1984565341",
        "1964262399",
        "2000215628",
        "2114804204",
        "2151561903",
        "3012395598",
        "1965061793",
        "2024683548",
        "2096411881"
    ]
},{
    "id": "1632114991",
    "title": "Building a large annotated corpus of English: the penn treebank",
    "abstract": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant.",
    "date": "1993",
    "authors": [
        "Mitchell P. Marcus",
        "Mary Ann Marcinkiewicz",
        "Beatrice Santorini"
    ],
    "related_topics": [
        "Corpus linguistics",
        "Brown Corpus",
        "Treebank"
    ],
    "citation_count": "9,170",
    "reference_count": "12",
    "references": [
        "2099247782",
        "1483126227",
        "2439178139",
        "2334801970",
        "900993354",
        "2110190189",
        "2012837062",
        "2121407024",
        "2076526090",
        "2166675302"
    ]
},{
    "id": "1970689298",
    "title": "Continuous space language models",
    "abstract": "This paper describes the use of a neural network language model for large vocabulary continuous speech recognition. The underlying idea of this approach is to attack the data sparseness problem by performing the language model probability estimation in a continuous space. Highly efficient learning algorithms are described that enable the use of training corpora of several hundred million words. It is also shown that this approach can be incorporated into a large vocabulary continuous speech recognizer using a lattice rescoring framework at a very low additional processing time. The neural network language model was thoroughly evaluated in a state-of-the-art large vocabulary continuous speech recognizer for several international benchmark tasks, in particular the Nist evaluations on broadcast news and conversational speech recognition. The new approach is compared to four-gram back-off language models trained with modified Kneser-Ney smoothing which has often been reported to be the best known smoothing method. Usually the neural network language model is interpolated with the back-off language model. In that way, consistent word error rate reductions for all considered tasks and languages were achieved, ranging from 0.4% to almost 1% absolute.",
    "date": "2007",
    "authors": [
        "Holger Schwenk"
    ],
    "related_topics": [
        "Cache language model",
        "Language model",
        "Vocabulary"
    ],
    "citation_count": "604",
    "reference_count": "63",
    "references": [
        "2148603752",
        "1554663460",
        "2912934387",
        "2132339004",
        "2147152072",
        "1631260214",
        "2096175520",
        "2110485445",
        "36903255",
        "2158195707"
    ]
},{
    "id": "2130903752",
    "title": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data",
    "abstract": "One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting.",
    "date": "2005",
    "authors": [
        "Rie Kubota Ando",
        "Tong Zhang"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Instance-based learning"
    ],
    "citation_count": "1,514",
    "reference_count": "26",
    "references": [
        "2148603752",
        "1480376833",
        "2154455818",
        "2139823104",
        "2048679005",
        "2097089247",
        "2107008379",
        "2914746235",
        "2010353172",
        "2101210369"
    ]
},{
    "id": "2158847908",
    "title": "The Proposition Bank: An Annotated Corpus of Semantic Roles",
    "abstract": "The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated.We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty ''trace'' categories of the treebank.",
    "date": "2005",
    "authors": [
        "Martha Palmer",
        "Daniel Gildea",
        "Paul Kingsbury"
    ],
    "related_topics": [
        "Treebank",
        "Semantic role labeling",
        "Explicit semantic analysis"
    ],
    "citation_count": "2,678",
    "reference_count": "57",
    "references": [
        "1632114991",
        "1535015163",
        "2092654472",
        "2115792525",
        "2151170651",
        "3021452258",
        "2039217078",
        "1567277581",
        "2126851059",
        "2154626406"
    ]
},{
    "id": "2107008379",
    "title": "Transductive Inference for Text Classification using Support Vector Machines",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Thorsten Joachims"
    ],
    "related_topics": [
        "Relevance vector machine",
        "Transduction (machine learning)",
        "Structured support vector machine"
    ],
    "citation_count": "3,773",
    "reference_count": "0",
    "references": []
},{
    "id": "2914746235",
    "title": "Multitask learning",
    "abstract": "Multitask Learning is an approach to inductive transfer that improves learning for one task by using the information contained in the training signals of other related tasks. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. In this thesis we demonstrate multitask learning for a dozen problems. We explain how multitask learning works and show that there are many opportunities for multitask learning in real domains. We show that in some cases features that would normally be used as inputs work better if used as multitask outputs instead. We present suggestions for how to get the most out of multitask learning in artificial neural nets, present an algorithm for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Multitask learning improves generalization performance, can be applied in many different kinds of domains, and can be used with different learning algorithms. We conjecture there will be many opportunities for its use on real-world problems.",
    "date": "1998",
    "authors": [
        "Rich Caruana"
    ],
    "related_topics": [
        "Multi-task learning",
        "Inductive transfer",
        "Artificial neural network"
    ],
    "citation_count": "8,123",
    "reference_count": "0",
    "references": []
},{
    "id": "2173629880",
    "title": "Phoneme recognition using time-delay neural networks",
    "abstract": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >",
    "date": "1994",
    "authors": [
        "Alexander Waibel",
        "Toshiyuki Hanazawa",
        "Geoffrey Hinton",
        "Kiyohiro Shikano",
        "Kevin J. Lang"
    ],
    "related_topics": [
        "Time delay neural network",
        "Hidden Markov model",
        "Artificial neural network"
    ],
    "citation_count": "4,360",
    "reference_count": "0",
    "references": []
},{
    "id": "2885050925",
    "title": "Shallow Semantic Parsing using Support Vector Machines.",
    "abstract": "",
    "date": "2003",
    "authors": [
        "Sameer S. Pradhan",
        "Wayne H. Ward",
        "Kadri Hacioglu",
        "James H. Martin",
        "Daniel Jurafsky"
    ],
    "related_topics": [
        "Parsing",
        "Support vector machine",
        "Natural language processing"
    ],
    "citation_count": "498",
    "reference_count": "19",
    "references": [
        "2092654472",
        "2151170651",
        "2166776180",
        "1520377376",
        "1988995507",
        "2145310422",
        "2155693943",
        "2093647425",
        "2040909025",
        "2150203234"
    ]
},{
    "id": "2158823144",
    "title": "Dynamic conditional random fields: factorized probabilistic models for labeling and segmenting sequence data",
    "abstract": "In sequence modeling, we often wish to represent complex interaction between labels, such as when performing multiple, cascaded labeling tasks on the same sequence, or when long-range dependencies exist. We present dynamic conditional random fields (DCRFs), a generalization of linear-chain conditional random fields (CRFs) in which each time slice contains a set of state variables and edges---a distributed state representation as in dynamic Bayesian networks (DBNs)---and parameters are tied across slices. Since exact inference can be intractable in such models, we perform approximate inference using several schedules for belief propagation, including tree-based reparameterization (TRP). On a natural-language chunking task, we show that a DCRF performs better than a series of linear-chain CRFs, achieving comparable performance using only half the training data.",
    "date": "2004",
    "authors": [
        "Charles Sutton",
        "Khashayar Rohanimanesh",
        "Andrew McCallum"
    ],
    "related_topics": [
        "Approximate inference",
        "Variable elimination",
        "Bayesian network"
    ],
    "citation_count": "1,059",
    "reference_count": "57",
    "references": [
        "2147880316",
        "2116064496",
        "2125838338",
        "1574901103",
        "1632114991",
        "2008652694",
        "2096175520",
        "1934019294",
        "2169415915",
        "2156515921"
    ]
},{
    "id": "2163568299",
    "title": "Effective Self-Training for Parsing",
    "abstract": "We present a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data. We show that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker. Our improved model achieves an f-score of 92.1%, an absolute 1.1% improvement (12% error reduction) over the previous best result for Wall Street Journal parsing. Finally, we provide some analysis to better understand the phenomenon.",
    "date": "2006",
    "authors": [
        "David McClosky",
        "Eugene Charniak",
        "Mark Johnson"
    ],
    "related_topics": [
        "Parsing",
        "Discriminative model",
        "Bootstrapping"
    ],
    "citation_count": "602",
    "reference_count": "20",
    "references": [
        "1632114991",
        "2048679005",
        "1535015163",
        "2158195707",
        "3021452258",
        "1567570606",
        "2125712079",
        "2729906263",
        "2098379588",
        "2037894654"
    ]
},{
    "id": "1631260214",
    "title": "SRILM \u2013 An Extensible Language Modeling Toolkit",
    "abstract": "",
    "date": "2001",
    "authors": [
        "Andreas Stolcke"
    ],
    "related_topics": [
        "Modeling language",
        "High-level programming language",
        "Computer science"
    ],
    "citation_count": "5,402",
    "reference_count": "19",
    "references": [
        "2158195707",
        "2121227244",
        "1904457459",
        "2594610113",
        "1549285799",
        "2100506586",
        "1797288984",
        "2097978681",
        "1528470941",
        "2127836646"
    ]
},{
    "id": "2096175520",
    "title": "A maximum entropy approach to natural language processing",
    "abstract": "The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper, we describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in natural language processing.",
    "date": "1996",
    "authors": [
        "Adam L. Berger",
        "Vincent J. Della Pietra",
        "Stephen A. Della Pietra"
    ],
    "related_topics": [
        "Maximum-entropy Markov model",
        "Principle of maximum entropy",
        "Statistical model"
    ],
    "citation_count": "4,915",
    "reference_count": "25",
    "references": [
        "2099111195",
        "2049633694",
        "2006969979",
        "2121227244",
        "2160842254",
        "2097333193",
        "1597533204",
        "2099345940",
        "2167434254",
        "1976241232"
    ]
},{
    "id": "2110485445",
    "title": "Finding Structure in Time",
    "abstract": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.",
    "date": "1990",
    "authors": [
        "Jeffrey L. Elman"
    ],
    "related_topics": [
        "Task (project management)",
        "Context (language use)",
        "Semantics"
    ],
    "citation_count": "12,889",
    "reference_count": "39",
    "references": [
        "2154642048",
        "1652505363",
        "2173629880",
        "2016589492",
        "3036751298",
        "2118373646",
        "2046432185",
        "2122988375",
        "2170716495",
        "2094249282"
    ]
},{
    "id": "1575350781",
    "title": "MPI: A Message-Passing Interface Standard",
    "abstract": "The Message Passing Interface Forum (MPIF), with participation from over 40 organizations, has been meeting since November 1992 to discuss and define a set of library standards for message passing. MPIF is not sanctioned or supported by any official standards organization. The goal of the Message Passing Interface, simply stated, is to develop a widely used standard for writing message-passing programs. As such the interface should establish a practical, portable, efficient and flexible standard for message passing. , This is the final report, Version 1.0, of the Message Passing Interface Forum. This document contains all the technical features proposed for the interface. This copy of the draft was processed by LATEX on April 21, 1994. , Please send comments on MPI to mpi-comments@cs.utk.edu. Your comment will be forwarded to MPIF committee members who will attempt to respond.",
    "date": "1994",
    "authors": [
        "Message P Forum"
    ],
    "related_topics": [
        "Message passing",
        "Message Passing Interface",
        "Interface (Java)"
    ],
    "citation_count": "4,616",
    "reference_count": "21",
    "references": [
        "1480928214",
        "1521571223",
        "1964564149",
        "1978513924",
        "2083200599",
        "2090683636",
        "2010542899",
        "2294265735",
        "1843937266",
        "2010269868"
    ]
},{
    "id": "2158195707",
    "title": "An empirical study of smoothing techniques for language modeling",
    "abstract": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including those described by Jelinek and Mercer (1980); Katz (1987); Bell, Cleary and Witten (1990); Ney, Essen and Kneser (1994), and Kneser and Ney (1995). We investigate how factors such as training data size, training corpus (e.g. Brown vs. Wall Street Journal), count cutoffs, and n -gram order (bigram vs. trigram) affect the relative performance of these methods, which is measured through the cross-entropy of test data. We find that these factors can significantly affect the relative performance of models, with the most significant factor being training data size. Since no previous comparisons have examined these factors systematically, this is the first thorough characterization of the relative performance of various algorithms. In addition, we introduce methodologies for analyzing smoothing algorithm efficacy in detail, and using these techniques we motivate a novel variation of Kneser?Ney smoothing that consistently outperforms all other algorithms evaluated. Finally, results showing that improved language model smoothing leads to improved speech recognition performance are presented.",
    "date": "1999",
    "authors": [
        "Stanley F. Chen",
        "Joshua Goodman"
    ],
    "related_topics": [
        "Kneser\u2013Ney smoothing",
        "Smoothing",
        "Bigram"
    ],
    "citation_count": "3,698",
    "reference_count": "23",
    "references": [
        "2170120409",
        "2158195707",
        "2121227244",
        "2099247782",
        "2097333193",
        "1966812932",
        "2611071497",
        "2166637769",
        "2134237567",
        "2075201173"
    ]
},{
    "id": "2121227244",
    "title": "Class-based n -gram models of natural language",
    "abstract": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics.",
    "date": "1992",
    "authors": [
        "Peter F. Brown",
        "Peter V. deSouza",
        "Robert L. Mercer",
        "Vincent J. Della Pietra",
        "Jenifer C. Lai"
    ],
    "related_topics": [
        "n-gram",
        "Natural language",
        "Word (group theory)"
    ],
    "citation_count": "4,024",
    "reference_count": "12",
    "references": [
        "2049633694",
        "2097333193",
        "1966812932",
        "2142901448",
        "2751862591",
        "1597533204",
        "1575431606",
        "2007780422",
        "2016871293",
        "1628850721"
    ]
},{
    "id": "2914484425",
    "title": "Efficient BackProp",
    "abstract": "",
    "date": "1997",
    "authors": [
        "Yann LeCun",
        "L\u00e9on Bottou",
        "Genevieve B. Orr",
        "Klaus-Robert M\u00fcller"
    ],
    "related_topics": [
        "Computer science"
    ],
    "citation_count": "4,270",
    "reference_count": "0",
    "references": []
},{
    "id": "1880262756",
    "title": "Latent dirichlet allocation",
    "abstract": "We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.",
    "date": "2003",
    "authors": [
        "David M. Blei",
        "Andrew Y. Ng",
        "Michael I. Jordan"
    ],
    "related_topics": [
        "Latent Dirichlet allocation",
        "Dynamic topic model",
        "Hierarchical Dirichlet process"
    ],
    "citation_count": "38,465",
    "reference_count": "28",
    "references": [
        "2045656233",
        "2147152072",
        "2107743791",
        "2097089247",
        "1956559956",
        "1516111018",
        "1508165687",
        "1746680969",
        "2020842694",
        "2063392856"
    ]
},{
    "id": "168564468",
    "title": "Software Framework for Topic Modelling with Large Corpora",
    "abstract": "Large corpora are ubiquitous in today's world and memory quickly becomes the limiting factor in practical applications of the Vector Space Model (VSM). We identify gap in existing VSM implementations, which is their scalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document streaming, i.e. processing corpora document after document, in a memory independent fashion. In this framework, we implement several popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes them completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design, so that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the usefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ.",
    "date": "2010",
    "authors": [
        "Radim \u0158eh\u016f\u0159ek",
        "Petr Sojka"
    ],
    "related_topics": [
        "Latent Dirichlet allocation",
        "Topic model",
        "Software framework"
    ],
    "citation_count": "3,231",
    "reference_count": "25",
    "references": [
        "1880262756",
        "2170120409",
        "2001082470",
        "2147152072",
        "2158266063",
        "2047804403",
        "2143017621",
        "2159426623",
        "2334889010",
        "2063392856"
    ]
},{
    "id": "2296073425",
    "title": "Curriculum learning",
    "abstract": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).",
    "date": "2009",
    "authors": [
        "Yoshua Bengio",
        "J\u00e9r\u00f4me Louradour",
        "Ronan Collobert",
        "Jason Weston"
    ],
    "related_topics": [
        "Active learning",
        "Stability (learning theory)",
        "Instance-based learning"
    ],
    "citation_count": "2,862",
    "reference_count": "31",
    "references": [
        "2136922672",
        "2100495367",
        "2072128103",
        "2117130368",
        "2025768430",
        "2110798204",
        "2099866409",
        "1994197834",
        "2172174689",
        "205159212"
    ]
},{
    "id": "2158997610",
    "title": "An introduction to latent semantic analysis",
    "abstract": "Latent Semantic Analysis (LSA) is a theory and method for extracting and representing the contextual\u2010usage meaning of words by statistical computations applied to a large corpus of text (Landauer & Dumais, 1997). The underlying idea is that the aggregate of all the word contexts in which a given word does and does not appear provides a set of mutual constraints that largely determines the similarity of meaning of words and sets of words to each other. The adequacy of LSA's reflection of human knowledge has been established in a variety of ways. For example, its scores overlap those of humans on standard vocabulary and subject matter tests; it mimics human word sorting and category judgments; it simulates word\u2010word and passage\u2010word lexical priming data; and, as reported in 3 following articles in this issue, it accurately estimates passage coherence, learnability of passages by individual students, and the quality and quantity of knowledge contained in an essay.",
    "date": "1997",
    "authors": [
        "Thomas K Landauer",
        "Peter W. Foltz",
        "Darrell Laham"
    ],
    "related_topics": [
        "Latent semantic analysis",
        "Probabilistic latent semantic analysis",
        "Vocabulary"
    ],
    "citation_count": "6,465",
    "reference_count": "33",
    "references": [
        "2147152072",
        "1983578042",
        "1674947250",
        "2072773380",
        "2056029990",
        "1981617416",
        "2059086756",
        "2092919341",
        "2928502135",
        "1996650435"
    ]
},{
    "id": "2004763266",
    "title": "Design Challenges and Misconceptions in Named Entity Recognition",
    "abstract": "We analyze some of the fundamental design challenges and misconceptions that underlie the development of an efficient and robust NER system. In particular, we address issues such as the representation of text chunks, the inference approach needed to combine local NER decisions, the sources of prior knowledge and how to use them within an NER system. In the process of comparing several solutions to these challenges we reach some surprising conclusions, as well as develop an NER system that achieves 90.8 F1 score on the CoNLL-2003 NER shared task, the best reported result for this dataset.",
    "date": "2009",
    "authors": [
        "Lev Ratinov",
        "Dan Roth"
    ],
    "related_topics": [
        "Named-entity recognition",
        "Inference",
        "F1 score"
    ],
    "citation_count": "1,567",
    "reference_count": "32",
    "references": [
        "2147880316",
        "2125838338",
        "2096765155",
        "2008652694",
        "1996430422",
        "2148540243",
        "2144578941",
        "2121227244",
        "2128634885",
        "1979711143"
    ]
},{
    "id": "2156515921",
    "title": "Shallow parsing with conditional random fields",
    "abstract": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models.",
    "date": "2003",
    "authors": [
        "Fei Sha",
        "Fernando Pereira"
    ],
    "related_topics": [
        "Conditional random field",
        "Shallow parsing",
        "Sequence labeling"
    ],
    "citation_count": "1,924",
    "reference_count": "33",
    "references": [
        "1995945562",
        "2147880316",
        "2008652694",
        "2096175520",
        "1934019294",
        "1773803948",
        "2160842254",
        "2962735828",
        "2117400858",
        "1520377376"
    ]
},{
    "id": "2067191022",
    "title": "Mean shift: a robust approach toward feature space analysis",
    "abstract": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.",
    "date": "2002",
    "authors": [
        "D. Comaniciu",
        "P. Meer"
    ],
    "related_topics": [
        "Mean-shift",
        "Smoothing",
        "Estimator"
    ],
    "citation_count": "14,663",
    "reference_count": "69",
    "references": [
        "2798766386",
        "2140235142",
        "2099244020",
        "2132549764",
        "2159128898",
        "2150134853",
        "1971784203",
        "2129905273",
        "2999729612",
        "2482402870"
    ]
},{
    "id": "1574901103",
    "title": "Foundations of Statistical Natural Language Processing",
    "abstract": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.",
    "date": "1999",
    "authors": [
        "Christopher D. Manning",
        "Hinrich Sch\u00fctze"
    ],
    "related_topics": [
        "Computational linguistics",
        "Natural language",
        "Parsing"
    ],
    "citation_count": "15,331",
    "reference_count": "9",
    "references": [
        "1508165687",
        "182831726",
        "1994851566",
        "2108321481",
        "1549026077",
        "2949237929",
        "1795234945",
        "1746620543",
        "1736036918"
    ]
},{
    "id": "1566135517",
    "title": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope",
    "abstract": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.",
    "date": "2001",
    "authors": [
        "Aude Oliva",
        "Antonio Torralba"
    ],
    "related_topics": [
        "Scene statistics",
        "Representation (systemics)",
        "Envelope (motion)"
    ],
    "citation_count": "7,505",
    "reference_count": "45",
    "references": [
        "2117812871",
        "2128716185",
        "2012352340",
        "2130259898",
        "2156406284",
        "1524408959",
        "2180838288",
        "2142796031",
        "2104825706",
        "2167034998"
    ]
},{
    "id": "2536208356",
    "title": "Decomposing a scene into geometric and semantically consistent regions",
    "abstract": "High-level, or holistic, scene understanding involves reasoning about objects, regions, and the 3D relationships between them. This requires a representation above the level of pixels that can be endowed with high-level attributes such as class of object/region, its orientation, and (rough 3D) location within the scene. Towards this goal, we propose a region-based model which combines appearance and scene geometry to automatically decompose a scene into semantically meaningful regions. Our model is defined in terms of a unified energy function over scene appearance and structure. We show how this energy function can be learned from data and present an efficient inference technique that makes use of multiple over-segmentations of the image to propose moves in the energy-space. We show, experimentally, that our method achieves state-of-the-art performance on the tasks of both multi-class image segmentation and geometric reasoning. Finally, by understanding region classes and geometry, we show how our model can be used as the basis for 3D reconstruction of the scene.",
    "date": "2009",
    "authors": [
        "Stephen Gould",
        "Richard Fulton",
        "Daphne Koller"
    ],
    "related_topics": [
        "Orientation (computer vision)",
        "Image segmentation",
        "Object (computer science)"
    ],
    "citation_count": "810",
    "reference_count": "22",
    "references": [
        "2161969291",
        "2033819227",
        "3097096317",
        "2067191022",
        "2110764733",
        "1528789833",
        "2132947399",
        "2125310925",
        "2116877738",
        "2112301665"
    ]
},{
    "id": "2322002063",
    "title": "Principles of neurodynamics",
    "abstract": "",
    "date": "1961",
    "authors": [
        "A. A. Mullin",
        "Frank Rosenblatt"
    ],
    "related_topics": [
        "Computer science"
    ],
    "citation_count": "2,760",
    "reference_count": "0",
    "references": []
},{
    "id": "2173213060",
    "title": "MapReduce: simplified data processing on large clusters",
    "abstract": "MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.",
    "date": "2007",
    "authors": [
        "Jeffrey Dean",
        "Sanjay Ghemawat"
    ],
    "related_topics": [
        "Data-intensive computing",
        "Runtime system",
        "Many-task computing"
    ],
    "citation_count": "30,857",
    "reference_count": "19",
    "references": [
        "2173213060",
        "2119565742",
        "2148317584",
        "2073965851",
        "2109722477",
        "2104644701",
        "1510543252",
        "2044534358",
        "1988243929",
        "2045271686"
    ]
},{
    "id": "1532325895",
    "title": "Introduction to Information Retrieval",
    "abstract": "Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.",
    "date": "2004",
    "authors": [
        "Christopher D. Manning",
        "Prabhakar Raghavan",
        "Hinrich Sch\u00fctze"
    ],
    "related_topics": [
        "Human\u2013computer information retrieval",
        "Cognitive models of information retrieval",
        "Concept search"
    ],
    "citation_count": "19,614",
    "reference_count": "0",
    "references": []
},{
    "id": "3013264884",
    "title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine.",
    "abstract": "In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/. To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.",
    "date": "1997",
    "authors": [
        "Sergey Brin",
        "Lawrence Page"
    ],
    "related_topics": [
        "Web search engine",
        "Web page",
        "Hypertext"
    ],
    "citation_count": "20,977",
    "reference_count": "0",
    "references": []
},{
    "id": "2024165284",
    "title": "Tensor Decompositions and Applications",
    "abstract": "This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or $N$-way array. Decompositions of higher-order tensors (i.e., $N$-way arrays with $N \\geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.",
    "date": "2009",
    "authors": [
        "Tamara G. Kolda",
        "Brett W. Bader"
    ],
    "related_topics": [
        "Tensor contraction",
        "Cartesian tensor",
        "Symmetric tensor"
    ],
    "citation_count": "7,886",
    "reference_count": "223",
    "references": [
        "1902027874",
        "2798909945",
        "2099741732",
        "2147152072",
        "2013912476",
        "2090208105",
        "2752853835",
        "2072773380",
        "2113722075",
        "2132267493"
    ]
},{
    "id": "1660390307",
    "title": "Modern Information Retrieval",
    "abstract": "From the Publisher: This is a rigorous and complete textbook for a first course on information retrieval from the computer science (as opposed to a user-centred) perspective. The advent of the Internet and the enormous increase in volume of electronically stored information generally has led to substantial work on IR from the computer science perspective - this book provides an up-to-date student oriented treatment of the subject.",
    "date": "1999",
    "authors": [
        "Ricardo A. Baeza-Yates",
        "Berthier Ribeiro-Neto"
    ],
    "related_topics": [
        "Human\u2013computer information retrieval",
        "Information science",
        "Electronically stored information"
    ],
    "citation_count": "19,681",
    "reference_count": "5",
    "references": [
        "1499900670",
        "166263196",
        "2107745473",
        "2122962290",
        "2037959956"
    ]
},{
    "id": "2166706824",
    "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
    "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.",
    "date": "2002",
    "authors": [
        "Bo Pang",
        "Lillian Lee",
        "Shivakumar Vaithyanathan"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Multiclass classification",
        "Relevance vector machine"
    ],
    "citation_count": "10,502",
    "reference_count": "32",
    "references": [
        "3146306708",
        "2149684865",
        "1576520375",
        "2096175520",
        "1550206324",
        "2140785063",
        "2155328222",
        "2199803028",
        "2160842254",
        "1924689489"
    ]
},{
    "id": "1992419399",
    "title": "Data clustering: a review",
    "abstract": "Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.",
    "date": "1999",
    "authors": [
        "A. K. Jain",
        "M. N. Murty",
        "P. J. Flynn"
    ],
    "related_topics": [
        "Cluster analysis",
        "Correlation clustering",
        "Single-linkage clustering"
    ],
    "citation_count": "18,116",
    "reference_count": "191",
    "references": [
        "2912565176",
        "1639032689",
        "1497256448",
        "2581275558",
        "2152150600",
        "2049633694",
        "2133671888",
        "1971784203",
        "2095897464",
        "2138745909"
    ]
},{
    "id": "71795751",
    "title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions",
    "abstract": "We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.",
    "date": "2011",
    "authors": [
        "Richard Socher",
        "Jeffrey Pennington",
        "Eric H. Huang",
        "Andrew Y. Ng",
        "Christopher D. Manning"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Machine learning",
        "Multinomial distribution"
    ],
    "citation_count": "1,477",
    "reference_count": "35",
    "references": [
        "1880262756",
        "2097726431",
        "2117130368",
        "2166706824",
        "2132339004",
        "2158139315",
        "3146306708",
        "1423339008",
        "2114524997",
        "2022204871"
    ]
},{
    "id": "2097606805",
    "title": "Accurate Unlexicalized Parsing",
    "abstract": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.",
    "date": "2003",
    "authors": [
        "Dan Klein",
        "Christopher D. Manning"
    ],
    "related_topics": [
        "Statistical parsing",
        "Parsing",
        "Treebank"
    ],
    "citation_count": "3,786",
    "reference_count": "18",
    "references": [
        "1535015163",
        "2092654472",
        "2110882317",
        "1567570606",
        "2153439141",
        "1551104980",
        "2155693943",
        "2161204834",
        "1859173823",
        "2170716495"
    ]
},{
    "id": "2103305545",
    "title": "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection",
    "abstract": "Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classifier. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus.",
    "date": "2011",
    "authors": [
        "Richard Socher",
        "Eric H. Huang",
        "Jeffrey Pennin",
        "Christopher D Manning",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Paraphrase",
        "Feature vector",
        "Pooling"
    ],
    "citation_count": "979",
    "reference_count": "26",
    "references": [
        "2117130368",
        "2132339004",
        "2158139315",
        "1423339008",
        "71795751",
        "2296073425",
        "2097606805",
        "2140833774",
        "1566018662",
        "2095739681"
    ]
},{
    "id": "2163455955",
    "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales",
    "abstract": "We address the rating-inference problem, wherein rather than simply decide whether a review is \"thumbs up\" or \"thumbs down\", as in previous sentiment analysis work, one must determine an author's evaluation with respect to a multi-point scale (e.g., one to five \"stars\"). This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example, \"three stars\" is intuitively closer to \"four stars\" than to \"one star\".We first evaluate human performance at the task. Then, we apply a meta-algorithm, based on a metric labeling formulation of the problem, that alters a given n-ary classifier's output in an explicit attempt to ensure that similar items receive similar labels. We show that the meta-algorithm can provide significant improvements over both multi-class and regression versions of SVMs when we employ a novel similarity measure appropriate to the problem.",
    "date": "2005",
    "authors": [
        "Bo Pang",
        "Lillian Lee"
    ],
    "related_topics": [
        "Semantic similarity",
        "Class (philosophy)",
        "Sentiment analysis"
    ],
    "citation_count": "2,401",
    "reference_count": "26",
    "references": [
        "2156909104",
        "2166706824",
        "1964357740",
        "2143516773",
        "3146306708",
        "2114524997",
        "1576520375",
        "2115023510",
        "2053463056",
        "2155328222"
    ]
},{
    "id": "1984052055",
    "title": "Composition in distributional models of semantics.",
    "abstract": "Vector-based models of word meaning have become increasingly popular in cognitive science. The appeal of these models lies in their ability to represent meaning simply by using distributional information under the assumption that words occurring within similar contexts are semantically similar. Despite their widespread use, vector-based models are typically directed at representing words in isolation, and methods for constructing representations for phrases or sentences have received little attention in the literature. This is in marked contrast to experimental evidence (e.g., in sentential priming) suggesting that semantic similarity is more complex than simply a relation between isolated words. This article proposes a framework for representing the meaning of word combinations in vector space. Central to our approach is vector composition, which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models that we evaluate empirically on a phrase similarity task.",
    "date": "2010",
    "authors": [
        "Jeff Mitchell",
        "Mirella Lapata"
    ],
    "related_topics": [
        "Distributional semantics",
        "Semantic similarity",
        "Semantics"
    ],
    "citation_count": "994",
    "reference_count": "217",
    "references": [
        "2156909104",
        "1880262756",
        "2038721957",
        "2132339004",
        "1652505363",
        "2147152072",
        "1498436455",
        "1662133657",
        "1587094587",
        "1631260214"
    ]
},{
    "id": "2151048449",
    "title": "Local and Global Algorithms for Disambiguation to Wikipedia",
    "abstract": "Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing. The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation. Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible. In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call \"global\" approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.",
    "date": "2011",
    "authors": [
        "Lev Ratinov",
        "Dan Roth",
        "Doug Downey",
        "Mike Anderson"
    ],
    "related_topics": [
        "Entity linking",
        "Online encyclopedia",
        "Natural language processing"
    ],
    "citation_count": "790",
    "reference_count": "17",
    "references": [
        "2120779048",
        "2100341149",
        "86887328",
        "2096152098",
        "2131357087",
        "1548663377",
        "2165897980",
        "158057341",
        "1960027552",
        "2123142779"
    ]
},{
    "id": "36903255",
    "title": "Hierarchical Probabilistic Neural Network Language Model.",
    "abstract": "In recent years, variants of a neural network architecture for statistical language modeling have been proposed and successfully applied, e.g. in the language modeling component of speech recognizers. The main advantage of these architectures is that they learn an embedding for words (or other symbols) in a continuous space that helps to smooth the language model and provide good generalization even when the number of training examples is insufficient. However, these models are extremely slow in comparison to the more commonly used n-gram models, both for training and recognition. As an alternative to an importance sampling method proposed to speed-up training, we introduce a hierarchical decomposition of the conditional probabilities that yields a speed-up of about 200 both during training and recognition. The hierarchical decomposition is a binary hierarchical clustering constrained by the prior knowledge extracted from the WordNet semantic hierarchy.",
    "date": "2004",
    "authors": [
        "Frederic Morin",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Hierarchical network model",
        "Language model",
        "Time delay neural network"
    ],
    "citation_count": "1,118",
    "reference_count": "27",
    "references": [
        "2038721957",
        "2116064496",
        "2132339004",
        "2147152072",
        "1631260214",
        "2096175520",
        "2110485445",
        "1978394996",
        "2121227244",
        "2127314673"
    ]
},{
    "id": "2091812280",
    "title": "Three new graphical models for statistical language modelling",
    "abstract": "The supremacy of n-gram models in statistical language modelling has recently been challenged by parametric models that use distributed representations to counteract the difficulties caused by data sparsity. We propose three new probabilistic language models that define the distribution of the next word in a sequence given several preceding words by using distributed representations of those words. We show how real-valued distributed representations for words can be learned at the same time as learning a large set of stochastic binary hidden features that are used to predict the distributed representation of the next word from previous distributed representations. Adding connections from the previous states of the binary hidden features improves performance as does adding direct connections between the real-valued distributed representations. One of our models significantly outperforms the very best n-gram models.",
    "date": "2007",
    "authors": [
        "Andriy Mnih",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Language model",
        "Graphical model",
        "Word (computer architecture)"
    ],
    "citation_count": "699",
    "reference_count": "13",
    "references": [
        "2136922672",
        "2116064496",
        "2132339004",
        "1631260214",
        "36903255",
        "2158195707",
        "2147010501",
        "145476170",
        "2437096199",
        "1558797106"
    ]
},{
    "id": "2127314673",
    "title": "DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS",
    "abstract": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data.",
    "date": "1993",
    "authors": [
        "Fernando Pereira",
        "Naftali Tishby",
        "Lillian Lee"
    ],
    "related_topics": [
        "Single-linkage clustering",
        "Complete-linkage clustering",
        "Correlation clustering"
    ],
    "citation_count": "1,456",
    "reference_count": "11",
    "references": [
        "2099111195",
        "2049633694",
        "3017143921",
        "2121227244",
        "2099247782",
        "2123084125",
        "2025887562",
        "2059800182",
        "2016001305",
        "1982944197"
    ]
},{
    "id": "2056590938",
    "title": "Connectionist language modeling for large vocabulary continuous speech recognition",
    "abstract": "This paper describes ongoing work on a new approach for language modeling for large vocabulary continuous speech recognition. Almost all state.. o. f-the-art systems use statistical n-gram language models estimated on text corpora. One principle problem with such language models is the fact that many of the n-grams are never observed even in very large training corpora, and therefore it is common to back-off to a lower-order model. In this paper we propose to address this problem by carrying out the estimation task in a continuous space, enabling a smooth interpolation of the probabilities. A neural network is used to learn the projection of the words onto a continuous space and to estimate the n-gram probabilities. The connectionist language model is being evaluated on the DARPA HUB5 conversational telephone speech recognition task and preliminary results show consistent improvements in both perplexity and word error rate.",
    "date": "2002",
    "authors": [
        "Holger Schwenk",
        "Jean-Luc Gauvain"
    ],
    "related_topics": [
        "Cache language model",
        "Language model",
        "Vocabulary"
    ],
    "citation_count": "172",
    "reference_count": "6",
    "references": [
        "1554663460",
        "2132339004",
        "2016243284",
        "2140679639",
        "82490022",
        "17500809"
    ]
},{
    "id": "2111305191",
    "title": "A bit of progress in language modeling",
    "abstract": "In the past several years, a number of different language modeling improvements over simple trigram models have been found, including caching, higher-order n -grams, skipping, interpolated Kneser?Ney smoothing, and clustering. We present explorations of variations on, or of the limits of, each of these techniques, including showing that sentence mixture models may have more potential. While all of these techniques have been studied separately, they have rarely been studied in combination. We compare a combination of all techniques together to a Katz smoothed trigram model with no count cutoffs. We achieve perplexity reductions between 38 and 50% (1 bit of entropy), depending on training data size, as well as a word error rate reduction of 8.9%. Our perplexity reductions are perhaps the highest reported compared to a fair baseline.",
    "date": "2001",
    "authors": [
        "Joshua T. Goodman"
    ],
    "related_topics": [
        "Perplexity",
        "Trigram",
        "Word error rate"
    ],
    "citation_count": "631",
    "reference_count": "50",
    "references": [
        "2170120409",
        "2158195707",
        "2121227244",
        "1996764654",
        "2099247782",
        "2097333193",
        "2127314673",
        "2595741664",
        "2134237567",
        "47415966"
    ]
},{
    "id": "1558797106",
    "title": "Quick Training of Probabilistic Neural Nets by Importance Sampling.",
    "abstract": "",
    "date": "2002",
    "authors": [
        "Yoshua Bengio",
        "Jean-S\u00e9bastien Senecal"
    ],
    "related_topics": [
        "Time delay neural network",
        "Probabilistic neural network",
        "Artificial neural network"
    ],
    "citation_count": "205",
    "reference_count": "16",
    "references": [
        "2116064496",
        "2132339004",
        "1574901103",
        "2096175520",
        "1535015163",
        "2092654472",
        "1746680969",
        "2134237567",
        "145476170",
        "1989705153"
    ]
},{
    "id": "2963542991",
    "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
    "abstract": "Abstract: We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
    "date": "2014",
    "authors": [
        "Pierre Sermanet",
        "David Eigen",
        "Xiang Zhang",
        "Michael Mathieu",
        "Rob Fergus",
        "Yann LeCun"
    ],
    "related_topics": [
        "Deep learning",
        "Feature (computer vision)",
        "Sliding window protocol"
    ],
    "citation_count": "4,460",
    "reference_count": "0",
    "references": []
},{
    "id": "2963911037",
    "title": "Network In Network",
    "abstract": "Abstract: We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.",
    "date": "2014",
    "authors": [
        "Min Lin",
        "Qiang Chen",
        "Shuicheng Yan"
    ],
    "related_topics": [
        "Multilayer perceptron",
        "Activation function",
        "Artificial neural network"
    ],
    "citation_count": "4,773",
    "reference_count": "0",
    "references": []
},{
    "id": "2068730032",
    "title": "Scalable Object Detection Using Deep Neural Networks",
    "abstract": "Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012). The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image. Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance. In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest. The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network. We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.",
    "date": "2014",
    "authors": [
        "Dumitru Erhan",
        "Christian Szegedy",
        "Alexander Toshev",
        "Dragomir Anguelov"
    ],
    "related_topics": [
        "Time delay neural network",
        "Object detection",
        "Minimum bounding box"
    ],
    "citation_count": "1,061",
    "reference_count": "16",
    "references": [
        "2618530766",
        "2102605133",
        "2168356304",
        "2031489346",
        "2088049833",
        "2130306094",
        "2129305389",
        "2017691720",
        "2128715914",
        "2122146326"
    ]
},{
    "id": "2031489346",
    "title": "The Pascal Visual Object Classes (VOC) Challenge",
    "abstract": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.",
    "date": "2010",
    "authors": [
        "Mark Everingham",
        "Luc Gool",
        "Christopher K. Williams",
        "John Winn",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Object detection",
        "Cognitive neuroscience of visual object recognition",
        "Pascal (programming language)"
    ],
    "citation_count": "11,248",
    "reference_count": "57",
    "references": [
        "2151103935",
        "2161969291",
        "3097096317",
        "2162915993",
        "2038721957",
        "2131846894",
        "2110764733",
        "2104974755",
        "1576445103",
        "1565746575"
    ]
},{
    "id": "2088049833",
    "title": "Selective Search for Object Recognition",
    "abstract": "This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99 % recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi.unitn.it/~uijlings/SelectiveSearch.html ).",
    "date": "2013",
    "authors": [
        "J. R. Uijlings",
        "K. E. Sande",
        "T. Gevers",
        "A. W. Smeulders"
    ],
    "related_topics": [
        "Beam search",
        "Brute-force search",
        "Cognitive neuroscience of visual object recognition"
    ],
    "citation_count": "5,484",
    "reference_count": "37",
    "references": [
        "2151103935",
        "2161969291",
        "2168356304",
        "2164598857",
        "2031489346",
        "3097096317",
        "2162915993",
        "2163352848",
        "2121947440",
        "2110158442"
    ]
},{
    "id": "2155541015",
    "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition",
    "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
    "date": "2014",
    "authors": [
        "Jeff Donahue",
        "Yangqing Jia",
        "Oriol Vinyals",
        "Judy Hoffman",
        "Ning Zhang",
        "Eric Tzeng",
        "Trevor Darrell"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Cognitive neuroscience of visual object recognition",
        "Machine learning"
    ],
    "citation_count": "4,369",
    "reference_count": "46",
    "references": [
        "2618530766",
        "2108598243",
        "2161969291",
        "2168356304",
        "2310919327",
        "2100495367",
        "1904365287",
        "1677409904",
        "2187089797",
        "2546302380"
    ]
},{
    "id": "1663973292",
    "title": "Pattern Recognition and Machine Learning",
    "abstract": "Probability Distributions.- Linear Models for Regression.- Linear Models for Classification.- Neural Networks.- Kernel Methods.- Sparse Kernel Machines.- Graphical Models.- Mixture Models and EM.- Approximate Inference.- Sampling Methods.- Continuous Latent Variables.- Sequential Data.- Combining Models.",
    "date": "2006",
    "authors": [
        "Christopher M. Bishop"
    ],
    "related_topics": [
        "Kernel method",
        "Kernel (statistics)",
        "Graphical model"
    ],
    "citation_count": "52,177",
    "reference_count": "2",
    "references": [
        "2117812871",
        "1496357020"
    ]
},{
    "id": "2109255472",
    "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition",
    "abstract": "Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 $\\times$ 224) input image. This requirement is \u201cartificial\u201d and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, \u201cspatial pyramid pooling\u201d, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 $\\times$ faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.",
    "date": "2015",
    "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Contextual image classification",
        "Object detection"
    ],
    "citation_count": "5,651",
    "reference_count": "45",
    "references": [
        "2618530766",
        "2962835968",
        "2097117768",
        "2151103935",
        "2102605133",
        "2117539524",
        "2153635508",
        "2108598243",
        "2161969291",
        "2168356304"
    ]
},{
    "id": "753012316",
    "title": "Torch7: A Matlab-like Environment for Machine Learning",
    "abstract": "Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be interfaced to third-party software thanks to Lua\u2019s light interface.",
    "date": "2010",
    "authors": [
        "Ronan Collobert",
        "Koray Kavukcuoglu",
        "Cl\u00e9ment Farabet"
    ],
    "related_topics": [
        "Scripting language",
        "CUDA",
        "Interface (Java)"
    ],
    "citation_count": "1,761",
    "reference_count": "1",
    "references": [
        "2606594511"
    ]
},{
    "id": "1825604117",
    "title": "Open-vocabulary Object Retrieval",
    "abstract": "",
    "date": "2014",
    "authors": [
        "Sergio Guadarrama",
        "Erik Rodner",
        "Kate Saenko",
        "Ning Zhang",
        "Ryan Farrell",
        "Jeff Donahue",
        "Trevor Darrell"
    ],
    "related_topics": [
        "Visual Word",
        "Computer science",
        "Natural language processing"
    ],
    "citation_count": "81",
    "reference_count": "34",
    "references": [
        "2088049833",
        "2131846894",
        "2128017662",
        "2141362318",
        "2094728533",
        "1889268436",
        "1618905105",
        "21006490",
        "1897761818",
        "2066134726"
    ]
},{
    "id": "2147414309",
    "title": "PANDA: Pose Aligned Networks for Deep Attribute Modeling",
    "abstract": "We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets [4] and DPM [12] have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.",
    "date": "2014",
    "authors": [
        "Ning Zhang",
        "Manohar Paluri",
        "Marc'Aurelio Ranzato",
        "Trevor Darrell",
        "Lubomir Bourdev"
    ],
    "related_topics": [
        "3D pose estimation",
        "Deep learning",
        "Context (language use)"
    ],
    "citation_count": "511",
    "reference_count": "29",
    "references": [
        "2618530766",
        "2168356304",
        "2310919327",
        "2155541015",
        "2162915993",
        "2546302380",
        "1498436455",
        "2536626143",
        "2253807446",
        "2098411764"
    ]
},{
    "id": "1872489089",
    "title": "Pylearn2: a machine learning research library",
    "abstract": "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
    "date": "2013",
    "authors": [
        "Ian J. Goodfellow",
        "David Warde-Farley",
        "Pascal Lamblin",
        "Vincent Dumoulin",
        "Mehdi Mirza",
        "Razvan Pascanu",
        "James Bergstra",
        "Fr\u00e9d\u00e9ric Bastien",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Flexibility (engineering)",
        "Computer science",
        "Machine learning"
    ],
    "citation_count": "307",
    "reference_count": "44",
    "references": [
        "2618530766",
        "2101234009",
        "3118608800",
        "2310919327",
        "1904365287",
        "2168231600",
        "2119821739",
        "2116064496",
        "2025768430",
        "2335728318"
    ]
},{
    "id": "2962883796",
    "title": "Recognizing Image Style.",
    "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best \u2013 even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.",
    "date": "2013",
    "authors": [
        "Sergey Karayev",
        "Matthew Trentacoste",
        "Helen Han",
        "Aseem Agarwala",
        "Trevor Darrell",
        "Aaron Hertzmann",
        "Holger Winnemoeller"
    ],
    "related_topics": [
        "Style (sociolinguistics)",
        "Natural language processing",
        "Computer science"
    ],
    "citation_count": "389",
    "reference_count": "22",
    "references": [
        "2618530766",
        "2108598243",
        "2146502635",
        "2155541015",
        "1566135517",
        "2135957164",
        "1511924373",
        "2075456404",
        "2078807908",
        "2157462866"
    ]
},{
    "id": "2164598857",
    "title": "Rapid object detection using a boosted cascade of simple features",
    "abstract": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.",
    "date": "2001",
    "authors": [
        "P. Viola",
        "M. Jones"
    ],
    "related_topics": [
        "Object detection",
        "Object-class detection",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "23,739",
    "reference_count": "18",
    "references": [
        "3124955340",
        "2128272608",
        "2217896605",
        "2115763357",
        "1975846642",
        "2124351082",
        "2159686933",
        "2155511848",
        "2101522199",
        "3146003712"
    ]
},{
    "id": "2135046866",
    "title": "Regression Shrinkage and Selection via the Lasso",
    "abstract": "SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.",
    "date": "1995",
    "authors": [
        "Robert Tibshirani"
    ],
    "related_topics": [
        "Lasso (statistics)",
        "Elastic net regularization",
        "Residual sum of squares"
    ],
    "citation_count": "40,049",
    "reference_count": "19",
    "references": [
        "1995945562",
        "1594031697",
        "2158940042",
        "2797583072",
        "2106706098",
        "2102201073",
        "2117897510",
        "191129667",
        "2954064014",
        "2007069447"
    ]
},{
    "id": "2145094598",
    "title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion",
    "abstract": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.",
    "date": "2010",
    "authors": [
        "Pascal Vincent",
        "Hugo Larochelle",
        "Isabelle Lajoie",
        "Yoshua Bengio",
        "Pierre-Antoine Manzagol"
    ],
    "related_topics": [
        "Deep belief network",
        "Support vector machine",
        "Pattern recognition"
    ],
    "citation_count": "6,087",
    "reference_count": "55",
    "references": [
        "2136922672",
        "2100495367",
        "2072128103",
        "2116064496",
        "2025768430",
        "2110798204",
        "1652505363",
        "2108384452",
        "1479807131",
        "1994197834"
    ]
},{
    "id": "2131241448",
    "title": "Practical Bayesian Optimization of Machine Learning Algorithms",
    "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",
    "date": "2012",
    "authors": [
        "Jasper Snoek",
        "Hugo Larochelle",
        "Ryan P Adams"
    ],
    "related_topics": [
        "Weighted Majority Algorithm",
        "Wake-sleep algorithm",
        "Bayesian optimization"
    ],
    "citation_count": "4,039",
    "reference_count": "23",
    "references": [
        "3118608800",
        "1746819321",
        "2141125852",
        "2097998348",
        "2106411961",
        "2951665052",
        "60686164",
        "2165599843",
        "2099201756",
        "1973333099"
    ]
},{
    "id": "2335728318",
    "title": "Reading Digits in Natural Images with Unsupervised Feature Learning",
    "abstract": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks.",
    "date": "2010",
    "authors": [
        "Yuval Netzer",
        "Tao Wang",
        "Adam Coates",
        "Alessandro Bissacco",
        "Bo Wu",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Feature learning",
        "Reading (process)",
        "Pattern recognition"
    ],
    "citation_count": "2,782",
    "reference_count": "28",
    "references": [
        "2161969291",
        "2122410182",
        "2145094598",
        "2147768505",
        "2145607950",
        "2097018403",
        "2118858186",
        "2144161366",
        "1998042868",
        "2132424367"
    ]
},{
    "id": "2296319761",
    "title": "Convex Optimization",
    "abstract": "Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.",
    "date": "2004",
    "authors": [
        "Stephen Boyd",
        "Lieven Vandenberghe"
    ],
    "related_topics": [
        "Conic optimization",
        "Convex optimization",
        "Nonlinear programming"
    ],
    "citation_count": "59,058",
    "reference_count": "6",
    "references": [
        "2030723843",
        "2000296233",
        "2020830442",
        "2006980285",
        "82689443",
        "2611147814"
    ]
},{
    "id": "3120740533",
    "title": "UCI Machine Learning Repository",
    "abstract": "",
    "date": "2006",
    "authors": [
        "A. Asuncion"
    ],
    "related_topics": [
        "Ensembles of classifiers",
        "LPBoost",
        "Computer science"
    ],
    "citation_count": "33,352",
    "reference_count": "0",
    "references": []
},{
    "id": "2798766386",
    "title": "Nonlinear Programming",
    "abstract": "",
    "date": "1994",
    "authors": [
        "Dimitri Bertsekas"
    ],
    "related_topics": [
        "Nonlinear programming",
        "Fritz John conditions",
        "Computer science"
    ],
    "citation_count": "16,962",
    "reference_count": "0",
    "references": []
},{
    "id": "2610857016",
    "title": "Matrix Analysis",
    "abstract": "Linear algebra and matrix theory are fundamental tools in mathematical and physical science, as well as fertile fields for research. This new edition of the acclaimed text presents results of both classic and recent matrix analyses using canonical forms as a unifying theme, and demonstrates their importance in a variety of applications. The authors have thoroughly revised, updated, and expanded on the first edition. The book opens with an extended summary of useful concepts and facts and includes numerous new topics and features, such as: - New sections on the singular value and CS decompositions - New applications of the Jordan canonical form - A new section on the Weyr canonical form - Expanded treatments of inverse problems and of block matrices - A central role for the Von Neumann trace theorem - A new appendix with a modern list of canonical forms for a pair of Hermitian matrices and for a symmetric-skew symmetric pair - Expanded index with more than 3,500 entries for easy reference - More than 1,100 problems and exercises, many with hints, to reinforce understanding and develop auxiliary themes such as finite-dimensional quantum systems, the compound and adjugate matrices, and the Loewner ellipsoid - A new appendix provides a collection of problem-solving hints.",
    "date": "1984",
    "authors": [
        "Roger A. Horn",
        "Charles R. Johnson"
    ],
    "related_topics": [
        "Weyr canonical form",
        "Canonical form",
        "Matrix (mathematics)"
    ],
    "citation_count": "45,196",
    "reference_count": "0",
    "references": []
},{
    "id": "2150102617",
    "title": "RCV1: A New Benchmark Collection for Text Categorization Research",
    "abstract": "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.",
    "date": "2004",
    "authors": [
        "David D. Lewis",
        "Yiming Yang",
        "Tony G. Rose",
        "Fan Li"
    ],
    "related_topics": [
        "Documentation",
        "Supervised learning",
        "Information retrieval"
    ],
    "citation_count": "3,008",
    "reference_count": "35",
    "references": [
        "2118020653",
        "2149684865",
        "2118202495",
        "2098162425",
        "2435251607",
        "2114535528",
        "2005422315",
        "2107008379",
        "2000672666",
        "1620204465"
    ]
},{
    "id": "2167732364",
    "title": "Smooth minimization of non-smooth functions",
    "abstract": "In this paper we propose a new approach for constructing efficient schemes for non-smooth convex optimization. It is based on a special smoothing technique, which can be applied to functions with explicit max-structure. Our approach can be considered as an alternative to black-box minimization. From the viewpoint of efficiency estimates, we manage to improve the traditional bounds on the number of iterations of the gradient schemes from ** keeping basically the complexity of each iteration unchanged.",
    "date": "2005",
    "authors": [
        "Yu Nesterov"
    ],
    "related_topics": [
        "Convex optimization",
        "Proximal Gradient Methods",
        "Random coordinate descent"
    ],
    "citation_count": "3,029",
    "reference_count": "10",
    "references": [
        "3141595720",
        "1669104078",
        "1568307856",
        "2124541940",
        "1553702074",
        "1568288633",
        "2015263936",
        "2150126561",
        "2969945254",
        "2008164266"
    ]
},{
    "id": "1992208280",
    "title": "Robust Stochastic Approximation Approach to Stochastic Programming",
    "abstract": "In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques, namely, the stochastic approximation (SA) and the sample average approximation (SAA) methods. Both approaches, the SA and SAA methods, have a long history. Current opinion is that the SAA method can efficiently use a specific (say, linear) structure of the considered problem, while the SA approach is a crude subgradient method, which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems. We extend the analysis to the case of convex-concave stochastic saddle point problems and present (in our opinion highly encouraging) results of numerical experiments.",
    "date": "2008",
    "authors": [
        "A. Nemirovski",
        "A. Juditsky",
        "G. Lan",
        "A. Shapiro"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Stochastic approximation",
        "Stochastic programming"
    ],
    "citation_count": "1,868",
    "reference_count": "26",
    "references": [
        "2038669746",
        "2169713291",
        "203276351",
        "2064076655",
        "1983916623",
        "2090359754",
        "2000257769",
        "2086161653",
        "1490324987",
        "2000953623"
    ]
},{
    "id": "2160218441",
    "title": "Online Passive-Aggressive Algorithms",
    "abstract": "We present a family of margin based online learning algorithms for various prediction tasks. In particular we derive and analyze algorithms for binary and multiclass categorization, regression, uniclass prediction and sequence prediction. The update steps of our different algorithms are all based on analytical solutions to simple constrained optimization problems. This unified view allows us to prove worst-case loss bounds for the different algorithms and for the various decision problems based on a single lemma. Our bounds on the cumulative loss of the algorithms are relative to the smallest loss that can be attained by any fixed hypothesis, and as such are applicable to both realizable and unrealizable settings. We demonstrate some of the merits of the proposed algorithms in a series of experiments with synthetic and real data sets.",
    "date": "2006",
    "authors": [
        "Koby Crammer",
        "Ofer Dekel",
        "Joseph Keshet",
        "Shai Shalev-Shwartz",
        "Yoram Singer"
    ],
    "related_topics": [
        "Margin Infused Relaxed Algorithm",
        "Margin (machine learning)",
        "Decision problem"
    ],
    "citation_count": "2,130",
    "reference_count": "35",
    "references": [
        "2296319761",
        "2148603752",
        "1563088657",
        "1560724230",
        "1601740268",
        "2053463056",
        "2032210760",
        "1978394996",
        "2101276256",
        "2157791002"
    ]
},{
    "id": "1978394996",
    "title": "Term Weighting Approaches in Automatic Text Retrieval",
    "abstract": "The experimental evidence accumulated over the past 20 years indicates that textindexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective term weighting systems. This paper summarizes the insights gained in automatic term weighting, and provides baseline single term indexing models with which other more elaborate content analysis procedures can be compared.",
    "date": "1988",
    "authors": [
        "Gerard Salton",
        "Christopher Buckley"
    ],
    "related_topics": [
        "Term Discrimination",
        "Weighting",
        "Term (time)"
    ],
    "citation_count": "11,455",
    "reference_count": "48",
    "references": [
        "1956559956",
        "2043909051",
        "2083605078",
        "2068632118",
        "3090556797",
        "2095396650",
        "2075006521",
        "11171803",
        "3091372544",
        "1557757161"
    ]
},{
    "id": "2141125852",
    "title": "Multi-column deep neural networks for image classification",
    "abstract": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.",
    "date": "2012",
    "authors": [
        "Dan Cire\u015fan",
        "Ueli Meier",
        "Juergen Schmidhuber"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Deep learning",
        "Artificial neural network"
    ],
    "citation_count": "4,678",
    "reference_count": "39",
    "references": [
        "3118608800",
        "2310919327",
        "2110798204",
        "2154642048",
        "2134557905",
        "2156163116",
        "2138857742",
        "2148461049",
        "2144982973",
        "1991848143"
    ]
},{
    "id": "2184045248",
    "title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition",
    "abstract": "Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.",
    "date": "2012",
    "authors": [
        "Geoffrey Hinton",
        "Li Deng",
        "Dong Yu",
        "George Dahl",
        "Abdel-rahman Mohamed",
        "Navdeep Jaitly",
        "Andrew Senior",
        "Vincent Vanhoucke",
        "Patrick Nguyen",
        "Tara Sainath",
        "Brian Kingsbury"
    ],
    "related_topics": [
        "Time delay neural network",
        "Hidden Markov model",
        "Artificial neural network"
    ],
    "citation_count": "5,940",
    "reference_count": "64",
    "references": [
        "2136922672",
        "2100495367",
        "1533861849",
        "2116064496",
        "2145094598",
        "2147768505",
        "1993882792",
        "2159080219",
        "44815768",
        "1498436455"
    ]
},{
    "id": "2118858186",
    "title": "An analysis of single-layer networks in unsupervised feature learning",
    "abstract": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several othe-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR, NORB, and STL datasets using only singlelayer networks. We then present a detailed analysis of the eect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (\u201cstride\u201d) between extracted features, and the eect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyperparameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).",
    "date": "2011",
    "authors": [
        "Adam Coates",
        "Andrew Y. Ng",
        "Honglak Lee"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Feature learning",
        "Cluster analysis"
    ],
    "citation_count": "2,577",
    "reference_count": "34",
    "references": [
        "2136922672",
        "3118608800",
        "2162915993",
        "2546302380",
        "2116064496",
        "2025768430",
        "2130325614",
        "2097018403",
        "2107034620",
        "1625255723"
    ]
},{
    "id": "3141595720",
    "title": "Introductory Lectures on Convex Optimization: A Basic Course",
    "abstract": "It was in the middle of the 1980s, when the seminal paper by Kar- markar opened a new epoch in nonlinear optimization. The importance of this paper, containing a new polynomial-time algorithm for linear op- timization problems, was not only in its complexity bound. At that time, the most surprising feature of this algorithm was that the theoretical pre- diction of its high efficiency was supported by excellent computational results. This unusual fact dramatically changed the style and direc- tions of the research in nonlinear optimization. Thereafter it became more and more common that the new methods were provided with a complexity analysis, which was considered a better justification of their efficiency than computational experiments. In a new rapidly develop- ing field, which got the name \"polynomial-time interior-point methods\", such a justification was obligatory. Afteralmost fifteen years of intensive research, the main results of this development started to appear in monographs [12, 14, 16, 17, 18, 19]. Approximately at that time the author was asked to prepare a new course on nonlinear optimization for graduate students. The idea was to create a course which would reflect the new developments in the field. Actually, this was a major challenge. At the time only the theory of interior-point methods for linear optimization was polished enough to be explained to students. The general theory of self-concordant functions had appeared in print only once in the form of research monograph [12].",
    "date": "2014",
    "authors": [
        "I\ufe20u\ufe21. E. Nesterov"
    ],
    "related_topics": [
        "Nonlinear programming",
        "Convex optimization",
        "Linear programming"
    ],
    "citation_count": "5,543",
    "reference_count": "0",
    "references": []
},{
    "id": "2120420045",
    "title": "No more pesky learning rates",
    "abstract": "The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of SGD or other adaptive approaches with their best settings obtained through systematic search, and effectively removes the need for learning rate tuning.",
    "date": "2013",
    "authors": [
        "Tom Schaul",
        "Sixin Zhang",
        "Yann LeCun"
    ],
    "related_topics": [
        "Online machine learning",
        "Stochastic gradient descent",
        "Artificial intelligence"
    ],
    "citation_count": "402",
    "reference_count": "21",
    "references": [
        "3118608800",
        "2146502635",
        "1533861849",
        "2113651538",
        "2914484425",
        "2156779765",
        "2137515395",
        "1568229137",
        "1598497354",
        "2130984546"
    ]
},{
    "id": "19621276",
    "title": "Improving the convergence of back-propagation learning with second-order methods",
    "abstract": "",
    "date": "1988",
    "authors": [
        "S. Becker",
        "Yann Lecun"
    ],
    "related_topics": [
        "Convergence (routing)",
        "Order (business)",
        "Backpropagation"
    ],
    "citation_count": "505",
    "reference_count": "2",
    "references": [
        "2160699933",
        "1526055535"
    ]
},{
    "id": "1994616650",
    "title": "A Stochastic Approximation Method",
    "abstract": "Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown to the experimenter, and it is desired to find the solution x = \u03b8 of the equation M(x) = \u03b1, where a is a given constant. We give a method for making successive experiments at levels x1, x2, \u00b7\u00b7\u00b7 in such a way that xn will tend to \u03b8 in probability.",
    "date": "1951",
    "authors": [
        "Herbert Robbins",
        "Sutton Monro"
    ],
    "related_topics": [
        "Minimax approximation algorithm",
        "Stochastic approximation",
        "Constant (mathematics)"
    ],
    "citation_count": "10,733",
    "reference_count": "0",
    "references": []
},{
    "id": "2171928131",
    "title": "Extensions of recurrent neural network language model",
    "abstract": "We present several modifications of the original recurrent neural network language model (RNN LM).While this model has been shown to significantly outperform many competitive language modeling techniques in terms of accuracy, the remaining problem is the computational complexity. In this work, we show approaches that lead to more than 15 times speedup for both training and testing phases. Next, we show importance of using a backpropagation through time algorithm. An empirical comparison with feedforward networks is also provided. In the end, we discuss possibilities how to reduce the amount of parameters in the model. The resulting RNN model can thus be smaller, faster both during training and testing, and more accurate than the basic one.",
    "date": "2011",
    "authors": [
        "Tomas Mikolov",
        "Stefan Kombrink",
        "Lukas Burget",
        "Jan Cernocky",
        "Sanjeev Khudanpur"
    ],
    "related_topics": [
        "Backpropagation through time",
        "Recurrent neural network",
        "Language model"
    ],
    "citation_count": "5,404",
    "reference_count": "20",
    "references": [
        "179875071",
        "2132339004",
        "1498436455",
        "2110485445",
        "2107878631",
        "2613634265",
        "36903255",
        "2096072088",
        "2111305191",
        "2152808281"
    ]
},{
    "id": "2251222643",
    "title": "Continuous Space Translation Models for Phrase-Based Statistical Machine Translation",
    "abstract": "This paper presents a new approach to perform the estimation of the translation model probabilities of a phrase-based statistical machine translation system. We use neural networks to directly learn the translation probability of phrase pairs using continuous representations. The system can be easily trained on the same data used to build standard phrase-based systems. We provide experimental evidence that the approach seems to be able to infer meaningful translation probabilities for phrase pairs not seen in the training data, or even predict a list of the most likely translations given a source phrase. The approach can be used to rescore n-best lists, but we also discuss an integration into the Moses decoder. A preliminary evaluation on the English/French IWSLT task achieved improvements in the BLEU score and a human analysis showed that the new model often chooses semantically better translations. Several extensions of this work are discussed.",
    "date": "2012",
    "authors": [
        "Holger Schwenk"
    ],
    "related_topics": [
        "Phrase",
        "Example-based machine translation",
        "Machine translation"
    ],
    "citation_count": "143",
    "reference_count": "17",
    "references": [
        "2132339004",
        "2156985047",
        "2146574666",
        "1970689298",
        "2109664771",
        "2251098065",
        "2143719855",
        "2140679639",
        "2250379827",
        "2103078213"
    ]
},{
    "id": "2006969979",
    "title": "The mathematics of statistical machine translation: parameter estimation",
    "abstract": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus.",
    "date": "1993",
    "authors": [
        "Peter F. Brown",
        "Vincent J. Della Pietra",
        "Stephen A. Della Pietra",
        "Robert L. Mercer"
    ],
    "related_topics": [
        "Hybrid machine translation",
        "Example-based machine translation",
        "Synchronous context-free grammar"
    ],
    "citation_count": "5,809",
    "reference_count": "15",
    "references": [
        "2049633694",
        "2121227244",
        "2097333193",
        "1489181569",
        "2117652747",
        "2129139611",
        "2154384676",
        "2138584836",
        "1575431606",
        "2048390999"
    ]
},{
    "id": "196214544",
    "title": "Generating Text with Recurrent Neural Networks",
    "abstract": "Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or \"gated\") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \u2013 a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date.",
    "date": "2011",
    "authors": [
        "Ilya Sutskever",
        "James Martens",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Language model",
        "Artificial intelligence"
    ],
    "citation_count": "1,439",
    "reference_count": "23",
    "references": [
        "2064675550",
        "179875071",
        "1498436455",
        "196761320",
        "2131462252",
        "2118706537",
        "2107878631",
        "2110575115",
        "1408639475",
        "2170942820"
    ]
},{
    "id": "2912934387",
    "title": "Bagging predictors",
    "abstract": "",
    "date": "1996",
    "authors": [
        "Leo Breiman"
    ],
    "related_topics": [
        "Computer science",
        "Bootstrap aggregating",
        "Classifier fusion"
    ],
    "citation_count": "27,423",
    "reference_count": "0",
    "references": []
},{
    "id": "189596042",
    "title": "Deep Boltzmann machines",
    "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.",
    "date": "2009",
    "authors": [
        "Ruslan Salakhutdinov",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Restricted Boltzmann machine",
        "MNIST database"
    ],
    "citation_count": "1,550",
    "reference_count": "21",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2134557905",
        "2096192494",
        "2613634265",
        "2116825644",
        "2567948266",
        "2159737176",
        "2124914669"
    ]
},{
    "id": "1554663460",
    "title": "Neural networks for pattern recognition",
    "abstract": "From the Publisher: This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.",
    "date": "1994",
    "authors": [
        "Christopher M. Bishop"
    ],
    "related_topics": [
        "Time delay neural network",
        "Types of artificial neural networks",
        "Feature (machine learning)"
    ],
    "citation_count": "33,877",
    "reference_count": "0",
    "references": []
},{
    "id": "2143612262",
    "title": "Speech recognition with deep recurrent neural networks",
    "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.",
    "date": "2013",
    "authors": [
        "Alex Graves",
        "Abdel-rahman Mohamed",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Deep learning",
        "Time delay neural network"
    ],
    "citation_count": "7,525",
    "reference_count": "26",
    "references": [
        "2064675550",
        "2160815625",
        "1993882792",
        "2184045248",
        "2127141656",
        "2144499799",
        "2108677974",
        "3023071679",
        "2155273149",
        "1828163288"
    ]
},{
    "id": "44815768",
    "title": "A Practical Guide to Training Restricted Boltzmann Machines",
    "abstract": "Restricted Boltzmann machines (RBMs) have been used as generative models of many different types of data. RBMs are usually trained using the contrastive divergence learning procedure. This requires a certain amount of practical experience to decide how to set the values of numerical meta-parameters. Over the last few years, the machine learning group at the University of Toronto has acquired considerable expertise at training RBMs and this guide is an attempt to share this expertise with other machine learning researchers.",
    "date": "2011",
    "authors": [
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Restricted Boltzmann machine",
        "Deep belief network"
    ],
    "citation_count": "3,207",
    "reference_count": "25",
    "references": [
        "2136922672",
        "1665214252",
        "2116064496",
        "2099866409",
        "2096192494",
        "2293063825",
        "2029949252",
        "2116825644",
        "2158164339",
        "2124914669"
    ]
},{
    "id": "2108677974",
    "title": "Practical Variational Inference for Neural Networks",
    "abstract": "Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.",
    "date": "2011",
    "authors": [
        "Alex Graves"
    ],
    "related_topics": [
        "Stochastic neural network",
        "Recurrent neural network",
        "Artificial neural network"
    ],
    "citation_count": "904",
    "reference_count": "25",
    "references": [
        "2064675550",
        "1498436455",
        "2127141656",
        "2129652681",
        "3161062409",
        "2170942820",
        "2103359087",
        "2114766824",
        "2150218618",
        "2054658115"
    ]
},{
    "id": "2120861206",
    "title": "A fast and simple algorithm for training neural probabilistic language models",
    "abstract": "In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients. We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well. We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset.",
    "date": "2012",
    "authors": [
        "Andriy Mnih",
        "Yee W. Teh"
    ],
    "related_topics": [
        "Probabilistic logic",
        "Language model",
        "Vocabulary"
    ],
    "citation_count": "494",
    "reference_count": "21",
    "references": [
        "2117130368",
        "179875071",
        "2132339004",
        "2158139315",
        "1423339008",
        "1631260214",
        "1521626219",
        "2131462252",
        "2138204974",
        "2096175520"
    ]
},{
    "id": "3023071679",
    "title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures",
    "abstract": "In this paper, we present bidirectional Long Short Term Memory (LSTM) networks, and a modified, full gradient version of the LSTM learning algorithm. We evaluate Bidirectional LSTM (BLSTM) and several other network architectures on the benchmark task of framewise phoneme classification, using the TIMIT database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory (LSTM) is much faster and also more accurate than both standard Recurrent Neural Nets (RNNs) and time-windowed Multilayer Perceptrons (MLPs). Our results support the view that contextual information is crucial to speech processing, and suggest that BLSTM is an effective architecture with which to exploit it'.",
    "date": "2004",
    "authors": [
        "Alex Graves",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Artificial neural network",
        "Perceptron",
        "Speech processing"
    ],
    "citation_count": "3,038",
    "reference_count": "0",
    "references": []
},{
    "id": "2130942839",
    "title": "Sequence to Sequence Learning with Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.",
    "date": "2014",
    "authors": [
        "Ilya Sutskever",
        "Oriol Vinyals",
        "Quoc V. Le"
    ],
    "related_topics": [
        "Sequence learning",
        "Phrase",
        "Sentence"
    ],
    "citation_count": "12,925",
    "reference_count": "29",
    "references": [
        "2618530766",
        "2964308564",
        "2157331557",
        "2310919327",
        "2064675550",
        "2101105183",
        "179875071",
        "2147768505",
        "2132339004",
        "1753482797"
    ]
},{
    "id": "2395935897",
    "title": "Audio Chord Recognition with Recurrent Neural Networks.",
    "abstract": "In this paper, we present an audio chord recognition system based on a recurrent neural network. The audio features are obtained from a deep neural network optimized with a combination of chromagram targets and chord information, and aggregated over different time scales. Contrarily to other existing approaches, our system incorporates acoustic and musicological models under a single training objective. We devise an efficient algorithm to search for the global mode of the output distribution while taking long-term dependencies into account. The resulting method is competitive with state-of-the-art approaches on the MIREX dataset in the major/minor prediction task.",
    "date": "2012",
    "authors": [
        "Nicolas Boulanger-Lewandowski",
        "Yoshua Bengio",
        "Pascal Vincent"
    ],
    "related_topics": [
        "Time delay neural network",
        "Chord (music)",
        "Recurrent neural network"
    ],
    "citation_count": "179",
    "reference_count": "25",
    "references": [
        "2136922672",
        "2072128103",
        "2147768505",
        "2154642048",
        "2184045248",
        "2107878631",
        "2962968839",
        "1828163288",
        "2108563286",
        "2162911105"
    ]
},{
    "id": "1828163288",
    "title": "Sequence Transduction with Recurrent Neural Networks",
    "abstract": "Many machine learning tasks can be expressed as the transformation---or \\emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \\emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus.",
    "date": "2012",
    "authors": [
        "Alex Graves"
    ],
    "related_topics": [
        "Sequence learning",
        "Recurrent neural network",
        "Transduction (machine learning)"
    ],
    "citation_count": "1,022",
    "reference_count": "19",
    "references": [
        "2310919327",
        "2064675550",
        "2147880316",
        "179875071",
        "2127141656",
        "196214544",
        "3023071679",
        "2131774270",
        "2079735306",
        "2170942820"
    ]
},{
    "id": "1905522558",
    "title": "Domain Adaptation via Pseudo In-Domain Data Selection",
    "abstract": "We explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large general-domain parallel corpus that are most relevant to the target domain. These sentences may be selected with simple cross-entropy based methods, of which we present three. As these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain subcorpora. These subcorpora -- 1% the size of the original -- can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus. Performance is further improved when we use these domain-adapted models in combination with a true in-domain model. The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding.",
    "date": "2011",
    "authors": [
        "Amittai Axelrod",
        "Xiaodong He",
        "Jianfeng Gao"
    ],
    "related_topics": [
        "Rule-based machine translation",
        "Machine translation",
        "Domain (software engineering)"
    ],
    "citation_count": "533",
    "reference_count": "18",
    "references": [
        "2124807415",
        "2156985047",
        "1631260214",
        "2146574666",
        "2158195707",
        "2117278770",
        "2137387514",
        "2132001515",
        "2130450156",
        "2148861208"
    ]
},{
    "id": "2341457423",
    "title": "BLEU Deconstructed: Designing a Better MT Evaluation Metric",
    "abstract": "BLEU is the de facto standard automatic evaluation metric in machine translation. While BLEU is undeniably useful, it has a number of limitations. Although it works well for large documents and multiple references, it is unreliable at the sentence or sub-sentence levels, and with a single reference. In this paper, we propose new variants of BLEU which address these limitations, resulting in a more flexible metric which is not only more reliable, but also allows for more accurate discriminative training. Our best metric has better correlation with human judgements than standard BLEU, despite using a simpler formulation. Moreover, these improvements carry over to a system tuned for our new metric.",
    "date": "2012",
    "authors": [
        "Xingyi Song",
        "Trevor Cohn",
        "Lucia Specia"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "Metric (mathematics)",
        "BLEU"
    ],
    "citation_count": "20",
    "reference_count": "29",
    "references": [
        "2101105183",
        "2124807415",
        "2146574666",
        "2123301721",
        "2078861931",
        "2087735403",
        "222053410",
        "1489525520",
        "2115081467",
        "2895810819"
    ]
},{
    "id": "1606347560",
    "title": "Theano: new features and speed improvements",
    "abstract": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.",
    "date": "2012",
    "authors": [
        "Fr\u00e9d\u00e9ric Bastien",
        "Pascal Lamblin",
        "Razvan Pascanu",
        "James Bergstra",
        "Ian J. Goodfellow",
        "Arnaud Bergeron",
        "Nicolas Bouchard",
        "David Warde-Farley",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Theano",
        "Compiler",
        "Recurrent neural network"
    ],
    "citation_count": "1,557",
    "reference_count": "10",
    "references": [
        "2011301426",
        "2154642048",
        "2061939373",
        "753012316",
        "3005347330",
        "1408639475",
        "2110114082",
        "2185726469",
        "2254715784",
        "2006903949"
    ]
},{
    "id": "2171865010",
    "title": "Survey: Reservoir computing approaches to recurrent neural network training",
    "abstract": "Echo State Networks and Liquid State Machines introduced a new paradigm in artificial recurrent neural network (RNN) training, where an RNN (the reservoir) is generated randomly and only a readout is trained. The paradigm, becoming known as reservoir computing, greatly facilitated the practical application of RNNs and outperformed classical fully trained RNNs in many tasks. It has lately become a vivid research field with numerous extensions of the basic idea, including reservoir adaptation, thus broadening the initial paradigm to using different methods for training the reservoir and the readout. This review systematically surveys both current ways of generating/adapting the reservoirs and training different types of readouts. It offers a natural conceptual classification of the techniques, which transcends boundaries of the current ''brand-names'' of reservoir methods, and thus aims to help in unifying the field and providing the reader with a detailed ''map'' of it.",
    "date": "2009",
    "authors": [
        "Mantas Luko\u0161evi\u010dius",
        "Herbert Jaeger"
    ],
    "related_topics": [
        "Reservoir computing",
        "Echo state network",
        "Recurrent neural network"
    ],
    "citation_count": "1,853",
    "reference_count": "144",
    "references": [
        "2100495367",
        "2112090702",
        "2008620264",
        "2064675550",
        "1497256448",
        "2154642048",
        "2108384452",
        "2293063825",
        "1659842140",
        "2118706537"
    ]
},{
    "id": "2122585011",
    "title": "A Novel Connectionist System for Unconstrained Handwriting Recognition",
    "abstract": "Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters, combined with the need to exploit surrounding context, has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed, most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition, despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases, our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data, significantly outperforming a state-of-the-art HMM-based system. In addition, we demonstrate the network's robustness to lexicon size, measure the individual influence of its hidden layers, and analyze its use of context. Last, we provide an in-depth discussion of the differences between the network and HMMs, suggesting reasons for the network's superior performance.",
    "date": "2009",
    "authors": [
        "A. Graves",
        "M. Liwicki",
        "S. Fernandez",
        "R. Bertolami",
        "H. Bunke",
        "J. Schmidhuber"
    ],
    "related_topics": [
        "Intelligent character recognition",
        "Handwriting recognition",
        "Language model"
    ],
    "citation_count": "1,876",
    "reference_count": "54",
    "references": [
        "2064675550",
        "2125838338",
        "2127141656",
        "3023071679",
        "2107878631",
        "2142069714",
        "2131774270",
        "2079735306",
        "1578856370",
        "2147568880"
    ]
},{
    "id": "2118706537",
    "title": "Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication",
    "abstract": "We present a method for learning nonlinear systems, echo state networks (ESNs). ESNs employ artificial recurrent neural networks in a way that has recently been proposed independently as a learning mechanism in biological brains. The learning method is computationally efficient and easy to use. On a benchmark task of predicting a chaotic time series, accuracy is improved by a factor of 2400 over previous techniques. The potential for engineering applications is illustrated by equalizing a communication channel, where the signal error rate is improved by two orders of magnitude.",
    "date": "2004",
    "authors": [
        "Herbert Jaeger",
        "Harald Haas"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Echo state network",
        "Reservoir computing"
    ],
    "citation_count": "2,644",
    "reference_count": "12",
    "references": [
        "2103179919",
        "2016589492",
        "1543237449",
        "2166322089",
        "2134514463",
        "2094631910",
        "2058580716",
        "2143879519",
        "2045182040",
        "1943433854"
    ]
},{
    "id": "2107878631",
    "title": "Learning long-term dependencies with gradient descent is difficult",
    "abstract": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered. >",
    "date": "1994",
    "authors": [
        "Y. Bengio",
        "P. Simard",
        "P. Frasconi"
    ],
    "related_topics": [
        "Vanishing gradient problem",
        "Gradient descent",
        "Recurrent neural network"
    ],
    "citation_count": "6,843",
    "reference_count": "19",
    "references": [
        "2581275558",
        "2154642048",
        "2016589492",
        "19621276",
        "2128499899",
        "2088978850",
        "2148099973",
        "1996741810",
        "2125329357",
        "1527772862"
    ]
},{
    "id": "2101105183",
    "title": "Bleu: a Method for Automatic Evaluation of Machine Translation",
    "abstract": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.",
    "date": "2002",
    "authors": [
        "Kishore Papineni",
        "Salim Roukos",
        "Todd Ward",
        "Wei-Jing Zhu"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "Interactive machine translation",
        "Hybrid machine translation"
    ],
    "citation_count": "15,214",
    "reference_count": "3",
    "references": [
        "2001810881",
        "3037252522",
        "2732923061"
    ]
},{
    "id": "1508165687",
    "title": "Statistical methods for speech recognition",
    "abstract": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory the complexity of tasks - the quality of language models the expectation - maximization algorithm and its consequences decision trees and tree language models phonetics from orthography - spelling-to-base from mappings triphones and allophones maximum entropy probability estimation and language models three applications of maximum entropy estimation to language modelling estimation of probabilities from counts and the Back-Off method.",
    "date": "1996",
    "authors": [
        "Frederick Jelinek"
    ],
    "related_topics": [
        "Cache language model",
        "Language model",
        "Principle of maximum entropy"
    ],
    "citation_count": "2,874",
    "reference_count": "1",
    "references": [
        "1980862600"
    ]
},{
    "id": "1973923101",
    "title": "Improved statistical alignment models",
    "abstract": "In this paper, we present and compare various single-word based alignment models for statistical machine translation. We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications. We present different methods to combine alignments. As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies.",
    "date": "2000",
    "authors": [
        "Franz Josef Och",
        "Hermann Ney"
    ],
    "related_topics": [
        "Viterbi algorithm",
        "Machine translation",
        "Algorithm"
    ],
    "citation_count": "1,319",
    "reference_count": "9",
    "references": [
        "2006969979",
        "2038698865",
        "1979102019",
        "1575431606",
        "3104029765",
        "1811404221",
        "2030750105",
        "1525706028",
        "136130055"
    ]
},{
    "id": "1986543644",
    "title": "Three Generative, Lexicalised Models for Statistical Parsing",
    "abstract": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96).",
    "date": "1997",
    "authors": [
        "Michael Collins"
    ],
    "related_topics": [
        "Parser combinator",
        "Top-down parsing",
        "Statistical parsing"
    ],
    "citation_count": "1,111",
    "reference_count": "15",
    "references": [
        "1632114991",
        "1773803948",
        "2110882317",
        "2153439141",
        "2052449326",
        "2093647425",
        "1972573551",
        "2087165009",
        "2069912724",
        "2162455891"
    ]
},{
    "id": "2116316001",
    "title": "A Syntax-based Statistical Translation Model",
    "abstract": "We present a syntax-based statistical translation model. Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node. These operations capture linguistic differences such as word order and case marking. Model parameters are estimated in polynomial time using an EM algorithm. The model produces word alignments that are better than those produced by IBM Model 5.",
    "date": "2001",
    "authors": [
        "Kenji Yamada",
        "Kevin Knight"
    ],
    "related_topics": [
        "Parse tree",
        "Word error rate",
        "Word (computer architecture)"
    ],
    "citation_count": "1,046",
    "reference_count": "315",
    "references": [
        "2101105183",
        "2122410182",
        "1574901103",
        "2049633694",
        "2006969979",
        "1916559533",
        "2092654472",
        "2135843243",
        "2117400858",
        "2101210369"
    ]
},{
    "id": "1517947178",
    "title": "Improved Alignment Models for Statistical Machine Translation",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Franz Josef Och",
        "Christoph Tillmann",
        "Hermann Ney"
    ],
    "related_topics": [
        "Interactive machine translation",
        "Machine translation",
        "Speech recognition"
    ],
    "citation_count": "878",
    "reference_count": "7",
    "references": [
        "2006969979",
        "2038698865",
        "2107551411",
        "2113106066",
        "2196555355",
        "2294072136",
        "2158164089"
    ]
},{
    "id": "2161792612",
    "title": "A Phrase-Based,Joint Probability Model for Statistical Machine Translation",
    "abstract": "We present a joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora. Translations produced with parameters estimated using the joint model are more accurate than translations produced using IBM Model 4.",
    "date": "2002",
    "authors": [
        "Daniel Marcu",
        "Daniel Wong"
    ],
    "related_topics": [
        "Machine translation",
        "Phrase",
        "Word (computer architecture)"
    ],
    "citation_count": "632",
    "reference_count": "15",
    "references": [
        "2049633694",
        "2006969979",
        "1916559533",
        "2001810881",
        "2116316001",
        "1517947178",
        "2129765547",
        "1549285799",
        "2139403546",
        "133045130"
    ]
},{
    "id": "1549285799",
    "title": "Statistical Language Modeling using the CMU-Cambridge Toolkit",
    "abstract": "",
    "date": "1996",
    "authors": [
        "Philip Clarkson",
        "Ronald Rosenfeld"
    ],
    "related_topics": [
        "Modeling language",
        "Language model",
        "Computer science"
    ],
    "citation_count": "972",
    "reference_count": "0",
    "references": []
},{
    "id": "2158388102",
    "title": "Stochastic inversion transduction grammars and bilingual parsing of parallel corpora",
    "abstract": "We introduce (1) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and (2) the concept of bilingual parsing with a variety of parallel corpus analysis applications. Aside from the bilingual orientation, three major features distinguish the formalism from the finite-state transducers more traditionally found in computational linguistics: it skips directly to a context-free rather than finite-state base, it permits a minimal extra degree of ordering flexibility, and its probabilistic formulation admits an efficient maximum-likelihood bilingual parsing algorithm. A convenient normal form is shown to exist. Analysis of the formalism's expressiveness suggests that it is particularly well suited to modeling ordering shifts between languages, balancing needed flexibility against complexity constraints. We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation, bracketing, phrasal alignment, and parsing.",
    "date": "1997",
    "authors": [
        "Dekai Wu"
    ],
    "related_topics": [
        "S-attributed grammar",
        "Parsing",
        "Language model"
    ],
    "citation_count": "1,119",
    "reference_count": "48",
    "references": [
        "2006969979",
        "2097333193",
        "1489181569",
        "2117652747",
        "1513168562",
        "1991133427",
        "2439178139",
        "2138584836",
        "201288405",
        "2110190189"
    ]
},{
    "id": "2096733369",
    "title": "FaceNet: A unified embedding for face recognition and clustering",
    "abstract": "Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors.",
    "date": "2015",
    "authors": [
        "Florian Schroff",
        "Dmitry Kalenichenko",
        "James Philbin"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face detection",
        "Object-class detection"
    ],
    "citation_count": "7,601",
    "reference_count": "23",
    "references": [
        "2097117768",
        "1849277567",
        "2146502635",
        "2963911037",
        "2168231600",
        "2145287260",
        "1782590233",
        "2294059674",
        "1498436455",
        "2296073425"
    ]
},{
    "id": "2016053056",
    "title": "Large-Scale Video Classification with Convolutional Neural Networks",
    "abstract": "Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a new dataset of 1 million YouTube videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggest a multiresolution, foveated architecture as a promising way of speeding up the training. Our best spatio-temporal networks display significant performance improvements compared to strong feature-based baselines (55.3% to 63.9%), but only a surprisingly modest improvement compared to single-frame models (59.3% to 60.9%). We further study the generalization performance of our best model by retraining the top layers on the UCF-101 Action Recognition dataset and observe significant performance improvements compared to the UCF-101 baseline model (63.3% up from 43.9%).",
    "date": "2014",
    "authors": [
        "Andrej Karpathy",
        "George Toderici",
        "Sanketh Shetty",
        "Thomas Leung",
        "Rahul Sukthankar",
        "Li Fei-Fei"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Feature (machine learning)",
        "Feature extraction"
    ],
    "citation_count": "5,760",
    "reference_count": "28",
    "references": [
        "2618530766",
        "2102605133",
        "2108598243",
        "2161969291",
        "2963542991",
        "2310919327",
        "2168231600",
        "2022508996",
        "2131846894",
        "2062118960"
    ]
},{
    "id": "2097726431",
    "title": "Opinion Mining and Sentiment Analysis",
    "abstract": "An important part of our information-gathering behavior has always been to find out what other people think. With the growing availability and popularity of opinion-rich resources such as online review sites and personal blogs, new opportunities and challenges arise as people now can, and do, actively use information technologies to seek out and understand the opinions of others. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has thus occurred at least in part as a direct response to the surge of interest in new systems that deal directly with opinions as a first-class object. This survey covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems. Our focus is on methods that seek to address the new challenges raised by sentiment-aware applications, as compared to those that are already present in more traditional fact-based analysis. We include material on summarization of evaluative text and on broader issues regarding privacy, manipulation, and economic impact that the development of opinion-oriented information-access services gives rise to. To facilitate future work, a discussion of available resources, benchmark datasets, and evaluation campaigns is also provided.",
    "date": "2008",
    "authors": [
        "Bo Pang",
        "Lillian Lee"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Automatic summarization",
        "Information technology"
    ],
    "citation_count": "8,811",
    "reference_count": "314",
    "references": [
        "1880262756",
        "3013264884",
        "2147880316",
        "2038721957",
        "2138621811",
        "2166706824",
        "2160660844",
        "2118020653",
        "3146306708",
        "2114524997"
    ]
},{
    "id": "2057175746",
    "title": "Shape matching and object recognition using shape contexts",
    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.",
    "date": "2002",
    "authors": [
        "S. Belongie",
        "J. Malik",
        "J. Puzicha"
    ],
    "related_topics": [
        "Shape analysis (digital geometry)",
        "Heat kernel signature",
        "Shape context"
    ],
    "citation_count": "8,336",
    "reference_count": "58",
    "references": [
        "2310919327",
        "2124386111",
        "2119821739",
        "2117812871",
        "2138451337",
        "2038952578",
        "2124087378",
        "2123977795",
        "2101522199",
        "2146766088"
    ]
},{
    "id": "2159080219",
    "title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
    "abstract": "From the Publisher: Probabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. Probabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability.",
    "date": "1987",
    "authors": [
        "Judea Pearl"
    ],
    "related_topics": [
        "Reasoning system",
        "Intelligent decision support system",
        "Probabilistic logic network"
    ],
    "citation_count": "24,375",
    "reference_count": "235",
    "references": [
        "2581275558",
        "1997063559",
        "1593793857",
        "2797148637",
        "2155322595",
        "158727920",
        "2138162238",
        "2108309071",
        "1986808060",
        "2142901448"
    ]
},{
    "id": "2156163116",
    "title": "Best practices for convolutional neural networks applied to visual document analysis",
    "abstract": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages.",
    "date": "2003",
    "authors": [
        "P.Y. Simard",
        "D. Steinkraus",
        "J.C. Platt"
    ],
    "related_topics": [
        "Convolutional neural network",
        "MNIST database",
        "Artificial neural network"
    ],
    "citation_count": "2,757",
    "reference_count": "8",
    "references": [
        "2310919327",
        "1554663460",
        "2159737176",
        "2027197837",
        "2068017609",
        "2147345686",
        "51975515",
        "2166469100"
    ]
},{
    "id": "2131686571",
    "title": "Fields of Experts: a framework for learning image priors",
    "abstract": "We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov random field (MRF) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we obtain results that compete with and even outperform specialized techniques.",
    "date": "2005",
    "authors": [
        "S. Roth",
        "M.J. Black"
    ],
    "related_topics": [
        "Markov random field",
        "Approximate inference",
        "Inpainting"
    ],
    "citation_count": "1,178",
    "reference_count": "25",
    "references": [
        "2133665775",
        "2116064496",
        "2108384452",
        "1997063559",
        "2121927366",
        "2113945798",
        "2295936755",
        "2116013899",
        "2149760002",
        "2105464873"
    ]
},{
    "id": "2158778629",
    "title": "Toward automatic phenotyping of developing embryos from videos",
    "abstract": "We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.",
    "date": "2005",
    "authors": [
        "Feng Ning",
        "D. Delhomme",
        "Y. LeCun",
        "F. Piano",
        "L. Bottou",
        "P.E. Barbano"
    ],
    "related_topics": [
        "Image segmentation",
        "Image processing",
        "Contextual image classification"
    ],
    "citation_count": "305",
    "reference_count": "42",
    "references": [
        "2164598857",
        "2310919327",
        "2147880316",
        "2104095591",
        "1647075334",
        "2134557905",
        "2121927366",
        "2119823327",
        "1991848143",
        "2157364932"
    ]
},{
    "id": "2567948266",
    "title": "A view of the EM algorithm that justifies incremental, sparse, and other variants",
    "abstract": "The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible.",
    "date": "1998",
    "authors": [
        "Radford M. Neal",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Expectation\u2013maximization algorithm",
        "Conditional probability distribution",
        "Function (mathematics)"
    ],
    "citation_count": "3,196",
    "reference_count": "6",
    "references": [
        "2049633694",
        "2117853077",
        "2024476015",
        "1580495158",
        "1991278573",
        "581152777"
    ]
},{
    "id": "2159737176",
    "title": "Training Invariant Support Vector Machines",
    "abstract": "Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.",
    "date": "2002",
    "authors": [
        "Dennis Decoste",
        "Bernhard Sch\u00f6lkopf"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Structured support vector machine",
        "Least squares support vector machine"
    ],
    "citation_count": "771",
    "reference_count": "38",
    "references": [
        "2156909104",
        "2148603752",
        "2310919327",
        "2119821739",
        "2140095548",
        "1512098439",
        "2087347434",
        "1604938182",
        "2147800946",
        "2151040995"
    ]
},{
    "id": "2153663612",
    "title": "Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries",
    "abstract": "We address the image denoising problem, where zero-mean white and homogeneous Gaussian additive noise is to be removed from a given image. The approach taken is based on sparse and redundant representations over trained dictionaries. Using the K-SVD algorithm, we obtain a dictionary that describes the image content effectively. Two training options are considered: using the corrupted image itself, or training on a corpus of high-quality image database. Since the K-SVD is limited in handling small image patches, we extend its deployment to arbitrary image sizes by defining a global image prior that forces sparsity over patches in every location in the image. We show how such Bayesian treatment leads to a simple and effective denoising algorithm. This leads to a state-of-the-art denoising performance, equivalent and sometimes surpassing recently published leading alternative denoising methods",
    "date": "2006",
    "authors": [
        "M. Elad",
        "M. Aharon"
    ],
    "related_topics": [
        "Non-local means",
        "Video denoising",
        "Feature detection (computer vision)"
    ],
    "citation_count": "5,578",
    "reference_count": "41",
    "references": [
        "2160547390",
        "2078204800",
        "2146842127",
        "2158940042",
        "2151693816",
        "2097323375",
        "2113945798",
        "2132680427",
        "2079724595",
        "2131686571"
    ]
},{
    "id": "2613634265",
    "title": "Scaling learning algorithms towards AI",
    "abstract": "One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), reasoning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with minimal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally limited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very inefficient in terms of required number of computational elements and examples. Second, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learning) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more abstract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence.",
    "date": "2006",
    "authors": [
        "Yoshua Bengio",
        "Yann Lecun"
    ],
    "related_topics": [
        "Kernel method",
        "Kernel (statistics)",
        "Nonlinear dimensionality reduction"
    ],
    "citation_count": "1,415",
    "reference_count": "47",
    "references": [
        "2136922672",
        "2148603752",
        "2310919327",
        "2119821739",
        "2053186076",
        "2116064496",
        "2001141328",
        "2110798204",
        "2057175746",
        "2140095548"
    ]
},{
    "id": "1993845689",
    "title": "The \"Wake-Sleep\" Algorithm for Unsupervised Neural Networks",
    "abstract": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.",
    "date": "1995",
    "authors": [
        "Geoffrey E. Hinton",
        "Peter Dayan",
        "Brendan J. Frey",
        "Radford M. Neal"
    ],
    "related_topics": [
        "Helmholtz machine",
        "Wake-sleep algorithm",
        "Artificial neural network"
    ],
    "citation_count": "1,275",
    "reference_count": "5",
    "references": [
        "2740373864",
        "2177040213",
        "1533169541",
        "2044875682",
        "94647076"
    ]
},{
    "id": "2109779438",
    "title": "The Cascade-Correlation Learning Architecture",
    "abstract": "Cascade-Correlation is a new architecture and supervised learning algorithm for artificial neural networks. Instead of just adjusting the weights in a network of fixed topology. Cascade-Correlation begins with a minimal network, then automatically trains and adds new hidden units one by one, creating a multi-layer structure. Once a new hidden unit has been added to the network, its input-side weights are frozen. This unit then becomes a permanent feature-detector in the network, available for producing outputs or for creating other, more complex feature detectors. The Cascade-Correlation architecture has several advantages over existing algorithms: it learns very quickly, the network determines its own size and topology, it retains the structures it has built even if the training set changes, and it requires no back-propagation of error signals through the connections of the network.",
    "date": "1988",
    "authors": [
        "Scott E. Fahlman",
        "Christian Lebiere"
    ],
    "related_topics": [
        "Network topology",
        "Network simulation",
        "Artificial neural network"
    ],
    "citation_count": "4,259",
    "reference_count": "12",
    "references": [
        "2154642048",
        "1652505363",
        "2160208155",
        "19621276",
        "3121126077",
        "2160699933",
        "50076749",
        "2127385318",
        "2169163929",
        "2167277568"
    ]
},{
    "id": "2103626435",
    "title": "Practical Issues in Temporal Difference Learning",
    "abstract": "This paper examines whether temporal difference methods for training connectionist networks, such as Sutton's TD(\u03bb) algorithm, can be successfully applied to complex real-world problems. A number of important practical issues are identified and discussed from a general theoretical perspective. These practical issues are then examined in the context of a case study in which TD(\u03bb) is applied to learning the game of backgammon from the outcome of self-play. This is apparently the first application of this algorithm to a complex non-trivial task. It is found that, with zero knowledge built in, the network is able to learn from scratch to play the entire game at a fairly strong intermediate level of performance, which is clearly better than conventional commercial programs, and which in fact surpasses comparable networks trained on a massive human expert data set. This indicates that TD learning may work better in practice than one would expect based on current theory, and it suggests that further analysis of TD methods, as well as applications in other complex domains, may be worth investigating.",
    "date": "1992",
    "authors": [
        "Gerald Tesauro"
    ],
    "related_topics": [
        "Temporal difference learning",
        "Outcome (game theory)",
        "Context (language use)"
    ],
    "citation_count": "1,601",
    "reference_count": "28",
    "references": [
        "2154642048",
        "1652505363",
        "2137983211",
        "3146803896",
        "2100677568",
        "2178806388",
        "1583833196",
        "2154952480",
        "2159047538",
        "1569296262"
    ]
},{
    "id": "2125569215",
    "title": "The Curse of Highly Variable Functions for Local Kernel Machines",
    "abstract": "We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality, or more precisely to the variability of the target. Our discussion covers supervised, semi-supervised and unsupervised learning algorithms. These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality, well studied for classical non-parametric statistical learning. We show in the case of the Gaussian kernel that when the function to be learned has many variations, these algorithms require a number of training examples proportional to the number of variations, which could be large even though there may exist short descriptions of the target function, i.e. their Kolmogorov complexity may be low. This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions (because locally they have many variations), while not using very specific prior domain knowledge.",
    "date": "2005",
    "authors": [
        "Yoshua Bengio",
        "Olivier Delalleau",
        "Nicolas L. Roux"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Kernel method",
        "Kernel embedding of distributions"
    ],
    "citation_count": "222",
    "reference_count": "19",
    "references": [
        "2119821739",
        "2053186076",
        "2001141328",
        "2140095548",
        "2087347434",
        "2154455818",
        "2139823104",
        "1604938182",
        "3017143921",
        "2160167256"
    ]
},{
    "id": "2167967601",
    "title": "Convex Neural Networks",
    "abstract": "Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artificial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an infinite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time finding a linear classifier that minimizes a weighted sum of errors.",
    "date": "2005",
    "authors": [
        "Yoshua Bengio",
        "Nicolas L. Roux",
        "Pascal Vincent",
        "Olivier Delalleau",
        "Patrice Marcotte"
    ],
    "related_topics": [
        "Deep learning",
        "Convex optimization",
        "Types of artificial neural networks"
    ],
    "citation_count": "189",
    "reference_count": "16",
    "references": [
        "2135046866",
        "3124955340",
        "1678356000",
        "1498436455",
        "2151693816",
        "2091886411",
        "2504871398",
        "2108263314",
        "2109405055",
        "2075887074"
    ]
},{
    "id": "2153635508",
    "title": "LIBSVM: A library for support vector machines",
    "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",
    "date": "2011",
    "authors": [
        "Chih-Chung Chang",
        "Chih-Jen Lin"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Structured support vector machine",
        "Support vector machine"
    ],
    "citation_count": "43,932",
    "reference_count": "52",
    "references": [
        "2148603752",
        "2119821739",
        "2109943925",
        "2172000360",
        "1512098439",
        "2104978738",
        "1576520375",
        "2087347434",
        "2132870739",
        "2124351082"
    ]
},{
    "id": "2147800946",
    "title": "Backpropagation applied to handwritten zip code recognition",
    "abstract": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.",
    "date": "1989",
    "authors": [
        "Y. LeCun",
        "B. Boser",
        "J. S. Denker",
        "D. Henderson",
        "R. E. Howard",
        "W. Hubbard",
        "L. D. Jackel"
    ],
    "related_topics": [
        "Backpropagation",
        "Character (computing)",
        "Pattern recognition"
    ],
    "citation_count": "8,702",
    "reference_count": "14",
    "references": [
        "2154642048",
        "2165758113",
        "169539560",
        "19621276",
        "2101926813",
        "56903235",
        "2157475639",
        "2606594511",
        "1965770722",
        "2116360511"
    ]
},{
    "id": "1902027874",
    "title": "Learning the parts of objects by non-negative matrix factorization",
    "abstract": "Is perception of the whole based on perception of its parts? There is psychological1 and physiological2,3 evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations4,5. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.",
    "date": "1999",
    "authors": [
        "Daniel D. Lee",
        "H. Sebastian Seung"
    ],
    "related_topics": [
        "Non-negative matrix factorization",
        "Matrix decomposition",
        "Document-term matrix"
    ],
    "citation_count": "12,731",
    "reference_count": "23",
    "references": [
        "2138451337",
        "2108384452",
        "2049633694",
        "1956559956",
        "2145889472",
        "1983578042",
        "1996355918",
        "1993845689",
        "2156406284",
        "2180838288"
    ]
},{
    "id": "2105464873",
    "title": "Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by V1 ?",
    "abstract": "The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and ban@ass, comparable with the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images. Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete--i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output function will deviate from being purely linear. These deviations from linearity provide a potential explanation for the weak forms of non-linearity observed in the response properties of cortical simple cells, and they further make predictions about the expected interactions among units in response to naturalistic stimuli. \u00a9 1997 Elsevier Science Ltd",
    "date": "1997",
    "authors": [
        "Bruno A. Olshausen",
        "David J. Field"
    ],
    "related_topics": [
        "Basis function",
        "Efficient coding hypothesis",
        "Neural coding"
    ],
    "citation_count": "4,196",
    "reference_count": "38",
    "references": [
        "2132984323",
        "2099741732",
        "2108384452",
        "2145889472",
        "1536929369",
        "2133069808",
        "2107790757",
        "2167034998",
        "3022628558",
        "2145012779"
    ]
},{
    "id": "1802356529",
    "title": "Energy-based models for sparse overcomplete representations",
    "abstract": "We present a new way of extending independent components analysis (ICA) to overcomplete representations. In contrast to the causal generative extensions of ICA which maintain marginal independence of sources, we define features as deterministic (linear) functions of the inputs. This assumption results in marginal dependencies among the features, but conditional independence of the features given the inputs. By assigning energies to the features a probability distribution over the input states is defined through the Boltzmann distribution. Free parameters of this model are trained using the contrastive divergence objective (Hinton, 2002). When the number of features is equal to the number of input dimensions this energy-based model reduces to noiseless ICA and we show experimentally that the proposed learning algorithm is able to perform blind source separation on speech data. In additional experiments we train overcomplete energy-based models to extract features from various standard data-sets containing speech, natural images, hand-written digits and faces.",
    "date": "2003",
    "authors": [
        "Yee Whye Teh",
        "Max Welling",
        "Simon Osindero",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Independent component analysis",
        "Independence (probability theory)",
        "Conditional independence"
    ],
    "citation_count": "206",
    "reference_count": "31",
    "references": [
        "2116064496",
        "2078204800",
        "2154642048",
        "1652505363",
        "2099741732",
        "2108384452",
        "2151693816",
        "2145889472",
        "2146474141",
        "2105464873"
    ]
},{
    "id": "2075187489",
    "title": "The Cost of Cortical Computation",
    "abstract": "Electrophysiological recordings show that individual neurons in cortex are strongly activated when engaged in appropriate tasks, but they tell us little about how many neurons might be engaged by a task, which is important to know if we are to understand how cortex encodes information. For human cortex, I estimate the cost of individual spikes, then, from the known energy consumption of cortex, I establish how many neurons can be active concurrently. The cost of a single spike is high, and this severely limits, possibly to fewer than 1%, the number of neurons that can be substantially active concurrently. The high cost of spikes requires the brain not only to use representational codes that rely on very few active neurons, but also to allocate its energy resources flexibly among cortical regions according to task demand. The latter constraint explains the investment in local control of hemodynamics, exploited by functional magnetic resonance imaging, and the need for mechanisms of selective attention.",
    "date": "2003",
    "authors": [
        "Peter Lennie"
    ],
    "related_topics": [
        "Functional magnetic resonance imaging",
        "Cortex (anatomy)",
        "Brain mapping"
    ],
    "citation_count": "1,155",
    "reference_count": "37",
    "references": [
        "2110208125",
        "2042422091",
        "1907121963",
        "1976738367",
        "2003739479",
        "1603661052",
        "1993303421",
        "1991233288",
        "2096519870",
        "43284170"
    ]
},{
    "id": "2102409316",
    "title": "Autoencoders, Minimum Description Length and Helmholtz Free Energy",
    "abstract": "An autoencoder network uses a set of recognition weights to convert an input vector into a code vector. It then uses a set of generative weights to convert the code vector into an approximate reconstruction of the input vector. We derive an objective function for training autoencoders based on the Minimum Description Length (MDL) principle. The aim is to minimize the information required to describe both the code vector and the reconstruction error. We show that this information is minimized by choosing code vectors stochastically according to a Boltzmann distribution, where the generative weights define the energy of each possible code vector given the input vector. Unfortunately, if the code vectors use distributed representations, it is exponentially expensive to compute this Boltzmann distribution because it involves all possible code vectors. We show that the recognition weights of an autoencoder can be used to compute an approximation to the Boltzmann distribution and that this approximation gives an upper bound on the description length. Even when this bound is poor, it can be used as a Lyapunov function for learning both the generative and the recognition weights. We demonstrate that this approach can be used to learn factorial codes.",
    "date": "1993",
    "authors": [
        "Geoffrey E. Hinton",
        "Richard S. Zemel"
    ],
    "related_topics": [
        "Autoencoder",
        "Minimum description length",
        "Upper and lower bounds"
    ],
    "citation_count": "1,045",
    "reference_count": "6",
    "references": [
        "2176028050",
        "2078626246",
        "2063089147",
        "1578739277",
        "2110553242",
        "2151907713"
    ]
},{
    "id": "11828546",
    "title": "4.7 \u2013 Statistical Modeling of Photographic Images",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Eero P. Simoncelli"
    ],
    "related_topics": [
        "Statistical model",
        "Computer vision",
        "Computer science"
    ],
    "citation_count": "119",
    "reference_count": "61",
    "references": [
        "2132984323",
        "2053691921",
        "2113945798",
        "2145889472",
        "2105464873",
        "2103504761",
        "2134929491",
        "2127006916",
        "2137234026",
        "2109863423"
    ]
},{
    "id": "2025170735",
    "title": "Coronavirus as a possible cause of severe acute respiratory syndrome",
    "abstract": "Summary Background An outbreak of severe acute respiratory syndrome (SARS) has been reported in Hong Kong. We investigated the viral cause and clinical presentation among 50 patients. Methods We analysed case notes and microbiological findings for 50 patients with SARS, representing more than five separate epidemiologically linked transmission clusters. We defined the clinical presentation and risk factors associated with severe disease and investigated the causal agents by chest radiography and laboratory testing of nasopharyngeal aspirates and sera samples. We compared the laboratory findings with those submitted for microbiological investigation of other diseases from patients whose identity was masked. Findings Patients' age ranged from 23 to 74 years. Fever, chills, myalgia, and cough were the most frequent complaints. When compared with chest radiographic changes, respiratory symptoms and auscultatory findings were disproportionally mild. Patients who were household contacts of other infected people and had older age, lymphopenia, and liver dysfunction were associated with severe disease. A virus belonging to the family Coronaviridae was isolated from two patients. By use of serological and reverse-transcriptase PCR specific for this virus, 45 of 50 patients with SARS, but no controls, had evidence of infection with this virus. Interpretation A coronavirus was isolated from patients with SARS that might be the primary agent associated with this disease. Serological and molecular tests specific for the virus permitted a definitive laboratory diagnosis to be made and allowed further investigation to define whether other cofactors play a part in disease progression.",
    "date": "2003",
    "authors": [
        "Jsm Peiris",
        "ST Lai",
        "Llm Poon",
        "Y Guan",
        "Lyc Yam",
        "W Lim",
        "J Nicholls",
        "Wks Yee",
        "WW Yan",
        "MT Cheung",
        "Vcc Cheng",
        "KH Chan",
        "Dnc Tsang",
        "Rwh Yung",
        "TK Ng",
        "KY Yuen"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Human coronavirus NL63",
        "Coronavirus"
    ],
    "citation_count": "3,651",
    "reference_count": "11",
    "references": [
        "2116682907",
        "2122399224",
        "2104730345",
        "2141291230",
        "2154664055",
        "1970720481",
        "576359727",
        "2239493136",
        "2081510963",
        "2336133541"
    ]
},{
    "id": "2129542667",
    "title": "Clinical progression and viral load in a community outbreak of coronavirus-associated SARS pneumonia: a prospective study.",
    "abstract": "Summary Background We investigated the temporal progression of the clinical, radiological, and virological changes in a community outbreak of severe acute respiratory syndrome (SARS). Methods We followed up 75 patients for 3 weeks managed with a standard treatment protocol of ribavirin and corticosteroids, and assessed the pattern of clinical disease, viral load, risk factors for poor clinical outcome, and the usefulness of virological diagnostic methods. Findings Fever and pneumonia initially improved but 64 (85%) patients developed recurrent fever after a mean of 8\u00b79 (SD 3\u00b71) days, 55 (73%) had watery diarrhoea after 7\u00b75 (2\u00b73) days, 60 (80%) had radiological worsening after 7\u00b74 (2\u00b72) days, and respiratory symptoms worsened in 34 (45%) after 8\u00b76 (3\u00b70) days. In 34 (45%) patients, improvement of initial pulmonary lesions was associated with appearance of new radiological lesions at other sites. Nine (12%) patients developed spontaneous pneumomediastinum and 15 (20%) developed acute respiratory distress syndrome (ARDS) in week 3. Quantitative reverse-transcriptase (RT) PCR of nasopharyngeal aspirates in 14 patients (four with ARDS) showed peak viral load at day 10, and at day 15 a load lower than at admission. Age and chronic hepatitis B virus infection treated with lamivudine were independent significant risk factors for progression to ARDS (p=0\u00b7001). SARS-associated coronavirus in faeces was seen on RT-PCR in 65 (97%) of 67 patients at day 14. The mean time to seroconversion was 20 days. Interpretation The consistent clinical progression, shifting radiological infiltrates, and an inverted V viral-load profile suggest that worsening in week 2 is unrelated to uncontrolled viral replication but may be related to immunopathological damage.",
    "date": "2003",
    "authors": [
        "J S M Peiris",
        "C M Chu",
        "V C C Cheng",
        "K S Chan",
        "I F N Hung",
        "L L M Poon",
        "K I Law",
        "B S F Tang",
        "T Y W Hon",
        "C S Chan",
        "K H Chan",
        "J S C Ng",
        "B J Zheng",
        "W L Ng",
        "R W M Lai",
        "Y Guan",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Viral load",
        "ARDS"
    ],
    "citation_count": "2,458",
    "reference_count": "15",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2100820722",
        "2125251240",
        "2107978811",
        "2161328469",
        "2155583106",
        "1675164605",
        "2061759246"
    ]
},{
    "id": "1703839189",
    "title": "Detection of a novel human coronavirus by real-time reverse-transcription polymerase chain reaction",
    "abstract": "We present two real-time reverse-transcription polymerase chain reaction assays for a novel human coronavirus (CoV), targeting regions upstream of the E gene (upE) or within open reading frame (ORF)1b, respectively. Sensitivity for upE is 3.4 copies per reaction (95% confidence interval (CI): 2.5-6.9 copies) or 291 copies/mL of sample. No cross-reactivity was observed with coronaviruses OC43, NL63, 229E, SARS-CoV, nor with 92 clinical specimens containing common human respiratory viruses. We recommend using upE for screening and ORF1b for confirmation.",
    "date": "2012",
    "authors": [
        "V M Corman",
        "I Eckerle",
        "T Bleicker",
        "A Zaki",
        "O Landt",
        "M Eschbach-Bludau",
        "S van Boheemen",
        "R Gopal",
        "M Ballhause",
        "T M Bestebroer",
        "D Muth",
        "M A M\u00fcller",
        "J F Drexler",
        "M Zambon",
        "A D Osterhaus",
        "R M Fouchier",
        "C Drosten"
    ],
    "related_topics": [
        "Coronavirus",
        "Reverse transcription polymerase chain reaction",
        "Real-time polymerase chain reaction"
    ],
    "citation_count": "629",
    "reference_count": "12",
    "references": [
        "2132260239",
        "2129542667",
        "2167080692",
        "1593955729",
        "2145810580",
        "1975169783",
        "2069961370",
        "2105870155",
        "2100516702",
        "2161315652"
    ]
},{
    "id": "1987783718",
    "title": "Extracorporeal membrane oxygenation for 2009 Influenza A (H1N1) Acute Respiratory Distress Syndrome",
    "abstract": "CONTEXT The novel influenza A(H1N1) pandemic affected Australia and New Zealand during the 2009 southern hemisphere winter. It caused an epidemic of critical illness and some patients developed severe acute respiratory distress syndrome (ARDS) and were treated with extracorporeal membrane oxygenation (ECMO). OBJECTIVES To describe the characteristics of all patients with 2009 influenza A(H1N1)-associated ARDS treated with ECMO and to report incidence, resource utilization, and patient outcomes. DESIGN, SETTING, AND PATIENTS An observational study of all patients (n = 68) with 2009 influenza A(H1N1)-associated ARDS treated with ECMO in 15 intensive care units (ICUs) in Australia and New Zealand between June 1 and August 31, 2009. MAIN OUTCOME MEASURES Incidence, clinical features, degree of pulmonary dysfunction, technical characteristics, duration of ECMO, complications, and survival. RESULTS Sixty-eight patients with severe influenza-associated ARDS were treated with ECMO, of whom 61 had either confirmed 2009 influenza A(H1N1) (n = 53) or influenza A not subtyped (n = 8), representing an incidence rate of 2.6 ECMO cases per million population. An additional 133 patients with influenza A received mechanical ventilation but no ECMO in the same ICUs. The 68 patients who received ECMO had a median (interquartile range [IQR]) age of 34.4 (26.6-43.1) years and 34 patients (50%) were men. Before ECMO, patients had severe respiratory failure despite advanced mechanical ventilatory support with a median (IQR) Pao(2)/fraction of inspired oxygen (Fio(2)) ratio of 56 (48-63), positive end-expiratory pressure of 18 (15-20) cm H(2)O, and an acute lung injury score of 3.8 (3.5-4.0). The median (IQR) duration of ECMO support was 10 (7-15) days. At the time of reporting, 48 of the 68 patients (71%; 95% confidence interval [CI], 60%-82%) had survived to ICU discharge, of whom 32 had survived to hospital discharge and 16 remained as hospital inpatients. Fourteen patients (21%; 95% CI, 11%-30%) had died and 6 remained in the ICU, 2 of whom were still receiving ECMO. CONCLUSIONS During June to August 2009 in Australia and New Zealand, the ICUs at regional referral centers provided mechanical ventilation for many patients with 2009 influenza A(H1N1)-associated respiratory failure, one-third of whom received ECMO. These ECMO-treated patients were often young adults with severe hypoxemia and had a 21% mortality rate at the end of the study period.",
    "date": "2009",
    "authors": [
        "Andrew Davies",
        "Daryl Jones",
        "Michael Bailey",
        "John Beca",
        "Rinaldo Bellomo",
        "Nikki Blackwell",
        "Paul Forrest",
        "David Gattas",
        "Emily Granger",
        "Robert Herkes",
        "Andrew Jackson",
        "Shay McGuinness",
        "Priya Nair",
        "Vincent Pellegrino",
        "Ville Yrjo Olavi Pettila",
        "Brian Plunkett",
        "Roger Pye",
        "Paul Torzillo",
        "Steven Webb",
        "Michael Wilson",
        "Marc Ziegenfuss"
    ],
    "related_topics": [
        "Extracorporeal membrane oxygenation",
        "Intensive care",
        "Fraction of inspired oxygen"
    ],
    "citation_count": "1,802",
    "reference_count": "0",
    "references": []
},{
    "id": "2111412754",
    "title": "Identification of a new human coronavirus",
    "abstract": "Three human coronaviruses are known to exist: human coronavirus 229E (HCoV-229E), HCoV-OC43 and severe acute respiratory syndrome (SARS)-associated coronavirus (SARS-CoV). Here we report the identification of a fourth human coronavirus, HCoV-NL63, using a new method of virus discovery. The virus was isolated from a 7-month-old child suffering from bronchiolitis and conjunctivitis. The complete genome sequence indicates that this virus is not a recombinant, but rather a new group 1 coronavirus. The in vitro host cell range of HCoV-NL63 is notable because it replicates on tertiary monkey kidney cells and the monkey kidney LLC-MK2 cell line. The viral genome contains distinctive features, including a unique N-terminal fragment within the spike protein. Screening of clinical specimens from individuals suffering from respiratory illness identified seven additional HCoV-NL63-infected individuals, indicating that the virus was widely spread within the human population.",
    "date": "2004",
    "authors": [
        "Lia van der Hoek",
        "Krzysztof Pyrc",
        "Maarten F Jebbink",
        "Wilma Vermeulen-Oost",
        "Ron J M Berkhout",
        "Katja C Wolthers",
        "Pauline M E Wertheim-van Dillen",
        "Jos Kaandorp",
        "Joke Spaargaren",
        "Ben Berkhout"
    ],
    "related_topics": [
        "Human coronavirus OC43",
        "Human coronavirus 229E",
        "Coronavirus"
    ],
    "citation_count": "1,819",
    "reference_count": "39",
    "references": [
        "2132260239",
        "2104548316",
        "2129542667",
        "2116586125",
        "2169198329",
        "2134061616",
        "2166229810",
        "2163400707",
        "2159857626",
        "2029293367"
    ]
},{
    "id": "1963953102",
    "title": "Fingerprinting genomes using PCR with arbitrary primers",
    "abstract": "Simple and reproducible fingerprints of complex genomes can be generated using single arbitrarily chosen primers and the polymerase chain reaction (PCR). No prior sequence information is required. The method, arbitrarily primed PCR (AP-PCR), involves two cycles of low stringency amplification followed by PCR at higher stringency. We show that strains can be distinguished by comparing polymorphisms in genomic fingerprints. The generality of the method is demonstrated by application to twenty four strains from five species of Staphylococcus, eleven strains of Streptococcus pyogenes and three varieties of Oryza sativa (rice).",
    "date": "1989",
    "authors": [
        "John Welsh",
        "Michael McClelland"
    ],
    "related_topics": [
        "RAPD",
        "DNA profiling",
        "Polymerase chain reaction"
    ],
    "citation_count": "8,259",
    "reference_count": "0",
    "references": []
},{
    "id": "2170933940",
    "title": "Characterization and Complete Genome Sequence of a Novel Coronavirus, Coronavirus HKU1, from Patients with Pneumonia",
    "abstract": "Despite extensive laboratory investigations in patients with respiratory tract infections, no microbiological cause can be identified in a significant proportion of patients. In the past 3 years, several novel respiratory viruses, including human metapneumovirus, severe acute respiratory syndrome (SARS) coronavirus (SARSCoV), and human coronavirus NL63, were discovered. Here we report the discovery of another novel coronavirus, coronavirus HKU1 (CoV-HKU1), from a 71-year-old man with pneumonia who had just returned from Shenzhen, China. Quantitative reverse transcription-PCR showed that the amount of CoV-HKU1 RNA was 8.5 to 9.6 10 6 copies per ml in his nasopharyngeal aspirates (NPAs) during the first week of the illness and dropped progressively to undetectable levels in subsequent weeks. He developed increasing serum levels of specific antibodies against the recombinant nucleocapsid protein of CoV-HKU1, with immunoglobulin M (IgM) titers of 1:20, 1:40, and 1:80 and IgG titers of <1:1,000, 1:2,000, and 1:8,000 in the first, second and fourth weeks of the illness, respectively. Isolation of the virus by using various cell lines, mixed neuron-glia culture, and intracerebral inoculation of suckling mice was unsuccessful. The complete genome sequence of CoV-HKU1 is a 29,926-nucleotide, polyadenylated RNA, with GC content of 32%, the lowest among all known coronaviruses with available genome sequence. Phylogenetic analysis reveals that CoV-HKU1 is a new group 2 coronavirus. Screening of 400 NPAs, negative for SARS-CoV, from patients with respiratory illness during the SARS period identified the presence of CoV-HKU1 RNA in an additional specimen, with a viral load of 1.13 10 6 copies per ml, from a 35-year-old woman with pneumonia. Our data support the existence of a novel group 2 coronavirus associated with pneumonia in humans.",
    "date": "2005",
    "authors": [
        "Patrick C. Y. Woo",
        "Susanna K. P. Lau",
        "Chung-ming Chu",
        "Kwok-hung Chan",
        "Hoi-wah Tsoi",
        "Yi Huang",
        "Beatrice H. L. Wong",
        "Rosana W. S. Poon",
        "James J. Cai",
        "Wei-kwang Luk",
        "Leo L. M. Poon",
        "Samson S. Y. Wong",
        "Yi Guan",
        "J. S. Malik Peiris",
        "Kwok-yung Yuen"
    ],
    "related_topics": [
        "Human coronavirus OC43",
        "Coronavirus",
        "Human coronavirus HKU1"
    ],
    "citation_count": "1,469",
    "reference_count": "52",
    "references": [
        "2141885858",
        "2025170735",
        "2129542667",
        "2116586125",
        "2169198329",
        "2171091522",
        "2134061616",
        "2170881661",
        "2141877163",
        "2111412754"
    ]
},{
    "id": "2126707939",
    "title": "Severe acute respiratory syndrome",
    "abstract": "Severe acute respiratory syndrome (SARS) was caused by a previously unrecognized animal coronavirus that exploited opportunities provided by 'wet markets' in southern China to adapt to become a virus readily transmissible between humans. Hospitals and international travel proved to be 'amplifiers' that permitted a local outbreak to achieve global dimensions. In this review we will discuss the substantial scientific progress that has been made towards understanding the virus-SARS coronavirus (SARS-CoV)-and the disease. We will also highlight the progress that has been made towards developing vaccines and therapies The concerted and coordinated response that contained SARS is a triumph for global public health and provides a new paradigm for the detection and control of future emerging infectious disease threats.",
    "date": "2004",
    "authors": [
        "J S M Peiris",
        "Y Guan",
        "K Y Yuen"
    ],
    "related_topics": [
        "Emerging infectious disease",
        "Coronavirus",
        "Global health"
    ],
    "citation_count": "993",
    "reference_count": "146",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2100820722",
        "2125251240",
        "2147166346",
        "2116586125",
        "1966238900"
    ]
},{
    "id": "2107277218",
    "title": "ANALYSIS OF RELATIVE GENE EXPRESSION DATA USING REAL-TIME QUANTITATIVE PCR AND THE 2(-DELTA DELTA C(T)) METHOD",
    "abstract": "The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2(-Delta Delta C(T)) method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2(-Delta Delta C(T)) method. In addition, we present the derivation and applications of two variations of the 2(-Delta Delta C(T)) method that may be useful in the analysis of real-time, quantitative PCR data.",
    "date": "2001",
    "authors": [
        "Kenneth J. Livak",
        "Thomas D. Schmittgen"
    ],
    "related_topics": [
        "Cell wall organization",
        "Protein kinase B signaling",
        "Lupeol synthase"
    ],
    "citation_count": "135,494",
    "reference_count": "11",
    "references": [
        "2164578725",
        "2109970232",
        "2128088040",
        "2145879504",
        "1983241347",
        "2123325948",
        "2134343377",
        "1756433044",
        "1566892773",
        "2069943574"
    ]
},{
    "id": "2470646526",
    "title": "SARS and MERS: recent insights into emerging coronaviruses",
    "abstract": "The emergence of Middle East respiratory syndrome coronavirus (MERS-CoV) in 2012 marked the second introduction of a highly pathogenic coronavirus into the human population in the twenty-first century. The continuing introductions of MERS-CoV from dromedary camels, the subsequent travel-related viral spread, the unprecedented nosocomial outbreaks and the high case-fatality rates highlight the need for prophylactic and therapeutic measures. Scientific advancements since the 2002-2003 severe acute respiratory syndrome coronavirus (SARS-CoV) pandemic allowed for rapid progress in our understanding of the epidemiology and pathogenesis of MERS-CoV and the development of therapeutics. In this Review, we detail our present understanding of the transmission and pathogenesis of SARS-CoV and MERS-CoV, and discuss the current state of development of measures to combat emerging coronaviruses.",
    "date": "2016",
    "authors": [
        "Emmie de Wit",
        "Neeltje van Doremalen",
        "Darryl Falzarano",
        "Vincent J. Munster"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Population"
    ],
    "citation_count": "2,410",
    "reference_count": "156",
    "references": [
        "2166867592",
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2006434809",
        "2129542667",
        "1993577573",
        "1909499787",
        "2138324310"
    ]
},{
    "id": "1993577573",
    "title": "Isolation and characterization of a bat SARS-like coronavirus that uses the ACE2 receptor",
    "abstract": "The 2002-3 pandemic caused by severe acute respiratory syndrome coronavirus (SARS-CoV) was one of the most significant public health events in recent history. An ongoing outbreak of Middle East respiratory syndrome coronavirus suggests that this group of viruses remains a key threat and that their distribution is wider than previously recognized. Although bats have been suggested to be the natural reservoirs of both viruses, attempts to isolate the progenitor virus of SARS-CoV from bats have been unsuccessful. Diverse SARS-like coronaviruses (SL-CoVs) have now been reported from bats in China, Europe and Africa, but none is considered a direct progenitor of SARS-CoV because of their phylogenetic disparity from this virus and the inability of their spike proteins to use the SARS-CoV cellular receptor molecule, the human angiotensin converting enzyme II (ACE2). Here we report whole-genome sequences of two novel bat coronaviruses from Chinese horseshoe bats (family: Rhinolophidae) in Yunnan, China: RsSHC014 and Rs3367. These viruses are far more closely related to SARS-CoV than any previously identified bat coronaviruses, particularly in the receptor binding domain of the spike protein. Most importantly, we report the first recorded isolation of a live SL-CoV (bat SL-CoV-WIV1) from bat faecal samples in Vero E6 cells, which has typical coronavirus morphology, 99.9% sequence identity to Rs3367 and uses ACE2 from humans, civets and Chinese horseshoe bats for cell entry. Preliminary in vitro testing indicates that WIV1 also has a broad species tropism. Our results provide the strongest evidence to date that Chinese horseshoe bats are natural reservoirs of SARS-CoV, and that intermediate hosts may not be necessary for direct human infection by some bat SL-CoVs. They also highlight the importance of pathogen-discovery programs targeting high-risk wildlife groups in emerging disease hotspots as a strategy for pandemic preparedness.",
    "date": "2013",
    "authors": [
        "Xing Yi Ge",
        "Jia Lu Li",
        "Xing Lou Yang",
        "Aleksei A. Chmura",
        "Guangjian Zhu",
        "Jonathan H. Epstein",
        "Jonna A Mazet",
        "Ben Hu",
        "Wei Zhang",
        "Cheng Peng",
        "Yu Ji Zhang",
        "Chu Ming Luo",
        "Bing Tan",
        "Ning Wang",
        "Yan Zhu",
        "Gary Crameri",
        "Shu Yi Zhang",
        "Lin Fa Wang",
        "Peter Daszak",
        "Zheng Li Shi"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Virus genetics"
    ],
    "citation_count": "1,339",
    "reference_count": "30",
    "references": [
        "2166867592",
        "2104548316",
        "2119111857",
        "1966238900",
        "2103503670",
        "2140338292",
        "2141008678",
        "2049975503",
        "2101063972",
        "1990059132"
    ]
},{
    "id": "2565805236",
    "title": "Middle East Respiratory Syndrome Coronavirus (MERS-CoV)",
    "abstract": "",
    "date": "2016",
    "authors": [
        "Geethamma Jolly"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Virology",
        "Medicine"
    ],
    "citation_count": "632",
    "reference_count": "0",
    "references": []
},{
    "id": "2791599184",
    "title": "Treatment of Middle East Respiratory Syndrome with a combination of lopinavir-ritonavir and interferon-\u03b21b (MIRACLE trial): study protocol for a randomized controlled trial.",
    "abstract": "It had been more than 5 years since the first case of Middle East Respiratory Syndrome coronavirus infection (MERS-CoV) was recorded, but no specific treatment has been investigated in randomized clinical trials. Results from in vitro and animal studies suggest that a combination of lopinavir/ritonavir and interferon-\u03b21b (IFN-\u03b21b) may be effective against MERS-CoV. The aim of this study is to investigate the efficacy of treatment with a combination of lopinavir/ritonavir and recombinant IFN-\u03b21b provided with standard supportive care, compared to treatment with placebo provided with standard supportive care in patients with laboratory-confirmed MERS requiring hospital admission. The protocol is prepared in accordance with the SPIRIT (Standard Protocol Items: Recommendations for Interventional Trials) guidelines. Hospitalized adult patients with laboratory-confirmed MERS will be enrolled in this recursive, two-stage, group sequential, multicenter, placebo-controlled, double-blind randomized controlled trial. The trial is initially designed to include 2 two-stage components. The first two-stage component is designed to adjust sample size and determine futility stopping, but not efficacy stopping. The second two-stage component is designed to determine efficacy stopping and possibly readjustment of sample size. The primary outcome is 90-day mortality. This will be the first randomized controlled trial of a potential treatment for MERS. The study is sponsored by King Abdullah International Medical Research Center, Riyadh, Saudi Arabia. Enrollment for this study began in November 2016, and has enrolled thirteen patients as of Jan 24-2018. ClinicalTrials.gov, ID: NCT02845843. Registered on 27 July 2016.",
    "date": "2018",
    "authors": [
        "Yaseen M. Arabi",
        "Adel Alothman",
        "Hanan H. Balkhy",
        "Abdulaziz Al-Dawood",
        "Sameera AlJohani",
        "Shmeylan Al Harbi",
        "Suleiman Kojan",
        "Majed Al Jeraisy",
        "Ahmad M. Deeb",
        "Abdullah M. Assiri",
        "Fahad Al-Hameed",
        "Asim AlSaedi",
        "Yasser Mandourah",
        "Ghaleb A. Almekhlafi",
        "Nisreen Murad Sherbeeni",
        "Fatehi Elnour Elzein",
        "Javed Memon",
        "Yusri Taha",
        "Abdullah Almotairi",
        "Khalid A. Maghrabi",
        "Ismael Qushmaq",
        "Ali Al Bshabshe",
        "Ayman Kharaba",
        "Sarah Shalhoub",
        "Jesna Jose",
        "Robert A. Fowler",
        "Frederick G. Hayden",
        "Mohamed A. Hussein"
    ],
    "related_topics": [
        "Lopinavir/ritonavir",
        "Randomized controlled trial",
        "Lopinavir"
    ],
    "citation_count": "267",
    "reference_count": "36",
    "references": [
        "2166867592",
        "2145758369",
        "2139937737",
        "2591646177",
        "1703839189",
        "2034462612",
        "1977050884",
        "2586093485",
        "2150120685",
        "2345375456"
    ]
},{
    "id": "2255243349",
    "title": "Coronaviruses - drug discovery and therapeutic options.",
    "abstract": "Severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS), which are caused by coronaviruses, have attracted substantial attention owing to their high mortality rates and potential to cause epidemics. Yuen and colleagues discuss progress with treatment options for these syndromes, including virus- and host-targeted drugs, and the challenges that need to be overcome in their further development. In humans, infections with the human coronavirus (HCoV) strains HCoV-229E, HCoV-OC43, HCoV-NL63 and HCoV-HKU1 usually result in mild, self-limiting upper respiratory tract infections, such as the common cold. By contrast, the CoVs responsible for severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS), which were discovered in Hong Kong, China, in 2003, and in Saudi Arabia in 2012, respectively, have received global attention over the past 12 years owing to their ability to cause community and health-care-associated outbreaks of severe infections in human populations. These two viruses pose major challenges to clinical management because there are no specific antiviral drugs available. In this Review, we summarize the epidemiology, virology, clinical features and current treatment strategies of SARS and MERS, and discuss the discovery and development of new virus-based and host-based therapeutic options for CoV infections.",
    "date": "2016",
    "authors": [
        "Alimuddin Zumla",
        "Jasper F. W. Chan",
        "Esam I. Azhar",
        "David S. C. Hui",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Respiratory tract infections",
        "Common cold"
    ],
    "citation_count": "1,197",
    "reference_count": "299",
    "references": [
        "2166867592",
        "2132260239",
        "2104548316",
        "2107053896",
        "2025170735",
        "2131262274",
        "2006434809",
        "2129542667",
        "1993577573",
        "2138324310"
    ]
},{
    "id": "2290466312",
    "title": "A simple practice guide for dose conversion between animals and human.",
    "abstract": "Understanding the concept of extrapolation of dose between species is important for pharmaceutical researchers when initiating new animal or human experiments. Interspecies allometric scaling for dose conversion from animal to human studies is one of the most controversial areas in clinical pharmacology. Allometric approach considers the differences in body surface area, which is associated with animal weight while extrapolating the doses of therapeutic agents among the species. This review provides basic information about translation of doses between species and estimation of starting dose for clinical trials using allometric scaling. The method of calculation of injection volume for parenteral formulation based on human equivalent dose is also briefed.",
    "date": "2016",
    "authors": [
        "Anroop B Nair",
        "Shery Jacob"
    ],
    "related_topics": [
        "Clinical pharmacology",
        "Body surface area",
        "Clinical trial"
    ],
    "citation_count": "1,862",
    "reference_count": "8",
    "references": [
        "2024938615",
        "2100521244",
        "2142366069",
        "2065093669",
        "2080335269",
        "2034194552",
        "2160483062",
        "2057666951"
    ]
},{
    "id": "2793022939",
    "title": "Coronavirus Susceptibility to the Antiviral Remdesivir (GS-5734) Is Mediated by the Viral Polymerase and the Proofreading Exoribonuclease",
    "abstract": "Emerging coronaviruses (CoVs) cause severe disease in humans, but no approved therapeutics are available. The CoV nsp14 exoribonuclease (ExoN) has complicated development of antiviral nucleosides due to its proofreading activity. We recently reported that the nucleoside analogue GS-5734 (remdesivir) potently inhibits human and zoonotic CoVs in vitro and in a severe acute respiratory syndrome coronavirus (SARS-CoV) mouse model. However, studies with GS-5734 have not reported resistance associated with GS-5734, nor do we understand the action of GS-5734 in wild-type (WT) proofreading CoVs. Here, we show that GS-5734 inhibits murine hepatitis virus (MHV) with similar 50% effective concentration values (EC50) as SARS-CoV and Middle East respiratory syndrome coronavirus (MERS-CoV). Passage of WT MHV in the presence of the GS-5734 parent nucleoside selected two mutations in the nsp12 polymerase at residues conserved across all CoVs that conferred up to 5.6-fold resistance to GS-5734, as determined by EC50 The resistant viruses were unable to compete with WT in direct coinfection passage in the absence of GS-5734. Introduction of the MHV resistance mutations into SARS-CoV resulted in the same in vitro resistance phenotype and attenuated SARS-CoV pathogenesis in a mouse model. Finally, we demonstrate that an MHV mutant lacking ExoN proofreading was significantly more sensitive to GS-5734. Combined, the results indicate that GS-5734 interferes with the nsp12 polymerase even in the setting of intact ExoN proofreading activity and that resistance can be overcome with increased, nontoxic concentrations of GS-5734, further supporting the development of GS-5734 as a broad-spectrum therapeutic to protect against contemporary and emerging CoVs.IMPORTANCE Coronaviruses (CoVs) cause severe human infections, but there are no approved antivirals to treat these infections. Development of nucleoside-based therapeutics for CoV infections has been hampered by the presence of a proofreading exoribonuclease. Here, we expand the known efficacy of the nucleotide prodrug remdesivir (GS-5734) to include a group \u03b2-2a CoV. Further, GS-5734 potently inhibits CoVs with intact proofreading. Following selection with the GS-5734 parent nucleoside, 2 amino acid substitutions in the nsp12 polymerase at residues that are identical across CoVs provide low-level resistance to GS-5734. The resistance mutations decrease viral fitness of MHV in vitro and attenuate pathogenesis in a SARS-CoV animal model of infection. Together, these studies define the target of GS-5734 activity and demonstrate that resistance is difficult to select, only partial, and impairs fitness and virulence of MHV and SARS-CoV, supporting further development of GS-5734 as a potential effective pan-CoV antiviral.",
    "date": "2018",
    "authors": [
        "Maria L. Agostini",
        "Erica L. Andres",
        "Amy C Sims",
        "Rachel Lauren Graham",
        "Timothy Patrick Sheahan",
        "Xiaotao Lu",
        "Everett Clinton Smith",
        "James Brett Case",
        "Joy Y. Feng",
        "Robert Jordan",
        "Adrian S. Ray",
        "Tomas Cihlar",
        "Dustin Siegel",
        "Richard L. Mackman",
        "Michael O. Clarke",
        "Ralph S Baric",
        "Mark R. Denison"
    ],
    "related_topics": [
        "Coronavirus",
        "Proofreading",
        "Nucleoside analogue"
    ],
    "citation_count": "767",
    "reference_count": "58",
    "references": [
        "2166867592",
        "2104548316",
        "2725497285",
        "2195009776",
        "311927316",
        "2255243349",
        "2292021561",
        "2115555188",
        "2298153446",
        "2586093485"
    ]
},{
    "id": "2100820722",
    "title": "Identification of Severe Acute Respiratory Syndrome in Canada",
    "abstract": "background Severe acute respiratory syndrome (SARS) is a condition of unknown cause that has recently been recognized in patients in Asia, North America, and Europe. This report summarizes the initial epidemiologic findings, clinical description, and diagnostic findings that followed the identification of SARS in Canada. methods SARS was first identified in Canada in early March 2003. We collected epidemiologic, clinical, and diagnostic data from each of the first 10 cases prospectively as they were identified. Specimens from all cases were sent to local, provincial, national, and international laboratories for studies to identify an etiologic agent. results The patients ranged from 24 to 78 years old; 60 percent were men. Transmission occurred only after close contact. The most common presenting symptoms were fever (in 100 percent of cases) and malaise (in 70 percent), followed by nonproductive cough (in 100 percent) and dyspnea (in 80 percent) associated with infiltrates on chest radiography (in 100 percent). Lymphopenia (in 89 percent of those for whom data were available), elevated lactate dehydrogenase levels (in 80 percent), elevated aspartate aminotransferase levels (in 78 percent), and elevated creatinine kinase levels (in 56 percent) were common. Empirical therapy most commonly included antibiotics, oseltamivir, and intravenous ribavirin. Mechanical ventilation was required in five patients. Three patients died, and five have had clinical improvement. The results of laboratory investigations were negative or not clinically significant except for the amplification of human metapneumovirus from respiratory specimens from five of nine patients and the isolation and amplification of a novel coronavirus from five of nine patients. In four cases both pathogens were isolated. conclusions SARS is a condition associated with substantial morbidity and mortality. It appears to be of viral origin, with patterns suggesting droplet or contact transmission. The role of human metapneumovirus, a novel coronavirus, or both requires further investigation.",
    "date": "2003",
    "authors": [
        "Susan M. Poutanen",
        "Donald E. Low",
        "Bonnie Henry",
        "Sandy Finkelstein",
        "David Rose",
        "Karen Green",
        "Raymond Tellier",
        "Ryan Draker",
        "Dena Adachi",
        "Melissa Ayers",
        "Adrienne K. Chan",
        "Danuta M. Skowronski",
        "Irving Salit",
        "Andrew E. Simor",
        "Arthur S. Slutsky",
        "Patrick W. Doyle",
        "Mel Krajden",
        "Martin Petric",
        "Robert C. Brunham",
        "Allison J. McGeer"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Human metapneumovirus",
        "Epidemiology"
    ],
    "citation_count": "1,769",
    "reference_count": "22",
    "references": [
        "2597070792",
        "2161328469",
        "2170881661",
        "2093852073",
        "2463755683",
        "2152552492",
        "2135259291",
        "2136166622",
        "2097665403",
        "1898899939"
    ]
},{
    "id": "2125251240",
    "title": "A cluster of cases of severe acute respiratory syndrome in Hong Kong.",
    "abstract": "Background Information on the clinical features of the severe acute respiratory syndrome (SARS) will be of value to physicians caring for patients suspected of having this disorder. Methods We abstracted data on the clinical presentation and course of disease in 10 epidemiologically linked Chinese patients (5 men and 5 women 38 to 72 years old) in whom SARS was diagnosed between February 22, 2003, and March 22, 2003, at our hospitals in Hong Kong, China. Results Exposure between the source patient and subsequent patients ranged from minimal to that between patient and health care provider. The incubation period ranged from 2 to 11 days. All patients presented with fever (temperature, >38\u00b0C for over 24 hours), and most presented with rigor, dry cough, dyspnea, malaise, headache, and hypoxemia. Physical examination of the chest revealed crackles and percussion dullness. Lymphopenia was observed in nine patients, and most patients had mildly elevated aminotransferase levels but normal serum creatinine levels...",
    "date": "2003",
    "authors": [
        "Kenneth W. Tsang",
        "Pak L. Ho",
        "Gaik C. Ooi",
        "Wilson K. Yee",
        "Teresa Wang",
        "Moira Chan-Yeung",
        "Wah K. Lam",
        "Wing H. Seto",
        "Loretta Y. Yam",
        "Thomas M. Cheung",
        "Poon C. Wong",
        "Bing Lam",
        "Mary S. Ip",
        "Jane Chan",
        "Kwok Y. Yuen",
        "Kar N. Lai"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Crackles",
        "Physical examination"
    ],
    "citation_count": "1,587",
    "reference_count": "4",
    "references": [
        "1607298558",
        "1982444609",
        "2041775285",
        "2132293969"
    ]
},{
    "id": "2107922358",
    "title": "Rapid detection and quantification of RNA of Ebola and Marburg viruses, Lassa virus, Crimean-Congo hemorrhagic fever virus, Rift Valley fever virus, dengue virus, and yellow fever virus by real-time reverse transcription-PCR.",
    "abstract": "Viral hemorrhagic fevers (VHFs) are acute infections with high case fatality rates. Important VHF agents are Ebola and Marburg viruses (MBGV/EBOV), Lassa virus (LASV), Crimean-Congo hemorrhagic fever virus (CCHFV), Rift Valley fever virus (RVFV), dengue virus (DENV), and yellow fever virus (YFV). VHFs are clinically difficult to diagnose and to distinguish; a rapid and reliable laboratory diagnosis is required in suspected cases. We have established six one-step, real-time reverse transcription-PCR assays for these pathogens based on the Superscript reverse transcriptase-Platinum Taq polymerase enzyme mixture. Novel primers and/or 5\u2032-nuclease detection probes were designed for RVFV, DENV, YFV, and CCHFV by using the latest DNA database entries. PCR products were detected in real time on a LightCycler instrument by using 5\u2032-nuclease technology (RVFV, DENV, and YFV) or SybrGreen dye intercalation (MBGV/EBOV, LASV, and CCHFV). The inhibitory effect of SybrGreen on reverse transcription was overcome by initial immobilization of the dye in the reaction capillaries. Universal cycling conditions for SybrGreen and 5\u2032-nuclease probe detection were established. Thus, up to three assays could be performed in parallel, facilitating rapid testing for several pathogens. All assays were thoroughly optimized and validated in terms of analytical sensitivity by using in vitro-transcribed RNA. The \u226595% detection limits as determined by probit regression analysis ranged from 1,545 to 2,835 viral genome equivalents/ml of serum (8.6 to 16 RNA copies per assay). The suitability of the assays was exemplified by detection and quantification of viral RNA in serum samples of VHF patients.",
    "date": "2002",
    "authors": [
        "Christian Drosten",
        "Stephan G\u00f6ttig",
        "Stefan Schilling",
        "Marcel Asper",
        "Marcus Panning",
        "Herbert Schmitz",
        "Stephan G\u00fcnther"
    ],
    "related_topics": [
        "Lassa virus",
        "Phlebovirus",
        "Dengue virus"
    ],
    "citation_count": "786",
    "reference_count": "39",
    "references": [
        "2047480444",
        "1994091239",
        "2070721758",
        "2131589770",
        "2149579937",
        "2137089963",
        "2163760194",
        "2134971582",
        "2171308211",
        "2798078005"
    ]
},{
    "id": "2127062009",
    "title": "Viruses and Bacteria in the Etiology of the Common Cold",
    "abstract": "Two hundred young adults with common colds were studied during a 10-month period. Virus culture, antigen detection, PCR, and serology with paired samples were used to identify the infection. Viral etiology was established for 138 of the 200 patients (69%). Rhinoviruses were detected in 105 patients, coronavirus OC43 or 229E infection was detected in 17, influenza A or B virus was detected in 12, and single infections with parainfluenza virus, respiratory syncytial virus, adenovirus, and enterovirus were found in 14 patients. Evidence for bacterial infection was found in seven patients. Four patients had a rise in antibodies against Chlamydia pneumoniae, one had a rise in antibodies against Haemophilus influenzae, one had a rise in antibodies against Streptococcus pneumoniae, and one had immunoglobulin M antibodies against Mycoplasma pneumoniae. The results show that although approximately 50% of episodes of the common cold were caused by rhinoviruses, the etiology can vary depending on the epidemiological situation with regard to circulating viruses. Bacterial infections were rare, supporting the concept that the common cold is almost exclusively a viral disease.",
    "date": "1998",
    "authors": [
        "Mika J. M\u00e4kel\u00e4",
        "Tuomo Puhakka",
        "Olli Ruuskanen",
        "Maija Leinonen",
        "Pekka Saikku",
        "Marko Kimpim\u00e4ki",
        "Soile Blomqvist",
        "Timo Hyypi\u00e4",
        "Pertti Arstila"
    ],
    "related_topics": [
        "Viral culture",
        "Serology",
        "Rhinovirus"
    ],
    "citation_count": "886",
    "reference_count": "31",
    "references": [
        "2055750915",
        "2337555053",
        "2098388207",
        "163073849",
        "2032842024",
        "1856165804",
        "2018812376",
        "2146133178",
        "1830634530",
        "1699035432"
    ]
},{
    "id": "2084994773",
    "title": "Phylogenetic analysis of a highly conserved region of the polymerase gene from 11 coronaviruses and development of a consensus polymerase chain reaction assay.",
    "abstract": "Viruses in the genus Coronavirus are currently placed in three groups based on antigenic cross-reactivity and sequence analysis of structural protein genes. Consensus polymerase chain reaction (PCR) primers were used to obtain cDNA, then cloned and sequenced a highly conserved 922 nucleotide region in open reading frame (ORF) 1b of the polymerase (pol) gene from eight coronaviruses. These sequences were compared with published sequences for three additional coronaviruses. In this comparison, it was found that nucleotide substitution frequencies (per 100 nucleotides) varied from 46.40 to 50.13 when viruses were compared among the traditional coronavirus groups and, with one exception (the human coronavirus (HCV) 229E), varied from 2.54 to 15.89 when compared within these groups. (The substitution frequency for 229E, as compared to other members of the same group, varied from 35.37 to 35.72.) Phylogenetic analysis of these pol gene sequences resulted in groupings which correspond closely with the previously described groupings, including recent data which places the two avian coronaviruses--infectious bronchitis virus (IBV) of chickens and turkey coronavirus (TCV)--in the same group [Guy, J.S., Barnes, H.J., Smith L.G., Breslin, J., 1997. Avian Dis. 41:583-590]. A single pair of degenerate primers was identified which amplify a 251 bp region from coronaviruses of all three groups using the same reaction conditions. This consensus PCR assay for the genus Coronavirus may be useful in identifying as yet unknown coronaviruses.",
    "date": "1999",
    "authors": [
        "Charles B. Stephensen",
        "Donald B. Casebolt",
        "Nupur N. Gangopadhyay"
    ],
    "related_topics": [
        "Coronavirus",
        "Consensus PCR",
        "Turkey coronavirus"
    ],
    "citation_count": "230",
    "reference_count": "25",
    "references": [
        "2134812217",
        "2009310436",
        "132455992",
        "2156596665",
        "1582561043",
        "2149495938",
        "2087363345",
        "2329318335",
        "3011200155",
        "1994193749"
    ]
},{
    "id": "2149579937",
    "title": "Imported Lassa fever in Germany: molecular characterization of a new Lassa virus strain.",
    "abstract": "We describe the isolation and characterization of a new Lassa virus strain imported into Germany by a traveler who had visited Ghana, Cote D'Ivoire, and Burkina Faso. This strain, designated \"AV,\" originated from a region in West Africa where Lassa fever has not been reported. Viral S RNA isolated from the patient's serum was amplified and sequenced. A long-range reverse transcription polymerase chain reaction allowed amplification of the full-length (3.4 kb) S RNA. The coding sequences of strain AV differed from those of all known Lassa prototype strains (Josiah, Nigeria, and LP) by approximately 20%, mainly at third codon positions. Phylogenetically, strain AV appears to be most closely related to strain Josiah from Sierra Leone. Lassa viruses comprise a group of genetically highly diverse strains, which has implications for vaccine development. The new method for full-length S RNA amplification may facilitate identification and molecular analysis of new arenaviruses or arenavirus strains.",
    "date": "2000",
    "authors": [
        "S G\u00fcnther",
        "P Emmerich",
        "T Laue",
        "O K\u00fchle",
        "M Asper",
        "A Jung",
        "T Grewing",
        "J ter Meulen",
        "H Schmitz"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Arenavirus"
    ],
    "citation_count": "211",
    "reference_count": "40",
    "references": [
        "2154128645",
        "1967150940",
        "2044967254",
        "2171229191",
        "2163443142",
        "1845818816",
        "2326037208",
        "2109638242",
        "1941129807",
        "1509033271"
    ]
},{
    "id": "2090060897",
    "title": "Evaluation of concurrent shedding of bovine coronavirus via the respiratory tract and enteric route in feedlot cattle.",
    "abstract": "Objective\u2014To assess the relationship between shedding of bovine coronavirus (BCV) via the respiratory tract and enteric routes and the association with weight gain in feedlot cattle. Animals\u201456 crossbred steers. Procedures\u2014Paired fecal samples and nasal swab specimens were obtained and were tested for BCV, using antigen-capture ELISA. Paired serum samples obtained were tested for antibodies to BCV, using antibody-detection ELISA. Information was collected on weight gain, clinical signs, and treatments for enteric and respiratory tract disease during the study period. Results\u2014Number of samples positive for bovine respiratory coronavirus (BRCV) or bovine enteric coro navirus (BECV) was 37/224 (17%) and 48/223 (22%), respectively. Some cattle (25/46, 45%) shed BECV and BRCV. There were 25/29 (86%) cattle positive for BECV that shed BRCV, but only 1/27 (4%) cattle negative to BECV shed BRCV. Twenty-seven of 48 (56%) paired nasal swab specimens and fecal samples positive for BECV were positive for BRCV. In con...",
    "date": "2001",
    "authors": [
        "Kyoung Oh Cho",
        "Armando E. Hoet",
        "Steven C. Loerch",
        "Thomas E. Wittum",
        "Linda J. Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Coronavirus",
        "Feces"
    ],
    "citation_count": "104",
    "reference_count": "31",
    "references": [
        "50597173",
        "2072381230",
        "2409643934",
        "1987051173",
        "2045765248",
        "1963591796",
        "2406151794",
        "2032346601",
        "1979854169",
        "2302897180"
    ]
},{
    "id": "2004869546",
    "title": "TTV a common virus, but pathogenic?",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Yvonne Cossart"
    ],
    "related_topics": [
        "Virus",
        "Virology",
        "Medicine"
    ],
    "citation_count": "60",
    "reference_count": "6",
    "references": [
        "2038264706",
        "2089551619",
        "2016137045",
        "2328399749",
        "2022277835",
        "2028973331"
    ]
},{
    "id": "2030133843",
    "title": "HGV: hepatitis G virus or harmless G virus?",
    "abstract": "The discovery of the hepatitis G virus (HGV) has given hepatologists a new lease on life. Just when they were becoming frustrated with the slow rate of progress in unravell ing the pathobiological consequences of hepatitis B and C virus infections, along comes another candidate virus. HGV, a single-stranded ribonucleic acid (RNA) virus that belongs to the Flaviviridae family, has a global distribution. The virus is present in 1-2% of blood donors in the USA, a frequency higher than that of either HCV or hepatitis B virus (HBV) (Alter). Even more striking is the seroprevalence of 15\"2% reported in West African residents (JMed Virol 1996; 50: 97). HGVexis t s in a chronic carrier state. The virus is transmitted parenterally and is often present in patients who have received multiple transfusions or who are on haemodialysis (N Engl J Med 1996; 334: 1485), and in intravenous drug users. There is preliminary evidence for perinatal transmission (Lancet 1996; 347: 615). HGV RNA sequences have been identified in serum from patients with non-A-E acute and chronic hepatitis and cirrhosis. Impressive data comes from Brescia, Italy, where 35% of patients with acute hepatitis and 39% of those with chronic hepatitis were positive for HGV RNA (Fiordalisi). Among blood donors the virus is more common in those with raised serum aminotransferase concentrations (3\"9%) than in those with normal concentrations (0\"8%) (ff Med Virol 1996; 50: 97). These findings imply that HGV is a human pathogen, but is it? Other information is more consistent with HGV being an innocent passenger. The great majority of individuals who become HGV-RNA positive after blood transfusion have normal serum aminotronsperase concentrations and neither they, nor those found positive for HGV RNA in other circumstances, develop liver disease during prolonged follow-up (Alter). Moreover, when serum enzyme concentrations are raised they seldom accord with levels of viraemia. HGV and HCV are often, and HGV and HBV less often, found together in serum. In those coinfected with HGV and HCV, aminotransterases run parallel to HCV rather than HGV, and the presence of the latter seems to have no effect on outcome. HGV usually accounts for only a minority of cases of acute non-A-E hepatitis, and there is no evidence yet of progression over time to chronic hepatitis, cirrhosis, or hepatocellular",
    "date": "1996",
    "authors": [
        "Michael C Kew",
        "Chris Kassianides"
    ],
    "related_topics": [
        "Hepatitis B",
        "Hepatitis B virus",
        "Hepatitis"
    ],
    "citation_count": "20",
    "reference_count": "6",
    "references": [
        "2083266836",
        "2313004219",
        "2023962288",
        "2155517838",
        "2075432722",
        "1984200234"
    ]
},{
    "id": "1967300023",
    "title": "Acute Kidney Injury Network: Report of an Initiative to Improve Outcomes in Acute Kidney Injury",
    "abstract": "Acute kidney injury (AKI) is a complex disorder for which currently there is no accepted definition. Having a uniform standard for diagnosing and classifying AKI would enhance our ability to manage these patients. Future clinical and translational research in AKI will require collaborative networks of investigators drawn from various disciplines, dissemination of information via multidisciplinary joint conferences and publications, and improved translation of knowledge from pre-clinical research. We describe an initiative to develop uniform standards for defining and classifying AKI and to establish a forum for multidisciplinary interaction to improve care for patients with or at risk for AKI. Members representing key societies in critical care and nephrology along with additional experts in adult and pediatric AKI participated in a two day conference in Amsterdam, The Netherlands, in September 2005 and were assigned to one of three workgroups. Each group's discussions formed the basis for draft recommendations that were later refined and improved during discussion with the larger group. Dissenting opinions were also noted. The final draft recommendations were circulated to all participants and subsequently agreed upon as the consensus recommendations for this report. Participating societies endorsed the recommendations and agreed to help disseminate the results. The term AKI is proposed to represent the entire spectrum of acute renal failure. Diagnostic criteria for AKI are proposed based on acute alterations in serum creatinine or urine output. A staging system for AKI which reflects quantitative changes in serum creatinine and urine output has been developed. We describe the formation of a multidisciplinary collaborative network focused on AKI. We have proposed uniform standards for diagnosing and classifying AKI which will need to be validated in future studies. The Acute Kidney Injury Network offers a mechanism for proceeding with efforts to improve patient outcomes.",
    "date": "2007",
    "authors": [
        "Ravindra L Mehta",
        "John A Kellum",
        "Sudhir V Shah",
        "Bruce A Molitoris",
        "Claudio Ronco",
        "David G Warnock",
        "Adeera Levin"
    ],
    "related_topics": [
        "Renal angina",
        "Acute kidney injury",
        "Translational research"
    ],
    "citation_count": "7,411",
    "reference_count": "42",
    "references": [
        "2139937737",
        "2149687213",
        "2131419242",
        "1489794536",
        "2133482423",
        "2116909658",
        "2043132544",
        "2069722312",
        "2009995285",
        "2073859061"
    ]
},{
    "id": "2131419242",
    "title": "Acute Kidney Injury, Mortality, Length of Stay, and Costs in Hospitalized Patients",
    "abstract": "The marginal effects of acute kidney injury on in-hospital mortality, length of stay (LOS), and costs have not been well described. A consecutive sample of 19,982 adults who were admitted to an urban academic medical center, including 9210 who had two or more serum creatinine (SCr) determinations, was evaluated. The presence and degree of acute kidney injury were assessed using absolute and relative increases from baseline to peak SCr concentration during hospitalization. Large increases in SCr concentration were relatively rare (e.g., >or=2.0 mg/dl in 105 [1%] patients), whereas more modest increases in SCr were common (e.g., >or=0.5 mg/dl in 1237 [13%] patients). Modest changes in SCr were significantly associated with mortality, LOS, and costs, even after adjustment for age, gender, admission International Classification of Diseases, Ninth Revision, Clinical Modification diagnosis, severity of illness (diagnosis-related group weight), and chronic kidney disease. For example, an increase in SCr >or=0.5 mg/dl was associated with a 6.5-fold (95% confidence interval 5.0 to 8.5) increase in the odds of death, a 3.5-d increase in LOS, and nearly 7500 dollars in excess hospital costs. Acute kidney injury is associated with significantly increased mortality, LOS, and costs across a broad spectrum of conditions. Moreover, outcomes are related directly to the severity of acute kidney injury, whether characterized by nominal or percentage changes in serum creatinine.",
    "date": "2005",
    "authors": [
        "Glenn M. Chertow",
        "Elisabeth Burdick",
        "Melissa Honour",
        "Joseph V. Bonventre",
        "David W. Bates"
    ],
    "related_topics": [
        "Kidney disease",
        "Acute kidney injury",
        "Nephrology"
    ],
    "citation_count": "3,403",
    "reference_count": "18",
    "references": [
        "2157825442",
        "1992332433",
        "2133482423",
        "1996020381",
        "1550111394",
        "2072075701",
        "2029723446",
        "2153767046",
        "2154145185",
        "2023644538"
    ]
},{
    "id": "2143432233",
    "title": "A comparison of albumin and saline for fluid resuscitation in the intensive care unit",
    "abstract": "background It remains uncertain whether the choice of resuscitation fluid for patients in intensive care units (ICUs) affects survival. We conducted a multicenter, randomized, double-blind trial to compare the effect of fluid resuscitation with albumin or saline on mortality in a heterogeneous population of patients in the ICU. methods We randomly assigned patients who had been admitted to the ICU to receive either 4 percent albumin or normal saline for intravascular-fluid resuscitation during the next 28 days. The primary outcome measure was death from any cause during the 28-day period after randomization. results Of the 6997 patients who underwent randomization, 3497 were assigned to receive albumin and 3500 to receive saline; the two groups had similar baseline characteristics. There were 726 deaths in the albumin group, as compared with 729 deaths in the saline group (relative risk of death, 0.99; 95 percent confidence interval, 0.91 to 1.09; P=0.87). The proportion of patients with new single-organ and multiple-organ failure was similar in the two groups (P=0.85). There were no significant differences between the groups in the mean (\u00b1SD) numbers of days spent in the ICU (6.5\u00b16.6 in the albumin group and 6.2\u00b16.2 in the saline group, P=0.44), days spent in the hospital (15.3\u00b19.6 and 15.6\u00b19.6, respectively; P = 0.30), days of mechanical ventilation (4.5\u00b16.1 and 4.3\u00b15.7, respectively; P = 0.74), or days of renal-replacement therapy (0.5\u00b12.3 and 0.4\u00b12.0, respectively; P = 0.41). conclusions In patients in the ICU, use of either 4 percent albumin or normal saline for fluid resuscitation results in similar outcomes at 28 days.",
    "date": "2004",
    "authors": [
        "Rinaldo Bellomo",
        "Julie French",
        "John Myburgh"
    ],
    "related_topics": [
        "Resuscitation",
        "Intensive care",
        "Intensive care unit"
    ],
    "citation_count": "3,138",
    "reference_count": "19",
    "references": [
        "2768146862",
        "2107978811",
        "127034668",
        "2161328469",
        "1991864206",
        "2599527603",
        "1554783366",
        "2112577081",
        "1603121691",
        "2046852559"
    ]
},{
    "id": "2117958746",
    "title": "Intensity of renal support in critically ill patients with acute kidney injury",
    "abstract": "We randomly assigned critically ill patients with acute kidney injury and failure of at least one nonrenal organ or sepsis to receive intensive or less intensive renal-replacement therapy. The primary end point was death from any cause by day 60. In both study groups, hemodynamically stable patients underwent intermittent hemodialysis, and hemodynamically unstable patients underwent continuous venovenous hemodiafiltration or sustained low-efficiency dialysis. Patients receiving the intensive treatment strategy underwent intermittent hemodialysis and sustained low-efficiency dialysis six times per week and continuous venovenous hemodiafiltration at 35 ml per kilogram of body weight per hour; for patients receiving the less-intensive treatment strategy, the corresponding treatments were provided thrice weekly and at 20 ml per kilogram per hour. Results Baseline characteristics of the 1124 patients in the two groups were similar. The rate of death from any cause by day 60 was 53.6% with intensive therapy and 51.5% with less-intensive therapy (odds ratio, 1.09; 95% confidence interval, 0.86 to 1.40; P = 0.47). There was no significant difference between the two groups in the duration of renalreplacement therapy or the rate of recovery of kidney function or nonrenal organ failure. Hypotension during intermittent dialysis occurred in more patients randomly assigned to receive intensive therapy, although the frequency of hemodialysis sessions complicated by hypotension was similar in the two groups. Conclusions Intensive renal support in critically ill patients with acute kidney injury did not decrease mortality, improve recovery of kidney function, or reduce the rate of nonrenal organ failure as compared with less-intensive therapy involving a defined dose of intermittent hemodialysis three times per week and continuous renal-replacement therapy at 20 ml per kilogram per hour. (ClinicalTrials.gov number, NCT00076219.)",
    "date": "2008",
    "authors": [
        "Paul M. Palevsky",
        "Jane Hongyuan Zhang",
        "Theresa Z. O'Connor",
        "Glenn M. Chertow",
        "Susan T. Crowley",
        "Devasmita Choudhury",
        "Kevin Finkel",
        "John A. Kellum",
        "Emil Paganini",
        "Roland M.H. Schein",
        "Mark W. Smith",
        "Kathleen M. Swanson",
        "B. Taylor Thompson",
        "Anitha Vijayan",
        "Suzanne Watnick",
        "Robert A. Star",
        "Peter Peduzzi",
        "E. Young",
        "R. Fissel",
        "W. Fissel",
        "U. Patel",
        "K. Belanger",
        "A. Raine",
        "N. Ricci",
        "J. Lohr",
        "P. Arora",
        "D. Cloen",
        "D. Wassel",
        "L. Yohe",
        "J. Amanzadeh",
        "J. Penfield",
        "M. Hussain",
        "R. Katneni",
        "A. Sajgure",
        "A. Swann",
        "G. Dolson",
        "V. Ramanathan",
        "G. Tasby",
        "R. Bacallao",
        "M. Jaradat",
        "K. Graves",
        "Q. Li",
        "M. Krause",
        "M. Shaver",
        "M. Alam",
        "K. Morris",
        "T. Bland",
        "E. Satter",
        "J. Kraut",
        "A. Felsenfeld"
    ],
    "related_topics": [
        "Dialysis",
        "Acute kidney injury",
        "Hemodialysis"
    ],
    "citation_count": "2,029",
    "reference_count": "29",
    "references": [
        "1898928487",
        "2149687213",
        "1996020381",
        "2148973700",
        "2043132544",
        "2069722312",
        "1980228387",
        "1997278766",
        "2107538404",
        "1988629947"
    ]
},{
    "id": "1531106656",
    "title": "Intensity of continuous renal-replacement therapy in critically ill patients.",
    "abstract": "Background The optimal intensity of continuous renal-replacement therapy remains unclear. We conducted a multicenter, randomized trial to compare the effect of this therapy, delivered at two different levels of intensity, on 90-day mortality among critically ill patients with acute kidney injury. Methods We randomly assigned critically ill adults with acute kidney injury to continuous renal-replacement therapy in the form of postdilution continuous venovenous hemodiafiltration with an effluent flow of either 40 ml per kilogram of body weight per hour (higher intensity) or 25 ml per kilogram per hour (lower intensity). The primary outcome measure was death within 90 days after randomization. Results Of the 1508 enrolled patients, 747 were randomly assigned to higher-intensity therapy, and 761 to lower-intensity therapy with continuous venovenous hemodiafiltration. Data on primary outcomes were available for 1464 patients (97.1%): 721 in the higher-intensity group and 743 in the lower-intensity group. The two study groups had similar baseline characteristics and received the study treatment for an average of 6.3 and 5.9 days, respectively (P = 0.35). At 90 days after randomization, 322 deaths had occurred in the higher-intensity group and 332 deaths in the lower-intensity group, for a mortality of 44.7% in each group (odds ratio, 1.00; 95% confidence interval [CI], 0.81 to 1.23; P = 0.99). At 90 days, 6.8% of survivors in the higher-intensity group (27 of 399), as compared with 4.4% of survivors in the lower-intensity group (18 of 411), were still receiving renal-replacement therapy (odds ratio, 1.59; 95% CI, 0.86 to 2.92; P = 0.14). Hypophosphatemia was more common in the higher-intensity group than in the lower-intensity group (65% vs. 54%, P Conclusions In critically ill patients with acute kidney injury, treatment with higher-intensity continuous renal-replacement therapy did not reduce mortality at 90 days. (ClinicalTrials.gov number, NCT00221013.)",
    "date": "2009",
    "authors": [
        "Rinaldo Bellomo",
        "Alan Cass",
        "Louise Cole",
        "Simon Finfer",
        "Martin Gallagher",
        "Serigne Lo",
        "Colin McArthur",
        "Shay McGuinness",
        "John Myburgh",
        "Robyn Norton",
        "Carlos Scheinkestel",
        "Steve Su"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Acute kidney injury",
        "Randomized controlled trial"
    ],
    "citation_count": "1,395",
    "reference_count": "16",
    "references": [
        "2149687213",
        "2098931866",
        "1489794536",
        "2117958746",
        "2116909658",
        "2148973700",
        "1970593590",
        "2156916779",
        "2159674113",
        "2085529382"
    ]
},{
    "id": "2157775267",
    "title": "Intensive insulin therapy and mortality among critically ill patients: a meta-analysis including NICE-SUGAR study data",
    "abstract": "Background: Hyperglycemia is associated with increased mortality in critically ill patients. Randomized trials of intensive insulin therapy have reported inconsistent effects on mortality and increased rates of severe hypoglycemia. We conducted a meta-analysis to update the totality of evidence regarding the influence of intensive insulin therapy compared with conventional insulin therapy on mortality and severe hypoglycemia in the intensive care unit (ICU). Methods: We conducted searches of electronic databases, abstracts from scientific conferences and bibliographies of relevant articles. We included published randomized controlled trials conducted in the ICU that directly compared intensive insulin therapy with conventional glucose management and that documented mortality. We included in our meta-analysis the data from the recent NICE-SUGAR (Normoglycemia in Intensive Care Evaluation \u2014 Survival Using Glucose Algorithm Regulation) study. Results: We included 26 trials involving a total of 13 567 patients in our meta-analysis. Among the 26 trials that reported mortality, the pooled relative risk (RR) of death with intensive insulin therapy compared with conventional therapy was 0.93 (95% confidence interval [CI] 0.83\u20131.04). Among the 14 trials that reported hypoglycemia, the pooled RR with intensive insulin therapy was 6.0 (95% CI 4.5\u20138.0). The ICU setting was a contributing factor, with patients in surgical ICUs appearing to benefit from intensive insulin therapy (RR 0.63, 95% CI 0.44\u20130.91); patients in the other ICU settings did not (medical ICU: RR 1.0, 95% CI 0.78\u20131.28; mixed ICU: RR 0.99, 95% CI 0.86\u20131.12). The different targets of intensive insulin therapy (glucose level \u2264 6.1 mmol/L v. \u2264 8.3 mmol/L) did not influence either mortality or risk of hypoglycemia. Interpretation: Intensive insulin therapy significantly increased the risk of hypoglycemia and conferred no overall mortality benefit among critically ill patients. However, this therapy may be beneficial to patients admitted to a surgical ICU.",
    "date": "2009",
    "authors": [
        "Donald E.G. Griesdale",
        "Russell J. de Souza",
        "Rob M. van Dam",
        "Daren K. Heyland",
        "Deborah J. Cook",
        "Atul Malhotra",
        "Rupinder Dhaliwal",
        "William R. Henderson",
        "Dean R. Chittock",
        "Simon Finfer",
        "Daniel Talmor"
    ],
    "related_topics": [
        "Intensive care",
        "Intensive care unit",
        "Hypoglycemia"
    ],
    "citation_count": "1,338",
    "reference_count": "47",
    "references": [
        "2125435699",
        "2118858814",
        "1980717583",
        "1986215651",
        "2145053281",
        "2107328434",
        "2115285670",
        "2148706741",
        "2081040380",
        "2007884458"
    ]
},{
    "id": "2028701043",
    "title": "Long-term Risk of Mortality and Other Adverse Outcomes After Acute Kidney Injury: A Systematic Review and Meta-analysis",
    "abstract": "Background Acute kidney injury (AKI) is common in hospitalized patients. The impact of AKI on long-term outcomes is controversial. Study Design Systematic review and meta-analysis. Setting & Participants Persons with AKI. Selection Criteria for Studies MEDLINE and EMBASE databases were searched from 1985 through October 2007. Original studies describing outcomes of AKI for patients who survived hospital discharge were included. Studies were excluded from review when participants were followed up for less than 6 months. Predictor AKI, defined as acute changes in serum creatinine level or acute need for renal replacement therapy. Outcomes Chronic kidney disease (CKD), cardiovascular disease, and mortality. Results 48 studies that contained a total of 47,017 participants were reviewed; 15 studies reported long-term data for patients without AKI. The incidence rate of mortality was 8.9 deaths/100 person-years in survivors of AKI and 4.3 deaths/100 patient-years in survivors without AKI (rate ratio [RR], 2.59; 95% confidence interval, 1.97 to 3.42). AKI was associated independently with mortality risk in 6 of 6 studies that performed multivariate adjustment (adjusted RR, 1.6 to 3.9) and with myocardial infarction in 2 of 2 studies (RR, 2.05; 95% confidence interval, 1.61 to 2.61). The incidence rate of CKD after an episode of AKI was 7.8 events/100 patient-years, and the rate of end-stage renal disease was 4.9 events/100 patient-years. Limitations The relative risk for CKD and end-stage renal disease after AKI was unattainable because of lack of follow-up of appropriate controls without AKI. Conclusions The development of AKI, defined as acute changes in serum creatinine level, characterizes hospitalized patients at increased risk of long-term adverse outcomes.",
    "date": "2009",
    "authors": [
        "Steven G. Coca",
        "Bushra Yusuf",
        "Michael G. Shlipak",
        "Amit X. Garg",
        "Chirag R. Parikh"
    ],
    "related_topics": [
        "Kidney disease",
        "Renal replacement therapy",
        "Acute kidney injury"
    ],
    "citation_count": "999",
    "reference_count": "77",
    "references": [
        "2125435699",
        "2536590171",
        "1979423827",
        "75245760",
        "2107328434",
        "2131419242",
        "2133482423",
        "2153104532",
        "2122814783",
        "2111704803"
    ]
},{
    "id": "2111704803",
    "title": "Incidence and Outcomes in Acute Kidney Injury: A Comprehensive Population-Based Study",
    "abstract": "Epidemiological studies of acute kidney injury (AKI) and acute-on-chronic renal failure (ACRF) are surprisingly sparse and confounded by differences in definition. Reported incidences vary, with few studies being population-based. Given this and our aging population, the incidence of AKI may be much higher than currently thought. We tested the hypothesis that the incidence is higher by including all patients with AKI (in a geographical population base of 523,390) regardless of whether they required renal replacement therapy irrespective of the hospital setting in which they were treated. We also tested the hypothesis that the Risk, Injury, Failure, Loss, and End-Stage Kidney (RIFLE) classification predicts outcomes. We identified all patients with serum creatinine concentrations \u2265150 \u03bcmol/L (male) or \u2265130\u03bcmol/L (female) over a 6-mo period in 2003. Clinical outcomes were obtained from each patient9s case records. The incidences of AKI and ACRF were 1811 and 336 per million population, respectively. Median age was 76 yr for AKI and 80.5 yr for ACRF. Sepsis was a precipitating factor in 47% of patients. The RIFLE classification was useful for predicting full recovery of renal function ( P P P P = 0.035). RIFLE did not predict mortality at 90 d or 6 mo. Thus the incidence of AKI is much higher than previously thought, with implications for service planning and providing information to colleagues about methods to prevent deterioration of renal function. The RIFLE classification is useful for identifying patients at greatest risk of adverse short-term outcomes.",
    "date": "2007",
    "authors": [
        "Tariq Ali",
        "Izhar Khan",
        "William Simpson",
        "Gordon Prescott",
        "John Andrew Townend",
        "William Cairns Stewart Smith",
        "Alison Murray MacLeod"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Rifle",
        "Acute kidney injury"
    ],
    "citation_count": "1,037",
    "reference_count": "25",
    "references": [
        "2487377689",
        "2139937737",
        "2149687213",
        "2069722312",
        "2155939210",
        "2036544704",
        "2139529386",
        "2171344771",
        "2095573004",
        "2150098992"
    ]
},{
    "id": "2042074736",
    "title": "Acute Renal Failure After Coronary Intervention: Incidence, Risk Factors, and Relationship to Mortality",
    "abstract": "Abstract PURPOSE: This study set out to define the incidence, predictors, and mortality related to acute renal failure (ARF) and acute renal failure requiring dialysis (ARFD) after coronary intervention. PATIENTS AND METHODS: Derivation-validation set methods were used in 1,826 consecutive patients undergoing coronary intervention with evaluation of baseline creatinine clearance (CrCl), diabetic status, contrast exposure, postprocedure creatinine, ARF, ARFD, in-hospital mortality, and long-term survival (derivation set). Multiple logistic regression was used to derive the prior probability of ARFD in a second set of 1,869 consecutive patients (validation set). RESULTS: The incidence of ARF and ARFD was 144.6/1,000 and 7.7/1,000 cases respectively. The cutoff dose of contrast below which there was no ARFD was 100 mL. No patient with a CrCl > 47 mL/min developed ARFD. These thresholds were confirmed in the validation set. Multivariate analysis found CrCl [odds ratio (OR) = 0.83, 95% confidence interval (CI) 0.77 to 0.89, P P = 0.01), and contrast dose (OR = 1.008, 95% CI 1.002 to 1.013, P = 0.01) to be independent predictors of ARFD. Patients in the validation set who underwent dialysis had a predicted prior probability of ARFD of between 0.07 and 0.73. The in-hospital mortality for those who developed ARFD was 35.7% and the 2-year survival was 18.8%. CONCLUSION: The occurrence of ARFD after coronary intervention is rare (",
    "date": "1997",
    "authors": [
        "Peter A McCullough",
        "Robert Wolyn",
        "Leslie L Rocher",
        "Robert N Levin",
        "William W O\u2019Neill"
    ],
    "related_topics": [
        "Renal function",
        "Odds ratio",
        "Dialysis"
    ],
    "citation_count": "2,194",
    "reference_count": "52",
    "references": [
        "1973948212",
        "1550111394",
        "2029723446",
        "2071273488",
        "2330776976",
        "1996698106",
        "2018224788",
        "2056699935",
        "2316461329",
        "2073085411"
    ]
},{
    "id": "2106882534",
    "title": "CLUSTAL W: IMPROVING THE SENSITIVITY OF PROGRESSIVE MULTIPLE SEQUENCE ALIGNMENT THROUGH SEQUENCE WEIGHTING, POSITION-SPECIFIC GAP PENALTIES AND WEIGHT MATRIX CHOICE",
    "abstract": "The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to down-weight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.",
    "date": "1994",
    "authors": [
        "Julie D. Thompson",
        "Desmond G. Higgins",
        "Toby J. Gibson"
    ],
    "related_topics": [
        "Gap penalty",
        "Multiple sequence alignment",
        "Structural alignment"
    ],
    "citation_count": "67,894",
    "reference_count": "34",
    "references": [
        "2097706568",
        "2015292449",
        "2009310436",
        "2143210482",
        "2065461553",
        "1998300401",
        "2008708467",
        "2045391589",
        "2149208773",
        "2102122585"
    ]
},{
    "id": "2463755683",
    "title": "Update: Outbreak of severe acute respiratory syndrome - Worldwide, 2003",
    "abstract": "",
    "date": "2002",
    "authors": [
        "T. Tsang",
        "L. Pak-Yin",
        "M. Lee",
        "J.-S. Wu",
        "Y.-C. Wu",
        "I.-H. Chiang",
        "K.-T. Chen",
        "K.-H. Hsu",
        "T.-J. Chen",
        "H.-T. Lee",
        "S.-J. Twu",
        "S. Chunsuttiwat",
        "P. Sawanpanyalert",
        "K. Ungchusak",
        "A. Chaovavanich"
    ],
    "related_topics": [
        "Outbreak",
        "Respiratory system",
        "Medicine"
    ],
    "citation_count": "339",
    "reference_count": "1",
    "references": [
        "2089784797"
    ]
},{
    "id": "2398786667",
    "title": "Microbial Threats to Health: Emergence, Detection, and Response",
    "abstract": "Infectious diseases are a global hazard that puts every nation and every person at risk. The recent SARS outbreak is a prime example. Knowing neither geographic nor political borders, often arriving silently and lethally, microbial pathogens constitute a grave threat to the health of humans. Indeed, a majority of countries recently identified the spread of infectious disease as the greatest global problem they confront. Throughout history, humans have struggled to control both the causes and consequences of infectious diseases and we will continue to do so into the foreseeable future.Following up on a high-profile 1992 report from the Institute of Medicine, Microbial Threats to Health examines the current state of knowledge and policy pertaining to emerging and re-emerging infectious diseases from around the globe. It examines the spectrum of microbial threats, factors in disease emergence, and the ultimate capacity of the United States to meet the challenges posed by microbial threats to human health. From the impact of war or technology on disease emergence to the development of enhanced disease surveillance and vaccine strategies, Microbial Threats to Health contains valuable information for researchers, students, health care providers, policymakers, public health officials. and the interested public.",
    "date": "2003",
    "authors": [
        "Mark S. Smolinski",
        "Margaret A. Hamburg",
        "Joshua Lederberg"
    ],
    "related_topics": [
        "Public health",
        "Infectious disease (medical specialty)",
        "Disease surveillance"
    ],
    "citation_count": "649",
    "reference_count": "0",
    "references": []
},{
    "id": "2127949919",
    "title": "Nipah Virus: A Recently Emergent Deadly Paramyxovirus",
    "abstract": "A paramyxovirus virus termed Nipah virus has been identified as the etiologic agent of an outbreak of severe encephalitis in people with close contact exposure to pigs in Malaysia and Singapore. The outbreak was first noted in late September 1998 and by mid-June 1999, more than 265 encephalitis cases, including 105 deaths, had been reported in Malaysia, and 11 cases of encephalitis or respiratory illness with one death had been reported in Singapore. Electron microscopic, serologic, and genetic studies indicate that this virus belongs to the family Paramyxoviridae and is most closely related to the recently discovered Hendra virus. We suggest that these two viruses are representative of a new genus within the family Paramyxoviridae. Like Hendra virus, Nipah virus is unusual among the paramyxoviruses in its ability to infect and cause potentially fatal disease in a number of host species, including humans.",
    "date": "2000",
    "authors": [
        "K. B. Chua",
        "W. J. Bellini",
        "P. A. Rota",
        "B. H. Harcourt",
        "A. Tamin",
        "S. K. Lam",
        "T. G. Ksiazek",
        "P. E. Rollin",
        "S. R. Zaki",
        "W.-J. Shieh",
        "C. S. Goldsmith",
        "D. J. Gubler",
        "J. T. Roehrig",
        "B. Eaton",
        "A. R. Gould",
        "J. Olson",
        "P. Daniels",
        "A. E. Ling",
        "C. J. Peters",
        "L. J. Anderson",
        "B. W. J. Mahy"
    ],
    "related_topics": [
        "Hendra Virus",
        "Tioman virus",
        "Henipavirus"
    ],
    "citation_count": "1,314",
    "reference_count": "13",
    "references": [
        "2094644220",
        "1981329413",
        "1983097458",
        "2130324980",
        "2040567164",
        "2028665290",
        "1699123896",
        "2029131064",
        "2147898590",
        "367527820"
    ]
},{
    "id": "1576737979",
    "title": "Microarray-based detection and genotyping of viral pathogens",
    "abstract": "The detection of viral pathogens is of critical importance in biology, medicine, and agriculture. Unfortunately, existing techniques to screen for a broad spectrum of viruses suffer from severe limitations. To facilitate the comprehensive and unbiased analysis of viral prevalence in a given biological setting, we have developed a genomic strategy for highly parallel viral screening. The cornerstone of this approach is a long oligonucleotide (70-mer) DNA microarray capable of simultaneously detecting hundreds of viruses. Using virally infected cell cultures, we were able to efficiently detect and identify many diverse viruses. Related viral serotypes could be distinguished by the unique pattern of hybridization generated by each virus. Furthermore, by selecting microarray elements derived from highly conserved regions within viral families, individual viruses that were not explicitly represented on the microarray were still detected, raising the possibility that this approach could be used for virus discovery. Finally, by using a random PCR amplification strategy in conjunction with the microarray, we were able to detect multiple viruses in human respiratory specimens without the use of sequence-specific or degenerate primers. This method is versatile and greatly expands the spectrum of detectable viruses in a single assay while simultaneously providing the capability to discriminate among viral subtypes.",
    "date": "2002",
    "authors": [
        "David Wang",
        "Laurent Coscoy",
        "Maxine Zylberberg",
        "Pedro C. Avila",
        "Homer A. Boushey",
        "Don Ganem",
        "Joseph L. DeRisi"
    ],
    "related_topics": [
        "DNA microarray",
        "Genotyping",
        "Virus"
    ],
    "citation_count": "927",
    "reference_count": "21",
    "references": [
        "2055043387",
        "1502936039",
        "1549647993",
        "2137089963",
        "2028318125",
        "2099369211",
        "2169391021",
        "2033380151",
        "2037142940",
        "2133247102"
    ]
},{
    "id": "2128788856",
    "title": "Human Metapneumovirus Infections in Young and Elderly Adults",
    "abstract": "Human metapneumovirus virus (hMPV) is a newly discovered respiratory pathogen with limited epidemiological data available. Cohorts of young and older adults were prospectively evaluated for hMPV infection during 2 winter seasons. Patients hospitalized for cardiopulmonary conditions during that period were also studied. Overall, 44 (4.5%) of 984 illnesses were associated with hMPV infection, and 9 (4.1%) of 217 asymptomatic subjects were infected. There was a significant difference in rates of hMPV illnesses between years 1 and 2 (7/452 [1.5%] vs. 37/532 [7.0%]; P<.0001). In the second year, 11% of hospitalized patients had evidence of hMPV infection. Infections occurred in all age groups but were most common among young adults. Frail elderly people with hMPV infection frequently sought medical attention. In conclusion, hMPV infection occurs in adults of all ages and may account for a significant portion of persons hospitalized with respiratory infections during some years.",
    "date": "2003",
    "authors": [
        "Ann R Falsey",
        "Dean Erdman",
        "Larry J Anderson",
        "Edward E Walsh"
    ],
    "related_topics": [
        "Human metapneumovirus",
        "Asymptomatic",
        "Young adult"
    ],
    "citation_count": "699",
    "reference_count": "10",
    "references": [
        "2170881661",
        "2152552492",
        "2048618475",
        "1589490904",
        "2110198546",
        "2165127900",
        "2076770315",
        "2079378048",
        "2068094897",
        "2065996927"
    ]
},{
    "id": "2076620790",
    "title": "A morbillivirus that caused fatal disease in horses and humans",
    "abstract": "A morbillivirus has been isolated and added to an increasing list of emerging viral diseases. This virus caused an outbreak of fatal respiratory disease in horses and humans. Genetic analyses show it to be only distantly related to the classic morbilliviruses rinderpest, measles, and canine distemper. When seen by electron microscopy, viruses had 10- and 18-nanometer surface projections that gave them a \"double-fringed\" appearance. The virus induced syncytia that developed in the endothelium of blood vessels, particularly the lungs.",
    "date": "1995",
    "authors": [
        "K Murray",
        "P Selleck",
        "P Hooper",
        "A Hyatt",
        "A Gould",
        "L Gleeson",
        "H Westbury",
        "L Hiley",
        "L Selvey",
        "B Rodwell"
    ],
    "related_topics": [
        "Morbillivirus",
        "Rinderpest virus",
        "Phocine distemper virus"
    ],
    "citation_count": "798",
    "reference_count": "18",
    "references": [
        "2034148010",
        "2123427059",
        "1972759043",
        "2020526182",
        "2002849005",
        "2078406556",
        "1582863396",
        "2148205933",
        "1997387663",
        "2106255335"
    ]
},{
    "id": "2107053896",
    "title": "Hospital Outbreak of Middle East Respiratory Syndrome Coronavirus",
    "abstract": "Background In September 2012, the World Health Organization reported the first cases of pneumonia caused by the novel Middle East respiratory syndrome coronavirus (MERS-CoV). We describe a cluster of health care\u2013acquired MERS-CoV infections. Methods Medical records were reviewed for clinical and demographic information and determination of potential contacts and exposures. Case patients and contacts were interviewed. The incubation period and serial interval (the time between the successive onset of symptoms in a chain of transmission) were estimated. Viral RNA was sequenced. Results Between April 1 and May 23, 2013, a total of 23 cases of MERS-CoV infection were reported in the eastern province of Saudi Arabia. Symptoms included fever in 20 patients (87%), cough in 20 (87%), shortness of breath in 11 (48%), and gastrointestinal symptoms in 8 (35%); 20 patients (87%) presented with abnormal chest radiographs. As of June 12, a total of 15 patients (65%) had died, 6 (26%) had recovered, and 2 (9%) remained ...",
    "date": "2013",
    "authors": [
        "Abdullah Assiri",
        "Allison McGeer",
        "Trish M. Perl",
        "Connie S. Price",
        "Abdullah A. Al Rabeeah",
        "Derek A.T. Cummings",
        "Zaki N. Alabdullatif",
        "Maher Assad",
        "Abdulmohsen Almulhim",
        "Hatem Makhdoom",
        "Hossam Madani",
        "Rafat Alhakeem",
        "Jaffar A. Al-Tawfiq",
        "Matthew Cotten",
        "Simon J. Watson",
        "Paul Kellam",
        "Alimuddin I. Zumla",
        "Ziad A. Memish"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Pneumonia"
    ],
    "citation_count": "1,265",
    "reference_count": "30",
    "references": [
        "2166867592",
        "2132260239",
        "2100820722",
        "1703839189",
        "2147166346",
        "2116586125",
        "2045002682",
        "2113457186",
        "2058144955",
        "2111412754"
    ]
},{
    "id": "2112147913",
    "title": "Middle East respiratory syndrome coronavirus (MERS-CoV): announcement of the Coronavirus Study Group.",
    "abstract": "During the summer of 2012, in Jeddah, Saudi Arabia, a hitherto unknown coronavirus (CoV) was isolated from the sputum of a patient with acute pneumonia and renal failure ([1][1], [2][2]). The isolate was provisionally called human coronavirus Erasmus Medical Center (EMC) ([3][3]). Shortly thereafter",
    "date": "2013",
    "authors": [
        "R. J. de Groot",
        "S. C. Baker",
        "R. S. Baric",
        "C. S. Brown",
        "C. Drosten",
        "L. Enjuanes",
        "R. A. M. Fouchier",
        "M. Galiano",
        "A. E. Gorbalenya",
        "Z. A. Memish",
        "S. Perlman",
        "L. L. M. Poon",
        "E. J. Snijder",
        "G. M. Stephens",
        "P. C. Y. Woo",
        "A. M. Zaki",
        "M. Zambon",
        "J. Ziebuhr"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Coronavirus",
        "Sputum"
    ],
    "citation_count": "1,149",
    "reference_count": "9",
    "references": [
        "2166867592",
        "2113457186",
        "1690366459",
        "2066347985",
        "2105558355",
        "1035662337",
        "2102229939",
        "2060720058",
        "2079206979"
    ]
},{
    "id": "2045002682",
    "title": "Family Cluster of Middle East Respiratory Syndrome Coronavirus Infections",
    "abstract": "A human coronavirus, called the Middle East respiratory syndrome coronavirus (MERS-CoV), was first identified in September 2012 in samples obtained from a Saudi Arabian businessman who died from acute respiratory failure. Since then, 49 cases of infections caused by MERS-CoV (previously called a novel coronavirus) with 26 deaths have been reported to date. In this report, we describe a family case cluster of MERS-CoV infection, including the clinical presentation, treatment outcomes, and household relationships of three young men who became ill with MERS-CoV infection after the hospitalization of an elderly male relative, who died of the disease. Twenty-four other family members living in the same household and 124 attending staff members at the hospitals did not become ill. MERS-CoV infection may cause a spectrum of clinical illness. Although an animal reservoir is suspected, none has been discovered. Meanwhile, global concern rests on the ability of MERS-CoV to cause major illness in close contacts of patients.",
    "date": "2013",
    "authors": [
        "Ziad A. Memish",
        "Alimuddin I. Zumla",
        "Rafat F. Al-Hakeem",
        "Abdullah A. Al-Rabeeah",
        "Gwen M. Stephens"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Coronavirus",
        "Pneumonia"
    ],
    "citation_count": "519",
    "reference_count": "7",
    "references": [
        "2166867592",
        "2129542667",
        "1703839189",
        "2158773042",
        "2130450914",
        "2088479029",
        "297155885"
    ]
},{
    "id": "1852588318",
    "title": "Assays for laboratory confirmation of novel human coronavirus (hCoV-EMC) infections.",
    "abstract": "We present a rigorously validated and highly sensitive confirmatory real-time RT-PCR assay (1A assay) that can be used in combination with the previously reported upE assay. Two additional RT-PCR assays for sequencing are described, targeting the RdRp gene (RdRpSeq assay) and N gene (NSeq assay), where an insertion/deletion polymorphism might exist among different hCoV-EMC strains. Finally, a simplified and biologically safe protocol for detection of antibody response by immunofluorescence microscopy was developed using convalescent patient serum.",
    "date": "2012",
    "authors": [
        "Victor Corman",
        "Marcel M\u00fcller",
        "U. Costabel",
        "J. Timm",
        "Tabea Binger",
        "Bernhard Meyer",
        "P. Kreher",
        "Erik Lattwein",
        "Monika Eschbach-Bludau",
        "A. Nitsche",
        "T. Bleicker",
        "O. Landt",
        "Brunhilde Schweiger",
        "Jan-Felix Drexler",
        "Albert Osterhaus",
        "Bart Haagmans",
        "U. Dittmer",
        "F. Bonin",
        "Thorsten Wolff",
        "Christian Drosten"
    ],
    "related_topics": [
        "Sequence analysis",
        "Virology",
        "Gene"
    ],
    "citation_count": "413",
    "reference_count": "12",
    "references": [
        "2166867592",
        "2129542667",
        "1703839189",
        "1690366459",
        "2167080692",
        "2082755732",
        "1593955729",
        "2145810580",
        "2122612816",
        "2136039989"
    ]
},{
    "id": "2163627712",
    "title": "Clinical features and short-term outcomes of 144 patients with SARS in the greater Toronto area.",
    "abstract": "ContextSevere acute respiratory syndrome (SARS) is an emerging infectious disease that first manifested in humans in China in November 2002 and has subsequently spread worldwide.ObjectivesTo describe the clinical characteristics and short-term outcomes of SARS in the first large group of patients in North America; to describe how these patients were treated and the variables associated with poor outcome.Design, Setting, and PatientsRetrospective case series involving 144 adult patients admitted to 10 academic and community hospitals in the greater Toronto, Ontario, area between March 7 and April 10, 2003, with a diagnosis of suspected or probable SARS. Patients were included if they had fever, a known exposure to SARS, and respiratory symptoms or infiltrates observed on chest radiograph. Patients were excluded if an alternative diagnosis was determined.Main Outcome MeasuresLocation of exposure to SARS; features of the history, physical examination, and laboratory tests at admission to the hospital; and 21-day outcomes such as death or intensive care unit (ICU) admission with or without mechanical ventilation.ResultsOf the 144 patients, 111 (77%) were exposed to SARS in the hospital setting. Features of the clinical examination most commonly found in these patients at admission were self-reported fever (99%), documented elevated temperature (85%), nonproductive cough (69%), myalgia (49%), and dyspnea (42%). Common laboratory features included elevated lactate dehydrogenase (87%), hypocalcemia (60%), and lymphopenia (54%). Only 2% of patients had rhinorrhea. A total of 126 patients (88%) were treated with ribavirin, although its use was associated with significant toxicity, including hemolysis (in 76%) and decrease in hemoglobin of 2 g/dL (in 49%). Twenty-nine patients (20%) were admitted to the ICU with or without mechanical ventilation, and 8 patients died (21-day mortality, 6.5%; 95% confidence interval [CI], 1.9%-11.8%). Multivariable analysis showed that the presence of diabetes (relative risk [RR], 3.1; 95% CI, 1.4-7.2; P = .01) or other comorbid conditions (RR, 2.5; 95% CI, 1.1-5.8; P = .03) were independently associated with poor outcome (death, ICU admission, or mechanical ventilation).ConclusionsThe majority of cases in the SARS outbreak in the greater Toronto area were related to hospital exposure. In the event that contact history becomes unreliable, several features of the clinical presentation will be useful in raising the suspicion of SARS. Although SARS is associated with significant morbidity and mortality, especially in patients with diabetes or other comorbid conditions, the vast majority (93.5%) of patients in our cohort survived.Published online May 6, 2003 (doi:10.1001/jama.289.21.JOC30885).",
    "date": "2003",
    "authors": [
        "Christopher M. Booth",
        "Larissa M. Matukas",
        "George A. Tomlinson",
        "Anita R. Rachlis",
        "David B. Rose",
        "Hy A. Dwosh",
        "Sharon L. Walmsley",
        "Tony Mazzulli",
        "Monica Avendano",
        "Peter Derkach",
        "Issa E. Ephtimios",
        "Ian Kitai",
        "Barbara D. Mederski",
        "Steven B. Shadowitz",
        "Wayne L. Gold",
        "Laura A. Hawryluck",
        "Elizabeth Rea",
        "Jordan S. Chenkin",
        "David W. Cescon",
        "Susan M. Poutanen",
        "Allan S. Detsky"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Intensive care unit",
        "Relative risk"
    ],
    "citation_count": "1,608",
    "reference_count": "14",
    "references": [
        "2104548316",
        "2131262274",
        "2115709314",
        "2100820722",
        "2125251240",
        "2136883754",
        "2463755683",
        "1966714873",
        "2136166622",
        "2158075347"
    ]
},{
    "id": "2140143765",
    "title": "Clinical features and virological analysis of a case of Middle East respiratory syndrome coronavirus infection",
    "abstract": "Summary Background The Middle East respiratory syndrome coronavirus (MERS-CoV) is an emerging virus involved in cases and case clusters of severe acute respiratory infection in the Arabian Peninsula, T unisia, Morocco, France, Italy, Germany, and the UK. We provide a full description of a fatal case of MERS-CoV infection and associated phylogenetic analyses. Methods We report data for a patient who was admitted to the Klinikum Schwabing (Munich, Germany) for severe acute respiratory infection. We did diagnostic RT -PCR and indirect immunofl uorescence. From time of diagnosis, respiratory, faecal, and urine samples were obtained for virus quantifi cation. We constructed a maximum likelihood tree of the fi ve available complete MERS-CoV genomes.",
    "date": "2013",
    "authors": [
        "Christian Drosten",
        "Michael Seilmaier",
        "Victor M. Corman",
        "Wulf Hartmann",
        "Gregor Scheible",
        "Stefan Sack",
        "Wolfgang Guggemos",
        "Rene Kallies",
        "Doreen Muth",
        "Sandra Junglen",
        "Marcel A. M\u00fcller",
        "Walter Haas",
        "Hana Guberina",
        "Tim R\u00f6hnisch",
        "Monika Schmid-Wendtner",
        "Souhaib Aldabbagh",
        "Ulf Dittmer",
        "Hermann Gold",
        "Petra Graf",
        "Frank Bonin",
        "Andrew Rambaut",
        "Clemens Martin Wendtner"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Viral load",
        "Respiratory system"
    ],
    "citation_count": "440",
    "reference_count": "29",
    "references": [
        "2166867592",
        "2103546861",
        "2132260239",
        "1703839189",
        "2119111857",
        "2112147913",
        "2045002682",
        "1852588318",
        "2119775949",
        "1690366459"
    ]
},{
    "id": "2119775949",
    "title": "Clinical features and viral diagnosis of two cases of infection with Middle East Respiratory Syndrome coronavirus: a report of nosocomial transmission",
    "abstract": "Summary Background Human infection with a novel coronavirus named Middle East Respiratory Syndrome coronavirus (MERS-CoV) was first identified in Saudi Arabia and the Middle East in September, 2012, with 44 laboratory-confirmed cases as of May 23, 2013. We report detailed clinical and virological data for two related cases of MERS-CoV disease, after nosocomial transmission of the virus from one patient to another in a French hospital. Methods Patient 1 visited Dubai in April, 2013; patient 2 lives in France and did not travel abroad. Both patients had underlying immunosuppressive disorders. We tested specimens from the upper (nasopharyngeal swabs) or the lower (bronchoalveolar lavage, sputum) respiratory tract and whole blood, plasma, and serum specimens for MERS-CoV by real-time RT-PCR targeting the upE and Orf1A genes of MERS-CoV. Findings Initial clinical presentation included fever, chills, and myalgia in both patients, and for patient 1, diarrhoea. Respiratory symptoms rapidly became predominant with acute respiratory failure leading to mechanical ventilation and extracorporeal membrane oxygenation (ECMO). Both patients developed acute renal failure. MERS-CoV was detected in lower respiratory tract specimens with high viral load (eg, cycle threshold [Ct] values of 22\u00b79 for upE and 24 for Orf1a for a bronchoalveolar lavage sample from patient 1; Ct values of 22\u00b75 for upE and 23\u00b79 for Orf1a for an induced sputum sample from patient 2), whereas nasopharyngeal specimens were weakly positive or inconclusive. The two patients shared the same room for 3 days. The incubation period was estimated at 9\u201312 days for the second case. No secondary transmission was documented in hospital staff despite the absence of specific protective measures before the diagnosis of MERS-CoV was suspected. Patient 1 died on May 28, due to refractory multiple organ failure. Interpretation Patients with respiratory symptoms returning from the Middle East or exposed to a confirmed case should be isolated and investigated for MERS-CoV with lower respiratory tract sample analysis and an assumed incubation period of 12 days. Immunosuppression should also be taken into account as a risk factor. Funding French Institute for Public Health Surveillance, ANR grant Labex Integrative Biology of Emerging Infectious Diseases, and the European Community's Seventh Framework Programme projects EMPERIE and PREDEMICS.",
    "date": "2013",
    "authors": [
        "Benoit Guery",
        "Julien Poissy",
        "Loubna El Mansouf",
        "Caroline S\u00e9journ\u00e9",
        "Nicolas Ettahar",
        "Xavier Lemaire",
        "Fanny Vuotto",
        "Anne Goffard",
        "Sylvie Behillil",
        "Vincent Enouf",
        "Val\u00e9rie Caro",
        "Alexandra Mailles",
        "Didier Che",
        "Jean Claude Manuguerra",
        "Daniel Mathieu",
        "Arnaud Fontanet",
        "Sylvie Van Der Werf"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Sputum",
        "Coronavirus"
    ],
    "citation_count": "476",
    "reference_count": "22",
    "references": [
        "2166867592",
        "2129542667",
        "1703839189",
        "2112147913",
        "1852588318",
        "2113457186",
        "2163627712",
        "2046153984",
        "1690366459",
        "1998725525"
    ]
},{
    "id": "2195009776",
    "title": "A SARS-like cluster of circulating bat coronaviruses shows potential for human emergence",
    "abstract": "The emergence of severe acute respiratory syndrome coronavirus (SARS-CoV) and Middle East respiratory syndrome (MERS)-CoV underscores the threat of cross-species transmission events leading to outbreaks in humans. Here we examine the disease potential of a SARS-like virus, SHC014-CoV, which is currently circulating in Chinese horseshoe bat populations. Using the SARS-CoV reverse genetics system, we generated and characterized a chimeric virus expressing the spike of bat coronavirus SHC014 in a mouse-adapted SARS-CoV backbone. The results indicate that group 2b viruses encoding the SHC014 spike in a wild-type backbone can efficiently use multiple orthologs of the SARS receptor human angiotensin converting enzyme II (ACE2), replicate efficiently in primary human airway cells and achieve in vitro titers equivalent to epidemic strains of SARS-CoV. Additionally, in vivo experiments demonstrate replication of the chimeric virus in mouse lung with notable pathogenesis. Evaluation of available SARS-based immune-therapeutic and prophylactic modalities revealed poor efficacy; both monoclonal antibody and vaccine approaches failed to neutralize and protect from infection with CoVs using the novel spike protein. On the basis of these findings, we synthetically re-derived an infectious full-length SHC014 recombinant virus and demonstrate robust viral replication both in vitro and in vivo. Our work suggests a potential risk of SARS-CoV re-emergence from viruses currently circulating in bat populations.",
    "date": "2015",
    "authors": [
        "Vineet D. Menachery",
        "Boyd L. Yount",
        "Kari Debbink",
        "Sudhakar Agnihothram",
        "Lisa E. Gralinski",
        "Jessica A. Plante",
        "Rachel L. Graham",
        "Trevor Scobey",
        "Xing Yi Ge",
        "Eric F. Donaldson",
        "Scott H. Randell",
        "Antonio Lanzavecchia",
        "Wayne A. Marasco",
        "Zhengli Li Shi",
        "Ralph S. Baric"
    ],
    "related_topics": [
        "Virus",
        "Middle East respiratory syndrome",
        "Viral replication"
    ],
    "citation_count": "628",
    "reference_count": "25",
    "references": [
        "1993577573",
        "2094993149",
        "2126707939",
        "2092969802",
        "2152528032",
        "1995367098",
        "2143230291",
        "2074618762",
        "1963580683",
        "2098037373"
    ]
},{
    "id": "2115555188",
    "title": "Middle East Respiratory Syndrome Coronavirus: Another Zoonotic Betacoronavirus Causing SARS-Like Disease",
    "abstract": "SUMMARY The source of the severe acute respiratory syndrome (SARS) epidemic was traced to wildlife market civets and ultimately to bats. Subsequent hunting for novel coronaviruses (CoVs) led to the discovery of two additional human and over 40 animal CoVs, including the prototype lineage C betacoronaviruses, Tylonycteris bat CoV HKU4 and Pipistrellus bat CoV HKU5; these are phylogenetically closely related to the Middle East respiratory syndrome (MERS) CoV, which has affected more than 1,000 patients with over 35% fatality since its emergence in 2012. All primary cases of MERS are epidemiologically linked to the Middle East. Some of these patients had contacted camels which shed virus and/or had positive serology. Most secondary cases are related to health care-associated clusters. The disease is especially severe in elderly men with comorbidities. Clinical severity may be related to MERS-CoV9s ability to infect a broad range of cells with DPP4 expression, evade the host innate immune response, and induce cytokine dysregulation. Reverse transcription-PCR on respiratory and/or extrapulmonary specimens rapidly establishes diagnosis. Supportive treatment with extracorporeal membrane oxygenation and dialysis is often required in patients with organ failure. Antivirals with potent in vitro activities include neutralizing monoclonal antibodies, antiviral peptides, interferons, mycophenolic acid, and lopinavir. They should be evaluated in suitable animal models before clinical trials. Developing an effective camel MERS-CoV vaccine and implementing appropriate infection control measures may control the continuing epidemic.",
    "date": "2015",
    "authors": [
        "Jasper F. W. Chan",
        "Susanna K. P. Lau",
        "Kelvin K. W. To",
        "Vincent C. C. Cheng",
        "Patrick C. Y. Woo",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Betacoronavirus"
    ],
    "citation_count": "719",
    "reference_count": "351",
    "references": [
        "2166867592",
        "2107053896",
        "2025170735",
        "2006434809",
        "2129542667",
        "1993577573",
        "1703839189",
        "2565805236",
        "2119111857",
        "2112147913"
    ]
},{
    "id": "2298153446",
    "title": "SARS-like WIV1-CoV poised for human emergence",
    "abstract": "Outbreaks from zoonotic sources represent a threat to both human disease as well as the global economy. Despite a wealth of metagenomics studies, methods to leverage these datasets to identify future threats are underdeveloped. In this study, we describe an approach that combines existing metagenomics data with reverse genetics to engineer reagents to evaluate emergence and pathogenic potential of circulating zoonotic viruses. Focusing on the severe acute respiratory syndrome (SARS)-like viruses, the results indicate that the WIV1-coronavirus (CoV) cluster has the ability to directly infect and may undergo limited transmission in human populations. However, in vivo attenuation suggests additional adaptation is required for epidemic disease. Importantly, available SARS monoclonal antibodies offered success in limiting viral infection absent from available vaccine approaches. Together, the data highlight the utility of a platform to identify and prioritize prepandemic strains harbored in animal reservoirs and document the threat posed by WIV1-CoV for emergence in human populations.",
    "date": "2016",
    "authors": [
        "Vineet D. Menachery",
        "Boyd L. Yount",
        "Amy C Sims",
        "Kari Debbink",
        "Sudhakar S. Agnihothram",
        "Lisa E. Gralinski",
        "Rachel Lauren Graham",
        "Trevor Scobey",
        "Jessica A. Plante",
        "Scott R. Royal",
        "Jesica Swanstrom",
        "Timothy Patrick Sheahan",
        "Raymond J Pickles",
        "Davide Corti",
        "Scott H Randell",
        "Antonio Lanzavecchia",
        "Wayne A. Marasco",
        "Ralph S Baric"
    ],
    "related_topics": [
        "Transmission (medicine)",
        "Metagenomics",
        "Outbreak"
    ],
    "citation_count": "271",
    "reference_count": "27",
    "references": [
        "1993577573",
        "2094993149",
        "2126707939",
        "2092969802",
        "2101176145",
        "2152528032",
        "1998383538",
        "1995367098",
        "2143230291",
        "1963580683"
    ]
},{
    "id": "2525468044",
    "title": "Viral Load Kinetics of MERS Coronavirus Infection.",
    "abstract": "Middle East respiratory syndrome coronavirus continues to circulate in the Middle East. During a recent outbreak in Korea, changes in MERS coronavirus viral load were determined during the course of illness in 17 patients.",
    "date": "2016",
    "authors": [
        "Myoung Don Oh",
        "Wan Beom Park",
        "Pyoeng Gyun Choe",
        "Su Jin Choi",
        "Jong I.I. Kim",
        "Jeesoo Chae",
        "Sung Sup Park",
        "Eui Chong Kim",
        "Hong Sang Oh",
        "Eun Jung Kim",
        "Eun Young Nam",
        "Sun Hee Na",
        "Dong Ki Kim",
        "Sang Min Lee",
        "Kyoung Ho Song",
        "Ji Hwan Bang",
        "Eu Suk Kim",
        "Hong Bin Kim",
        "Sang Won Park",
        "Nam Joong Kim"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Viral load",
        "Outbreak"
    ],
    "citation_count": "175",
    "reference_count": "4",
    "references": [
        "2126707939",
        "2103118479",
        "2405185968",
        "2134527559"
    ]
},{
    "id": "1945961678",
    "title": "Treatment With Lopinavir/Ritonavir or Interferon-\u03b21b Improves Outcome of MERS-CoV Infection in a Nonhuman Primate Model of Common Marmoset",
    "abstract": "Middle East respiratory syndrome coronavirus (MERS-CoV) causes severe disease in human with an overall case-fatality rate of >35%. Effective antivirals are crucial for improving the clinical outcome of MERS. Although a number of repurposed drugs, convalescent-phase plasma, antiviral peptides, and neutralizing antibodies exhibit anti-MERS-CoV activity in vitro, most are not readily available or have not been evaluated in nonhuman primates. We assessed 3 repurposed drugs with potent in vitro anti-MERS-CoV activity (mycophenolate mofetil [MMF], lopinavir/ritonavir, and interferon-\u03b21b) in common marmosets with severe disease resembling MERS in humans. The lopinavir/ritonavir-treated and interferon-\u03b21b-treated animals had better outcome than the untreated animals, with improved clinical (mean clinical scores \u219350.9%-95.0% and \u2193weight loss than the untreated animals), radiological (minimal pulmonary infiltrates), and pathological (mild bronchointerstitial pneumonia) findings, and lower mean viral loads in necropsied lung (\u21930.59-1.06 log10 copies/glyceraldehyde 3-phosphate dehydrogenase [GAPDH]; P < .050) and extrapulmonary (\u21930.11-1.29 log10 copies/GAPDH; P < .050 in kidney) tissues. In contrast, all MMF-treated animals developed severe and/or fatal disease with higher mean viral loads (\u21910.15-0.54 log10 copies/GAPDH) than the untreated animals. The mortality rate at 36 hours postinoculation was 67% (untreated and MMF-treated) versus 0-33% (lopinavir/ritonavir-treated and interferon-\u03b21b-treated). Lopinavir/ritonavir and interferon-\u03b21b alone or in combination should be evaluated in clinical trials. MMF alone may worsen MERS and should not be used.",
    "date": "2015",
    "authors": [
        "Jasper Fuk Woo Chan",
        "Yanfeng Yao",
        "Man Lung Yeung",
        "Wei Deng",
        "Linlin Bao",
        "Lilong Jia",
        "Fengdi Li",
        "Chong Xiao",
        "Hong Gao",
        "Pin Yu",
        "Jian Piao Cai",
        "Hin Chu",
        "Jie Zhou",
        "Honglin Chen",
        "Chuan Qin",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Lopinavir/ritonavir",
        "Lopinavir",
        "Ritonavir"
    ],
    "citation_count": "573",
    "reference_count": "47",
    "references": [
        "2166867592",
        "2006434809",
        "2115555188",
        "2034462612",
        "1977050884",
        "2150120685",
        "1947409115",
        "2017248106",
        "2078121682",
        "2096238447"
    ]
},{
    "id": "2099941783",
    "title": "Presence of Middle East respiratory syndrome coronavirus antibodies in Saudi Arabia: a nationwide, cross-sectional, serological study",
    "abstract": "Summary Background Scientific evidence suggests that dromedary camels are the intermediary host for the Middle East respiratory syndrome coronavirus (MERS-CoV). However, the actual number of infections in people who have had contact with camels is unknown and most index patients cannot recall any such contact. We aimed to do a nationwide serosurvey in Saudi Arabia to establish the prevalence of MERS-CoV antibodies, both in the general population and in populations of individuals who have maximum exposure to camels. Methods In the cross-sectional serosurvey, we tested human serum samples obtained from healthy individuals older than 15 years who attended primary health-care centres or participated in a national burden-of-disease study in all 13 provinces of Saudi Arabia. Additionally, we tested serum samples from shepherds and abattoir workers with occupational exposure to camels. Samples were screened by recombinant ELISA and MERS-CoV seropositivity was confirmed by recombinant immunofluorescence and plaque reduction neutralisation tests. We used two-tailed Mann Whitney U exact tests, \u03c7 2 , and Fisher's exact tests to analyse the data. Findings Between Dec 1, 2012, and Dec 1, 2013, we obtained individual serum samples from 10\u2008009 individuals. Anti-MERS-CoV antibodies were confirmed in 15 (0\u00b715%; 95% CI 0\u00b709\u20130\u00b724) of 10\u2008009 people in six of the 13 provinces. The mean age of seropositive individuals was significantly younger than that of patients with reported, laboratory-confirmed, primary Middle Eastern respiratory syndrome (43\u00b75 years [SD 17\u00b73] vs 53\u00b78 years [17\u00b75]; p=0\u00b7008). Men had a higher antibody prevalence than did women (11 [0\u00b725%] of 4341 vs two [0\u00b705%] of 4378; p=0\u00b7028) and antibody prevalence was significantly higher in central versus coastal provinces (14 [0\u00b726%] of 5479 vs one [0\u00b702%] of 4529; p=0\u00b7003). Compared with the general population, seroprevalence of MERS-CoV antibodies was significantly increased by 15 times in shepherds (two [2\u00b73%] of 87, p=0\u00b70004) and by 23 times in slaughterhouse workers (five [3\u00b76%] of 140; p Interpretation Seroprevalence of MERS-CoV antibodies was significantly higher in camel-exposed individuals than in the general population. By simple multiplication, a projected 44\u2008951 (95% CI 26\u2008971\u201371\u2008922) individuals older than 15 years might be seropositive for MERS-CoV in Saudi Arabia. These individuals might be the source of infection for patients with confirmed MERS who had no previous exposure to camels. Funding European Union, German Centre for Infection Research, Federal Ministry of Education and Research, German Research Council, and Ministry of Health of Saudi Arabia.",
    "date": "2015",
    "authors": [
        "Marcel A. M\u00fcller",
        "Benjamin Meyer",
        "Victor M. Corman",
        "Malak Al-Masri",
        "Abdulhafeez Turkestani",
        "Daniel Ritz",
        "Andrea Sieberg",
        "Souhaib Aldabbagh",
        "Berend J. Bosch",
        "Erik Lattwein",
        "Raafat F. Alhakeem",
        "Abdullah M. Assiri",
        "Ali M. Albarrak",
        "Ali M. Al-Shangiti",
        "Jaffar A. Al-Tawfiq",
        "Paul Wikramaratna",
        "Abdullah A. Alrabeeah",
        "Christian Drosten",
        "Ziad A. Memish"
    ],
    "related_topics": [
        "Seroprevalence",
        "European union",
        "Population"
    ],
    "citation_count": "268",
    "reference_count": "21",
    "references": [
        "2107053896",
        "2119111857",
        "2160011624",
        "1852588318",
        "2145441153",
        "2128886090",
        "2119837294",
        "2108756402",
        "1968393246",
        "2130227690"
    ]
},{
    "id": "2306794997",
    "title": "Epidemiology, Genetic Recombination, and Pathogenesis of Coronaviruses",
    "abstract": "Human coronaviruses (HCoVs) were first described in the 1960s for patients with the common cold. Since then, more HCoVs have been discovered, including those that cause severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS), two pathogens that, upon infection, can cause fatal respiratory disease in humans. It was recently discovered that dromedary camels in Saudi Arabia harbor three different HCoV species, including a dominant MERS HCoV lineage that was responsible for the outbreaks in the Middle East and South Korea during 2015. In this review we aim to compare and contrast the different HCoVs with regard to epidemiology and pathogenesis, in addition to the virus evolution and recombination events which have, on occasion, resulted in outbreaks amongst humans.",
    "date": "2016",
    "authors": [
        "Shuo Su",
        "Gary Wong",
        "Weifeng Shi",
        "Jun Liu",
        "Alexander C.K. Lai",
        "Jiyong Zhou",
        "Wenjun Liu",
        "Yuhai Bi",
        "George F. Gao"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Coronavirus",
        "Outbreak"
    ],
    "citation_count": "1,894",
    "reference_count": "94",
    "references": [
        "2166867592",
        "2025170735",
        "2006434809",
        "2129542667",
        "1993577573",
        "2138324310",
        "2125251240",
        "2160011624",
        "2115555188",
        "2134061616"
    ]
},{
    "id": "1909499787",
    "title": "MERS, SARS, and Ebola: The Role of Super-Spreaders in Infectious Disease.",
    "abstract": "Super-spreading occurs when a single patient infects a disproportionate number of contacts. The 2015 MERS-CoV, 2003 SARS-CoV, and to a lesser extent 2014-15 Ebola virus outbreaks were driven by super-spreaders. We summarize documented super-spreading in these outbreaks, explore contributing factors, and suggest studies to better understand super-spreading.",
    "date": "2015",
    "authors": [
        "Gary Wong",
        "Wenjun Liu",
        "Yingxia Liu",
        "Boping Zhou",
        "Yuhai Bi",
        "George F. Gao"
    ],
    "related_topics": [
        "Ebola virus",
        "Infectious disease (medical specialty)",
        "Outbreak"
    ],
    "citation_count": "279",
    "reference_count": "12",
    "references": [
        "2115102869",
        "1975375203",
        "2096145431",
        "2227495319",
        "1994871753",
        "1979807576",
        "1942680103",
        "2024845268",
        "2135540513",
        "2089797630"
    ]
},{
    "id": "3027518954",
    "title": "Pathogen genomics in public health",
    "abstract": "Summary Rapid advances in DNA sequencing technology (\u201cnext-generation sequencing\u201d) have inspired optimism about the potential of human genomics for \u201cprecision medicine.\u201d Meanwhile, pathogen genomic...",
    "date": "2020",
    "authors": [
        "Gregory L. Armstrong",
        "Duncan R. MacCannell",
        "Jill Taylor",
        "Heather A. Carleton",
        "Elizabeth B. Neuhaus",
        "Richard S. Bradbury",
        "James E. Posey",
        "Marta Gwinn"
    ],
    "related_topics": [
        "Genomics",
        "DNA sequencing",
        "Pathogen"
    ],
    "citation_count": "80",
    "reference_count": "0",
    "references": []
},{
    "id": "2792024998",
    "title": "From \u201cA\u201dIV to \u201cZ\u201dIKV: Attacks from Emerging and Re-emerging Pathogens",
    "abstract": "100 years after the infamous \u201cSpanish flu\u201d pandemic, the 2017\u20132018 flu season has been severe, with numerous infections worldwide. In between, there have been continuous, relentless attacks from (re-)emerging viruses. To fully understand viral pathogenesis and develop effective medical countermeasures, we must strengthen current surveillance and basic research efforts.",
    "date": "2018",
    "authors": [
        "George F. Gao"
    ],
    "related_topics": [
        "Pandemic",
        "Flu season",
        "Viral pathogenesis"
    ],
    "citation_count": "165",
    "reference_count": "10",
    "references": [
        "1975375203",
        "2116682907",
        "2788045019",
        "1783641736",
        "1942680103",
        "1967283148",
        "2793181185",
        "2081635462",
        "2473338860",
        "2782496877"
    ]
},{
    "id": "2955025503",
    "title": "Viral and Bacterial Etiology of Acute Febrile Respiratory Syndrome among Patients in Qinghai, China",
    "abstract": "Objective This study was conducted to investigate the viral and bacterial etiology and epidemiology of patients with acute febrile respiratory syndrome (AFRS) in Qinghai using a commercial routine multiplex-ligation-nucleic acid amplification test (NAT)-based assay. Methods A total of 445 nasopharyngeal swabs specimens from patients with AFRS were analyzed using the RespiFinderSmart22kit (PathoFinder BV, Netherlands) and the LightCycler 480 real-time PCR system. Results Among the 225 (225/445, 51%) positive specimens, 329 positive pathogens were detected, including 298 (90.58%) viruses and 31 (9%) bacteria. The most commonly detected pathogens were infiuenza virus (IFV; 37.39%; 123/329), adenovirus (AdV; 17.02%; 56/329), human coronaviruses (HCoVs; 10.94%; 36/329), rhinovirus/enterovirus (RV/EV; 10.03%; 33/329), parainfiuenza viruses (PIVs; 8.51%; 28/329), and Mycoplasma pneumoniae (M. pneu; 8.51%; 28/329), respectively. Among the co-infected cases (17.53%; 78/445), IFV/AdV and IFV/M. pneu were the most common co-infections. Most of the respiratory viruses were detected in summer and fall. Conclusion In our study, IFV-A was the most common respiratory pathogen among 22 detected pathogens, followed by AdV, HCoV, RV/EV, PIV, and M. pneu. Bacteria appeared less frequently than viruses, and co-infection was the most common phenomenon among viral pathogens. Pathogens were distributed among different age groups and respiratory viruses were generally active in July, September, and November. Enhanced surveillance and early detection can be useful in the diagnosis, treatment, and prevention of AFRS, as well as for guiding the development of appropriate public health strategies.",
    "date": "2019",
    "authors": [
        "Gao Shan Liu",
        "Hong Li",
        "Sheng Cang Zhao",
        "Rou Jian Lu",
        "Pei Hua Niu",
        "Wen Jie Tan"
    ],
    "related_topics": [
        "Enterovirus",
        "Rhinovirus",
        "Mycoplasma pneumoniae"
    ],
    "citation_count": "9",
    "reference_count": "33",
    "references": [
        "2078917493",
        "2287076968",
        "2120839730",
        "2412526156",
        "2081835188",
        "2083870139",
        "2131338055",
        "2097213674",
        "2016253387",
        "2159773954"
    ]
},{
    "id": "2257005270",
    "title": "Coronaviruses and the human airway: a universal system for virus-host interaction studies.",
    "abstract": "Human coronaviruses (HCoVs) are large RNA viruses that infect the human respiratory tract. The emergence of both Severe Acute Respiratory Syndrome and Middle East Respiratory syndrome CoVs as well as the yearly circulation of four common CoVs highlights the importance of elucidating the different mechanisms employed by these viruses to evade the host immune response, determine their tropism and identify antiviral compounds. Various animal models have been established to investigate HCoV infection, including mice and non-human primates. To establish a link between the research conducted in animal models and humans, an organotypic human airway culture system, that recapitulates the human airway epithelium, has been developed. Currently, different cell culture systems are available to recapitulate the human airways, including the Air-Liquid Interface (ALI) human airway epithelium (HAE) model. Tracheobronchial HAE cultures recapitulate the primary entry point of human respiratory viruses while the alveolar model allows for elucidation of mechanisms involved in viral infection and pathogenesis in the alveoli. These organotypic human airway cultures represent a universal platform to study respiratory virus-host interaction by offering more detailed insights compared to cell lines. Additionally, the epidemic potential of this virus family highlights the need for both vaccines and antivirals. No commercial vaccine is available but various effective antivirals have been identified, some with potential for human treatment. These morphological airway cultures are also well suited for the identification of antivirals, evaluation of compound toxicity and viral inhibition.",
    "date": "2016",
    "authors": [
        "Hulda Run Jonsdottir",
        "Ronald Dijkman"
    ],
    "related_topics": [
        "Tissue tropism",
        "Middle East respiratory syndrome",
        "Respiratory epithelium"
    ],
    "citation_count": "72",
    "reference_count": "110",
    "references": [
        "2166867592",
        "2132260239",
        "1993577573",
        "2119111857",
        "2116586125",
        "2195009776",
        "311927316",
        "2167384912",
        "2111412754",
        "2170933940"
    ]
},{
    "id": "3000834295",
    "title": "Coronavirus Infections-More Than Just the Common Cold.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Catharine I. Paules",
        "Hilary D. Marston",
        "Anthony S. Fauci"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Common cold"
    ],
    "citation_count": "1,432",
    "reference_count": "12",
    "references": [
        "3000413850",
        "2470646526",
        "2909194930",
        "3027659922",
        "3027264380",
        "2718090702",
        "1993435091",
        "2792208289",
        "3030422584",
        "3023275846"
    ]
},{
    "id": "3003951199",
    "title": "Importation and Human-to-Human Transmission of a Novel Coronavirus in Vietnam.",
    "abstract": "Human-to-Human Coronavirus Transmission in Vietnam The authors describe transmission of 2019-nCoV from a father, who had flown with his wife from Wuhan to Hanoi, to the son, who met his father and ...",
    "date": "2020",
    "authors": [
        "Lan T. Phan",
        "Thuong V. Nguyen",
        "Quang C. Luong",
        "Thinh V. Nguyen",
        "Hieu T. Nguyen",
        "Hung Q. Le",
        "Thuc T. Nguyen",
        "Thang M. Cao",
        "Quang D. Pham"
    ],
    "related_topics": [
        "Coronavirus",
        "Transmission (mechanics)",
        "Virology"
    ],
    "citation_count": "1,046",
    "reference_count": "1",
    "references": [
        "3001897055"
    ]
},{
    "id": "2999409984",
    "title": "The continuing 2019-nCoV epidemic threat of novel coronaviruses to global health - The latest 2019 novel coronavirus outbreak in Wuhan, China.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "David S. Hui",
        "Esam Ei Azhar",
        "Tariq A. Madani",
        "Francine Ntoumi",
        "Richard Kock",
        "Osman Dar",
        "Giuseppe Ippolito",
        "Timothy D. Mchugh",
        "Ziad A. Memish",
        "Christian Drosten",
        "Alimuddin Zumla",
        "Eskild Petersen"
    ],
    "related_topics": [
        "Outbreak",
        "Global health",
        "Medicine"
    ],
    "citation_count": "1,895",
    "reference_count": "10",
    "references": [
        "3027264380",
        "2981657433",
        "2981752008",
        "3000092258",
        "3029903408",
        "2442480670",
        "3031559976",
        "3023268903",
        "3029135544",
        "2414957595"
    ]
},{
    "id": "2999318660",
    "title": "Outbreak of pneumonia of unknown etiology in Wuhan, China: The mystery and the miracle.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Hongzhou Lu",
        "Charles W. Stratton",
        "Yi Wei Tang"
    ],
    "related_topics": [
        "Pneumonia",
        "Outbreak",
        "Etiology"
    ],
    "citation_count": "2,100",
    "reference_count": "9",
    "references": [
        "2470646526",
        "2132260239",
        "2255243349",
        "2766931063",
        "2103503670",
        "2134061616",
        "1997954607",
        "2158887145",
        "2121494157"
    ]
},{
    "id": "1803784511",
    "title": "Acute respiratory distress syndrome: the Berlin Definition.",
    "abstract": "The acute respiratory distress syndrome (ARDS) was defined in 1994 by the American-European Consensus Conference (AECC); since then, issues regarding the reliability and validity of this definition have emerged. Using a consensus process, a panel of experts convened in 2011 (an initiative of the European Society of Intensive Care Medicine endorsed by the American Thoracic Society and the Society of Critical Care Medicine) developed the Berlin Definition, focusing on feasibility, reliability, validity, and objective evaluation of its performance. A draft definition proposed 3 mutually exclusive categories of ARDS based on degree of hypoxemia: mild (200 mm Hg < PaO2/FIO2 \u2264 300 mm Hg), moderate (100 mm Hg < PaO2/FIO2 \u2264 200 mm Hg), and severe (PaO2/FIO2 \u2264 100 mm Hg) and 4 ancillary variables for severe ARDS: radiographic severity, respiratory system compliance (\u226440 mL/cm H2O), positive end-expiratory pressure (\u226510 cm H2O), and corrected expired volume per minute (\u226510 L/min). The draft Berlin Definition was empirically evaluated using patient-level meta-analysis of 4188 patients with ARDS from 4 multicenter clinical data sets and 269 patients with ARDS from 3 single-center data sets containing physiologic information. The 4 ancillary variables did not contribute to the predictive validity of severe ARDS for mortality and were removed from the definition. Using the Berlin Definition, stages of mild, moderate, and severe ARDS were associated with increased mortality (27%; 95% CI, 24%-30%; 32%; 95% CI, 29%-34%; and 45%; 95% CI, 42%-48%, respectively; P < .001) and increased median duration of mechanical ventilation in survivors (5 days; interquartile [IQR], 2-11; 7 days; IQR, 4-14; and 9 days; IQR, 5-17, respectively; P < .001). Compared with the AECC definition, the final Berlin Definition had better predictive validity for mortality, with an area under the receiver operating curve of 0.577 (95% CI, 0.561-0.593) vs 0.536 (95% CI, 0.520-0.553; P < .001). This updated and revised Berlin Definition for ARDS addresses a number of the limitations of the AECC definition. The approach of combining consensus discussions with empirical evaluation may serve as a model to create more accurate, evidence-based, critical illness syndrome definitions and to better inform clinical care, research, and health services planning.",
    "date": "2012",
    "authors": [
        "Ards Definition Task Force",
        "V Marco Ranieri",
        "Gordon D Rubenfeld",
        "B Taylor Thompson",
        "Niall D Ferguson",
        "Ellen Caldwell",
        "Eddy Fan",
        "Luigi Camporota",
        "Arthur S Slutsky"
    ],
    "related_topics": [
        "ARDS",
        "Prone ventilation",
        "Interquartile range"
    ],
    "citation_count": "7,998",
    "reference_count": "33",
    "references": [
        "2161328469",
        "2068854215",
        "2328176404",
        "2326364273",
        "1823772832",
        "1979469936",
        "2113752525",
        "2070070465",
        "2168829312",
        "2074935456"
    ]
},{
    "id": "2999364275",
    "title": "Evolution of the novel coronavirus from the ongoing Wuhan outbreak and modeling of its spike protein for risk of human transmission",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Xintian Xu",
        "Ping Chen",
        "Jingfang Wang",
        "Jiannan Feng",
        "Hui Zhou",
        "Xuan Li",
        "Wu Zhong",
        "Pei Hao"
    ],
    "related_topics": [
        "Coronavirus",
        "Outbreak",
        "Betacoronavirus"
    ],
    "citation_count": "1,500",
    "reference_count": "9",
    "references": [
        "2605343262",
        "2775086803",
        "2119111857",
        "2404280981",
        "2060809301",
        "1982533785",
        "3021832855",
        "2126080553",
        "3000376083"
    ]
},{
    "id": "2909194930",
    "title": "From SARS to MERS, Thrusting Coronaviruses into the Spotlight",
    "abstract": "Coronaviruses (CoVs) have formerly been regarded as relatively harmless respiratory pathogens to humans. However, two outbreaks of severe respiratory tract infection, caused by the severe acute respiratory syndrome coronavirus (SARS-CoV) and the Middle East respiratory syndrome coronavirus (MERS-CoV), as a result of zoonotic CoVs crossing the species barrier, caused high pathogenicity and mortality rates in human populations. This brought CoVs global attention and highlighted the importance of controlling infectious pathogens at international borders. In this review, we focus on our current understanding of the epidemiology, pathogenesis, prevention, and treatment of SARS-CoV and MERS-CoV, as well as provides details on the pivotal structure and function of the spike proteins (S proteins) on the surface of each of these viruses. For building up more suitable animal models, we compare the current animal models recapitulating pathogenesis and summarize the potential role of host receptors contributing to diverse host affinity in various species. We outline the research still needed to fully elucidate the pathogenic mechanism of these viruses, to construct reproducible animal models, and ultimately develop countermeasures to conquer not only SARS-CoV and MERS-CoV, but also these emerging coronaviral diseases.",
    "date": "2019",
    "authors": [
        "Zhiqi Song",
        "Yanfeng Xu",
        "Linlin Bao",
        "Ling Zhang",
        "Pin Yu",
        "Yajin Qu",
        "Hua Zhu",
        "Wenjie Zhao",
        "Yunlin Han",
        "Chuan Qin"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Outbreak"
    ],
    "citation_count": "784",
    "reference_count": "209",
    "references": [
        "2903899730",
        "2166867592",
        "2470646526",
        "2132260239",
        "2104548316",
        "2107053896",
        "2131262274",
        "2006434809",
        "1993577573",
        "2138324310"
    ]
},{
    "id": "2991899552",
    "title": "Clinical Features Predicting Mortality Risk in Patients With Viral Pneumonia: The MuLBSTA Score.",
    "abstract": "Objective The aim of this study was to further clarify clinical characteristics and predict mortality risk among patients with viral pneumonia. Methods A total of 528 patients with viral pneumonia at RuiJin hospital in Shanghai from May 2015 to May 2019 were recruited. Multiplex real-time RT-PCR was used to detect respiratory viruses. Demographic information, comorbidities, routine laboratory examinations, immunological indexes, etiological detections, radiological images and treatment were collected on admission. Results 76 (14.4%) patients died within 90 days in hospital. A predictive MuLBSTA score was calculated on the basis of a multivariate logistic regression model in order to predict mortality with a weighted score that included multilobular infiltrates (OR = 5.20, 95% CI 1.41-12.52, p = 0.010; 5 points), lymphocyte \u2264 0.8\u2217109/L (OR = 4.53, 95% CI 2.55-8.05, p < 0.001; 4 points), bacterial coinfection (OR = 3.71, 95% CI 2.11-6.51, p < 0.001; 4 points), acute-smoker (OR = 3.19, 95% CI 1.34-6.26, p = 0.001; 3 points), quit-smoker (OR = 2.18, 95% CI 0.99-4.82, p = 0.054; 2 points), hypertension (OR = 2.39, 95% CI 1.55-4.26, p = 0.003; 2 points) and age \u226560 years (OR = 2.14, 95% CI 1.04-4.39, p = 0.038; 2 points). 12 points was used as a cut-off value for mortality risk stratification. This model showed sensitivity of 0.776, specificity of 0.778 and a better predictive ability than CURB-65 (AUROC = 0.773 vs. 0.717, p < 0.001). Conclusion Here, we designed an easy-to-use clinically predictive tool for assessing 90-day mortality risk of viral pneumonia. It can accurately stratify hospitalized patients with viral pneumonia into relevant risk categories and could provide guidance to make further clinical decisions.",
    "date": "2019",
    "authors": [
        "Lingxi Guo",
        "Dong Wei",
        "Xinxin Zhang",
        "Yurong Wu",
        "Qingyun Li",
        "Min Zhou",
        "Jieming Qu"
    ],
    "related_topics": [
        "Viral pneumonia",
        "Etiology",
        "Internal medicine"
    ],
    "citation_count": "275",
    "reference_count": "32",
    "references": [
        "2133979383",
        "2065974896",
        "2159340685",
        "2091139031",
        "2103645914",
        "2948483377",
        "2021046603",
        "2155020492",
        "1975461687",
        "2900850632"
    ]
},{
    "id": "3002533507",
    "title": "A Novel Coronavirus Emerging in China - Key Questions for Impact Assessment.",
    "abstract": "A Novel Coronavirus Emerging in China A novel coronavirus, designated as 2019-nCoV, emerged in Wuhan, China, at the end of 2019. Although many details of the emergence of this virus remain unknown,...",
    "date": "2020",
    "authors": [
        "Vincent J. Munster",
        "Marion Koopmans",
        "Neeltje van Doremalen",
        "Debby van Riel",
        "Emmie de Wit"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "China"
    ],
    "citation_count": "1,081",
    "reference_count": "0",
    "references": []
},{
    "id": "3002715510",
    "title": "Another Decade, Another Coronavirus.",
    "abstract": "For the third time in as many decades, a zoonotic coronavirus has crossed species to infect human populations. This virus, provisionally called 2019-nCoV, was first identified in Wuhan, China, in p...",
    "date": "2020",
    "authors": [
        "Stanley Perlman"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Virus"
    ],
    "citation_count": "736",
    "reference_count": "8",
    "references": [
        "3001897055",
        "2801339009",
        "2126707939",
        "2156273941",
        "2217313808",
        "2538584349",
        "96734778",
        "2002481497"
    ]
},{
    "id": "2147166346",
    "title": "Transmission Dynamics and Control of Severe Acute Respiratory Syndrome",
    "abstract": "Severe acute respiratory syndrome (SARS) is a recently described illness of humans that has spread widely over the past 6 months. With the use of detailed epidemiologic data from Singapore and epidemic curves from other settings, we estimated the reproductive number for SARS in the absence of interventions and in the presence of control efforts. We estimate that a single infectious case of SARS will infect about three secondary cases in a population that has not yet instituted control measures. Public-health efforts to reduce transmission are expected to have a substantial impact on reducing the size of the epidemic.",
    "date": "2003",
    "authors": [
        "Marc Lipsitch",
        "Ted Cohen",
        "Ben Cooper",
        "James M. Robins",
        "Stefan Ma",
        "Lyn James",
        "Gowri Gopalakrishna",
        "Suok Kai Chew",
        "Chorh Chuan Tan",
        "Matthew H. Samore",
        "David Fisman",
        "Megan Murray"
    ],
    "related_topics": [
        "Population",
        "Serial interval",
        "Transmission (mechanics)"
    ],
    "citation_count": "1,553",
    "reference_count": "7",
    "references": [
        "2132260239",
        "2104548316",
        "1606697907",
        "2011756067",
        "2318510691",
        "1965399019",
        "1979065938"
    ]
},{
    "id": "2149508011",
    "title": "Evidence for camel-to-human transmission of MERS coronavirus",
    "abstract": "We describe the isolation and sequencing of Middle East respiratory syndrome coronavirus (MERS-CoV) obtained from a dromedary camel and from a patient who died of laboratory-confirmed MERS-CoV infection after close contact with camels that had rhinorrhea. Nasal swabs collected from the patient and from one of his nine camels were positive for MERS-CoV RNA. In addition, MERS-CoV was isolated from the patient and the camel. The full genome sequences of the two isolates were identical. Serologic data indicated that MERS-CoV was circulating in the camels but not in the patient before the human infection occurred. These data suggest that this fatal case of human MERS-CoV infection was transmitted through close contact with an infected camel.",
    "date": "2014",
    "authors": [
        "Esam I. Azhar",
        "Sherif A. El-Kafrawy",
        "Suha A. Farraj",
        "Ahmed M. Hassan",
        "Muneera S. Al-Saeed",
        "Anwar M. Hashem",
        "Tariq A. Madani"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Serology",
        "Transmission (medicine)"
    ],
    "citation_count": "768",
    "reference_count": "14",
    "references": [
        "2166867592",
        "2107053896",
        "2160011624",
        "2045002682",
        "1852588318",
        "2113457186",
        "2145441153",
        "2119775949",
        "1690366459",
        "2049975503"
    ]
},{
    "id": "2103503670",
    "title": "Bats are natural reservoirs of SARS-like coronaviruses.",
    "abstract": "Severe acute respiratory syndrome (SARS) emerged in 2002 to 2003 in southern China. The origin of its etiological agent, the SARS coronavirus (SARS-CoV), remains elusive. Here we report that species of bats are a natural host of coronaviruses closely related to those responsible for the SARS outbreak. These viruses, termed SARS-like coronaviruses (SL-CoVs), display greater genetic variation than SARS-CoV isolated from humans or from civets. The human and civet isolates of SARS-CoV nestle phylogenetically within the spectrum of SL-CoVs, indicating that the virus responsible for the SARS outbreak was a member of this coronavirus group.",
    "date": "2005",
    "authors": [
        "Wendong Li",
        "Zhengli Shi",
        "Meng Yu",
        "Wuze Ren",
        "Craig Smith",
        "Jonathan H. Epstein",
        "Hanzhong Wang",
        "Gary Crameri",
        "Zhihong Hu",
        "Huajun Zhang",
        "Jianhong Zhang",
        "Jennifer McEachern",
        "Hume Field",
        "Peter Daszak",
        "Bryan T. Eaton",
        "Shuyi Zhang",
        "Lin-Fa Wang"
    ],
    "related_topics": [
        "Coronavirus",
        "Alphacoronavirus",
        "Disease reservoir"
    ],
    "citation_count": "2,278",
    "reference_count": "22",
    "references": [
        "2104548316",
        "2025170735",
        "2116586125",
        "2169198329",
        "2134061616",
        "1990059132",
        "2127949919",
        "96734778",
        "2076620790",
        "2042499956"
    ]
},{
    "id": "2807736175",
    "title": "Saliva as a diagnostic specimen for testing respiratory virus by a point-of-care molecular assay: a diagnostic validity study.",
    "abstract": "Abstract Objectives Automated point-of-care molecular assays have greatly shortened the turnaround time of respiratory virus testing. One of the major bottlenecks now lies at the specimen collection step, especially in a busy clinical setting. Saliva is a convenient specimen type that can be provided easily by adult patients. This study assessed the diagnostic validity, specimen collection time and cost associated with the use of saliva. Methods This was a prospective diagnostic validity study comparing the detection rate of respiratory viruses between saliva and nasopharyngeal aspirate (NPA) among adult hospitalized patients using Xpert\u00ae Xpress Flu/RSV. The cost and time associated with the collection of saliva and nasopharyngeal specimens were also estimated. Results Between July and October 2017, 214 patients were recruited. The overall agreement between saliva and NPA was 93.3% (196/210, \u03ba 0.851, 95% CI 0.776\u20130.926). There was no significant difference in the detection rate of respiratory viruses between saliva and NPA (32.9% (69/210) versus 35.7% (75/210); p 0.146). The overall sensitivity and specificity were 90.8% (81.9%\u201396.2%) and 100% (97.3%\u2013100%), respectively, for saliva, and were 96.1% (88.9%\u201399.2%) and 98.5% (94.7%\u201399.8%), respectively, for NPA. The time and cost associated with the collection of saliva were 2.26-fold and 2.59-fold lower, respectively, than those of NPA. Conclusions Saliva specimens have high sensitivity and specificity in the detection of respiratory viruses by an automated multiplex Clinical Laboratory Improvement Amendments-waived point-of-care molecular assay when compared with those of NPA. The use of saliva also reduces the time and cost associated with specimen collection.",
    "date": "2019",
    "authors": [
        "K.K.W. To",
        "C.C.Y. Yip",
        "C.Y.W. Lai",
        "C.K.H. Wong",
        "D.T.Y. Ho",
        "P.K.P. Pang",
        "A.C.K. Ng",
        "K.-H. Leung",
        "R.W.S. Poon",
        "K.-H. Chan",
        "V.C.C. Cheng",
        "I.F.N. Hung",
        "K.-Y. Yuen"
    ],
    "related_topics": [
        "Specimen collection",
        "Respiratory virus",
        "Saliva"
    ],
    "citation_count": "113",
    "reference_count": "26",
    "references": [
        "2000714505",
        "2164777277",
        "2102263282",
        "2103338644",
        "2752904261",
        "2605374894",
        "2101172433",
        "2623181050",
        "2752140764",
        "2548288333"
    ]
},{
    "id": "2889758689",
    "title": "Genomic characterization and infectivity of a novel SARS-like coronavirus in Chinese bats",
    "abstract": "SARS coronavirus (SARS-CoV), the causative agent of the large SARS outbreak in 2003, originated in bats. Many SARS-like coronaviruses (SL-CoVs) have been detected in bats, particularly those that reside in China, Europe, and Africa. To further understand the evolutionary relationship between SARS-CoV and its reservoirs, 334 bats were collected from Zhoushan city, Zhejiang province, China, between 2015 and 2017. PCR amplification of the conserved coronaviral protein RdRp detected coronaviruses in 26.65% of bats belonging to this region, and this number was influenced by seasonal changes. Full genomic analyses of the two new SL-CoVs from Zhoushan (ZXC21 and ZC45) showed that their genomes were 29,732 nucleotides (nt) and 29,802 nt in length, respectively, with 13 open reading frames (ORFs). These results revealed 81% shared nucleotide identity with human/civet SARS CoVs, which was more distant than that observed previously for bat SL-CoVs in China. Importantly, using pathogenic tests, we found that the virus can reproduce and cause disease in suckling rats, and further studies showed that the virus-like particles can be observed in the brains of suckling rats by electron microscopy. Thus, this study increased our understanding of the genetic diversity of the SL-CoVs carried by bats and also provided a new perspective to study the possibility of cross-species transmission of SL-CoVs using suckling rats as an animal model.",
    "date": "2018",
    "authors": [
        "Dan Hu",
        "Changqiang Zhu",
        "Lele Ai",
        "Ting He",
        "Yi Wang",
        "Fuqiang Ye",
        "Lu Yang",
        "Chenxi Ding",
        "Xuhui Zhu",
        "Ruicheng Lv",
        "Jin Zhu",
        "Bachar Hassan",
        "Youjun Feng",
        "Weilong Tan",
        "Changjun Wang"
    ],
    "related_topics": [
        "ORFS",
        "Infectivity",
        "Phylogenetics"
    ],
    "citation_count": "196",
    "reference_count": "39",
    "references": [
        "2311203695",
        "2104548316",
        "1993577573",
        "2775086803",
        "2169198329",
        "2298153446",
        "2046153984",
        "2141877163",
        "2140338292",
        "2141008678"
    ]
},{
    "id": "2769543984",
    "title": "Human intestinal tract serves as an alternative infection route for Middle East respiratory syndrome coronavirus",
    "abstract": "Middle East respiratory syndrome coronavirus (MERS-CoV) has caused human respiratory infections with a high case fatality rate since 2012. However, the mode of virus transmission is not well understood. The findings of epidemiological and virological studies prompted us to hypothesize that the human gastrointestinal tract could serve as an alternative route to acquire MERS-CoV infection. We demonstrated that human primary intestinal epithelial cells, small intestine explants, and intestinal organoids were highly susceptible to MERS-CoV and can sustain robust viral replication. We also identified the evidence of enteric MERS-CoV infection in the stool specimen of a clinical patient. MERS-CoV was considerably resistant to fed-state gastrointestinal fluids but less tolerant to highly acidic fasted-state gastric fluid. In polarized Caco-2 cells cultured in Transwell inserts, apical MERS-CoV inoculation was more effective in establishing infection than basolateral inoculation. Notably, direct intragastric inoculation of MERS-CoV caused a lethal infection in human DPP4 transgenic mice. Histological examination revealed MERS-CoV enteric infection in all inoculated mice, as shown by the presence of virus-positive cells, progressive inflammation, and epithelial degeneration in small intestines, which were exaggerated in the mice pretreated with the proton pump inhibitor pantoprazole. With the progression of the enteric infection, inflammation, virus-positive cells, and live viruses emerged in the lung tissues, indicating the development of sequential respiratory infection. Taken together, these data suggest that the human intestinal tract may serve as an alternative infection route for MERS-CoV.",
    "date": "2017",
    "authors": [
        "Jie Zhou",
        "Cun Li",
        "Guangyu Zhao",
        "Hin Chu",
        "Dong Wang",
        "Helen Hoi-Ning Yan",
        "Vincent Kwok-Man Poon",
        "Lei Wen",
        "Bosco Ho-Yin Wong",
        "Xiaoyu Zhao",
        "Man Chun Chiu",
        "Dong Yang",
        "Yixin Wang",
        "Rex K. H. Au-Yeung",
        "Ivy Hau-Yee Chan",
        "Shihui Sun",
        "Jasper Fuk-Woo Chan",
        "Kelvin Kai-Wang To",
        "Ziad Ahmed Memish",
        "Victor M. Corman",
        "Christian Drosten",
        "Ivan Fan-Ngai Hung",
        "Yusen Zhou",
        "Suet Yi Leung",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Respiratory infection",
        "Human gastrointestinal tract",
        "Small intestine"
    ],
    "citation_count": "272",
    "reference_count": "46",
    "references": [
        "2166867592",
        "2107053896",
        "2025170735",
        "2006434809",
        "2045002682",
        "2115555188",
        "2002513358",
        "2144410942",
        "1757215199",
        "1947409115"
    ]
},{
    "id": "2140338292",
    "title": "Severe acute respiratory syndrome coronavirus-like virus in Chinese horseshoe bats",
    "abstract": "Although the finding of severe acute respiratory syndrome coronavirus (SARS-CoV) in caged palm civets from live animal markets in China has provided evidence for interspecies transmission in the genesis of the SARS epidemic, subsequent studies suggested that the civet may have served only as an amplification host for SARS-CoV. In a surveillance study for CoV in noncaged animals from the wild areas of the Hong Kong Special Administration Region, we identified a CoV closely related to SARS-CoV (bat-SARS-CoV) from 23 (39%) of 59 anal swabs of wild Chinese horseshoe bats (Rhinolophus sinicus) by using RT-PCR. Sequencing and analysis of three bat-SARS-CoV genomes from samples collected at different dates showed that bat-SARS-CoV is closely related to SARS-CoV from humans and civets. Phylogenetic analysis showed that bat-SARS-CoV formed a distinct cluster with SARS-CoV as group 2b CoV, distantly related to known group 2 CoV. Most differences between the bat-SARS-CoV and SARS-CoV genomes were observed in the spike genes, ORF 3 and ORF 8, which are the regions where most variations also were observed between human and civet SARS-CoV genomes. In addition, the presence of a 29-bp insertion in ORF 8 of bat-SARS-CoV genome, not in most human SARS-CoV genomes, suggests that it has a common ancestor with civet SARS-CoV. Antibody against recombinant bat-SARS-CoV nucleocapsid protein was detected in 84% of Chinese horseshoe bats by using an enzyme immunoassay. Neutralizing antibody to human SARS-CoV also was detected in bats with lower viral loads. Precautions should be exercised in the handling of these animals.",
    "date": "2005",
    "authors": [
        "Susanna K. P. Lau",
        "Patrick C. Y. Woo",
        "Kenneth S. M. Li",
        "Yi Huang",
        "Hoi-Wah Tsoi",
        "Beatrice H. L. Wong",
        "Samson S. Y. Wong",
        "Suet-Yi Leung",
        "Kwok-Hung Chan",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Civet",
        "Alphacoronavirus",
        "Rhinolophus sinicus"
    ],
    "citation_count": "1,727",
    "reference_count": "40",
    "references": [
        "2141885858",
        "2132260239",
        "2104548316",
        "2025170735",
        "2116586125",
        "1966238900",
        "2169198329",
        "2171091522",
        "2134061616",
        "2111412754"
    ]
},{
    "id": "3004280078",
    "title": "A pneumonia outbreak associated with a new coronavirus of probable bat origin",
    "abstract": "Since the outbreak of severe acute respiratory syndrome (SARS) 18 years ago, a large number of SARS-related coronaviruses (SARSr-CoVs) have been discovered in their natural reservoir host, bats1-4. Previous studies have shown that some bat SARSr-CoVs have the potential to infect humans5-7. Here we report the identification and characterization of a new coronavirus (2019-nCoV), which caused an epidemic of acute respiratory syndrome in humans in Wuhan, China. The epidemic, which started on 12 December 2019, had caused 2,794 laboratory-confirmed infections including 80 deaths by 26 January 2020. Full-length genome sequences were obtained from five patients at an early stage of the outbreak. The sequences are almost identical and share 79.6% sequence identity to SARS-CoV. Furthermore, we show that 2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus. Pairwise protein sequence analysis of seven conserved non-structural proteins domains show that this virus belongs to the species of SARSr-CoV. In addition, 2019-nCoV virus isolated from the bronchoalveolar lavage fluid of a critically ill patient could be neutralized by sera from several patients. Notably, we confirmed that 2019-nCoV uses the same cell entry receptor-angiotensin converting enzyme II (ACE2)-as SARS-CoV.",
    "date": "2020",
    "authors": [
        "Peng Zhou",
        "Xing Lou Yang",
        "Xian Guang Wang",
        "Ben Hu",
        "Lei Zhang",
        "Wei Zhang",
        "Hao Rui Si",
        "Yan Zhu",
        "Bei Li",
        "Chao Lin Huang",
        "Hui Dong Chen",
        "Jing Chen",
        "Yun Luo",
        "Hua Guo",
        "Ren Di Jiang",
        "Mei Qin Liu",
        "Ying Chen",
        "Xu Rui Shen",
        "Xi Wang",
        "Xiao Shuang Zheng",
        "Kai Zhao",
        "Quan Jiao Chen",
        "Fei Deng",
        "Lin Lin Liu",
        "Bing Yan",
        "Fa Xian Zhan",
        "Yan Yi Wang",
        "Geng Fu Xiao",
        "Zheng Li Shi"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Outbreak"
    ],
    "citation_count": "11,423",
    "reference_count": "13",
    "references": [
        "2903899730",
        "2166867592",
        "2132260239",
        "1993577573",
        "2775086803",
        "1966238900",
        "2195009776",
        "2918873120",
        "2103503670",
        "2298153446"
    ]
},{
    "id": "2103441770",
    "title": "Fast and accurate short read alignment with Burrows\u2013Wheeler transform",
    "abstract": "Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals. Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows\u2013Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ~10\u201320\u00d7 faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package. Availability: http://maq.sourceforge.net Contact: [email protected]",
    "date": "2009",
    "authors": [
        "Heng Li",
        "Richard Durbin"
    ],
    "related_topics": [
        "Hybrid genome assembly",
        "Sequence assembly",
        "2 base encoding"
    ],
    "citation_count": "29,912",
    "reference_count": "31",
    "references": [
        "2108234281",
        "2158714788",
        "2124985265",
        "2112113834",
        "2136145671",
        "2139760555",
        "2015292449",
        "2132341951",
        "2055666215",
        "2142619120"
    ]
},{
    "id": "2141052558",
    "title": "RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies.",
    "abstract": "Motivation: Phylogenies are increasingly used in all fields of medical and biological research. Moreover, because of the next-generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace. RAxML (Randomized Axelerated Maximum Likelihood) is a popular program for phylogenetic analyses of large datasets under maximum likelihood. Since the last RAxML paper in 2006, it has been continuously maintained and extended to accommodate the increasingly growing input datasets and to serve the needs of the user community. Results: I present some of the most notable new features and extensions of RAxML, such as a substantial extension of substitution models and supported data types, the introduction of SSE3, AVX and AVX2 vector intrinsics, techniques for reducing the memory requirements of the code and a plethora of operations for conducting post-analyses on sets of trees. In addition, an up-to-date 50-page user manual covering all new RAxML options is available. Availability and implementation: The code is available under GNU GPL at https://github.com/stamatak/standard-RAxML. Contact: gro.sti-h@sikatamats.sordnaxela Supplementary information: Supplementary data are available at Bioinformatics online.",
    "date": "2014",
    "authors": [
        "Alexandros Stamatakis"
    ],
    "related_topics": [
        "Intrinsics",
        "Data type",
        "Supermatrix"
    ],
    "citation_count": "18,528",
    "reference_count": "15",
    "references": [
        "2111211467",
        "2168696662",
        "2127847431",
        "1794270752",
        "2012220164",
        "2068187483",
        "2151736966",
        "2100030044",
        "2122082385",
        "2156921764"
    ]
},{
    "id": "2804822363",
    "title": "SWISS-MODEL: homology modelling of protein structures and complexes.",
    "abstract": "Homology modelling has matured into an important technique in structural biology, significantly contributing to narrowing the gap between known protein sequences and experimentally determined structures. Fully automated workflows and servers simplify and streamline the homology modelling process, also allowing users without a specific computational expertise to generate reliable protein models and have easy access to modelling results, their visualization and interpretation. Here, we present an update to the SWISS-MODEL server, which pioneered the field of automated modelling 25 years ago and been continuously further developed. Recently, its functionality has been extended to the modelling of homo- and heteromeric complexes. Starting from the amino acid sequences of the interacting proteins, both the stoichiometry and the overall structure of the complex are inferred by homology modelling. Other major improvements include the implementation of a new modelling engine, ProMod3 and the introduction a new local model quality estimation method, QMEANDisCo. SWISS-MODEL is freely available at https://swissmodel.expasy.org.",
    "date": "2018",
    "authors": [
        "Andrew Waterhouse",
        "Martino Bertoni",
        "Stefan Bienert",
        "Gabriel Studer",
        "Gerardo Tauriello",
        "Rafal Gumienny",
        "Florian T Heer",
        "Tjaart A P de Beer",
        "Christine Rempfer",
        "Lorenza Bordoli",
        "Rosalba Lepore",
        "Torsten Schwede"
    ],
    "related_topics": [
        "Structural biology",
        "Server",
        "Visualization"
    ],
    "citation_count": "3,408",
    "reference_count": "69",
    "references": [
        "2158714788",
        "2142678478",
        "2149525061",
        "2152301430",
        "2154139219",
        "2015642465",
        "2060809301",
        "2065283382",
        "2051210555",
        "2159614853"
    ]
},{
    "id": "2991491848",
    "title": "A Randomized, Controlled Trial of Ebola Virus Disease Therapeutics.",
    "abstract": "Abstract Background Although several experimental therapeutics for Ebola virus disease (EVD) have been developed, the safety and efficacy of the most promising therapies need to be assessed in the ...",
    "date": "2019",
    "authors": [
        "Mulangu S",
        "Dodd Le",
        "Davey Rt",
        "Tshiani Mbaya O",
        "Proschan M",
        "Mukadi D",
        "Lusakibanza Manzo M",
        "Nzolo D",
        "Tshomba Oloma A",
        "Ibanda A",
        "Ali R",
        "Coulibaly S",
        "Levine Ac",
        "Grais R",
        "Diaz J",
        "Lane Hc",
        "Muyembe-Tamfum Jj",
        "Sivahera B",
        "Camara M",
        "Kojan R",
        "Walker R",
        "Dighero-Kemp B",
        "Cao H",
        "Mukumbayi P",
        "Mbala-Kingebeni P",
        "Ahuka S",
        "Albert S",
        "Bonnett T",
        "Crozier I",
        "Duvenhage M",
        "Proffitt C",
        "Teitelbaum M",
        "Moench T",
        "Aboulhab J",
        "Barrett K",
        "Cahill K",
        "Cone K",
        "Eckes R",
        "Hensley L",
        "Herpin B",
        "Higgs E",
        "Ledgerwood J",
        "Pierson J",
        "Smolskis M",
        "Sow Y",
        "Tierney J",
        "Sivapalasingam S",
        "Holman W",
        "Gettinger N",
        "Vall\u00e9e D"
    ],
    "related_topics": [
        "Ebola virus",
        "Randomized controlled trial",
        "MEDLINE"
    ],
    "citation_count": "889",
    "reference_count": "0",
    "references": []
},{
    "id": "2605343262",
    "title": "GISAID: Global initiative on sharing all influenza data - from vision to reality.",
    "abstract": "",
    "date": "2017",
    "authors": [
        "Yuelong Shu",
        "John McCauley"
    ],
    "related_topics": [
        "Public health informatics",
        "Data sharing",
        "Global health"
    ],
    "citation_count": "932",
    "reference_count": "18",
    "references": [
        "2106173155",
        "2259815689",
        "2587970647",
        "2063651055",
        "2222043208",
        "2532120756",
        "2557499142",
        "2104424333",
        "2033459705",
        "2096039130"
    ]
},{
    "id": "3004397688",
    "title": "Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak.",
    "abstract": "Abstract Backgrounds An ongoing outbreak of a novel coronavirus (2019-nCoV) pneumonia hit a major city in China, Wuhan, December 2019 and subsequently reached other provinces/regions of China and other countries. We present estimates of the basic reproduction number, R0, of 2019-nCoV in the early phase of the outbreak. Methods Accounting for the impact of the variations in disease reporting rate, we modelled the epidemic curve of 2019-nCoV cases time series, in mainland China from January 10 to January 24, 2020, through the exponential growth. With the estimated intrinsic growth rate (\u03b3), we estimated R0 by using the serial intervals (SI) of two other well-known coronavirus diseases, MERS and SARS, as approximations for the true unknown SI. Findings The early outbreak data largely follows the exponential growth. We estimated that the mean R0 ranges from 2.24 (95%CI: 1.96\u20132.55) to 3.58 (95%CI: 2.89\u20134.39) associated with 8-fold to 2-fold increase in the reporting rate. We demonstrated that changes in reporting rate substantially affect estimates of R0. Conclusion The mean estimate of R0 for the 2019-nCoV ranges from 2.24 to 3.58, and is significantly larger than 1. Our findings indicate the potential of 2019-nCoV to cause outbreaks.",
    "date": "2020",
    "authors": [
        "Shi Zhao",
        "Qianyin Lin",
        "Jinjun Ran",
        "Salihu S Musa",
        "Guangpu Yang",
        "Weiming Wang",
        "Yijun Lou",
        "Daozhou Gao",
        "Lin Yang",
        "Daihai He",
        "Maggie H Wang"
    ],
    "related_topics": [
        "Outbreak",
        "Serial interval",
        "Basic reproduction number"
    ],
    "citation_count": "1,413",
    "reference_count": "17",
    "references": [
        "2107053896",
        "3002764620",
        "3004026249",
        "2999612210",
        "2147166346",
        "3026046290",
        "1990049863",
        "2117002055",
        "3002747665",
        "2102187991"
    ]
},{
    "id": "3002764620",
    "title": "Novel coronavirus 2019-nCoV: early estimation of epidemiological parameters and epidemic predictions",
    "abstract": "Since first identified, the epidemic scale of the recently emerged novel coronavirus (2019-nCoV) in Wuhan, China, has increased rapidly, with cases arising across China and other countries and regions. using a transmission model, we estimate a basic reproductive number of 3.11 (95%CI, 2.39-4.13); 58-76% of transmissions must be prevented to stop increasing; Wuhan case ascertainment of 5.0% (3.6-7.4); 21022 (11090-33490) total infections in Wuhan 1 to 22 January.",
    "date": "2020",
    "authors": [
        "Read Jm",
        "Bridgen",
        "Cummings Da",
        "Ho A",
        "Jewell Cp"
    ],
    "related_topics": [
        "Coronavirus",
        "Basic reproduction number",
        "Transmission (mechanics)"
    ],
    "citation_count": "671",
    "reference_count": "15",
    "references": [
        "3001118548",
        "2582743722",
        "3002539152",
        "3017468735",
        "2999612210",
        "2147166346",
        "3002533591",
        "3026046290",
        "1998725525",
        "3001343166"
    ]
},{
    "id": "3002533591",
    "title": "Transmission Dynamics of 2019 Novel Coronavirus (2019-nCoV)",
    "abstract": "Background: Since December 29, 2019, pneumonia infection with 2019-nCoV has rapidly spread out from Wuhan, HubeProvince, China to most others provinces and ot",
    "date": "2020",
    "authors": [
        "Tao Liu",
        "Jianxiong Hu",
        "Min Kang",
        "Lifeng Lin",
        "Haojie Zhong",
        "Jianpeng Xiao",
        "Guanhao He",
        "Tie Song",
        "Qiong Huang",
        "Zuhua Rong",
        "Aiping Deng",
        "Weilin Zeng",
        "Xiaohua Tan",
        "Siqing Zeng",
        "Zhihua Zhu",
        "Jiansen Li",
        "Donghua Wan",
        "Jing Lu",
        "Huihong Deng",
        "Jianfeng He",
        "Wenjun Ma"
    ],
    "related_topics": [
        "Pneumonia",
        "Transmission (mechanics)",
        "Virology"
    ],
    "citation_count": "313",
    "reference_count": "23",
    "references": [
        "3001118548",
        "3005079553",
        "3003668884",
        "3002539152",
        "3003573988",
        "3001465255",
        "3004397688",
        "2147166346",
        "2117002055",
        "2140763962"
    ]
},{
    "id": "1815575713",
    "title": "Transmission characteristics of MERS and SARS in the healthcare setting: a comparative study",
    "abstract": "The Middle East respiratory syndrome (MERS) coronavirus has caused recurrent outbreaks in the Arabian Peninsula since 2012. Although MERS has low overall human-to-human transmission potential, there is occasional amplification in the healthcare setting, a pattern reminiscent of the dynamics of the severe acute respiratory syndrome (SARS) outbreaks in 2003. Here we provide a head-to-head comparison of exposure patterns and transmission dynamics of large hospital clusters of MERS and SARS, including the most recent South Korean outbreak of MERS in 2015.",
    "date": "2015",
    "authors": [
        "Gerardo Chowell",
        "Fatima Abdirizak",
        "Sunmi Lee",
        "Jonggul Lee",
        "Eunok Jung",
        "Hiroshi Nishiura",
        "C\u00e9cile Viboud"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Middle East respiratory syndrome",
        "Coronavirus"
    ],
    "citation_count": "411",
    "reference_count": "45",
    "references": [
        "2166867592",
        "2107053896",
        "2006434809",
        "2138324310",
        "2147166346",
        "1990049863",
        "2069251911",
        "2096145431",
        "1968393246",
        "2130227690"
    ]
},{
    "id": "2069251911",
    "title": "Superspreading and the effect of individual variation on disease emergence",
    "abstract": "Population-level analyses often use average quantities to describe heterogeneous systems, particularly when variation does not arise from identifiable groups. A prominent example, central to our current understanding of epidemic spread, is the basic reproductive number, R(0), which is defined as the mean number of infections caused by an infected individual in a susceptible population. Population estimates of R(0) can obscure considerable individual variation in infectiousness, as highlighted during the global emergence of severe acute respiratory syndrome (SARS) by numerous 'superspreading events' in which certain individuals infected unusually large numbers of secondary cases. For diseases transmitted by non-sexual direct contacts, such as SARS or smallpox, individual variation is difficult to measure empirically, and thus its importance for outbreak dynamics has been unclear. Here we present an integrated theoretical and statistical analysis of the influence of individual variation in infectiousness on disease emergence. Using contact tracing data from eight directly transmitted diseases, we show that the distribution of individual infectiousness around R(0) is often highly skewed. Model predictions accounting for this variation differ sharply from average-based approaches, with disease extinction more likely and outbreaks rarer but more explosive. Using these models, we explore implications for outbreak control, showing that individual-specific control measures outperform population-wide measures. Moreover, the dramatic improvements achieved through targeted control policies emphasize the need to identify predictive correlates of higher infectiousness. Our findings indicate that superspreading is a normal feature of disease spread, and to frame ongoing discussion we propose a rigorous definition for superspreading events and a method to predict their frequency.",
    "date": "2005",
    "authors": [
        "J. O. Lloyd-Smith",
        "S. J. Schreiber",
        "P. E. Kopp",
        "W. M. Getz"
    ],
    "related_topics": [
        "Susceptible individual",
        "Super-spreader",
        "Basic reproduction number"
    ],
    "citation_count": "1,977",
    "reference_count": "96",
    "references": [
        "1995945562",
        "2009435671",
        "2131262274",
        "2147166346",
        "1606697907",
        "2146272590",
        "1965499304",
        "2096145431",
        "2104595316",
        "2463755683"
    ]
},{
    "id": "2096145431",
    "title": "Transmission dynamics of the etiological agent of SARS in Hong Kong: impact of public health interventions.",
    "abstract": "We present an analysis of the first 10 weeks of the severe acute respiratory syndrome (SARS) epidemic in Hong Kong. The epidemic to date has been characterized by two large clusters-initiated by two separate \"super-spread\" events (SSEs)-and by ongoing community transmission. By fitting a stochastic model to data on 1512 cases, including these clusters, we show that the etiological agent of SARS is moderately transmissible. Excluding SSEs, we estimate that 2.7 secondary infections were generated per case on average at the start of the epidemic, with a substantial contribution from hospital transmission. Transmission rates fell during the epidemic, primarily as a result of reductions in population contact rates and improved hospital infection control, but also because of more rapid hospital attendance by symptomatic individuals. As a result, the epidemic is now in decline, although continued vigilance is necessary for this to be maintained. Restrictions on longer range population movement are shown to be a potentially useful additional control measure in some contexts. We estimate that most currently infected persons are now hospitalized, which highlights the importance of control of nosocomial transmission.",
    "date": "2003",
    "authors": [
        "Steven Riley",
        "Christophe Fraser",
        "Christl A. Donnelly",
        "Azra C. Ghani",
        "Laith J. Abu-Raddad",
        "Anthony J. Hedley",
        "Gabriel M. Leung",
        "Lai Ming Ho",
        "Tai Hing Lam",
        "Thuan Q. Thach",
        "Patsy Chau",
        "King Pan Chan",
        "Su Vui Lo",
        "Pak Yin Leung",
        "Thomas Tsang",
        "William Ho",
        "Koon Hung Lee",
        "Edith M.C. Lau",
        "Neil M. Ferguson",
        "Roy M. Anderson"
    ],
    "related_topics": [
        "Population",
        "Secondary infection",
        "Global health"
    ],
    "citation_count": "1,316",
    "reference_count": "8",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2100820722",
        "2169198329",
        "1606697907",
        "2104595316",
        "2124853344"
    ]
},{
    "id": "2104595316",
    "title": "Mathematical Epidemiology of Infectious Diseases: Model Building, Analysis and Interpretation",
    "abstract": "Provides systematic coverage of the mathematical theory of modelling epidemics in populations, with a clear and coherent discussion of the issues, concepts and phenomena. Mathematical modelling of epidemics is a vast and important area of study and this book helps the reader to translate, model, analyse and interpret, with numerous applications, examples and exercises to aid understanding.",
    "date": "2000",
    "authors": [
        "Odo Diekmann",
        "J. A. P Heesterbeek"
    ],
    "related_topics": [
        "Mathematical theory",
        "Mathematical modelling of infectious disease",
        "Model building"
    ],
    "citation_count": "3,610",
    "reference_count": "0",
    "references": []
},{
    "id": "1968393246",
    "title": "Middle East respiratory syndrome coronavirus: quantification of the extent of the epidemic, surveillance biases, and transmissibility",
    "abstract": "Summary Background The novel Middle East respiratory syndrome coronavirus (MERS-CoV) had, as of Aug 8, 2013, caused 111 virologically confirmed or probable human cases of infection worldwide. We analysed epidemiological and genetic data to assess the extent of human infection, the performance of case detection, and the transmission potential of MERS-CoV with and without control measures. Methods We assembled a comprehensive database of all confirmed and probable cases from public sources and estimated the incubation period and generation time from case cluster data. Using data of numbers of visitors to the Middle East and their duration of stay, we estimated the number of symptomatic cases in the Middle East. We did independent analyses, looking at the growth in incident clusters, the growth in viral population, the reproduction number of cluster index cases, and cluster sizes to characterise the dynamical properties of the epidemic and the transmission scenario. Findings The estimated number of symptomatic cases up to Aug 8, 2013, is 940 (95% CI 290\u20132200), indicating that at least 62% of human symptomatic cases have not been detected. We find that the case-fatality ratio of primary cases detected via routine surveillance (74%; 95% CI 49\u201391) is biased upwards because of detection bias; the case-fatality ratio of secondary cases was 20% (7\u201342). Detection of milder cases (or clinical management) seemed to have improved in recent months. Analysis of human clusters indicated that chains of transmission were not self-sustaining when infection control was implemented, but that R in the absence of controls was in the range 0\u00b78\u20131\u00b73. Three independent data sources provide evidence that R cannot be much above 1, with an upper bound of 1\u00b72\u20131\u00b75. Interpretation By showing that a slowly growing epidemic is underway either in human beings or in an animal reservoir, quantification of uncertainty in transmissibility estimates, and provision of the first estimates of the scale of the epidemic and extent of case detection biases, we provide valuable information for more informed risk assessment. Funding Medical Research Council, Bill & Melinda Gates Foundation, EU FP7, and National Institute of General Medical Sciences.",
    "date": "2013",
    "authors": [
        "Simon Cauchemez",
        "Christophe Fraser",
        "Maria D Van Kerkhove",
        "Christl A Donnelly",
        "Steven Riley",
        "Andrew Rambaut",
        "Vincent Enouf",
        "Sylvie van der Werf",
        "Neil M Ferguson"
    ],
    "related_topics": [
        "Population",
        "Middle East respiratory syndrome coronavirus",
        "Basic reproduction number"
    ],
    "citation_count": "342",
    "reference_count": "18",
    "references": [
        "2166867592",
        "2107053896",
        "2157725602",
        "2147166346",
        "2160011624",
        "2045002682",
        "2113457186",
        "2130227690",
        "2140763962",
        "2102187991"
    ]
},{
    "id": "2158899491",
    "title": "Natural Language Processing (Almost) from Scratch",
    "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.",
    "date": "2011",
    "authors": [
        "Ronan Collobert",
        "Jason Weston",
        "L\u00e9on Bottou",
        "Michael Karlen",
        "Koray Kavukcuoglu",
        "Pavel Kuksa"
    ],
    "related_topics": [
        "Named-entity recognition",
        "Chunking (psychology)",
        "Semantic role labeling"
    ],
    "citation_count": "7,413",
    "reference_count": "95",
    "references": [
        "2136922672",
        "2310919327",
        "2147880316",
        "2125838338",
        "2110798204",
        "2158139315",
        "2159080219",
        "2098162425",
        "2150102617",
        "2296073425"
    ]
},{
    "id": "2110158442",
    "title": "Contour Detection and Hierarchical Image Segmentation",
    "abstract": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications.",
    "date": "2011",
    "authors": [
        "P Arbela\u0301ez",
        "M Maire",
        "C Fowlkes",
        "J Malik"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Segmentation-based object categorization",
        "Image segmentation"
    ],
    "citation_count": "4,633",
    "reference_count": "76",
    "references": [
        "2121947440",
        "2067191022",
        "2116040950",
        "2124351162",
        "1999478155",
        "2145023731",
        "1578099820",
        "2169551590",
        "2121927366",
        "1528789833"
    ]
},{
    "id": "1999478155",
    "title": "Efficient Graph-Based Image Segmentation",
    "abstract": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.",
    "date": "2004",
    "authors": [
        "Pedro F. Felzenszwalb",
        "Daniel P. Huttenlocher"
    ],
    "related_topics": [
        "Segmentation-based object categorization",
        "Image segmentation",
        "Range segmentation"
    ],
    "citation_count": "7,269",
    "reference_count": "17",
    "references": [
        "2121947440",
        "2752885492",
        "1971784203",
        "1964443764",
        "2160167256",
        "2137560895",
        "2167077256",
        "2132603077",
        "1640070940",
        "2109562068"
    ]
},{
    "id": "2143516773",
    "title": "Fast approximate energy minimization via graph cuts",
    "abstract": "Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. The authors consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is NP-hard even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.",
    "date": "2001",
    "authors": [
        "Y. Boykov",
        "O. Veksler",
        "R. Zabih"
    ],
    "related_topics": [
        "Graph cuts in computer vision",
        "Approximation algorithm",
        "Minimum cut"
    ],
    "citation_count": "10,524",
    "reference_count": "47",
    "references": [
        "2121947440",
        "2104095591",
        "1997063559",
        "1977545325",
        "2113137767",
        "2620619910",
        "2121781154",
        "2913192828",
        "1554544485",
        "1649464328"
    ]
},{
    "id": "2169551590",
    "title": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images",
    "abstract": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm.",
    "date": "2001",
    "authors": [
        "Y.Y. Boykov",
        "M.-P. Jolly"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Segmentation-based object categorization",
        "Image segmentation"
    ],
    "citation_count": "6,221",
    "reference_count": "21",
    "references": [
        "2121947440",
        "2104095591",
        "2113137767",
        "1991113069",
        "1564419782",
        "2098152234",
        "2086921140",
        "2096139825",
        "1987983010",
        "2132603077"
    ]
},{
    "id": "2031342017",
    "title": "Unbiased look at dataset bias",
    "abstract": "Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue.",
    "date": "2011",
    "authors": [
        "Antonio Torralba",
        "Alexei A. Efros"
    ],
    "related_topics": [
        "Automatic identification and data capture",
        "Pascal (programming language)",
        "Data science"
    ],
    "citation_count": "1,652",
    "reference_count": "19",
    "references": [
        "2108598243",
        "2161969291",
        "2031489346",
        "2110764733",
        "1576445103",
        "2145607950",
        "2217896605",
        "2120419212",
        "1566135517",
        "2166049352"
    ]
},{
    "id": "2913932916",
    "title": "Semantic hashing",
    "abstract": "We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs ''semantic hashing'': Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set.",
    "date": "2009",
    "authors": [
        "Ruslan Salakhutdinov",
        "Geoffrey Hinton"
    ],
    "related_topics": [
        "Feature hashing",
        "Latent semantic analysis",
        "Locality-sensitive hashing"
    ],
    "citation_count": "1,096",
    "reference_count": "22",
    "references": [
        "2136922672",
        "1880262756",
        "2100495367",
        "2116064496",
        "2147152072",
        "2150102617",
        "2162006472",
        "2038276547",
        "2157364932",
        "1978394996"
    ]
},{
    "id": "2103359087",
    "title": "Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine",
    "abstract": "Straightforward application of Deep Belief Nets (DBNs) to acoustic modeling produces a rich distributed representation of speech data that is useful for recognition and yields impressive results on the speaker-independent TIMIT phone recognition task. However, the first-layer Gaussian-Bernoulli Restricted Boltzmann Machine (GRBM) has an important limitation, shared with mixtures of diagonal-covariance Gaussians: GRBMs treat different components of the acoustic input vector as conditionally independent given the hidden state. The mean-covariance restricted Boltzmann machine (mcRBM), first introduced for modeling natural images, is a much more representationally efficient and powerful way of modeling the covariance structure of speech data. Every configuration of the precision units of the mcRBM specifies a different precision matrix for the conditional distribution over the acoustic space. In this work, we use the mcRBM to learn features of speech data that serve as input into a standard DBN. The mcRBM features combined with DBNs allow us to achieve a phone error rate of 20.5%, which is superior to all published results on speaker-independent TIMIT to date.",
    "date": "2010",
    "authors": [
        "George Dahl",
        "Marc'aurelio Ranzato",
        "Abdel-rahman Mohamed",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Restricted Boltzmann machine",
        "TIMIT",
        "Word error rate"
    ],
    "citation_count": "400",
    "reference_count": "23",
    "references": [
        "2136922672",
        "1498436455",
        "1567512734",
        "137106866",
        "1983334819",
        "2161000554",
        "2161893161",
        "2083380015",
        "2131700150",
        "2110871230"
    ]
},{
    "id": "2033819227",
    "title": "Multiple view geometry in computer vision",
    "abstract": "From the Publisher: A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Recent major developments in the theory and practice of scene reconstruction are described in detail in a unified framework. The book covers the geometric principles and how to represent objects algebraically so they can be computed and applied. The authors provide comprehensive background material and explain how to apply the methods and implement the algorithms directly.",
    "date": "1999",
    "authors": [
        "Richard Hartley",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Structure from motion",
        "Epipolar geometry",
        "Computer graphics"
    ],
    "citation_count": "28,629",
    "reference_count": "0",
    "references": []
},{
    "id": "2124386111",
    "title": "Object recognition from local scale-invariant features",
    "abstract": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.",
    "date": "1999",
    "authors": [
        "D.G. Lowe"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Haar-like features",
        "Scale space"
    ],
    "citation_count": "21,469",
    "reference_count": "23",
    "references": [
        "2914885528",
        "2124087378",
        "2123977795",
        "2011891945",
        "22745672",
        "2096077837",
        "2096600681",
        "2131806657",
        "2042243448",
        "1553558465"
    ]
},{
    "id": "2154422044",
    "title": "Object class recognition by unsupervised scale-invariant learning",
    "abstract": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",
    "date": "2003",
    "authors": [
        "R. Fergus",
        "P. Perona",
        "A. Zisserman"
    ],
    "related_topics": [
        "Object model",
        "Implicit Shape Model",
        "Constellation model"
    ],
    "citation_count": "2,999",
    "reference_count": "19",
    "references": [
        "2164598857",
        "2217896605",
        "2049633694",
        "2119747362",
        "2109200236",
        "2159686933",
        "2155511848",
        "1949116567",
        "2160225842",
        "1699734612"
    ]
},{
    "id": "2012778485",
    "title": "Invariant Features from Interest Point Groups",
    "abstract": "This paper approaches the problem of \u00afnding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de\u00afned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines.",
    "date": "2002",
    "authors": [
        "Matthew Brown",
        "David G. Lowe"
    ],
    "related_topics": [
        "RANSAC",
        "Epipolar geometry",
        "Invariant (mathematics)"
    ],
    "citation_count": "1,139",
    "reference_count": "13",
    "references": [
        "2124386111",
        "2124087378",
        "2119747362",
        "2109200236",
        "2165497495",
        "2103504761",
        "1505641881",
        "2011891945",
        "22745672",
        "2005433550"
    ]
},{
    "id": "2124404372",
    "title": "Robust wide-baseline stereo from maximally stable extremal regions",
    "abstract": "Abstract The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions , is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5\u00d7), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.",
    "date": "2004",
    "authors": [
        "Jiri Matas",
        "Ondrej Chum",
        "Martin Urban",
        "Tom\u00e1s Pajdla"
    ],
    "related_topics": [
        "Maximally stable extremal regions",
        "Epipolar geometry",
        "Harris affine region detector"
    ],
    "citation_count": "7,034",
    "reference_count": "22",
    "references": [
        "2033819227",
        "2124386111",
        "1676552347",
        "2124087378",
        "2119747362",
        "2165497495",
        "2124260943",
        "1541642243",
        "2132332894",
        "2143753158"
    ]
},{
    "id": "1676552347",
    "title": "An Affine Invariant Interest Point Detector",
    "abstract": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.",
    "date": "2002",
    "authors": [
        "K. Mikolajczyk",
        "C. Schmid"
    ],
    "related_topics": [
        "Affine shape adaptation",
        "Harris affine region detector",
        "Affine transformation"
    ],
    "citation_count": "2,120",
    "reference_count": "17",
    "references": [
        "2124386111",
        "2124087378",
        "2119747362",
        "2109200236",
        "2111308925",
        "2165497495",
        "1991605728",
        "2112328181",
        "2005433550",
        "1970269179"
    ]
},{
    "id": "2124087378",
    "title": "Local grayvalue invariants for image retrieval",
    "abstract": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.",
    "date": "1997",
    "authors": [
        "C. Schmid",
        "R. Mohr"
    ],
    "related_topics": [
        "Visual Word",
        "Image retrieval",
        "Search engine indexing"
    ],
    "citation_count": "2,330",
    "reference_count": "36",
    "references": [
        "2914885528",
        "2111308925",
        "2098693229",
        "2123977795",
        "2095757522",
        "2011891945",
        "2109863423",
        "2112328181",
        "2022735534",
        "2160835070"
    ]
},{
    "id": "2111308925",
    "title": "A COMBINED CORNER AND EDGE DETECTOR",
    "abstract": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed.",
    "date": "1987",
    "authors": [
        "Christopher G. Harris",
        "Mike Stephens"
    ],
    "related_topics": [
        "Motion analysis",
        "Corner detection",
        "Interest point detection"
    ],
    "citation_count": "19,157",
    "reference_count": "6",
    "references": [
        "1639227073",
        "1756736144",
        "2063599328",
        "2048192053",
        "2039106392",
        "2997169974"
    ]
},{
    "id": "2165497495",
    "title": "Reliable feature matching across widely separated views",
    "abstract": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches.",
    "date": "2000",
    "authors": [
        "A. Baumberg"
    ],
    "related_topics": [
        "Feature extraction",
        "Affine transformation",
        "Hessian affine region detector"
    ],
    "citation_count": "913",
    "reference_count": "20",
    "references": [
        "2124386111",
        "2130103520",
        "2124087378",
        "2111308925",
        "2085261163",
        "2112328181",
        "3022352042",
        "1970269179",
        "2143753158",
        "1549739843"
    ]
},{
    "id": "1949116567",
    "title": "Unsupervised Learning of Models for Recognition",
    "abstract": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars.",
    "date": "2000",
    "authors": [
        "Markus Weber",
        "Max Welling",
        "Pietro Perona"
    ],
    "related_topics": [
        "Constellation model",
        "Unsupervised learning",
        "Cluster analysis"
    ],
    "citation_count": "947",
    "reference_count": "16",
    "references": [
        "2049633694",
        "3017143921",
        "1564419782",
        "2095757522",
        "1958762911",
        "2124722975",
        "2117138270",
        "2125791971",
        "2029727948",
        "1628541567"
    ]
},{
    "id": "2177274842",
    "title": "A performance evaluation of local descriptors",
    "abstract": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.",
    "date": "2005",
    "authors": [
        "K. Mikolajczyk",
        "C. Schmid"
    ],
    "related_topics": [
        "Principal curvature-based region detector",
        "Hessian affine region detector",
        "GLOH"
    ],
    "citation_count": "20,352",
    "reference_count": "47",
    "references": [
        "2151103935",
        "2033819227",
        "2124386111",
        "2163352848",
        "2131846894",
        "2057175746",
        "2154422044",
        "2145023731",
        "1980911747",
        "2145072179"
    ]
},{
    "id": "2131846894",
    "title": "Video Google: a text retrieval approach to object matching in videos",
    "abstract": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films.",
    "date": "2003",
    "authors": [
        "Sivic",
        "Zisserman"
    ],
    "related_topics": [
        "Visual Word",
        "Video copy detection",
        "Inverted index"
    ],
    "citation_count": "7,789",
    "reference_count": "19",
    "references": [
        "3013264884",
        "2124386111",
        "2177274842",
        "1660390307",
        "2124404372",
        "1676552347",
        "2124087378",
        "2165497495",
        "2160484851",
        "1541642243"
    ]
},{
    "id": "2104978738",
    "title": "The pyramid match kernel: discriminative classification with sets of image features",
    "abstract": "Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classification methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences epsivnerally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space. This \"pyramid match\" computation is linear in the number of features, and it implicitly finds correspondences based on the finest resolution histogram cell where a matched pair first appears. Since the kernel does not penalize the presence of extra features, it is robust to clutter. We show the kernel function is positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels. We demonstrate our algorithm on object recognition tasks and show it to be accurate and dramatically faster than current approaches",
    "date": "2005",
    "authors": [
        "K. Grauman",
        "T. Darrell"
    ],
    "related_topics": [
        "Variable kernel density estimation",
        "Radial basis function kernel",
        "String kernel"
    ],
    "citation_count": "1,993",
    "reference_count": "32",
    "references": [
        "2151103935",
        "2153635508",
        "3145128584",
        "2148603752",
        "1563088657",
        "2131846894",
        "2057175746",
        "1510073064",
        "2145072179",
        "2914885528"
    ]
},{
    "id": "2172188317",
    "title": "Scale & Affine Invariant Interest Point Detectors",
    "abstract": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix. Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point. We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching resultss the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.",
    "date": "2004",
    "authors": [
        "Krystian Mikolajczyk",
        "Cordelia Schmid"
    ],
    "related_topics": [
        "Harris affine region detector",
        "Affine shape adaptation",
        "Hessian affine region detector"
    ],
    "citation_count": "5,428",
    "reference_count": "43",
    "references": [
        "2033819227",
        "2124386111",
        "2012778485",
        "2124404372",
        "1676552347",
        "2124087378",
        "2119747362",
        "2109200236",
        "2111308925",
        "2165497495"
    ]
},{
    "id": "2147717514",
    "title": "Approximate nearest neighbors: towards removing the curse of dimensionality",
    "abstract": "We present two algorithms for the approximate nearest neighbor problem in high-dimensional spaces. For data sets of size n living in R d , the algorithms require space that is only polynomial in n and d, while achieving query times that are sub-linear in n and polynomial in d. We also show applications to other high-dimensional geometric problems, such as the approximate minimum spanning tree. The article is based on the material from the authors' STOC'98 and FOCS'01 papers. It unifies, generalizes and simplifies the results from those papers.",
    "date": "1998",
    "authors": [
        "Piotr Indyk",
        "Rajeev Motwani"
    ],
    "related_topics": [
        "Nearest neighbor search",
        "Best bin first",
        "Ball tree"
    ],
    "citation_count": "5,012",
    "reference_count": "66",
    "references": [
        "2752885492",
        "2147152072",
        "1634005169",
        "2295428206",
        "1956559956",
        "2160066518",
        "1502916507",
        "3017143921",
        "2427881153",
        "2152565070"
    ]
},{
    "id": "2162006472",
    "title": "Locality-sensitive hashing scheme based on p-stable distributions",
    "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p",
    "date": "2004",
    "authors": [
        "Mayur Datar",
        "Nicole Immorlica",
        "Piotr Indyk",
        "Vahab S. Mirrokni"
    ],
    "related_topics": [
        "Locality-sensitive hashing",
        "Dynamic perfect hashing",
        "Universal hashing"
    ],
    "citation_count": "3,252",
    "reference_count": "29",
    "references": [
        "2147717514",
        "1502916507",
        "1541459201",
        "2520931985",
        "2165533158",
        "2045533739",
        "2169351022",
        "2109034006",
        "2048779798",
        "1595303882"
    ]
},{
    "id": "2138451337",
    "title": "Eigenfaces for recognition",
    "abstract": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.",
    "date": "1990",
    "authors": [
        "Matthew Turk",
        "Alex Pentland"
    ],
    "related_topics": [
        "Eigenface",
        "Three-dimensional face recognition",
        "Face Recognition Grand Challenge"
    ],
    "citation_count": "20,172",
    "reference_count": "23",
    "references": [
        "2135463994",
        "2125848778",
        "2130259898",
        "2055712799",
        "2125999363",
        "1509703770",
        "1526492552",
        "1507699566",
        "2032361618",
        "1986450498"
    ]
},{
    "id": "2107034620",
    "title": "A Bayesian hierarchical model for learning natural scene categories",
    "abstract": "We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.",
    "date": "2005",
    "authors": [
        "L. Fei-Fei",
        "P. Perona"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Categorization",
        "Bag-of-words model in computer vision"
    ],
    "citation_count": "4,720",
    "reference_count": "19",
    "references": []
},{
    "id": "2156598602",
    "title": "Photo tourism: exploring photo collections in 3D",
    "abstract": "We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering techniques to smoothly transition between photographs, while also enabling full 3D navigation and exploration of the set of images and world geometry, along with auxiliary information such as overhead maps. Our system also makes it easy to construct photo tours of scenic or historic locations, and to annotate image details, which are automatically transferred to other relevant images. We demonstrate our system on several large personal photo collections as well as images gathered from Internet photo sharing sites.",
    "date": "2006",
    "authors": [
        "Noah Snavely",
        "Steven M. Seitz",
        "Richard Szeliski"
    ],
    "related_topics": [
        "Digital photo frame",
        "Rendering (computer graphics)",
        "Rephotography"
    ],
    "citation_count": "4,019",
    "reference_count": "43",
    "references": [
        "2151103935",
        "3029645440",
        "2033819227",
        "2131846894",
        "2110764733",
        "1980911747",
        "2141282920",
        "2119781527",
        "2063366997",
        "2085261163"
    ]
},{
    "id": "3097096317",
    "title": "Robust Real-Time Face Detection",
    "abstract": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.",
    "date": "2004",
    "authors": [
        "Paul Viola",
        "Michael J. Jones"
    ],
    "related_topics": [
        "Object-class detection",
        "Face detection",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "19,088",
    "reference_count": "21",
    "references": [
        "3124955340",
        "2128272608",
        "2217896605",
        "2149706766",
        "2115763357",
        "1975846642",
        "2124351082",
        "2159686933",
        "2155511848",
        "2101522199"
    ]
},{
    "id": "2121647436",
    "title": "Eigenfaces vs. Fisherfaces: recognition using class specific linear projection",
    "abstract": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases.",
    "date": "1997",
    "authors": [
        "P.N. Belhumeur",
        "J.P. Hespanha",
        "D.J. Kriegman"
    ],
    "related_topics": [
        "Eigenface",
        "Three-dimensional face recognition",
        "Face Recognition Grand Challenge"
    ],
    "citation_count": "16,889",
    "reference_count": "31",
    "references": [
        "2138451337",
        "2098693229",
        "2123977795",
        "2115689562",
        "3017143921",
        "2098947662",
        "2113341759",
        "2740373864",
        "2130259898",
        "2159173611"
    ]
},{
    "id": "2033419168",
    "title": "The FERET evaluation methodology for face-recognition algorithms",
    "abstract": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1,199 individuals are included in the FERET database, which is divided into development and sequestered portions of the database. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to 1) assess the state of the art, 2) identify future areas of research, and 3) measure algorithm performance.",
    "date": "2000",
    "authors": [
        "P.J. Phillips",
        "Hyeonjoon Moon",
        "S.A. Rizvi",
        "P.J. Rauss"
    ],
    "related_topics": [
        "FERET database",
        "Face Recognition Grand Challenge",
        "Facial recognition system"
    ],
    "citation_count": "6,285",
    "reference_count": "12",
    "references": [
        "2138451337",
        "2120954940",
        "1997011019",
        "2128716185",
        "2012352340",
        "2131273085",
        "1761337995",
        "2132234724",
        "3094217134",
        "2689627924"
    ]
},{
    "id": "2123921160",
    "title": "From few to many: illumination cone models for face recognition under variable lighting and pose",
    "abstract": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions.",
    "date": "2001",
    "authors": [
        "A.S. Georghiades",
        "P.N. Belhumeur",
        "D.J. Kriegman"
    ],
    "related_topics": [
        "Illumination problem",
        "Image-based modeling and rendering",
        "Generative model"
    ],
    "citation_count": "5,440",
    "reference_count": "82",
    "references": [
        "2138451337",
        "2217896605",
        "2121647436",
        "2152826865",
        "2033419168",
        "2159686933",
        "2123977795",
        "2115689562",
        "2120954940",
        "2098947662"
    ]
},{
    "id": "2137659841",
    "title": "Overview of the face recognition grand challenge",
    "abstract": "Over the last couple of years, face recognition researchers have been developing new techniques. These developments are being fueled by advances in computer vision techniques, computer design, sensor design, and interest in fielding face recognition systems. Such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over Face Recognition Vendor Test (FRVT) 2002 results. The face recognition grand challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images. The data consists of 3D scans and high resolution still imagery taken under controlled and uncontrolled conditions. This paper describes the challenge problem, data corpus, and presents baseline performance and preliminary results on natural statistics of facial imagery.",
    "date": "2005",
    "authors": [
        "P.J. Phillips",
        "P.J. Flynn",
        "T. Scruggs",
        "K.W. Bowyer",
        "Jin Chang",
        "K. Hoffman",
        "J. Marques",
        "Jaesik Min",
        "W. Worek"
    ],
    "related_topics": [
        "Face Recognition Grand Challenge",
        "Face detection",
        "Facial recognition system"
    ],
    "citation_count": "2,766",
    "reference_count": "7",
    "references": [
        "2138451337",
        "2102773363",
        "2143542740",
        "2137385871",
        "2120838001",
        "1555969862",
        "138943044"
    ]
},{
    "id": "2098693229",
    "title": "Face recognition using eigenfaces",
    "abstract": "An approach to the detection and identification of human faces is presented, and a working, near-real-time face recognition system which tracks a subject's head and then recognizes the person by comparing characteristics of the face to those of known individuals is described. This approach treats face recognition as a two-dimensional recognition problem, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. Face images are projected onto a feature space ('face space') that best encodes the variation among known face images. The face space is defined by the 'eigenfaces', which are the eigenvectors of the set of faces; they do not necessarily correspond to isolated features such as eyes, ears, and noses. The framework provides the ability to learn to recognize new faces in an unsupervised manner. >",
    "date": "1991",
    "authors": [
        "M.A. Turk",
        "A.P. Pentland"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Eigenface",
        "Face detection"
    ],
    "citation_count": "8,467",
    "reference_count": "8",
    "references": [
        "2138451337",
        "2125848778",
        "2130259898",
        "2055712799",
        "2125999363",
        "1507699566",
        "1998186877",
        "2169718527"
    ]
},{
    "id": "2125310925",
    "title": "Recovering Surface Layout from an Image",
    "abstract": "Humans have an amazing ability to instantly grasp the overall 3D structure of a scene--ground orientation, relative positions of major landmarks, etc.--even from a single image. This ability is completely missing in most popular recognition algorithms, which pretend that the world is flat and/or view it through a patch-sized peephole. Yet it seems very likely that having a grasp of this \"surface layout\" of a scene should be of great assistance for many tasks, including recognition, navigation, and novel view synthesis. In this paper, we take the first step towards constructing the surface layout, a labeling of the image intogeometric classes. Our main insight is to learn appearance-based models of these geometric classes, which coarsely describe the 3D scene orientation of each image region. Our multiple segmentation framework provides robust spatial support, allowing a wide variety of cues (e.g., color, texture, and perspective) to contribute to the confidence in each geometric label. In experiments on a large set of outdoor images, we evaluate the impact of the individual cues and design choices in our algorithm. We further demonstrate the applicability of our method to indoor images, describe potential applications, and discuss extensions to a more complete notion of surface layout.",
    "date": "2007",
    "authors": [
        "Derek Hoiem",
        "Alexei A. Efros",
        "Martial Hebert"
    ],
    "related_topics": [
        "Orientation (computer vision)",
        "Image processing",
        "GRASP"
    ],
    "citation_count": "872",
    "reference_count": "53",
    "references": [
        "2033819227",
        "2147880316",
        "2121947440",
        "1999478155",
        "2143516773",
        "1566135517",
        "2024046085",
        "2209124607",
        "2032210760",
        "1484228140"
    ]
},{
    "id": "2994340921",
    "title": "The AR face databasae",
    "abstract": "",
    "date": "1997",
    "authors": [
        "A. M. Martinez"
    ],
    "related_topics": [
        "Face (sociological concept)",
        "Computer science",
        "Computer vision"
    ],
    "citation_count": "4,771",
    "reference_count": "0",
    "references": []
},{
    "id": "2006793117",
    "title": "The CMU pose, illumination, and expression database",
    "abstract": "In the Fall of 2000, we collected a database of more than 40,000 facial images of 68 people. Using the Carnegie Mellon University 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this the CMU pose, illumination, and expression (PIE) database. We describe the imaging hardware, the collection procedure, the organization of the images, several possible uses, and how to obtain the database.",
    "date": "2003",
    "authors": [
        "T. Sim",
        "S. Baker",
        "M. Bsat"
    ],
    "related_topics": [
        "Facial recognition system",
        "Expression (mathematics)",
        "Computer vision"
    ],
    "citation_count": "2,520",
    "reference_count": "9",
    "references": [
        "2155759509",
        "2118774738",
        "2102760078",
        "2120420721",
        "2110822444",
        "2121114545",
        "2106143125",
        "2141503314",
        "2144855601"
    ]
},{
    "id": "2111993661",
    "title": "Image retrieval: Ideas, influences, and trends of the new age",
    "abstract": "We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise, it also paved the way for a large number of new techniques and systems, got many new people involved, and triggered stronger association of weakly related fields. In this article, we survey almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation, and in the process discuss the spawning of related subfields. We also discuss significant challenges involved in the adaptation of existing image retrieval techniques to build systems that can be useful in the real world. In retrospect of what has been achieved so far, we also conjecture what the future may hold for image retrieval research.",
    "date": "2008",
    "authors": [
        "Ritendra Datta",
        "Dhiraj Joshi",
        "Jia Li",
        "James Z. Wang"
    ],
    "related_topics": [
        "Content-based image retrieval",
        "Automatic image annotation",
        "Image retrieval"
    ],
    "citation_count": "4,570",
    "reference_count": "282",
    "references": [
        "1480376833",
        "2177274842",
        "2121947440",
        "2067191022",
        "2119479037",
        "2057175746",
        "2154422044",
        "1989702938",
        "2130660124",
        "1579271636"
    ]
},{
    "id": "1666447063",
    "title": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary",
    "abstract": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach.",
    "date": "2002",
    "authors": [
        "P. Duygulu",
        "Kobus Barnard",
        "J. F. G. de Freitas",
        "David A. Forsyth"
    ],
    "related_topics": [
        "Vocabulary",
        "Lexicon",
        "Machine translation"
    ],
    "citation_count": "2,198",
    "reference_count": "11",
    "references": [
        "2121947440",
        "1574901103",
        "1508960934",
        "2006969979",
        "1579838312",
        "1934863104",
        "2129765547",
        "2293605478",
        "1540386283",
        "1585814348"
    ]
},{
    "id": "1934863104",
    "title": "Learning the semantics of words and pictures",
    "abstract": "We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition.",
    "date": "2001",
    "authors": [
        "K. Barnard",
        "D. Forsyth"
    ],
    "related_topics": [
        "Visual Word",
        "Image retrieval",
        "Automatic image annotation"
    ],
    "citation_count": "768",
    "reference_count": "23",
    "references": [
        "2049633694",
        "2160066518",
        "2135705692",
        "2125101937",
        "2062270497",
        "2155099190",
        "1587328194",
        "2099251025",
        "2011549082",
        "2117086609"
    ]
},{
    "id": "2166770390",
    "title": "Object Detection Using the Statistics of Parts",
    "abstract": "In this paper we describe a trainable object detector and its instantiations for detecting faces and cars at any size, location, and pose. To cope with variation in object orientation, the detector uses multiple classifiers, each spanning a different range of orientation. Each of these classifiers determines whether the object is present at a specified size within a fixed-size image window. To find the object at any location and size, these classifiers scan the image exhaustively. Each classifier is based on the statistics of localized parts. Each part is a transform from a subset of wavelet coefficients to a discrete set of values. Such parts are designed to capture various combinations of locality in space, frequency, and orientation. In building each classifier, we gathered the class-conditional statistics of these part values from representative samples of object and non-object images. We trained each classifier to minimize classification error on the training set by using Adaboost with Confidence-Weighted Predictions (Shapire and Singer, 1999). In detection, each classifier computes the part values within the image window and looks up their associated class-conditional probabilities. The classifier then makes a decision by applying a likelihood ratio test. For efficiency, the classifier evaluates this likelihood ratio in stages. At each stage, the classifier compares the partial likelihood ratio to a threshold and makes a decision about whether to cease evaluation\u2014labeling the input as non-object\u2014or to continue further evaluation. The detector orders these stages of evaluation from a low-resolution to a high-resolution search of the image. Our trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation.",
    "date": "2004",
    "authors": [
        "Henry Schneiderman",
        "Takeo Kanade"
    ],
    "related_topics": [
        "Margin classifier",
        "Quadratic classifier",
        "Object detection"
    ],
    "citation_count": "498",
    "reference_count": "31",
    "references": [
        "2164598857",
        "2119821739",
        "3124955340",
        "2217896605",
        "2914885528",
        "2124351082",
        "1658679052",
        "2159686933",
        "2032210760",
        "2140785063"
    ]
},{
    "id": "1587328194",
    "title": "Finding Naked People",
    "abstract": "This paper demonstrates a content-based retrieval strategy that can tell whether there are naked people present in an image. No manual intervention is required. The approach combines color and texture properties to obtain an effective mask for skin regions. The skin mask is shown to be effective for a wide range of shades and colors of skin. These skin regions are then fed to a specialized grouper, which attempts to group a human figure using geometric constraints on human structure. This approach introduces a new view of object recognition, where an object model is an organized collection of grouping hints obtained from a combination of constraints on geometric properties such as the structure of individual parts, and the relationships between parts, and constraints on color and texture. The system is demonstrated to have 60% precision and 52% recall on a test set of 138 uncontrolled images of naked people, mostly obtained from the internet, and 1401 assorted control images, drawn from a wide collection of sources.",
    "date": "1996",
    "authors": [
        "Margaret M. Fleck",
        "David A. Forsyth",
        "Chris Bregler"
    ],
    "related_topics": [
        "Object model",
        "Cognitive neuroscience of visual object recognition",
        "Texture (music)"
    ],
    "citation_count": "681",
    "reference_count": "20",
    "references": [
        "2145023731",
        "2123977795",
        "2093191240",
        "2008297189",
        "2068272887",
        "2053197265",
        "2102475035",
        "1530454533",
        "2037732452",
        "2069266228"
    ]
},{
    "id": "2293605478",
    "title": "Clustering art",
    "abstract": "We extend a recently developed method (K. Barnard and D. Forsyth, 2001) for learning the semantics of image databases using text and pictures. We incorporate statistical natural language processing in order to deal with free text. We demonstrate the current system on a difficult dataset, namely 10000 images of work from the Fine Arts Museum of San Francisco. The images include line drawings, paintings, and pictures of sculpture and ceramics. Many of the images have associated free text which varies greatly from physical description to interpretation and mood. We use WordNet to provide semantic grouping information and to help disambiguate word senses, as well as emphasize the hierarchical nature of semantic relationships. This allows us to impose a natural structure on the image collection that reflects semantics to a considerable degree. Our method produces a joint probability distribution for words and picture elements. We demonstrate that this distribution can be used: (a) to provide illustrations for given captions, and (b) to generate words for images outside the training set. Results from this annotation process yield a quantitative study of our method. Finally, the annotation process can be seen as a form of object recognizer that has been learned through a partially supervised process.",
    "date": "2000",
    "authors": [
        "K. Barnard",
        "P. Duygulu",
        "D. Forsyth"
    ],
    "related_topics": [
        "WordNet",
        "Semantics",
        "Natural language"
    ],
    "citation_count": "227",
    "reference_count": "10",
    "references": [
        "2121947440",
        "2049633694",
        "2102381086",
        "1934863104",
        "2081687495",
        "2117086609",
        "2166447979",
        "2004690028",
        "1972812142",
        "1504061712"
    ]
},{
    "id": "2970081408",
    "title": "Language Change",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Adrian Beard"
    ],
    "related_topics": [
        "Language change",
        "Linguistics",
        "Psychology"
    ],
    "citation_count": "285",
    "reference_count": "0",
    "references": []
},{
    "id": "2055225264",
    "title": "PicASHOW: pictorial authority search by hyperlinks on the web.",
    "abstract": "We describe PicASHOW, a fully automated WWW image retrieval system that is based on several link-structure analyzing algorithms. Our basic premise is that a page p displays (or links to) an image when the author of p considers the image to be of value to the viewers of the page. We thus extend some well known link-based WWW page retrieval schemes to the context of image retrieval. PicASHOW\u2019s analysis of the link structure enables it to retrieve relevant images even when those are stored in files with meaningless names. The same analysis also allows it to identify image containers and image hubs. We define these as Web pages that are rich in relevant images, or from which many images are readily accessible. PicASHOW requires no image analysis whatsoever and no creation of taxonomies for preclassification of the Web\u2019s images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user query formats. It can thus be used to easily add image retrieving capabilities to standard search engines. Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers.",
    "date": "2001",
    "authors": [
        "Ronny Lempel",
        "Aya Soffer"
    ],
    "related_topics": [
        "Image retrieval",
        "Static web page",
        "Web page"
    ],
    "citation_count": "122",
    "reference_count": "18",
    "references": [
        "3013264884",
        "2138621811",
        "2006119904",
        "2008297189",
        "2079672501",
        "1987777228",
        "2089199911",
        "2099251025",
        "2117086609",
        "2140350208"
    ]
},{
    "id": "2050457084",
    "title": "Categories, Photographs & Predicaments: Exploratory Research on Representing Pictures for Access",
    "abstract": "",
    "date": "2005",
    "authors": [
        "Brian C. O'Connor",
        "Mary Keeney O'Connor"
    ],
    "related_topics": [
        "Exploratory research",
        "Applied psychology",
        "Psychology"
    ],
    "citation_count": "5",
    "reference_count": "0",
    "references": []
},{
    "id": "181417509",
    "title": "Storage and Retrieval of Feature Data for a Very Large Online Image Collection.",
    "abstract": "",
    "date": "1995",
    "authors": [
        "T. K. Rengarajan",
        "Lucien A. Dimino",
        "Dwayne Chung"
    ],
    "related_topics": [
        "Visual Word",
        "Image retrieval",
        "Automatic image annotation"
    ],
    "citation_count": "84",
    "reference_count": "0",
    "references": []
},{
    "id": "2612148268",
    "title": "Categories, photographs & predicaments : Exploratory research on representing pictures for access : Theory and practice in the organization of images and other visuo-spatial data for retrieval",
    "abstract": "",
    "date": "1998",
    "authors": [
        "B. C. O'connor",
        "M. K. O'connor"
    ],
    "related_topics": [
        "Exploratory research",
        "Spatial analysis",
        "Information retrieval"
    ],
    "citation_count": "2",
    "reference_count": "0",
    "references": []
},{
    "id": "2217896605",
    "title": "Neural network-based face detection",
    "abstract": "We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.",
    "date": "1997",
    "authors": [
        "H.A. Rowley",
        "S. Baluja",
        "T. Kanade"
    ],
    "related_topics": [
        "Face detection",
        "Object-class detection",
        "Facial recognition system"
    ],
    "citation_count": "6,472",
    "reference_count": "46",
    "references": [
        "2139212933",
        "2981264952",
        "2133671888",
        "2124351082",
        "2147800946",
        "2098947662",
        "1997011019",
        "2173629880",
        "2042371054",
        "2159173611"
    ]
},{
    "id": "2045656233",
    "title": "Bayesian Data Analysis",
    "abstract": "FUNDAMENTALS OF BAYESIAN INFERENCE Probability and Inference Single-Parameter Models Introduction to Multiparameter Models Asymptotics and Connections to Non-Bayesian Approaches Hierarchical Models FUNDAMENTALS OF BAYESIAN DATA ANALYSIS Model Checking Evaluating, Comparing, and Expanding Models Modeling Accounting for Data Collection Decision Analysis ADVANCED COMPUTATION Introduction to Bayesian Computation Basics of Markov Chain Simulation Computationally Efficient Markov Chain Simulation Modal and Distributional Approximations REGRESSION MODELS Introduction to Regression Models Hierarchical Linear Models Generalized Linear Models Models for Robust Inference Models for Missing Data NONLINEAR AND NONPARAMETRIC MODELS Parametric Nonlinear Models Basic Function Models Gaussian Process Models Finite Mixture Models Dirichlet Process Models APPENDICES A: Standard Probability Distributions B: Outline of Proofs of Asymptotic Theorems C: Computation in R and Stan Bibliographic Notes and Exercises appear at the end of each chapter.",
    "date": "1994",
    "authors": [
        "Andrew Gelman",
        "John B. Carlin",
        "Hal S. Stern",
        "David B. Dunson",
        "Aki Vehtari",
        "Donald B. Rubin"
    ],
    "related_topics": [
        "Variable-order Bayesian network",
        "Bayesian statistics",
        "Dynamic Bayesian network"
    ],
    "citation_count": "30,244",
    "reference_count": "4",
    "references": [
        "2159080219",
        "2156273867",
        "2126163471",
        "1533179050"
    ]
},{
    "id": "2130416410",
    "title": "Markov Chain Monte Carlo in Practice",
    "abstract": "INTRODUCING MARKOV CHAIN MONTE CARLO Introduction The Problem Markov Chain Monte Carlo Implementation Discussion HEPATITIS B: A CASE STUDY IN MCMC METHODS Introduction Hepatitis B Immunization Modelling Fitting a Model Using Gibbs Sampling Model Elaboration Conclusion MARKOV CHAIN CONCEPTS RELATED TO SAMPLING ALGORITHMS Markov Chains Rates of Convergence Estimation The Gibbs Sampler and Metropolis-Hastings Algorithm INTRODUCTION TO GENERAL STATE-SPACE MARKOV CHAIN THEORY Introduction Notation and Definitions Irreducibility, Recurrence, and Convergence Harris Recurrence Mixing Rates and Central Limit Theorems Regeneration Discussion FULL CONDITIONAL DISTRIBUTIONS Introduction Deriving Full Conditional Distributions Sampling from Full Conditional Distributions Discussion STRATEGIES FOR IMPROVING MCMC Introduction Reparameterization Random and Adaptive Direction Sampling Modifying the Stationary Distribution Methods Based on Continuous-Time Processes Discussion IMPLEMENTING MCMC Introduction Determining the Number of Iterations Software and Implementation Output Analysis Generic Metropolis Algorithms Discussion INFERENCE AND MONITORING CONVERGENCE Difficulties in Inference from Markov Chain Simulation The Risk of Undiagnosed Slow Convergence Multiple Sequences and Overdispersed Starting Points Monitoring Convergence Using Simulation Output Output Analysis for Inference Output Analysis for Improving Efficiency MODEL DETERMINATION USING SAMPLING-BASED METHODS Introduction Classical Approaches The Bayesian Perspective and the Bayes Factor Alternative Predictive Distributions How to Use Predictive Distributions Computational Issues An Example Discussion HYPOTHESIS TESTING AND MODEL SELECTION Introduction Uses of Bayes Factors Marginal Likelihood Estimation by Importance Sampling Marginal Likelihood Estimation Using Maximum Likelihood Application: How Many Components in a Mixture? Discussion Appendix: S-PLUS Code for the Laplace-Metropolis Estimator MODEL CHECKING AND MODEL IMPROVEMENT Introduction Model Checking Using Posterior Predictive Simulation Model Improvement via Expansion Example: Hierarchical Mixture Modelling of Reaction Times STOCHASTIC SEARCH VARIABLE SELECTION Introduction A Hierarchical Bayesian Model for Variable Selection Searching the Posterior by Gibbs Sampling Extensions Constructing Stock Portfolios With SSVS Discussion BAYESIAN MODEL COMPARISON VIA JUMP DIFFUSIONS Introduction Model Choice Jump-Diffusion Sampling Mixture Deconvolution Object Recognition Variable Selection Change-Point Identification Conclusions ESTIMATION AND OPTIMIZATION OF FUNCTIONS Non-Bayesian Applications of MCMC Monte Carlo Optimization Monte Carlo Likelihood Analysis Normalizing-Constant Families Missing Data Decision Theory Which Sampling Distribution? Importance Sampling Discussion STOCHASTIC EM: METHOD AND APPLICATION Introduction The EM Algorithm The Stochastic EM Algorithm Examples GENERALIZED LINEAR MIXED MODELS Introduction Generalized Linear Models (GLMs) Bayesian Estimation of GLMs Gibbs Sampling for GLMs Generalized Linear Mixed Models (GLMMs) Specification of Random-Effect Distributions Hyperpriors and the Estimation of Hyperparameters Some Examples Discussion HIERARCHICAL LONGITUDINAL MODELLING Introduction Clinical Background Model Detail and MCMC Implementation Results Summary and Discussion MEDICAL MONITORING Introduction Modelling Medical Monitoring Computing Posterior Distributions Forecasting Model Criticism Illustrative Application Discussion MCMC FOR NONLINEAR HIERARCHICAL MODELS Introduction Implementing MCMC Comparison of Strategies A Case Study from Pharmacokinetics-Pharmacodynamics Extensions and Discussion BAYESIAN MAPPING OF DISEASE Introduction Hypotheses and Notation Maximum Likelihood Estimation of Relative Risks Hierarchical Bayesian Model of Relative Risks Empirical Bayes Estimation of Relative Risks Fully Bayesian Estimation of Relative Risks Discussion MCMC IN IMAGE ANALYSIS Introduction The Relevance of MCMC to Image Analysis Image Models at Different Levels Methodological Innovations in MCMC Stimulated by Imaging Discussion MEASUREMENT ERROR Introduction Conditional-Independence Modelling Illustrative examples Discussion GIBBS SAMPLING METHODS IN GENETICS Introduction Standard Methods in Genetics Gibbs Sampling Approaches MCMC Maximum Likelihood Application to a Family Study of Breast Cancer Conclusions MIXTURES OF DISTRIBUTIONS: INFERENCE AND ESTIMATION Introduction The Missing Data Structure Gibbs Sampling Implementation Convergence of the Algorithm Testing for Mixtures Infinite Mixtures and Other Extensions AN ARCHAEOLOGICAL EXAMPLE: RADIOCARBON DATING Introduction Background to Radiocarbon Dating Archaeological Problems and Questions Illustrative Examples Discussion Index",
    "date": "1997",
    "authors": [
        "W.R. Gilks",
        "S. Richardson",
        "David Spiegelhalter"
    ],
    "related_topics": [
        "Gibbs sampling",
        "Slice sampling",
        "Metropolis\u2013Hastings algorithm"
    ],
    "citation_count": "11,193",
    "reference_count": "2",
    "references": [
        "2108207895",
        "2163738067"
    ]
},{
    "id": "2030536784",
    "title": "Pictorial Structures for Object Recognition",
    "abstract": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.",
    "date": "2004",
    "authors": [
        "Pedro F. Felzenszwalb",
        "Daniel P. Huttenlocher"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Object model",
        "Method"
    ],
    "citation_count": "2,810",
    "reference_count": "43",
    "references": [
        "3145128584",
        "2138451337",
        "2752885492",
        "2143516773",
        "2159080219",
        "1560013842",
        "1997063559",
        "301824129",
        "2123977795",
        "2085261163"
    ]
},{
    "id": "2147880316",
    "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data",
    "abstract": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.",
    "date": "2001",
    "authors": [
        "John D. Lafferty",
        "Andrew McCallum",
        "Fernando C. N. Pereira"
    ],
    "related_topics": [
        "Variable-order Markov model",
        "Maximum-entropy Markov model",
        "Graphical model"
    ],
    "citation_count": "15,754",
    "reference_count": "24",
    "references": [
        "2310919327",
        "3124955340",
        "1574901103",
        "2009570821",
        "2096175520",
        "1934019294",
        "1773803948",
        "2160842254",
        "3021452258",
        "2117400858"
    ]
},{
    "id": "2124351162",
    "title": "\"GrabCut\": interactive foreground extraction using iterated graph cuts",
    "abstract": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools.",
    "date": "2004",
    "authors": [
        "Carsten Rother",
        "Vladimir Kolmogorov",
        "Andrew Blake"
    ],
    "related_topics": [
        "GrabCut",
        "Image segmentation",
        "Simple interactive object extraction"
    ],
    "citation_count": "6,950",
    "reference_count": "16",
    "references": [
        "2104095591",
        "2169551590",
        "2049633694",
        "2101309634",
        "2134820502",
        "2077786999",
        "2103917701",
        "2740373864",
        "2103334940",
        "1785730614"
    ]
},{
    "id": "2024046085",
    "title": "Additive logistic regression: a statistical view of boosting (With discussion and a rejoinder by the authors)",
    "abstract": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications.",
    "date": "2000",
    "authors": [
        "Jerome Friedman",
        "Trevor Hastie",
        "Robert Tibshirani"
    ],
    "related_topics": [
        "BrownBoost",
        "Gradient boosting",
        "Boosting (machine learning)"
    ],
    "citation_count": "8,451",
    "reference_count": "6",
    "references": [
        "1678356000",
        "2102201073",
        "1540007258",
        "2099968818",
        "1881647329",
        "2141518341"
    ]
},{
    "id": "2168002178",
    "title": "Shape matching and object recognition using low distortion correspondences",
    "abstract": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces.",
    "date": "2005",
    "authors": [
        "A.C. Berg",
        "T.L. Berg",
        "J. Malik"
    ],
    "related_topics": [
        "Caltech 101",
        "k-nearest neighbors algorithm",
        "Thin plate spline"
    ],
    "citation_count": "1,117",
    "reference_count": "33",
    "references": [
        "2151103935",
        "3097096317",
        "2124386111",
        "2177274842",
        "2154422044",
        "2124087378",
        "2119823327",
        "2155511848",
        "2101522199",
        "2295106276"
    ]
},{
    "id": "1484228140",
    "title": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons",
    "abstract": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions.",
    "date": "2001",
    "authors": [
        "Thomas Leung",
        "Jitendra Malik"
    ],
    "related_topics": [
        "Texton",
        "Visual appearance",
        "Texture synthesis"
    ],
    "citation_count": "2,043",
    "reference_count": "44",
    "references": [
        "2170120409",
        "2117812871",
        "2138451337",
        "2130416410",
        "1997063559",
        "1634005169",
        "2116013899",
        "1481646516",
        "2123977795",
        "3017143921"
    ]
},{
    "id": "3035018050",
    "title": "Early Detection and Assessment of Covid-19",
    "abstract": "Background: Since the Covid-19 global pandemic emerged, developing countries have been facing multiple challenges over its diagnosis. We aimed to establish a relationship between the signs and symptoms of COVID-19 for early detection and assessment to reduce the transmission rate of SARS-Cov-2. Methods: We collected published data on the clinical features of Covid-19 retrospectively and categorized them into physical and blood biomarkers. Common features were assigned scores by the Borg scoring method with slight modifications and were incorporated into a newly-developed Hashmi-Asif Covid-19 assessment Chart. Correlations between signs and symptoms with the development of Covid-19 was assessed by Pearson correlation and Spearman Correlation coefficient (rho). Linear regression analysis was employed to assess the highest correlating features. The frequency of signs and symptoms in developing Covid-19 was assessed through Chi-square test two tailed with Cramer's V strength. Changes in signs and symptoms were incorporated into a chart that consisted of four tiers representing disease stages. Results: Data from 10,172 Covid-19 laboratory confirmed cases showed a correlation with Fever in 43.9% (P = 0.000) cases, cough 54.08% and dry mucus 25.68% equally significant (P = 0.000), Hyperemic pharyngeal mucus membrane 17.92% (P = 0.005), leukopenia 28.11% (P = 0.000), lymphopenia 64.35% (P = 0.000), thrombopenia 35.49% (P = 0.000), elevated Alanine aminotransferase 50.02% (P = 0.000), and Aspartate aminotransferase 34.49% (P = 0.000). The chart exhibited a maximum scoring of 39. Normal tier scoring was \u2264 12/39, mild state scoring was 13-22/39, and star values scoring was \u22657/15; this latter category on the chart means Covid-19 is progressing and quarantine should be adopted. Moderate stage scored 23-33 and severe scored 34-39 in the chart. Conclusion: The Hashmi-Asif Covid-19 Chart is significant in assessing subclinical and clinical stages of Covid-19 to reduce the transmission rate.",
    "date": "2020",
    "authors": [
        "Hafiz Abdul Sattar Hashmi",
        "Hafiz Muhammad Asif"
    ],
    "related_topics": [
        "Chart",
        "Subclinical infection",
        "Spearman's rank correlation coefficient"
    ],
    "citation_count": "8",
    "reference_count": "39",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3003668884",
        "3003465021",
        "3009912996",
        "3008696669",
        "3008818676",
        "3016535995",
        "3012747666"
    ]
},{
    "id": "3037451072",
    "title": "Analysis of Risk Perceptions and Related Factors Concerning COVID-19 Epidemic in Chongqing, China.",
    "abstract": "To assess perceptions of risk and related factors concerning COVID-19 epidemic among residents in Chongqing city, China. With convenience sampling, a web questionnaire survey was conducted among 476 residents living in Chongqing on February 13rd to 14th in 2020, when citizens just started to get back to work. Residents\u2019 estimated perceived risks were (4.63\u2009\u00b1\u20090.57), (4.19\u2009\u00b1\u20090.76), (3.23\u2009\u00b1\u20090.91) and (2.29\u2009\u00b1\u20090.96) for the infectivity, pathogenicity, lethality and self-rated infection possibility of COVID-19, respectively. Females (OR\u2009=\u20094.234), people with income\u2009\u2265\u20092000 yuan (2000\u20134999 yuan: OR\u2009=\u20095.052, 5000\u20139999 yuan: OR\u2009=\u20094.301,\u2009\u2265\u200910,000 yuan: OR\u2009=\u200923.459), the married status (OR\u2009=\u20091.811), the divorced status, widows or widowers (OR\u2009=\u20093.038), people living with families including children (OR\u2009=\u20095.085) or chronic patients (OR\u2009=\u20092.423) had a higher perceived risk level, as well as people who used free media websites (OR\u2009=\u20091.756), community workers (OR\u2009=\u20094.064) or community information platforms (OR\u2009=\u20092.235) as main media information sources. The perceived risk increased by 4.9% for every one-year increase of age. People who used WeChat contacts (OR\u2009=\u20090.196) as the main media information source, reported a lower perceived risk. Residents reported a high level of risk perception towards COVID-19 in Chongqing and it was impacted by the population demographic characteristics. Media information sources, including community information platforms and community workers may cause the increase of public risk perceptions.",
    "date": "2021",
    "authors": [
        "Shan He",
        "Siyu Chen",
        "Lingna Kong",
        "Weiwei Liu"
    ],
    "related_topics": [
        "Population",
        "Risk perception",
        "Questionnaire"
    ],
    "citation_count": "15",
    "reference_count": "15",
    "references": [
        "3001118548",
        "3001897055",
        "3003668884",
        "3001465255",
        "3008818676",
        "2792024998",
        "3016902371",
        "3022459584",
        "2091069417",
        "3134923022"
    ]
},{
    "id": "3034593359",
    "title": "Epidemiological and Clinical Characteristics of Cases During the Early Phase of COVID-19 Pandemic: A Systematic Review and Meta-Analysis",
    "abstract": "Background: On 29th December 2019, a cluster of cases displaying the symptoms of a \"pneumonia of unknown cause\" was identified in Wuhan, Hubei province of China. This systematic review and meta-analysis aims to review the epidemiological and clinical characteristics of COVID-19 cases in the early phase of the COVID-19 pandemic. Methods: The search strategy involved peer-reviewed studies published between 1st January and 11th February 2020 in Pubmed, Google scholar and China Knowledge Resource Integrated database. Publications identified were screened for their title and abstracts according to the eligibility criteria, and further shortlisted by full-text screening. Three independent reviewers extracted data from these studies, and studies were assessed for potential risk of bias. Studies comprising non-overlapping patient populations, were included for qualitative and quantitative synthesis of results. Pooled prevalence with 95% confidence intervals were calculated for patient characteristics. Results: A total of 29 publications were selected after full-text review. This comprised of 18 case reports, three case series and eight cross-sectional studies on patients admitted from mid-December of 2019 to early February of 2020. A total of 533 adult patients with pooled median age of 56 (95% CI: 49-57) and a pooled prevalence of male of 60% (95% CI: 52-68%) were admitted to hospital at a pooled median of 7 days (95% CI: 7-7) post-onset of symptoms. The most common symptoms at admission were fever, cough and fatigue, with a pooled prevalence of 90% (95% CI: 81-97%), 58% (95% CI: 47-68%), and 50% (95% CI: 29-71%), respectively. Myalgia, shortness of breath, headache, diarrhea and sore throat were less common with pooled prevalence of 27% (95% CI: 20-36%), 25% (95% CI: 15-35%), 10% (95% CI: 7-13%), 8% (95% CI: 5-13%), and 7% (95% CI: 1-15%), respectively. ICU patients had a higher proportion of shortness of breath at presentation, as well as pre-existing hypertension, cardiovascular disease and COPD, compared to non-ICU patients in 2 studies (n = 179). Conclusion: This study highlights the key epidemiological and clinical features of COVID-19 cases during the early phase of the COVID-19 pandemic.",
    "date": "2020",
    "authors": [
        "Jiayun Koh",
        "Shimoni Urvish Shah",
        "Pearleen Ee Yong Chua",
        "Hao Gui",
        "Junxiong Pang"
    ],
    "related_topics": [
        "Epidemiology",
        "Meta-analysis",
        "Sore throat"
    ],
    "citation_count": "22",
    "reference_count": "66",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3008028633",
        "3002539152",
        "3001195213",
        "3003465021"
    ]
},{
    "id": "3033301213",
    "title": "Does Early Childhood Vaccination Protect Against COVID-19?",
    "abstract": "The coronavirus disease 2019 (COVID-19) is an on-going pandemic caused by the SARS-coronavirus-2 (SARS-CoV-2) which targets the respiratory system of humans. The published data show that children, unlike adults, are less susceptible to contracting the disease. This article aims at understanding why children constitute a minor group among hospitalized COVID-19 patients. Here, we hypothesize that the measles, mumps, and rubella (MMR) vaccine could provide a broad neutralizing antibody against numbers of diseases, including COVID-19. Our hypothesis is based on the 30 amino acid sequence homology between the SARS-CoV-2 Spike (S) glycoprotein (PDB: 6VSB) of both the measles virus fusion (F1) glycoprotein (PDB: 5YXW_B) and the rubella virus envelope (E1) glycoprotein (PDB: 4ADG_A). Computational analysis of the homologous region detected the sequence as antigenic epitopes in both measles and rubella. Therefore, we believe that humoral immunity, created through the MMR vaccination, provides children with advantageous protection against COVID-19 as well, however, an experimental analysis is required.",
    "date": "2020",
    "authors": [
        "Karzan R Sidiq",
        "Dana Khdr Sabir",
        "Shakhawan M Ali",
        "Rimantas Kodzius"
    ],
    "related_topics": [
        "Rubella",
        "Rubella virus",
        "Measles virus"
    ],
    "citation_count": "16",
    "reference_count": "29",
    "references": [
        "3004318991",
        "3003217347",
        "3008818676",
        "3007643904",
        "3011242477",
        "3010819577",
        "3012310845",
        "3004348779",
        "3035011439",
        "3004896487"
    ]
},{
    "id": "3021916232",
    "title": "Knowledge, awareness and practice of health care professionals amid sars-cov-2, corona virus disease outbreak",
    "abstract": "Objective: To assess the knowledge, awareness and practice level of health care workers towards Corona Virus disease - 2019 (COVID-19). Methods: A cross sectional study was conducted by administering a well-structured questionnaire comprising of three sections including knowledge, attitude and practice amongst health care professionals in various hospitals and clinics, over a duration of two months \u2018Feb-March\u2019 2020. The data from 810 participants were collected manually as well as through online survey registered on www.surveys.google.com, using a validated questionnaire. The questionnaire comprised of three sections assessing knowledge, awareness and practice of participants. The descriptive analysis was carried out for demographics and dependent variables with statistical program for social sciences. Spearman test was used to detect any relationship between the health care professional response with respect to their gender and level of education. A p-value of < 0.05 was considered statistically significant. Results: More than half (57.2%) of the health care professionals were working in a hospital setting. Fifty two percent of health care professionals had awareness and 72% were practicing adequate measures to combat COVID-19. The majority (81.9%) believed that the sign and symptoms are similar to a common flu and the main strata of population that could be affected by COVID-19 are elderly (79%). Seventy three percent of participants did not attend any lecture, workshop or seminar on COVID-19 for awareness purpose. Sixty seven percent of health care professionals were practicing universal precaution for infection control and 57.4% were using sodium hypochlorite as a surface disinfectant in dental surgeries. There was no significant relationship (p > 0.05) between the health care professionals\u2019 responses with gender and their education level. Conclusion: The study suggests that the vast majority of the health care professionals have adequate knowledge and awareness related to COVID-19. However some aspects of practice of health care professionals were found to be deficient including, following CDC guidelines during patient care, acquiring verified knowledge related to COVID-19, disinfection protocol and the use of N-95 mask. Mandatory Continued professional development programs including lectures and workshops on COVID-19 for all health care professionals are the need of the hour, to manage the pandemic and limiting the morbidity and mortality related to it. doi: https://doi.org/10.12669/pjms.36.COVID19-S4.2704 How to cite this:Ahmed N, Shakoor M, Vohra F, Abduljabbar T, Mariam Q, Rehman MA. Knowledge, Awareness and Practice of Health care Professionals amid SARS-CoV-2, Corona Virus Disease Outbreak. Pak J Med Sci. 2020;36(COVID19-S4):COVID19-S49-S56.  doi: https://doi.org/10.12669/pjms.36.COVID19-S4.2704 This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.",
    "date": "2020",
    "authors": [
        "Naseer Ahmed",
        "Maria Shakoor",
        "Fahim Vohra",
        "Tariq Abduljabbar",
        "Quratulain Mariam",
        "Mariam Abdul Rehman"
    ],
    "related_topics": [
        "Health care",
        "Population",
        "Universal precautions"
    ],
    "citation_count": "15",
    "reference_count": "22",
    "references": [
        "3008827533",
        "3009885589",
        "3008028633",
        "3008696669",
        "3008818676",
        "3006645647",
        "3011176674",
        "3009607814",
        "3011802905",
        "3005798348"
    ]
},{
    "id": "3031029566",
    "title": "Identification of RT-PCR-Negative Asymptomatic COVID-19 Patients via Serological Testing",
    "abstract": "Asymptomatic individuals with coronavirus disease (COVID-19) have been identified via nucleic acid testing for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); however, the epidemiologic characteristics and viral shedding pattern of asymptomatic patients remain largely unknown. In this study, serological testing was applied when identifying nine asymptomatic cases of COVID-19 who showed persistent negative RT-PCR test results for SARS-CoV-2 nucleic acid and no symptoms of COVID-19. Two asymptomatic cases were presumed to be index patients who had cleared the virus when their close contacts developed symptoms of COVID-19. Three of the asymptomatic cases were local individuals who spontaneously recovered before their presumed index patients developed symptoms of COVID-19. This report presents the epidemiologic and clinical characteristics of asymptomatic individuals with SARS-CoV-2 infection that were undetected on RT-PCR tests in previous epidemiologic investigations probably due to the transient viral shedding duration.",
    "date": "2020",
    "authors": [
        "Jinru Wu",
        "Xinyi Liu",
        "Dan Zhou",
        "Guangqian Qiu",
        "Miao Dai",
        "Qingting Yang",
        "Zhonghui Pan",
        "Ning Zhou",
        "Pa Wu"
    ],
    "related_topics": [
        "Asymptomatic",
        "Viral shedding",
        "Coronavirus"
    ],
    "citation_count": "6",
    "reference_count": "19",
    "references": [
        "3002539152",
        "3006961006",
        "3008696669",
        "3008818676",
        "3015571324",
        "3008874180",
        "3010781325",
        "3035011439",
        "3015792206",
        "3012188173"
    ]
},{
    "id": "3037552531",
    "title": "Analysis of clinical features and early warning signs in patients with severe COVID-19: A retrospective cohort study.",
    "abstract": "Coronavirus disease 2019 (COVID-19) was first identified in Wuhan, China, in December 2019. Although previous studies have described the clinical aspects of COVID-19, few studies have focused on the early detection of severe COVID-19. Therefore, this study aimed to identify the predictors of severe COVID-19 and to compare clinical features between patients with severe COVID-19 and those with less severe COVID-19. Patients admitted to designated hospital in the Henan Province of China who were either discharged or died prior to February 15, 2020 were enrolled retrospectively. Additionally, patients who underwent at least one of the following treatments were assigned to the severe group: continuous renal replacement therapy, high-flow oxygen absorption, noninvasive and invasive mechanical ventilation, or extracorporeal membrane oxygenation. The remaining patients were assigned to the non-severe group. Demographic information, initial symptoms, and first visit examination results were collected from the electronic medical records and compared between the groups. Multivariate logistic regression analysis was performed to determine the predictors of severe COVID-19. A receiver operating characteristic curve was used to identify a threshold for each predictor. Altogether,104 patients were enrolled in our study with 30 and 74 patients in the severe and non-severe groups, respectively. Multivariate logistic analysis indicated that patients aged \u226563 years (odds ratio = 41.0; 95% CI: 2.8, 592.4), with an absolute lymphocyte value of \u22641.02\u00d7109/L (odds ratio = 6.1; 95% CI = 1.5, 25.2) and a C-reactive protein level of \u226565.08mg/L (odds ratio = 8.9; 95% CI = 1.0, 74.2) were at a higher risk of severe illness. Thus, our results could be helpful in the early detection of patients at risk for severe illness, enabling the implementation of effective interventions and likely lowering the morbidity of COVID-19 patients.",
    "date": "2020",
    "authors": [
        "Xinkui Liu",
        "Xinpei Yue",
        "Furong Liu",
        "Le Wei",
        "Yuntian Chu",
        "Honghong Bao",
        "Yichao Dong",
        "Wenjie Cheng",
        "Linpeng Yang"
    ],
    "related_topics": [
        "Odds ratio",
        "Retrospective cohort study",
        "Predictive value of tests"
    ],
    "citation_count": "4",
    "reference_count": "23",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3009885589",
        "3004280078",
        "3008818676",
        "3007814559",
        "3009976289",
        "2131262274",
        "3009859788"
    ]
},{
    "id": "3037851904",
    "title": "Could urinary ACE2 protein level help identify individuals susceptible to SARS-CoV-2 infection and complication?",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Xiaotian Ni",
        "Changqing Sun",
        "Yaping Tian",
        "Yanjie Huang",
        "Tongqing Gong",
        "Lan Song",
        "Xing Yang",
        "Kai Li",
        "Nairen Zheng",
        "Jianping Wang",
        "Hongxing Wu",
        "Ruoxian Zhang",
        "Yi Wang",
        "Guangshun Wang",
        "Jun Qin"
    ],
    "related_topics": [
        "Complication",
        "Virology",
        "Urinary system"
    ],
    "citation_count": "1",
    "reference_count": "5",
    "references": [
        "3008827533",
        "3004280078",
        "3008818676",
        "2601317354",
        "2946740876"
    ]
},{
    "id": "2102634410",
    "title": "Fleischner Society: Glossary of Terms for Thoracic Imaging",
    "abstract": "Members of the Fleischner Society compiled a glossary of terms for thoracic imaging that replaces previous glossaries published in 1984 and 1996 for thoracic radiography and computed tomography (CT), respectively. The need to update the previous versions came from the recognition that new words have emerged, others have become obsolete, and the meaning of some terms has changed. Brief descriptions of some diseases are included, and pictorial examples (chest radiographs and CT scans) are provided for the majority of terms.",
    "date": "2008",
    "authors": [
        "David M Hansell",
        "Alexander A Bankier",
        "Heber MacMahon",
        "Theresa C McLoud",
        "Nestor L M\u00fcller",
        "Jacques Remy"
    ],
    "related_topics": [
        "Glossary",
        "Radiography",
        "Thorax"
    ],
    "citation_count": "2,981",
    "reference_count": "134",
    "references": [
        "2416914730",
        "2626588662",
        "2017898137",
        "1924766221",
        "2121350896",
        "2041775285",
        "2107051779",
        "2157678780",
        "2114857071",
        "2155323443"
    ]
},{
    "id": "2800783955",
    "title": "Radiographic and CT Features of Viral Pneumonia.",
    "abstract": "Viruses are the most common causes of respiratory infection. The imaging findings of viral pneumonia are diverse and overlap with those of other nonviral infectious and inflammatory conditions. However, identification of the underlying viral pathogens may not always be easy. There are a number of indicators for identifying viral pathogens on the basis of imaging patterns, which are associated with the pathogenesis of viral infections. Viruses in the same viral family share a similar pathogenesis of pneumonia, and the imaging patterns have distinguishable characteristics. Although not all cases manifest with typical patterns, most typical imaging patterns of viral pneumonia can be classified according to viral families. Although a definite diagnosis cannot be achieved on the basis of imaging features alone, recognition of viral pneumonia patterns may aid in differentiating viral pathogens, thus reducing the use of antibiotics. Recently, new viruses associated with recent outbreaks including human metapneumovirus, severe acute respiratory syndrome coronavirus, and Middle East respiratory syndrome coronavirus have been discovered. The imaging findings of these emerging pathogens have been described in a few recent studies. This review focuses on the radiographic and computed tomographic patterns of viral pneumonia caused by different pathogens, including new pathogens. Clinical characteristics that could affect imaging, such as patient age and immune status, seasonal variation and community outbreaks, and pathogenesis, are also discussed. The first goal of this review is to indicate that there are imaging features that should raise the possibility of viral infections. Second, to help radiologists differentiate viral infections, viruses in the same viridae that have similar pathogenesis and can have similar imaging characteristics are shown. By considering both the clinical and radiologic characteristics, radiologists can suggest the diagnosis of viral pneumonia. \u00a9RSNA, 2018.",
    "date": "2018",
    "authors": [
        "Hyun Jung Koo",
        "Soyeoun Lim",
        "Jooae Choe",
        "Sang Ho Choi",
        "Heungsup Sung",
        "Kyung Hyun Do"
    ],
    "related_topics": [
        "Viral pneumonia",
        "Pneumonia (non-human)",
        "Respiratory infection"
    ],
    "citation_count": "349",
    "reference_count": "0",
    "references": []
},{
    "id": "3004802901",
    "title": "CT Manifestations of Two Cases of 2019 Novel Coronavirus (2019-nCoV) Pneumonia.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Yicheng Fang",
        "Huangqi Zhang",
        "Yunyu Xu",
        "Jicheng Xie",
        "Peipei Pang",
        "Wenbin Ji"
    ],
    "related_topics": [
        "Pneumonia",
        "Medicine",
        "Pathology"
    ],
    "citation_count": "189",
    "reference_count": "0",
    "references": []
},{
    "id": "2056155046",
    "title": "Severe Acute Respiratory Syndrome: Temporal Lung Changes at Thin-Section CT in 30 Patients",
    "abstract": "PURPOSE: To evaluate lung abnormalities on serial thin-section computed tomographic (CT) scans in patients with severe acute respiratory syndrome (SARS) during acute and convalescent periods. MATERIALS AND METHODS: Serial thin-section CT scans in 30 patients (17 men, aged 42.5 years \u00b1 12.2 [SD]) with SARS were reviewed by two radiologists together for predominant patterns of lung abnormalities: ground-glass opacities, ground-glass opacities with superimposed linear opacities, consolidation, reticular pattern, and mixed pattern (consolidation, ground-glass opacities, and reticular pattern). Scans were classified according to duration in weeks after symptom onset. Longitudinal changes of specific abnormalities were documented in 17 patients with serial scans obtained during 3 weeks. Each lung was divided into three zones; each zone was evaluated for percentage of lung involvement. Summation of scores from all six lung zones provided overall CT score (maximal CT score, 24). RESULTS: Median CT scores increase...",
    "date": "2004",
    "authors": [
        "Gaik C. Ooi",
        "Pek L. Khong",
        "Nestor L. M\u00fcller",
        "Wai C. Yiu",
        "Lin J. Zhou",
        "James C. M. Ho",
        "Bing Lam",
        "Savvas Nicolaou",
        "Kenneth W. T. Tsang"
    ],
    "related_topics": [
        "Zones of the lung",
        "Respiratory disease",
        "Lung"
    ],
    "citation_count": "262",
    "reference_count": "17",
    "references": [
        "2025170735",
        "2131262274",
        "2125251240",
        "1971054351",
        "1976741900",
        "2151996610",
        "2119467724",
        "2099918622",
        "2098293966",
        "2097858003"
    ]
},{
    "id": "3005272159",
    "title": "Chest CT Findings in 2019 Novel Coronavirus (2019-nCoV) Infections from Wuhan, China: Key Points for the Radiologist.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Jeffrey P Kanne"
    ],
    "related_topics": [
        "Medicine",
        "Radiology",
        "2019-20 coronavirus outbreak"
    ],
    "citation_count": "487",
    "reference_count": "15",
    "references": [
        "3001118548",
        "3002539152",
        "2903899730",
        "2306794997",
        "2103118479",
        "2111742711",
        "2056155046",
        "3135910874",
        "3024264813",
        "3009749892"
    ]
},{
    "id": "2112136274",
    "title": "Middle East Respiratory Syndrome Coronavirus (MERS-CoV) Infection: Chest CT Findings",
    "abstract": "OBJECTIVE. The purpose of this study was to describe the chest CT findings in seven patients with Middle East respiratory syndrome coronavirus (MERS-CoV) infection. CONCLUSION. The most common CT finding in hospitalized patients with MERS-CoV infection is that of bilateral predominantly subpleural and basilar airspace changes, with more extensive ground-glass opacities than consolidation. The subpleural and peribronchovascular predilection of the abnormalities is suggestive of an organizing pneumonia pattern.",
    "date": "2014",
    "authors": [
        "Amr M. Ajlan",
        "Rayan A. Ahyad",
        "Lamia Ghazi Jamjoom",
        "Ahmed Alharthy",
        "Tariq A. Madani"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Coronavirus",
        "Internal medicine"
    ],
    "citation_count": "256",
    "reference_count": "20",
    "references": [
        "2166867592",
        "2107053896",
        "2006434809",
        "2149661971",
        "1703839189",
        "2045002682",
        "1852588318",
        "2109520345",
        "2119837294",
        "2049975503"
    ]
},{
    "id": "3001465255",
    "title": "A novel coronavirus outbreak of global health concern.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Chen Wang",
        "Peter W Horby",
        "Frederick G Hayden",
        "George F Gao"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Outbreak"
    ],
    "citation_count": "4,041",
    "reference_count": "6",
    "references": [
        "3001118548",
        "3002539152",
        "2006434809",
        "2141877163",
        "2162112824",
        "2156614913"
    ]
},{
    "id": "3001456238",
    "title": "Emerging coronaviruses: Genome structure, replication, and pathogenesis.",
    "abstract": "The recent emergence of a novel coronavirus (2019-nCoV), which is causing an outbreak of unusual viral pneumonia in patients in Wuhan, a central city in China, is another warning of the risk of CoVs posed to public health. In this minireview, we provide a brief introduction of the general features of CoVs and describe diseases caused by different CoVs in humans and animals. This review will help understand the biology and potential risk of CoVs that exist in richness in wildlife such as bats.",
    "date": "2020",
    "authors": [
        "Yu Chen",
        "Qianyun Liu",
        "Deyin Guo"
    ],
    "related_topics": [
        "Coronavirus",
        "Virus classification",
        "Outbreak"
    ],
    "citation_count": "1,935",
    "reference_count": "70",
    "references": [
        "2903899730",
        "2470646526",
        "2306794997",
        "1993577573",
        "311927316",
        "2046153984",
        "2105637133",
        "2794573360",
        "2148822770",
        "2017248106"
    ]
},{
    "id": "3004668429",
    "title": "Emerging 2019 Novel Coronavirus (2019-nCoV) Pneumonia.",
    "abstract": "BackgroundThe chest CT findings of patients with 2019 Novel Coronavirus (2019-nCoV) pneumonia have not previously been described in detail.PurposeTo investigate the clinical, laboratory, and imaging findings of emerging 2019-nCoV pneumonia in humans.Materials and MethodsFifty-one patients (25 men and 26 women; age range 16-76 years) with laboratory-confirmed 2019-nCoV infection by using real-time reverse transcription polymerase chain reaction underwent thin-section CT. The imaging findings, clinical data, and laboratory data were evaluated.ResultsFifty of 51 patients (98%) had a history of contact with individuals from the endemic center in Wuhan, China. Fever (49 of 51, 96%) and cough (24 of 51, 47%) were the most common symptoms. Most patients had a normal white blood cell count (37 of 51, 73%), neutrophil count (44 of 51, 86%), and either normal (17 of 51, 35%) or reduced (33 of 51, 65%) lymphocyte count. CT images showed pure ground-glass opacity (GGO) in 39 of 51 (77%) patients and GGO with reticular and/or interlobular septal thickening in 38 of 51 (75%) patients. GGO with consolidation was present in 30 of 51 (59%) patients, and pure consolidation was present in 28 of 51 (55%) patients. Forty-four of 51 (86%) patients had bilateral lung involvement, while 41 of 51 (80%) involved the posterior part of the lungs and 44 of 51 (86%) were peripheral. There were more consolidated lung lesions in patients 5 days or more from disease onset to CT scan versus 4 days or fewer (431 of 712 lesions vs 129 of 612 lesions; P < .001). Patients older than 50 years had more consolidated lung lesions than did those aged 50 years or younger (212 of 470 vs 198 of 854; P < .001). Follow-up CT in 13 patients showed improvement in seven (54%) patients and progression in four (31%) patients.ConclusionPatients with fever and/or cough and with conspicuous ground-glass opacity lesions in the peripheral and posterior lungs on CT images, combined with normal or decreased white blood cells and a history of epidemic exposure, are highly suspected of having 2019 Novel Coronavirus (2019-nCoV) pneumonia.\u00a9 RSNA, 2020.",
    "date": "2020",
    "authors": [
        "Fengxiang Song",
        "Nannan Shi",
        "Fei Shan",
        "Zhiyong Zhang",
        "Jie Shen",
        "Hongzhou Lu",
        "Yun Ling",
        "Yebin Jiang",
        "Yuxin Shi"
    ],
    "related_topics": [
        "Pneumonia",
        "Absolute neutrophil count",
        "Lung"
    ],
    "citation_count": "902",
    "reference_count": "10",
    "references": [
        "3002108456",
        "2999409984",
        "1993577573",
        "3003901880",
        "2800783955",
        "2128312233",
        "2015323375",
        "2789752210",
        "1922522683",
        "1997020575"
    ]
},{
    "id": "2786098272",
    "title": "Serological Evidence of Bat SARS-Related Coronavirus Infection in Humans, China",
    "abstract": "In our previous works, we have reported genetically diverse SARS-related coronaviruses (SARSr-CoV) in a single bat cave, Yunnan province, China, and suggested that some SARSr-CoVs may have high potential to infect humans without the necessity for an intermediate host. In this report, we developed a specific ELISA based on the nucleocapsid protein of a SARSr-CoV strain and detected its antibody in humans who are highly exposed to bat populations. From 218 human serum samples, 6 were positive against the nucleocapsid protein by ELISA and further confirmed by Western blot. For the first time, we demonstrated the SARSr-CoV had spillover to humans, although did not cause clinical diseases.",
    "date": "2018",
    "authors": [
        "Ning Wang",
        "Shi-Yue Li",
        "Xing-Lou Yang",
        "Hui-Min Huang",
        "Yu-Ji Zhang",
        "Hua Guo",
        "Chu-Ming Luo",
        "Maureen Miller",
        "Guangjian Zhu",
        "Aleksei A. Chmura",
        "Emily Hagan",
        "Ji-Hua Zhou",
        "Yun-Zhi Zhang",
        "Lin-Fa Wang",
        "Peter Daszak",
        "Zheng-Li Shi"
    ],
    "related_topics": [
        "Coronavirus",
        "Serology",
        "Intermediate host"
    ],
    "citation_count": "165",
    "reference_count": "15",
    "references": [
        "2104548316",
        "2025170735",
        "1993577573",
        "2103503670",
        "2298153446",
        "2134061616",
        "2126707939",
        "2285897784",
        "2200668708",
        "2151461700"
    ]
},{
    "id": "2021442163",
    "title": "Organ distribution of severe acute respiratory syndrome (SARS) associated coronavirus (SARS-CoV) in SARS patients: implications for pathogenesis and virus transmission pathways.",
    "abstract": "We previously identified the major pathological changes in the respiratory and immune systems of patients who died of severe acute respiratory syndrome (SARS) but gained little information on the organ distribution of SARS-associated coronavirus (SARS-CoV). In the present study, we used a murine monoclonal antibody specific for SARS-CoV nucleoprotein, and probes specific for a SARS-CoV RNA polymerase gene fragment, for immunohistochemistry and in situ hybridization, respectively, to detect SARS-CoV systematically in tissues from patients who died of SARS. SARS-CoV was found in lung, trachea/bronchus, stomach, small intestine, distal convoluted renal tubule, sweat gland, parathyroid, pituitary, pancreas, adrenal gland, liver and cerebrum, but was not detected in oesophagus, spleen, lymph node, bone marrow, heart, aorta, cerebellum, thyroid, testis, ovary, uterus or muscle. These results suggest that, in addition to the respiratory system, the gastrointestinal tract and other organs with detectable SARS-CoV may also be targets of SARS-CoV infection. The pathological changes in these organs may be caused directly by the cytopathic effect mediated by local replication of the SARS-CoV; or indirectly as a result of systemic responses to respiratory failure or the harmful immune response induced by viral infection. In addition to viral spread through a respiratory route, SARS-CoV in the intestinal tract, kidney and sweat glands may be excreted via faeces, urine and sweat, thereby leading to virus transmission. This study provides important information for understanding the pathogenesis of SARS-CoV infection and sheds light on possible virus transmission pathways. This data will be useful for designing new strategies for prevention and treatment of SARS.",
    "date": "2004",
    "authors": [
        "Yanqing Ding",
        "Li He",
        "Qingling Zhang",
        "Zhongxi Huang",
        "Xiaoyan Che",
        "Jinlin Hou",
        "Huijun Wang",
        "Hong Shen",
        "Liwen Qiu",
        "Zhuguo Li",
        "Jian Geng",
        "Junjie Cai",
        "Huixia Han",
        "Xin Li",
        "Wei Kang",
        "Desheng Weng",
        "Ping Liang",
        "Shibo Jiang"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Coronavirus",
        "Respiratory disease"
    ],
    "citation_count": "823",
    "reference_count": "29",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2116586125",
        "1966238900",
        "2169198329",
        "2134061616",
        "2168446943",
        "1757215199",
        "2158118659"
    ]
},{
    "id": "3025232310",
    "title": "Humoral Immune Responses in COVID-19 Patients: A Window on the State of the Art.",
    "abstract": "The novel SARS-CoV-2 is a recently emerging virus causing a human pandemic. A great variety of symptoms associated with COVID-19 disease, ranging from mild to severe symptoms, eventually leading to death. Specific SARS-CoV-2 RT-PCR is the standard method to screen symptomatic people; however, asymptomatic subjects and subjects with undetectable viral load escape from the screening, contributing to viral spread. Currently, the lock down imposed by many governments is an important measure to contain the spread, as there is no specific antiviral therapy or a vaccine and the main treatments are supportive. Therefore, there is urgent need to characterize the virus and the viral-mediated responses, in order to develop specific diagnostic and therapeutic tools to prevent viral transmission and efficiently cure COVID-19 patients. Here, we review the current studies on two viral mediated-responses, specifically the cytokine storm occurring in a subset of patients and the antibody response triggered by the infection. Further studies are needed to explore both the dynamics and the mechanisms of the humoral immune response in COVID-19 patients, in order to guide future vaccine design and antibody-based therapies for the management of the disease.",
    "date": "2020",
    "authors": [
        "Gabriel Siracusano",
        "Claudia Pastori",
        "Lucia Lopalco"
    ],
    "related_topics": [
        "Viral load",
        "Disease",
        "Cytokine storm"
    ],
    "citation_count": "67",
    "reference_count": "75",
    "references": [
        "3001118548",
        "3002108456",
        "3004280078",
        "3001465255",
        "3003217347",
        "3007643904",
        "3005679569",
        "3012756997",
        "3009314935",
        "3013985547"
    ]
},{
    "id": "3028321619",
    "title": "SARS-CoV-2 Infection and the Newborn",
    "abstract": "Severe Acute Respiratory Syndrome Coronavirus Type 2 (SARS-CoV-2) affects people at all ages and it may be encountered in pregnant women and newborns also. The information about its clinical features, laboratory findings and prognosis in children and newborns is scarce. All the reported cases in pregnant women were in the 2nd or 3rd trimester and only 1% of them developed severe disease. Miscarriages are rare. Materno-fetal transmission of the disease is controversial. Definitive diagnosis can be made by a history of contact with a proven case, fever, pneumonia and gastrointestinal disorder and a Polymerase chain reaction (PCR) test of nasopharyngeal swabs. Lymphopenia as well as liver and renal dysfunctions may be seen. Suspected or proven cases of newborns with symptoms should be quarantined in the neonatal intensive care unit for at least 14 days with standart and droplet isolation precautions. Asymptomatic infants may be quaratined at home. Transport of the neonates should be performed in a dedicated transport incubator and ambulance with isolation precautions. There is no specific treatment for the disease, but hemodynamic stabilization of the infant, respiratory management and other daily care are essential. Drugs against cytokine storm syndrome such as corticosteroids or tocilizumab are under investigation. Routine antibiotics are not recommended. No deaths have been reported so far in the neonatal population. Families and healthcare staff should receive pyschological support. Since the infection is quite new and knowledge is constantly accumulating, following developments and continuous updates are crucial.",
    "date": "2020",
    "authors": [
        "Fahri Oval\u0131"
    ],
    "related_topics": [
        "Neonatal intensive care unit",
        "Gastrointestinal disorder",
        "Population"
    ],
    "citation_count": "15",
    "reference_count": "83",
    "references": [
        "3001118548",
        "3008028633",
        "3002539152",
        "3004318991",
        "3007940623",
        "3010233963",
        "3010604545",
        "3005212621",
        "3011610993",
        "3005679569"
    ]
},{
    "id": "3003637715",
    "title": "Molecular Diagnosis of a Novel Coronavirus (2019-nCoV) Causing an Outbreak of Pneumonia.",
    "abstract": "BACKGROUND: A novel coronavirus of zoonotic origin (2019-nCoV) has recently been identified in patients with acute respiratory disease. This virus is genetically similar to SARS coronavirus and bat SARS-like coronaviruses. The outbreak was initially detected in Wuhan, a major city of China, but has subsequently been detected in other provinces of China. Travel-associated cases have also been reported in a few other countries. Outbreaks in health care workers indicate human-to-human transmission. Molecular tests for rapid detection of this virus are urgently needed for early identification of infected patients. METHODS: We developed two 1-step quantitative real-time reverse-transcription PCR assays to detect two different regions (ORF1b and N) of the viral genome. The primer and probe sets were designed to react with this novel coronavirus and its closely related viruses, such as SARS coronavirus. These assays were evaluated using a panel of positive and negative controls. In addition, respiratory specimens from two 2019-nCoV-infected patients were tested. RESULTS: Using RNA extracted from cells infected by SARS coronavirus as a positive control, these assays were shown to have a dynamic range of at least seven orders of magnitude (2x10-4-2000 TCID50/reaction). Using DNA plasmids as positive standards, the detection limits of these assays were found to be below 10 copies per reaction. All negative control samples were negative in the assays. Samples from two 2019-nCoV-infected patients were positive in the tests. CONCLUSIONS: The established assays can achieve a rapid detection of 2019n-CoV in human samples, thereby allowing early identification of patients.",
    "date": "2020",
    "authors": [
        "Daniel K W Chu",
        "Yang Pan",
        "Samuel M S Cheng",
        "Kenrie P Y Hui",
        "Pavithra Krishnan",
        "Yingzhi Liu",
        "Daisy Y M Ng",
        "Carrie K C Wan",
        "Peng Yang",
        "Quanyi Wang",
        "Malik Peiris",
        "Leo L M Poon"
    ],
    "related_topics": [
        "Coronavirus",
        "Virus",
        "Outbreak"
    ],
    "citation_count": "704",
    "reference_count": "14",
    "references": [
        "3001195213",
        "2903899730",
        "2799524357",
        "2470646526",
        "2775086803",
        "2134061616",
        "2789368753",
        "1998201250",
        "1971383779",
        "2954438954"
    ]
},{
    "id": "3009885589",
    "title": "Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study.",
    "abstract": "Summary Background Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods In this retrospective, multicentre cohort study, we included all adult inpatients (\u226518 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48%) patients had a comorbidity, with hypertension being the most common (58 [30%] patients), followed by diabetes (36 [19%] patients) and coronary heart disease (15 [8%] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1\u00b710, 95% CI 1\u00b703\u20131\u00b717, per year increase; p=0\u00b70043), higher Sequential Organ Failure Assessment (SOFA) score (5\u00b765, 2\u00b761\u201312\u00b723; p Interpretation The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 \u03bcg/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects of National Science and Technology on New Drug Creation and Development.",
    "date": "2020",
    "authors": [
        "Fei Zhou",
        "Ting Yu",
        "Ronghui Du",
        "Guohui Fan",
        "Ying Liu",
        "Zhibo Liu",
        "Jie Xiang",
        "Yeming Wang",
        "Bin Song",
        "Xiaoying Gu",
        "Lulu Guan",
        "Yuan Wei",
        "Hui Li",
        "Xudong Wu",
        "Jiuyang Xu",
        "Shengjin Tu",
        "Yi Zhang",
        "Hua Chen",
        "Bin Cao"
    ],
    "related_topics": [
        "Cohort study",
        "Retrospective cohort study",
        "Odds ratio"
    ],
    "citation_count": "19,122",
    "reference_count": "40",
    "references": [
        "3001118548",
        "3005079553",
        "3002108456",
        "3003668884",
        "3008090866",
        "3006961006",
        "2280404143",
        "3007940623",
        "1803784511",
        "2026274122"
    ]
},{
    "id": "3013893137",
    "title": "Virological assessment of hospitalized patients with COVID-2019.",
    "abstract": "Coronavirus disease 2019 (COVID-19) is an acute infection of the respiratory tract that emerged in late 20191,2. Initial outbreaks in China involved 13.8% of cases with severe courses, and 6.1% of cases with critical courses3. This severe presentation may result from the virus using a virus receptor that is expressed predominantly in the lung2,4; the same receptor tropism is thought to have determined the pathogenicity-but also aided in the control-of severe acute respiratory syndrome (SARS) in 20035. However, there are reports of cases of COVID-19 in which the patient shows mild upper respiratory tract symptoms, which suggests the potential for pre- or oligosymptomatic transmission6-8. There is an urgent need for information on virus replication, immunity and infectivity in specific sites of the body. Here we report a detailed virological analysis of nine cases of COVID-19 that provides proof of active virus replication in tissues of the upper respiratory tract. Pharyngeal virus shedding was very high during the first week of symptoms, with a peak at 7.11 \u00d7 108 RNA copies per throat swab on day 4. Infectious virus was readily isolated from samples derived from the throat or lung, but not from stool samples-in spite of high concentrations of virus RNA. Blood and urine samples never yielded virus. Active replication in the throat was confirmed by the presence of viral replicative RNA intermediates in the throat samples. We consistently detected sequence-distinct virus populations in throat and lung samples from one patient, proving independent replication. The shedding of viral RNA from sputum outlasted the end of symptoms. Seroconversion occurred after 7 days in 50% of patients (and by day 14 in all patients), but was not followed by a rapid decline in viral load. COVID-19 can present as a mild illness of the upper respiratory tract. The confirmation of active virus replication in the upper respiratory tract has implications for the containment of COVID-19.",
    "date": "2020",
    "authors": [
        "Roman W\u00f6lfel",
        "Victor M. Corman",
        "Wolfgang Guggemos",
        "Michael Seilmaier",
        "Sabine Zange",
        "Marcel A. M\u00fcller",
        "Daniela Niemeyer",
        "Terry C. Jones",
        "Patrick Vollmar",
        "Camilla Rothe",
        "Michael Hoelscher",
        "Tobias Bleicker",
        "Sebastian Br\u00fcnink",
        "Julia Schneider",
        "Rosina Ehmann",
        "Katrin Zwirglmaier",
        "Christian Drosten",
        "Clemens Wendtner"
    ],
    "related_topics": [
        "Virus receptor",
        "Viral shedding",
        "Viral load"
    ],
    "citation_count": "3,832",
    "reference_count": "34",
    "references": [
        "3001897055",
        "3002108456",
        "3001195213",
        "3003465021",
        "3006961006",
        "3004239190",
        "3009912996",
        "3009906937",
        "3010338568",
        "2132260239"
    ]
},{
    "id": "3003464757",
    "title": "Genomic characterization of the 2019 novel human-pathogenic coronavirus isolated from a patient with atypical pneumonia after visiting Wuhan.",
    "abstract": "A mysterious outbreak of atypical pneumonia in late 2019 was traced to a seafood wholesale market in Wuhan of China. Within a few weeks, a novel coronavirus tentatively named as 2019 novel coronavirus (2019-nCoV) was announced by the World Health Organization. We performed bioinformatics analysis on a virus genome from a patient with 2019-nCoV infection and compared it with other related coronavirus genomes. Overall, the genome of 2019-nCoV has 89% nucleotide identity with bat SARS-like-CoVZXC21 and 82% with that of human SARS-CoV. The phylogenetic trees of their orf1a/b, Spike, Envelope, Membrane and Nucleoprotein also clustered closely with those of the bat, civet and human SARS coronaviruses. However, the external subdomain of Spike's receptor binding domain of 2019-nCoV shares only 40% amino acid identity with other SARS-related coronaviruses. Remarkably, its orf3b encodes a completely novel short protein. Furthermore, its new orf8 likely encodes a secreted protein with an alpha-helix, following with a beta-sheet(s) containing six strands. Learning from the roles of civet in SARS and camel in MERS, hunting for the animal source of 2019-nCoV and its more ancestral virus would be important for understanding the origin and evolution of this novel lineage B betacoronavirus. These findings provide the basis for starting further studies on the pathogenesis, and optimizing the design of diagnostic, antiviral and vaccination strategies for this emerging infection.",
    "date": "2020",
    "authors": [
        "Jasper Fuk Woo Chan",
        "Kin Hang Kok",
        "Zheng Zhu",
        "Hin Chu",
        "Kelvin Kai Wang To",
        "Shuofeng Yuan",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Civet"
    ],
    "citation_count": "1,820",
    "reference_count": "24",
    "references": [
        "3001118548",
        "3002539152",
        "2799524357",
        "2097706568",
        "2025170735",
        "2030966943",
        "2115555188",
        "2170933940",
        "2162496804",
        "2255897570"
    ]
},{
    "id": "3009834387",
    "title": "Evidence for gastrointestinal infection of SARS-CoV-2",
    "abstract": "No abstract available Keywords: ACE2; Gastrointestinal Infection; Oral-Fecal Transmission; SARS-CoV-2.",
    "date": "2020",
    "authors": [
        "Fei Xiao",
        "Meiwen Tang",
        "Xiaobin Zheng",
        "Ye Liu",
        "Xiaofeng Li",
        "Hong Shan"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Pneumonia"
    ],
    "citation_count": "1,536",
    "reference_count": "13",
    "references": [
        "3001118548",
        "3003668884",
        "3004280078",
        "3003465021",
        "3010441732",
        "3005272159",
        "3031532178",
        "2131988685",
        "1974901207",
        "3034277126"
    ]
},{
    "id": "3011863580",
    "title": "Prolonged presence of SARS-CoV-2 viral RNA in faecal samples.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Yongjian Wu",
        "Cheng Guo",
        "Lantian Tang",
        "Zhongsi Hong",
        "Jianhui Zhou",
        "Xin Dong",
        "Huan Yin",
        "Qiang Xiao",
        "Yanping Tang",
        "Xiujuan Qu",
        "Liangjian Kuang",
        "Xiaomin Fang",
        "Nischay Mishra",
        "Jiahai Lu",
        "Hong Shan",
        "Guanmin Jiang",
        "Xi Huang"
    ],
    "related_topics": [
        "Viral shedding",
        "Viral Epidemiology",
        "RNA"
    ],
    "citation_count": "863",
    "reference_count": "4",
    "references": [
        "3008696669",
        "3002533507",
        "3006846061",
        "3008352032"
    ]
},{
    "id": "3010096538",
    "title": "Features, Evaluation and Treatment Coronavirus (COVID-19)",
    "abstract": "According to the World Health Organization (WHO), viral diseases continue to emerge and represent a serious issue to public health. In the last twenty years, several viral epidemics such as the severe acute respiratory syndrome coronavirus (SARS-CoV) from 2002 to 2003, and H1N1 influenza in 2009, have been recorded. Most recently, the Middle East respiratory syndrome coronavirus (MERS-CoV) was first identified in Saudi Arabia in 2012.In a timeline that reaches the present day, an epidemic of cases with unexplained low respiratory infections detected in Wuhan, the largest metropolitan area in China's Hubei province, was first reported to the WHO Country Office in China, on December 31, 2019. Published literature can trace the beginning of symptomatic individuals back to the beginning of December 2019. As they were unable to identify the causative agent, these first cases (n=29) were classified as \"pneumonia of unknown etiology.\" The Chinese Center for Disease Control and Prevention (CDC) and local CDCs organized an intensive outbreak investigation program. The etiology of this illness was attributed to a novel virus belonging to the coronavirus (CoV) family.On February 11, 2020, the WHO Director-General, Dr. Tedros Adhanom Ghebreyesus, announced that the disease caused by this new CoV was a \"COVID-19,\" which is the acronym of \"coronavirus disease 2019\". In the past twenty years, two additional CoVs epidemics have occurred. SARS-CoV provoked a large-scale epidemic beginning in China and involving two dozen countries with approximately 8000 cases and 800 deaths (fatality rate of 9,6%), and the MERS-CoV that began in Saudi Arabia and has approximately 2,500 cases and 800 deaths (fatality rate of 35%) and still causes as sporadic cases.This new virus is very contagious and has quickly spread globally. In a meeting on January 30, 2020, per the International Health Regulations (IHR, 2005), the outbreak was declared by the WHO a Public Health Emergency of International Concern (PHEIC) as it had spread to 18 countries with four countries reporting human-to-human transmission. An additional landmark occurred on February 26, 2020, as the first case of the disease, not imported from China, was recorded in the United States (US). Initially, the new virus was called 2019-nCoV. Subsequently, the task of experts of the International Committee on Taxonomy of Viruses (ICTV) termed it the SARS-CoV-2 virus as it is very similar to the one that caused the SARS outbreak (SARS-CoVs). The CoVs have become the major pathogens of emerging respiratory disease outbreaks. They are a large family of single-stranded RNA viruses (+ssRNA) that can be isolated in different animal species. For reasons yet to be explained, these viruses can cross species barriers and can cause, in humans, illness ranging from the common cold to more severe diseases such as MERS and SARS. Interestingly, these latter viruses have probably originated from bats and then moving into other mammalian hosts \u2014 the Himalayan palm civet for SARS-CoV, and the dromedary camel for MERS-CoV \u2014 before jumping to humans. The dynamics of SARS-Cov-2 are currently unknown, but there is speculation that it also has an animal origin.The potential for these viruses to grow to become a pandemic worldwide represents a serious public health risk. Concerning COVID-19, the WHO raised the threat to the CoV epidemic to the \"very high\" level, on February 28, 2020. On March 11, as the number of COVID-19 cases outside China has increased 13 times and the number of countries involved has tripled with more than 118,000 cases in 114 countries and over 4,000 deaths, WHO declared the COVID-19 a pandemic.World governments are at work to establish countermeasures to stem the devastating effects and it has been estimated that strict shutdowns may have saved 3 million lives across 11 European countries. Health organizations coordinate information flows and issues directives and guidelines to best mitigate the impact of the threat. At the same time, scientists around the world work tirelessly, and information about the transmission mechanisms, the clinical spectrum of disease, new diagnostics, and prevention and therapeutic strategies are rapidly developing. Many uncertainties remain with regard to both the virus-host interaction and the evolution of the pandemic, with specific reference to the times when it will reach its peak.At the moment, the therapeutic strategies to deal with the infection are only supportive, and prevention aimed at reducing transmission in the community is our best weapon. Aggressive isolation measures in China have led to a progressive reduction of cases. From China, the disease spread to Europe. In Italy, in geographic regions of the north, initially, and subsequently throughout the peninsula, political and health authorities have made incredible efforts to contain a shock wave that has severely tested the health system. Afterward, the COVID-19 quickly crossed the ocean and as of June 20, 2020, about 2,282,000 cases (with 121,000 deaths) have been recorded in the US, whereas Brazil with more than 1,000,000 cases and about 50,000 deaths is the most affected state in South America and the second in the world after the US. Although over time the lethality rate (total number of deaths for a given disease in relation to the total number of patients) of COVID-19 has been significantly lower than that of the SARS and MERS epidemics, the transmission of the SARS-CoV-2 virus is much larger than that of the previous viruses, with a much higher total number of deaths. It has been estimated that about one in five individuals worldwide could be at increased risk of severe COVID-19 disease if they become infected, due to underlying health conditions.In the midst of the crisis, the authors have chosen to use the \"Statpearls\" platform because, within the PubMed scenario, it represents a unique tool that may allow them to make updates in real-time. The aim, therefore, is to collect information and scientific evidence and to provide an overview of the topic that will be continuously updated.",
    "date": "2020",
    "authors": [
        "Marco Cascella",
        "Michael Rajnik",
        "Arturo Cuomo",
        "Scott C. Dulebohn",
        "Raffaela Di Napoli"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Outbreak",
        "Case fatality rate"
    ],
    "citation_count": "837",
    "reference_count": "54",
    "references": [
        "3001118548",
        "3002108456",
        "3003668884",
        "3009885589",
        "3008028633",
        "3009912996",
        "2280404143",
        "3010233963",
        "3010930696",
        "3012379316"
    ]
},{
    "id": "3006846061",
    "title": "Enteric involvement of coronaviruses: is faecal-oral transmission of SARS-CoV-2 possible?",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Charleen Yeo",
        "Sanghvi Kaushal",
        "Danson Yeo"
    ],
    "related_topics": [
        "Viral shedding",
        "Pneumonia",
        "Transmission (medicine)"
    ],
    "citation_count": "593",
    "reference_count": "14",
    "references": [
        "3005079553",
        "3002108456",
        "3003465021",
        "3004348779",
        "2006434809",
        "3003464757",
        "2144410942",
        "2769543984",
        "1984335993",
        "2064850047"
    ]
},{
    "id": "3008443627",
    "title": "An interactive web-based dashboard to track COVID-19 in real time.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Ensheng Dong",
        "Hongru Du",
        "Lauren Gardner"
    ],
    "related_topics": [
        "Dashboard (business)",
        "Web application",
        "Track (disk drive)"
    ],
    "citation_count": "4,371",
    "reference_count": "1",
    "references": [
        "2406220407"
    ]
},{
    "id": "3013967887",
    "title": "Estimates of the severity of coronavirus disease 2019: a model-based analysis.",
    "abstract": "Background In the face of rapidly changing data, a range of case fatality ratio estimates for coronavirus disease 2019 (COVID-19) have been produced that differ substantially in magnitude. We aimed to provide robust estimates, accounting for censoring and ascertainment biases. Methods We collected individual-case data for patients who died from COVID-19 in Hubei, mainland China (reported by national and provincial health commissions to Feb 8, 2020), and for cases outside of mainland China (from government or ministry of health websites and media reports for 37 countries, as well as Hong Kong and Macau, until Feb 25, 2020). These individual-case data were used to estimate the time between onset of symptoms and outcome (death or discharge from hospital). We next obtained age-stratified estimates of the case fatality ratio by relating the aggregate distribution of cases to the observed cumulative deaths in China, assuming a constant attack rate by age and adjusting for demography and age-based and location-based under-ascertainment. We also estimated the case fatality ratio from individual line-list data on 1334 cases identified outside of mainland China. Using data on the prevalence of PCR-confirmed cases in international residents repatriated from China, we obtained age-stratified estimates of the infection fatality ratio. Furthermore, data on age-stratified severity in a subset of 3665 cases from China were used to estimate the proportion of infected individuals who are likely to require hospitalisation. Findings Using data on 24 deaths that occurred in mainland China and 165 recoveries outside of China, we estimated the mean duration from onset of symptoms to death to be 17\u00b78 days (95% credible interval [CrI] 16\u00b79-19\u00b72) and to hospital discharge to be 24\u00b77 days (22\u00b79-28\u00b71). In all laboratory confirmed and clinically diagnosed cases from mainland China (n=70 117), we estimated a crude case fatality ratio (adjusted for censoring) of 3\u00b767% (95% CrI 3\u00b756-3\u00b780). However, after further adjusting for demography and under-ascertainment, we obtained a best estimate of the case fatality ratio in China of 1\u00b738% (1\u00b723-1\u00b753), with substantially higher ratios in older age groups (0\u00b732% [0\u00b727-0\u00b738] in those aged Interpretation These early estimates give an indication of the fatality ratio across the spectrum of COVID-19 disease and show a strong age gradient in risk of death. Funding UK Medical Research Council.",
    "date": "2020",
    "authors": [
        "Robert Verity",
        "Lucy C Okell",
        "Ilaria Dorigatti",
        "Peter Winskill",
        "Charles Whittaker",
        "Natsuko Imai",
        "Gina Cuomo-Dannenburg",
        "Hayley Thompson",
        "Patrick G T Walker",
        "Han Fu",
        "Amy Dighe",
        "Jamie T Griffin",
        "Marc Baguelin",
        "Sangeeta Bhatia",
        "Adhiratha Boonyasiri",
        "Anne Cori",
        "Zulma Cucunub\u00e1",
        "Rich FitzJohn",
        "Katy Gaythorpe",
        "Will Green",
        "Arran Hamlet",
        "Wes Hinsley",
        "Daniel Laydon",
        "Gemma Nedjati-Gilani",
        "Steven Riley",
        "Sabine van Elsland",
        "Erik Volz",
        "Haowei Wang",
        "Yuanrong Wang",
        "Xiaoyue Xi",
        "Christl A Donnelly",
        "Azra C Ghani",
        "Neil M Ferguson"
    ],
    "related_topics": [
        "Case fatality rate",
        "Mainland China",
        "Incidence (epidemiology)"
    ],
    "citation_count": "2,376",
    "reference_count": "27",
    "references": [
        "3001118548",
        "3008827533",
        "3002108456",
        "3003668884",
        "3009885589",
        "3002539152",
        "3008818676",
        "3007189521",
        "3020184843",
        "3001971765"
    ]
},{
    "id": "3015571324",
    "title": "Temporal dynamics in viral shedding and transmissibility of COVID-19.",
    "abstract": "We report temporal patterns of viral shedding in 94 patients with laboratory-confirmed COVID-19 and modeled COVID-19 infectiousness profiles from a separate sample of 77 infector-infectee transmission pairs. We observed the highest viral load in throat swabs at the time of symptom onset, and inferred that infectiousness peaked on or before symptom onset. We estimated that 44% (95% confidence interval, 25-69%) of secondary cases were infected during the index cases' presymptomatic stage, in settings with substantial household clustering, active case finding and quarantine outside the home. Disease control measures should be adjusted to account for probable substantial presymptomatic transmission.",
    "date": "2020",
    "authors": [
        "Xi He",
        "Eric H Y Lau",
        "Peng Wu",
        "Xilong Deng",
        "Jian Wang",
        "Xinxin Hao",
        "Yiu Chung Lau",
        "Jessica Y Wong",
        "Yujuan Guan",
        "Xinghua Tan",
        "Xiaoneng Mo",
        "Yanqing Chen",
        "Baolin Liao",
        "Weilie Chen",
        "Fengyu Hu",
        "Qing Zhang",
        "Mingqiu Zhong",
        "Yanrong Wu",
        "Lingzhai Zhao",
        "Fuchun Zhang",
        "Benjamin J Cowling",
        "Fang Li",
        "Gabriel M Leung"
    ],
    "related_topics": [
        "Viral load",
        "Viral shedding",
        "Serial interval"
    ],
    "citation_count": "3,175",
    "reference_count": "22",
    "references": [
        "3003668884",
        "3009885589",
        "3006961006",
        "3003573988",
        "3008696669",
        "3013893137",
        "3012756997",
        "3008294222",
        "2129542667",
        "3009983851"
    ]
},{
    "id": "3006642361",
    "title": "The reproductive number of COVID-19 is higher compared to SARS coronavirus.",
    "abstract": "Teaser: Our review found the average R0 for 2019-nCoV to be 3.28, which exceeds WHO estimates of 1.4 to 2.5.",
    "date": "2020",
    "authors": [
        "Ying Liu",
        "Albert A Gayle",
        "Annelies Wilder-Smith",
        "Joacim Rockl\u00f6v"
    ],
    "related_topics": [
        "Coronavirus",
        "Virology",
        "Medicine"
    ],
    "citation_count": "2,384",
    "reference_count": "14",
    "references": [
        "3003668884",
        "3003573988",
        "3004397688",
        "3002764620",
        "3004026249",
        "3002533591",
        "3002747665",
        "3001343166",
        "3001392146",
        "3023259384"
    ]
},{
    "id": "3013594674",
    "title": "The effect of human mobility and control measures on the COVID-19 epidemic in China.",
    "abstract": "The ongoing coronavirus disease 2019 (COVID-19) outbreak expanded rapidly throughout China. Major behavioral, clinical, and state interventions were undertaken to mitigate the epidemic and prevent the persistence of the virus in human populations in China and worldwide. It remains unclear how these unprecedented interventions, including travel restrictions, affected COVID-19 spread in China. We used real-time mobility data from Wuhan and detailed case data including travel history to elucidate the role of case importation in transmission in cities across China and to ascertain the impact of control measures. Early on, the spatial distribution of COVID-19 cases in China was explained well by human mobility data. After the implementation of control measures, this correlation dropped and growth rates became negative in most locations, although shifts in the demographics of reported cases were still indicative of local chains of transmission outside of Wuhan. This study shows that the drastic control measures implemented in China substantially mitigated the spread of COVID-19.",
    "date": "2020",
    "authors": [
        "Moritz U.G. Kraemer",
        "Chia Hung Yang",
        "Bernardo Gutierrez",
        "Chieh Hsi Wu",
        "Brennan Klein",
        "David M. Pigott",
        "Louis du Plessis",
        "Nuno R. Faria",
        "Ruoran Li",
        "William P. Hanage",
        "John S. Brownstein",
        "Maylis Layan",
        "Alessandro Vespignani",
        "Huaiyu Tian",
        "Christopher Dye",
        "Oliver G. Pybus",
        "Samuel V. Scarpino"
    ],
    "related_topics": [
        "China",
        "Transmission (mechanics)",
        "Outbreak"
    ],
    "citation_count": "1,304",
    "reference_count": "38",
    "references": [
        "3001897055",
        "3003668884",
        "3008028633",
        "1951724000",
        "3003573988",
        "3008818676",
        "2097360283",
        "3012284084",
        "2122825543",
        "3004912618"
    ]
},{
    "id": "3012789146",
    "title": "The effect of control strategies to reduce social mixing on outcomes of the COVID-19 epidemic in Wuhan, China: a modelling study.",
    "abstract": "BACKGROUND: In December, 2019, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), a novel coronavirus, emerged in Wuhan, China. Since then, the city of Wuhan has taken unprecedented measures in response to the outbreak, including extended school and workplace closures. We aimed to estimate the effects of physical distancing measures on the progression of the COVID-19 epidemic, hoping to provide some insights for the rest of the world. METHODS: To examine how changes in population mixing have affected outbreak progression in Wuhan, we used synthetic location-specific contact patterns in Wuhan and adapted these in the presence of school closures, extended workplace closures, and a reduction in mixing in the general community. Using these matrices and the latest estimates of the epidemiological parameters of the Wuhan outbreak, we simulated the ongoing trajectory of an outbreak in Wuhan using an age-structured susceptible-exposed-infected-removed (SEIR) model for several physical distancing measures. We fitted the latest estimates of epidemic parameters from a transmission model to data on local and internationally exported cases from Wuhan in an age-structured epidemic framework and investigated the age distribution of cases. We also simulated lifting of the control measures by allowing people to return to work in a phased-in way and looked at the effects of returning to work at different stages of the underlying outbreak (at the beginning of March or April). FINDINGS: Our projections show that physical distancing measures were most effective if the staggered return to work was at the beginning of April; this reduced the median number of infections by more than 92% (IQR 66-97) and 24% (13-90) in mid-2020 and end-2020, respectively. There are benefits to sustaining these measures until April in terms of delaying and reducing the height of the peak, median epidemic size at end-2020, and affording health-care systems more time to expand and respond. However, the modelled effects of physical distancing measures vary by the duration of infectiousness and the role school children have in the epidemic. INTERPRETATION: Restrictions on activities in Wuhan, if maintained until April, would probably help to delay the epidemic peak. Our projections suggest that premature and sudden lifting of interventions could lead to an earlier secondary peak, which could be flattened by relaxing the interventions gradually. However, there are limitations to our analysis, including large uncertainties around estimates of R0 and the duration of infectiousness. FUNDING: Bill & Melinda Gates Foundation, National Institute for Health Research, Wellcome Trust, and Health Data Research UK.",
    "date": "2020",
    "authors": [
        "Kiesha Prem",
        "Yang Liu",
        "Timothy W Russell",
        "Adam J Kucharski",
        "Rosalind M Eggo",
        "Nicholas Davies",
        "Mark Jit",
        "Petra Klepac"
    ],
    "related_topics": [
        "Psychological intervention",
        "Outbreak",
        "Demography"
    ],
    "citation_count": "1,337",
    "reference_count": "43",
    "references": [
        "3001897055",
        "3003668884",
        "3002539152",
        "3003573988",
        "3006659024",
        "3009577418",
        "3009468976",
        "3004912618",
        "3004026249",
        "3020184843"
    ]
},{
    "id": "3001195213",
    "title": "Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR.",
    "abstract": "Background The ongoing outbreak of the recently emerged novel coronavirus (2019-nCoV) poses a challenge for public health laboratories as virus isolates are unavailable while there is growing evidence that the outbreak is more widespread than initially thought, and international spread through travellers does already occur. Aim We aimed to develop and deploy robust diagnostic methodology for use in public health laboratory settings without having virus material available. Methods Here we present a validated diagnostic workflow for 2019-nCoV, its design relying on close genetic relatedness of 2019-nCoV with SARS coronavirus, making use of synthetic nucleic acid technology. Results The workflow reliably detects 2019-nCoV, and further discriminates 2019-nCoV from SARS-CoV. Through coordination between academic and public laboratories, we confirmed assay exclusivity based on 297 original clinical specimens containing a full spectrum of human respiratory viruses. Control material is made available through European Virus Archive \u2013 Global (EVAg), a European Union infrastructure project. Conclusion The present study demonstrates the enormous response capacity achieved through coordination of academic and public laboratories in national and European research networks.",
    "date": "2020",
    "authors": [
        "Victor M. Corman",
        "Olfert Landt",
        "Marco Kaiser",
        "Richard Molenkamp",
        "Adam Meijer",
        "Daniel K.W. Chu",
        "Tobias Bleicker",
        "Sebastian Br\u00fcnink",
        "Julia Schneider",
        "Marie Luisa Schmidt",
        "Daphne G.J.C. Mulders",
        "Bart L. Haagmans",
        "Bas Van Der Veer",
        "Sharon Van Den Brink",
        "Lisa Wijsman",
        "Gabriel Goderski",
        "Jean Louis Romette",
        "Joanna Ellis",
        "Maria Zambon",
        "Malik Peiris",
        "Herman Goossens",
        "Chantal Reusken",
        "Marion P.G. Koopmans",
        "Christian Drosten"
    ],
    "related_topics": [
        "European union",
        "Coronavirus",
        "Global health"
    ],
    "citation_count": "3,985",
    "reference_count": "18",
    "references": [
        "2903899730",
        "2132260239",
        "1703839189",
        "1852588318",
        "2793008036",
        "2167080692",
        "2894950287",
        "2884280018",
        "2031705962",
        "2101063972"
    ]
},{
    "id": "2105275554",
    "title": "Loop-mediated isothermal amplification of DNA",
    "abstract": "We have developed a novel method, termed loop-mediated isothermal amplification (LAMP), that amplifies DNA with high specificity, efficiency and rapidity under isothermal conditions. This method employs a DNA polymerase and a set of four specially designed primers that recognize a total of six distinct sequences on the target DNA. An inner primer containing sequences of the sense and antisense strands of the target DNA initiates LAMP. The following strand displacement DNA synthesis primed by an outer primer releases a single-stranded DNA. This serves as template for DNA synthesis primed by the second inner and outer primers that hybridize to the other end of the target, which produces a stem\u2013loop DNA structure. In subsequent LAMP cycling one inner primer hybridizes to the loop on the product and initiates displacement DNA synthesis, yielding the original stem\u2013loop DNA and a new stem\u2013loop DNA with a stem twice as long. The cycling reaction continues with accumulation of 109 copies of target in less than an hour. The final products are stem\u2013loop DNAs with several inverted repeats of the target and cauliflower-like structures with multiple loops formed by annealing between alternately inverted repeats of the target in the same strand. Because LAMP recognizes the target by six distinct sequences initially and by four distinct sequences afterwards, it is expected to amplify the target sequence with high selectivity.",
    "date": "2000",
    "authors": [
        "Tsugunori Notomi",
        "Hiroto Okayama",
        "Harumi Masubuchi",
        "Toshihiro Yonekawa",
        "Keiko Watanabe",
        "Nobuyuki Amino",
        "Tetsu Hase"
    ],
    "related_topics": [
        "DNA clamp",
        "Primer (molecular biology)",
        "Base pair"
    ],
    "citation_count": "7,786",
    "reference_count": "15",
    "references": [
        "2032118018",
        "2050717506",
        "2035792726",
        "2062756489",
        "1990689151",
        "2142539585",
        "2083121396",
        "2082277951",
        "1970137322",
        "2056636525"
    ]
},{
    "id": "3011969828",
    "title": "2019 Novel Coronavirus Disease (COVID-19): Paving the Road for Rapid Detection and Point-of-Care Diagnostics.",
    "abstract": "We believe a point-of-care (PoC) device for the rapid detection of the 2019 novel Coronavirus (SARS-CoV-2) is crucial and urgently needed. With this perspective, we give suggestions regarding a potential candidate for the rapid detection of the coronavirus disease 2019 (COVID-19), as well as factors for the preparedness and response to the outbreak of the COVID-19.",
    "date": "2020",
    "authors": [
        "Trieu Nguyen",
        "Dang Duong Bang",
        "Anders Wolff"
    ],
    "related_topics": [
        "Preparedness",
        "Outbreak",
        "Point-of-care testing"
    ],
    "citation_count": "176",
    "reference_count": "32",
    "references": [
        "3001118548",
        "3004280078",
        "3001195213",
        "3003465021",
        "3004239190",
        "3003573988",
        "3001465255",
        "3003951199",
        "3003637715",
        "3000771439"
    ]
},{
    "id": "2770752141",
    "title": "Loop-mediated isothermal amplification (LAMP): a versatile technique for detection of micro-organisms.",
    "abstract": "Summary Loop-mediated isothermal amplification (LAMP) amplifies DNA with high specificity, efficiency and rapidity under isothermal conditions by using a DNA polymerase with high displacement strand activity and a set of specifically designed primers to amplify targeted DNA strands. Following its first discovery by Notomi et al. (2000 Nucleic Acids Res 28: E63), LAMP was further developed over the years which involved the combination of this technique with other molecular approaches, such as reverse transcription and multiplex amplification for the detection of infectious diseases caused by micro-organisms in humans, livestock and plants. In this review, available types of LAMP techniques will be discussed together with their applications in detection of various micro-organisms. Up to date, there are varieties of LAMP detection methods available including colorimetric and fluorescent detection, real-time monitoring using turbidity metre and detection using lateral flow device which will also be highlighted in this review. Apart from that, commercialization of LAMP technique had also been reported such as lyophilized form of LAMP reagents kit and LAMP primer sets for detection of pathogenic micro-organisms. On top of that, advantages and limitations of this molecular detection method are also described together with its future potential as a diagnostic method for infectious disease.",
    "date": "2018",
    "authors": [
        "Y.-P. Wong",
        "S. Othman",
        "Y.-L. Lau",
        "S. Radu",
        "H.-Y. Chee"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Multiplex",
        "Polymerase"
    ],
    "citation_count": "175",
    "reference_count": "168",
    "references": [
        "2105275554",
        "1979974453",
        "1975801865",
        "1562219715",
        "89741002",
        "2063533401",
        "1997925861",
        "2050515639",
        "2141633648",
        "2035792726"
    ]
},{
    "id": "2263084061",
    "title": "Loop-Mediated Isothermal Amplification Assay for Identification of Five Human Plasmodium Species in Malaysia",
    "abstract": "The lack of rapid, affordable, and accurate diagnostic tests represents the primary hurdle affecting malaria surveillance in resource- and expertise-limited areas. Loop-mediated isothermal amplification (LAMP) is a sensitive, rapid, and cheap diagnostic method. Five species-specific LAMP assays were developed based on 18S rRNA gene. Sensitivity and specificity of LAMP results were calculated as compared with microscopic examination and nested polymerase chain reaction. LAMP reactions were highly sensitive with the detection limit of one copy for Plasmodium vivax, Plasmodium falciparum, and Plasmodium malariae and 10 copies for Plasmodium knowlesi and Plasmodium ovale. LAMP positively detected all human malaria species in all positive samples (N = 134; sensitivity = 100%) within 35 minutes. All negative samples were not amplified by LAMP (N = 67; specificity = 100%). LAMP successfully detected two samples with very low parasitemia. LAMP may offer a rapid, simple, and reliable test for the diagnosis of malaria in areas where malaria is prevalent.",
    "date": "2016",
    "authors": [
        "Yee Ling Lau",
        "Meng Yee Lai",
        "Mun Yik Fong",
        "Jenarun Jelip",
        "Rohela Mahmud"
    ],
    "related_topics": [
        "Plasmodium malariae",
        "Plasmodium ovale",
        "Plasmodium vivax"
    ],
    "citation_count": "37",
    "reference_count": "20",
    "references": [
        "2105275554",
        "2788073857",
        "2133724824",
        "2066385972",
        "2149136689",
        "2102131955",
        "2043762150",
        "1987713777",
        "2110753623",
        "2144345536"
    ]
},{
    "id": "2175815746",
    "title": "Development of reverse-transcription loop-mediated isothermal amplification assay for rapid detection and differentiation of dengue virus serotypes 1-4.",
    "abstract": "Dengue virus (DENV), the most widely prevalent arbovirus, continues to be a threat to human health in the tropics and subtropics. Early and rapid detection of DENV infection during the acute phase of illness is crucial for proper clinical patient management and preventing the spread of infection. The aim of the current study was to develop a specific, sensitive, and robust reverse transcriptase loop-mediated isothermal amplification (RT-LAMP) assay for detection and differentiation of DENV1-4 serotypes. The method detection primers, which were designed to target the different DENV serotypes, were identified by inspection of multiple sequence alignments of the non-structural protein (NS) 2A of DENV1, NS4B of DENV2, NS4A of DENV3 and the 3\u2032 untranslated region of the NS protein of DENV4. No cross-reactions of the four serotypes were observed during the tests. The detection limits of the DENV1-4-specific RT-LAMP assays were approximately 10-copy templates per reaction. The RT-LAMP assays were ten-fold more sensitive than RT-PCR or real-time PCR. The diagnostic rate was 100 % for clinical strains of DENV, and 98.9 % of the DENV-infected patients whose samples were tested were detected by RT-LAMP. Importantly, no false-positives were detected with the new equipment and methodology that was used to avoid aerosol contamination of the samples. The RT-LAMP method used in our study is specific, sensitive, and suitable for further investigation as a useful alternative to the current methods used for clinical diagnosis of DENV1-4, especially in hospitals and laboratories that lack sophisticated diagnostic systems.",
    "date": "2015",
    "authors": [
        "Sheng-feng Hu",
        "Miao Li",
        "Lan-lan Zhong",
        "Shi-miao Lu",
        "Ze-xia Liu",
        "Jie-ying Pu",
        "Jin-sheng Wen",
        "Xi Huang"
    ],
    "related_topics": [
        "Reverse Transcription Loop-mediated Isothermal Amplification",
        "Loop-mediated isothermal amplification",
        "Dengue virus"
    ],
    "citation_count": "26",
    "reference_count": "43",
    "references": [
        "2105275554",
        "2042479028",
        "2066385972",
        "2128110156",
        "2149136689",
        "2160892791",
        "2101258647",
        "1994850469",
        "2124449928",
        "2141627564"
    ]
},{
    "id": "1991420168",
    "title": "Utility of IgM ELISA, TaqMan real-time PCR, reverse transcription PCR, and RT-LAMP assay for the diagnosis of Chikungunya fever.",
    "abstract": "Chikungunya fever a re-emerging infection with expanding geographical boundaries, can mimic symptoms of other infections like dengue, malaria which makes the definitive diagnosis of the infection important. The present study compares the utility of four laboratory diagnostic methods viz. IgM capture ELISA, an in house reverse transcription PCR for the diagnosis of Chikungunya fever, TaqMan real-time PCR, and a one step reverse transcription-loop mediated isothermal amplification assay (RT-LAMP). Out of the 70 serum samples tested, 29 (41%) were positive for Chikungunya IgM antibody by ELISA and 50 (71%) samples were positive by one of the three molecular assays. CHIKV specific nucleic acid was detected in 33/70 (47%) by reverse transcription PCR, 46/70 (66%) by TaqMan real-time PCR, and 43/70 (62%) by RT-LAMP assay. A majority of the samples (62/70; 89%) were positive by at least one of the four assays used in the study. The molecular assays were more sensitive for diagnosis in the early stages of illness (2\u20135 days post onset) when antibodies were not detectable. In the later stages of illness, the IgM ELISA is a more sensitive diagnostic test. In conclusion we recommend that the IgM ELISA be used as an initial screening test followed one of the molecular assays in samples that are collected in the early phase of illness and negative for CHIKV IgM antibodies. Such as approach would enable rapid confirmation of the diagnosis and implementation of public health measures especially during outbreaks. J. Med. Virol. 84:1771\u20131778, 2012. \u00a9 2012 Wiley Periodicals, Inc.",
    "date": "2012",
    "authors": [
        "Vijayalakshmi Reddy",
        "Vasanthapuram Ravi",
        "Anita Desai",
        "Manmohan Parida",
        "Ann M. Powers",
        "Barbara W. Johnson"
    ],
    "related_topics": [
        "TaqMan",
        "Reverse transcription polymerase chain reaction",
        "Loop-mediated isothermal amplification"
    ],
    "citation_count": "65",
    "reference_count": "27",
    "references": [
        "2141987735",
        "2120801593",
        "1977296748",
        "2129358311",
        "1969557290",
        "2067506266",
        "2052129607",
        "2108924397",
        "1966636515",
        "2051304065"
    ]
},{
    "id": "2084576921",
    "title": "Visual detection of turkey coronavirus RNA in tissues and feces by reverse-transcription loop-mediated isothermal amplification (RT-LAMP) with hydroxynaphthol blue dye",
    "abstract": "Abstract A sensitive reverse-transcription loop-mediated isothermal amplification (RT-LAMP) assay was developed for the rapid visual detection of turkey coronavirus (TCoV) infection. The reaction is performed in one step in a single tube at 65 \u00b0C for 45 min, with hydroxynaphthol blue (HNB) dye added prior to amplification. The detection limit of the RT-LAMP assay was approximately 10 2 EID 50/50 \u03bcl TCoV genome, and no cross-reaction with other avian viruses was observed. The assay was evaluated further in tissue suspensions prepared from the ileum and ileum\u2013caecal junctions of infected turkey embryos; 100% of these samples were positive in the RT-LAMP assay. All individual feces samples collected in the field were considered positive by both conventional RT-PCR and RT-LAMP. In conclusion, RT-LAMP with HNB dye was shown to be a sensitive, simple assay for the rapid diagnosis of TCoV infection, either directly from feces or in association with virus isolation methods.",
    "date": "2010",
    "authors": [
        "Tereza C. Cardoso",
        "Heitor F. Ferrari",
        "Livia C. Bregano",
        "Camila Silva-Frade",
        "Ana Carolina G. Rosa",
        "Alexandre Lima de Andrade"
    ],
    "related_topics": [
        "Hydroxynaphthol blue",
        "Reverse Transcription Loop-mediated Isothermal Amplification",
        "Loop-mediated isothermal amplification"
    ],
    "citation_count": "62",
    "reference_count": "14",
    "references": [
        "2105275554",
        "1544561280",
        "2028571354",
        "1997738379",
        "2057637320",
        "2155485281",
        "1997343737",
        "1565181081",
        "2009652162",
        "2038706592"
    ]
},{
    "id": "3008090866",
    "title": "Clinical course and outcomes of critically ill patients with SARS-CoV-2 pneumonia in Wuhan, China: a single-centered, retrospective, observational study.",
    "abstract": "Summary Background An ongoing outbreak of pneumonia associated with the severe acute respiratory coronavirus 2 (SARS-CoV-2) started in December, 2019, in Wuhan, China. Information about critically ill patients with SARS-CoV-2 infection is scarce. We aimed to describe the clinical course and outcomes of critically ill patients with SARS-CoV-2 pneumonia. Methods In this single-centered, retrospective, observational study, we enrolled 52 critically ill adult patients with SARS-CoV-2 pneumonia who were admitted to the intensive care unit (ICU) of Wuhan Jin Yin-tan hospital (Wuhan, China) between late December, 2019, and Jan 26, 2020. Demographic data, symptoms, laboratory values, comorbidities, treatments, and clinical outcomes were all collected. Data were compared between survivors and non-survivors. The primary outcome was 28-day mortality, as of Feb 9, 2020. Secondary outcomes included incidence of SARS-CoV-2-related acute respiratory distress syndrome (ARDS) and the proportion of patients requiring mechanical ventilation. Findings Of 710 patients with SARS-CoV-2 pneumonia, 52 critically ill adult patients were included. The mean age of the 52 patients was 59\u00b77 (SD 13\u00b73) years, 35 (67%) were men, 21 (40%) had chronic illness, 51 (98%) had fever. 32 (61\u00b75%) patients had died at 28 days, and the median duration from admission to the intensive care unit (ICU) to death was 7 (IQR 3\u201311) days for non-survivors. Compared with survivors, non-survivors were older (64\u00b76 years [11\u00b72] vs 51\u00b79 years [12\u00b79]), more likely to develop ARDS (26 [81%] patients vs 9 [45%] patients), and more likely to receive mechanical ventilation (30 [94%] patients vs 7 [35%] patients), either invasively or non-invasively. Most patients had organ function damage, including 35 (67%) with ARDS, 15 (29%) with acute kidney injury, 12 (23%) with cardiac injury, 15 (29%) with liver dysfunction, and one (2%) with pneumothorax. 37 (71%) patients required mechanical ventilation. Hospital-acquired infection occurred in seven (13\u00b75%) patients. Interpretation The mortality of critically ill patients with SARS-CoV-2 pneumonia is considerable. The survival time of the non-survivors is likely to be within 1\u20132 weeks after ICU admission. Older patients (>65 years) with comorbidities and ARDS are at increased risk of death. The severity of SARS-CoV-2 pneumonia poses great strain on critical care resources in hospitals, especially if they are not adequately staffed or resourced. Funding None.",
    "date": "2020",
    "authors": [
        "Xiaobo Yang",
        "Yuan Yu",
        "Jiqian Xu",
        "Huaqing Shu",
        "Jia'an Xia",
        "Hong Liu",
        "Yongran Wu",
        "Lu Zhang",
        "Zhui Yu",
        "Minghao Fang",
        "Ting Yu",
        "Yaxin Wang",
        "Shangwen Pan",
        "Xiaojing Zou",
        "Shiying Yuan",
        "You Shang"
    ],
    "related_topics": [
        "Pneumonia",
        "ARDS",
        "Intensive care unit"
    ],
    "citation_count": "7,578",
    "reference_count": "22",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3003465021",
        "3004239190",
        "2470646526",
        "2026274122",
        "3005403371",
        "2286228001"
    ]
},{
    "id": "3007940623",
    "title": "Pathological findings of COVID-19 associated with acute respiratory distress syndrome.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Zhe Xu",
        "Lei Shi",
        "Yijin Wang",
        "Jiyuan Zhang",
        "Lei Huang",
        "Chao Zhang",
        "Shuhong Liu",
        "Peng Zhao",
        "Hongxia Liu",
        "Li Zhu",
        "Yanhong Tai",
        "Changqing Bai",
        "Tingting Gao",
        "Jinwen Song",
        "Peng Xia",
        "Jinghui Dong",
        "Jingmin Zhao",
        "Fu Sheng Wang"
    ],
    "related_topics": [
        "Cytokine storm",
        "Medicine",
        "Pathological"
    ],
    "citation_count": "5,395",
    "reference_count": "5",
    "references": [
        "3001118548",
        "3002539152",
        "3003217347",
        "2256430766",
        "2158118659"
    ]
},{
    "id": "3011242477",
    "title": "COVID-19 and Italy: what next?",
    "abstract": "Summary The spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has already taken on pandemic proportions, affecting over 100 countries in a matter of weeks. A global response to prepare health systems worldwide is imperative. Although containment measures in China have reduced new cases by more than 90%, this reduction is not the case elsewhere, and Italy has been particularly affected. There is now grave concern regarding the Italian national health system's capacity to effectively respond to the needs of patients who are infected and require intensive care for SARS-CoV-2 pneumonia. The percentage of patients in intensive care reported daily in Italy between March 1 and March 11, 2020, has consistently been between 9% and 11% of patients who are actively infected. The number of patients infected since Feb 21 in Italy closely follows an exponential trend. If this trend continues for 1 more week, there will be 30\u2008000 infected patients. Intensive care units will then be at maximum capacity; up to 4000 hospital beds will be needed by mid-April, 2020. Our analysis might help political leaders and health authorities to allocate enough resources, including personnel, beds, and intensive care facilities, to manage the situation in the next few days and weeks. If the Italian outbreak follows a similar trend as in Hubei province, China, the number of newly infected patients could start to decrease within 3\u20134 days, departing from the exponential trend. However, this cannot currently be predicted because of differences between social distancing measures and the capacity to quickly build dedicated facilities in China.",
    "date": "2020",
    "authors": [
        "Andrea Remuzzi",
        "Giuseppe Remuzzi"
    ],
    "related_topics": [
        "Intensive care",
        "Global health",
        "Pandemic"
    ],
    "citation_count": "2,309",
    "reference_count": "2",
    "references": [
        "3003668884",
        "3007613835"
    ]
},{
    "id": "3010449299",
    "title": "Air, Surface Environmental, and Personal Protective Equipment Contamination by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) From a Symptomatic Patient.",
    "abstract": "This study documents results of SARS-CoV-2 polymerase chain reaction (PCR) testing of environmental surfaces and personal protective equipment surrounding 3 COVID-19 patients in isolation rooms in a Singapore hospital.",
    "date": "2020",
    "authors": [
        "Sean Wei Xiang Ong",
        "Yian Kim Tan",
        "Po Ying Chia",
        "Tau Hong Lee",
        "Oon Tek Ng",
        "Michelle Su Yen Wong",
        "Kalisvar Marimuthu"
    ],
    "related_topics": [
        "Isolation (health care)",
        "Coronavirus",
        "Personal protective equipment"
    ],
    "citation_count": "1,707",
    "reference_count": "5",
    "references": [
        "3005079553",
        "3001195213",
        "3010338568",
        "1815575713",
        "2250074178"
    ]
},{
    "id": "3018334611",
    "title": "Aerodynamic analysis of SARS-CoV-2 in two Wuhan hospitals.",
    "abstract": "The ongoing outbreak of coronavirus disease 2019 (COVID-19) has spread rapidly on a global scale. Although it is clear that severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is transmitted through human respiratory droplets and direct contact, the potential for aerosol transmission is poorly understood1-3. Here we investigated the aerodynamic nature of SARS-CoV-2 by measuring viral RNA in aerosols in different areas of two Wuhan hospitals during the outbreak of COVID-19 in February and March 2020. The concentration of SARS-CoV-2 RNA in aerosols that was detected in isolation wards and ventilated patient rooms was very low, but it was higher in the toilet areas used by the patients. Levels of airborne SARS-CoV-2 RNA in the most public areas was undetectable, except in two areas that were prone to crowding; this increase was possibly due to individuals infected with SARS-CoV-2 in the crowd. We found that some medical staff areas initially had high concentrations of viral RNA with aerosol size distributions that showed peaks in the submicrometre and/or supermicrometre regions; however, these levels were reduced to undetectable levels after implementation of rigorous sanitization procedures. Although we have not established the infectivity of the virus detected in these hospital areas, we propose that SARS-CoV-2 may have the potential to be transmitted through aerosols. Our results indicate that room ventilation, open space, sanitization of protective apparel, and proper use and disinfection of toilet areas can effectively limit the concentration of SARS-CoV-2 RNA in aerosols. Future work should explore the infectivity of aerosolized virus.",
    "date": "2020",
    "authors": [
        "Yuan Liu",
        "Zhi Ning",
        "Yu Chen",
        "Ming Guo",
        "Yingle Liu",
        "Nirmal Kumar Gali",
        "Li Sun",
        "Yusen Duan",
        "Jing Cai",
        "Dane Westerdahl",
        "Xinjin Liu",
        "Ke Xu",
        "Kin fai Ho",
        "Haidong Kan",
        "Qingyan Fu",
        "Ke Lan"
    ],
    "related_topics": [
        "Coronavirus",
        "Outbreak",
        "Infectivity"
    ],
    "citation_count": "1,067",
    "reference_count": "12",
    "references": [
        "3004280078",
        "3012099172",
        "3010604545",
        "3009906937",
        "3010449299",
        "3005510968",
        "3027866910",
        "3018724240",
        "2215636165",
        "2147350479"
    ]
},{
    "id": "3030968929",
    "title": "Detection of air and surface contamination by SARS-CoV-2 in hospital rooms of infected patients.",
    "abstract": "Understanding the particle size distribution in the air and patterns of environmental contamination of SARS-CoV-2 is essential for infection prevention policies. Here we screen surface and air samples from hospital rooms of COVID-19 patients for SARS-CoV-2 RNA. Environmental sampling is conducted in three airborne infection isolation rooms (AIIRs) in the ICU and 27 AIIRs in the general ward. 245 surface samples are collected. 56.7% of rooms have at least one environmental surface contaminated. High touch surface contamination is shown in ten (66.7%) out of 15 patients in the first week of illness, and three (20%) beyond the first week of illness (p = 0.01, \u03c72 test). Air sampling is performed in three of the 27 AIIRs in the general ward, and detects SARS-CoV-2 PCR-positive particles of sizes >4 \u00b5m and 1-4 \u00b5m in two rooms, despite these rooms having 12 air changes per hour. This warrants further study of the airborne transmission potential of SARS-CoV-2.",
    "date": "2020",
    "authors": [
        "Po Ying Chia",
        "Kristen Kelli Coleman",
        "Yian Kim Tan",
        "Sean Wei Xiang Ong",
        "Marcus Gum",
        "Sok Kiang Lau",
        "Xiao Fang Lim",
        "Ai Sim Lim",
        "Stephanie Sutjipto",
        "Pei Hua Lee",
        "Barnaby Edward Young",
        "Donald K Milton",
        "Gregory C Gray",
        "Stephan Schuster",
        "Timothy Barkham",
        "Partha Pratim De",
        "Shawn Vasoo",
        "Monica Chan",
        "Brenda Sze Peng Ang",
        "Boon Huan Tan",
        "Yee-Sin Leo",
        "Oon-Tek Ng",
        "Michelle Su Yen Wong",
        "Kalisvar Marimuthu"
    ],
    "related_topics": [
        "Airborne transmission",
        "Air changes per hour",
        "Isolation (health care)"
    ],
    "citation_count": "274",
    "reference_count": "17",
    "references": [
        "3002539152",
        "3001195213",
        "3006961006",
        "3012099172",
        "3008696669",
        "3013893137",
        "3010604545",
        "3010338568",
        "2132260239",
        "3010449299"
    ]
},{
    "id": "2158121945",
    "title": "Guidelines for environmental infection control in health-care facilities. Recommendations of CDC and the Healthcare Infection Control Practices Advisory Committee (HICPAC).",
    "abstract": "The health-care facility environment is rarely implicated in disease transmission, except among patients who are immunocompromised. Nonetheless, inadvertent exposures to environmental pathogens (e.g., Aspergillus spp. and Legionella spp.) or airborne pathogens (e.g., Mycobacterium tuberculosis and varicella-zoster virus) can result in adverse patient outcomes and cause illness among health-care workers. Environmental infection-control strategies and engineering controls can effectively prevent these infections. The incidence of health-care--associated infections and pseudo-outbreaks can be minimized by 1) appropriate use of cleaners and disinfectants; 2) appropriate maintenance of medical equipment (e.g., automated endoscope reprocessors or hydrotherapy equipment); 3) adherence to water-quality standards for hemodialysis, and to ventilation standards for specialized care environments (e.g., airborne infection isolation rooms, protective environments, or operating rooms); and 4) prompt management of water intrusion into the facility. Routine environmental sampling is not usually advised, except for water quality determinations in hemodialysis settings and other situations where sampling is directed by epidemiologic principles, and results can be applied directly to infection-control decisions. This report reviews previous guidelines and strategies for preventing environment-associated infections in health-care facilities and offers recommendations. These include 1) evidence-based recommendations supported by studies; 2) requirements of federal agencies (e.g., Food and Drug Administration, U.S. Environmental Protection Agency, U.S. Department of Labor, Occupational Safety and Health Administration, and U.S. Department of Justice); 3) guidelines and standards from building and equipment professional organizations (e.g., American Institute of Architects, Association for the Advancement of Medical Instrumentation, and American Society of Heating, Refrigeration, and Air-Conditioning Engineers); 4) recommendations derived from scientific theory or rationale; and 5) experienced opinions based upon infection-control and engineering practices. The report also suggests a series of performance measurements as a means to evaluate infection-control efforts.",
    "date": "2003",
    "authors": [
        "Lynne Sehulster"
    ],
    "related_topics": [
        "Isolation (health care)",
        "Infection control",
        "Health care"
    ],
    "citation_count": "1,354",
    "reference_count": "500",
    "references": [
        "1856219842",
        "2798795107",
        "1833207062",
        "2093487930",
        "2905912541",
        "1536339477",
        "2465608195",
        "2153911335",
        "2315217144",
        "1589603082"
    ]
},{
    "id": "3015636815",
    "title": "Rapid Detection of COVID-19 Causative Virus (SARS-CoV-2) in Human Nasopharyngeal Swab Specimens Using Field-Effect Transistor-Based Biosensor.",
    "abstract": "Coronavirus disease 2019 (COVID-19) is a newly emerging human infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2, previously called 2019-nCoV). Based on the rapid increase in the rate of human infection, the World Health Organization (WHO) has classified the COVID-19 outbreak as a pandemic. Because no specific drugs or vaccines for COVID-19 are yet available, early diagnosis and management are crucial for containing the outbreak. Here, we report a field-effect transistor (FET)-based biosensing device for detecting SARS-CoV-2 in clinical samples. The sensor was produced by coating graphene sheets of the FET with a specific antibody against SARS-CoV-2 spike protein. The performance of the sensor was determined using antigen protein, cultured virus, and nasopharyngeal swab specimens from COVID-19 patients. Our FET device could detect the SARS-CoV-2 spike protein at concentrations of 1 fg/mL in phosphate-buffered saline and 100 fg/mL clinical transport medium. In addition, the FET sensor successfully detected SARS-CoV-2 in culture medium (limit of detection [LOD]: 1.6 \u00d7 101 pfu/mL) and clinical samples (LOD: 2.42 \u00d7 102 copies/mL). Thus, we have successfully fabricated a promising FET biosensor for SARS-CoV-2; our device is a highly sensitive immunological diagnostic method for COVID-19 that requires no sample pretreatment or labeling.",
    "date": "2020",
    "authors": [
        "Giwan Seo",
        "Geonhee Lee",
        "Mi Jeong Kim",
        "Seung Hwa Baek",
        "Minsuk Choi",
        "Keun Bon Ku",
        "Chang Seop Lee",
        "Sangmi Jun",
        "Daeui Park",
        "Hong Gi Kim",
        "Seong Jun Kim",
        "Jeong O. Lee",
        "Bum Tae Kim",
        "Edmond Changkyun Park",
        "Seung Il Kim"
    ],
    "related_topics": [
        "Virus",
        "Antigen",
        "Detection limit"
    ],
    "citation_count": "379",
    "reference_count": "20",
    "references": [
        "3003668884",
        "3004280078",
        "2014935324",
        "3004318991",
        "3006961006",
        "3003217347",
        "3008696669",
        "3007643904",
        "3009906937",
        "2470646526"
    ]
},{
    "id": "3018724240",
    "title": "SARS-CoV-2 can be detected in urine, blood, anal swabs, and oropharyngeal swabs specimens.",
    "abstract": "Purpose The purpose of this study was to detect severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) ribonucleic acid (RNA) in urine and blood specimens, and anal and oropharyngeal swabs from patients with confirmed SARS-CoV-2 infection, and correlated positive results with clinical findings. Methods Patients with confirmed SARS-CoV-2 infections were included in this study. Patients' demographic and clinical data were recorded. Quantitative real-time polymerase chain reaction was used to detect SARS-CoV-2 RNA in urine and blood specimens, and anal and oropharyngeal swabs. The study is registered at ClinicalTrials.gov (No. NCT04279782, 19 February, 2020). Results SARS-CoV-2 RNA was present in all four specimen types, though not all specimen types were positive simultaneously. The presence of viral RNA was not necessarily predictive of clinical symptoms, for example, the presence of viral RNA in the urine did not necessarily predict urinary tract symptoms. Conclusions SARS-CoV-2 can infect multiple systems, including the urinary tract. Testing different specimen types may be useful for monitoring disease changes and progression, and for establishing a prognosis.",
    "date": "2020",
    "authors": [
        "Liang Peng",
        "Jing Liu",
        "Wenxiong Xu",
        "Qiumin Luo",
        "Dabiao Chen",
        "Ziying Lei",
        "Zhanlian Huang",
        "Xuejun Li",
        "Keji Deng",
        "Bingliang Lin",
        "Zhiliang Gao"
    ],
    "related_topics": [
        "Urinary system",
        "Urine",
        "Real-time polymerase chain reaction"
    ],
    "citation_count": "208",
    "reference_count": "5",
    "references": [
        "3001118548",
        "3002539152",
        "3003465021",
        "3010604545",
        "3011060952"
    ]
},{
    "id": "3008028633",
    "title": "Characteristics of and Important Lessons From the Coronavirus Disease 2019 (COVID-19) Outbreak in China: Summary of a Report of 72 314 Cases From the Chinese Center for Disease Control and Prevention",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Zunyou Wu",
        "Jennifer M. McGoogan"
    ],
    "related_topics": [
        "Outbreak",
        "Pandemic",
        "China"
    ],
    "citation_count": "12,282",
    "reference_count": "10",
    "references": [
        "3006533361",
        "3024919756",
        "3082757469",
        "3006044875",
        "3005409672",
        "3004434564",
        "3033263492",
        "3031410613",
        "3026023364",
        "3034094473"
    ]
},{
    "id": "3010930696",
    "title": "Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial.",
    "abstract": "Background Chloroquine and hydroxychloroquine have been found to be efficient on SARS-CoV-2, and reported to be efficient in Chinese COV-19 patients. We evaluate the role of hydroxychloroquine on respiratory viral loads. Patients and methods French Confirmed COVID-19 patients were included in a single arm protocol from early March to March 16th, to receive 600mg of hydroxychloroquine daily and their viral load in nasopharyngeal swabs was tested daily in a hospital setting. Depending on their clinical presentation, azithromycin was added to the treatment. Untreated patients from another center and cases refusing the protocol were included as negative controls. Presence and absence of virus at Day6-post inclusion was considered the end point. Results Six patients were asymptomatic, 22 had upper respiratory tract infection symptoms and eight had lower respiratory tract infection symptoms. Twenty cases were treated in this study and showed a significant reduction of the viral carriage at D6-post inclusion compared to controls, and much lower average carrying duration than reported of untreated patients in the literature. Azithromycin added to hydroxychloroquine was significantly more efficient for virus elimination. Conclusion Despite its small sample size our survey shows that hydroxychloroquine treatment is significantly associated with viral load reduction/disappearance in COVID-19 patients and its effect is reinforced by azithromycin.",
    "date": "2020",
    "authors": [
        "Philippe Gautret",
        "Jean Christophe Lagier",
        "Philippe Parola",
        "Van Thuan Hoang",
        "Line Meddeb",
        "Morgane Mailhe",
        "Barbara Doudier",
        "Johan Courjon",
        "Val\u00e9rie Giordanengo",
        "Vera Esteves Vieira",
        "Herv\u00e9 Tissot Dupont",
        "St\u00e9phane Honor\u00e9",
        "Philippe Colson",
        "Eric Chabri\u00e8re",
        "Bernard La Scola",
        "Jean Marc Rolain",
        "Philippe Brouqui",
        "Didier Raoult"
    ],
    "related_topics": [
        "Hydroxychloroquine",
        "Viral load",
        "Lower respiratory tract infection"
    ],
    "citation_count": "4,339",
    "reference_count": "30",
    "references": [
        "3009885589",
        "3008028633",
        "3005212621",
        "3006645647",
        "3009577418",
        "3008763357",
        "3010277308",
        "2302013022",
        "3024400578",
        "3011032288"
    ]
},{
    "id": "3014294089",
    "title": "Baseline Characteristics and Outcomes of 1591 Patients Infected With SARS-CoV-2 Admitted to ICUs of the Lombardy Region, Italy.",
    "abstract": "Importance In December 2019, a novel coronavirus (severe acute respiratory syndrome coronavirus 2 [SARS-CoV-2]) emerged in China and has spread globally, creating a pandemic. Information about the clinical characteristics of infected patients who require intensive care is limited. Objective To characterize patients with coronavirus disease 2019 (COVID-19) requiring treatment in an intensive care unit (ICU) in the Lombardy region of Italy. Design, Setting, and Participants Retrospective case series of 1591 consecutive patients with laboratory-confirmed COVID-19 referred for ICU admission to the coordinator center (Fondazione IRCCS Ca\u2019 Granda Ospedale Maggiore Policlinico, Milan, Italy) of the COVID-19 Lombardy ICU Network and treated at one of the ICUs of the 72 hospitals in this network between February 20 and March 18, 2020. Date of final follow-up was March 25, 2020. Exposures SARS-CoV-2 infection confirmed by real-time reverse transcriptase\u2013polymerase chain reaction (RT-PCR) assay of nasal and pharyngeal swabs. Main Outcomes and Measures Demographic and clinical data were collected, including data on clinical management, respiratory failure, and patient mortality. Data were recorded by the coordinator center on an electronic worksheet during telephone calls by the staff of the COVID-19 Lombardy ICU Network. Results Of the 1591 patients included in the study, the median (IQR) age was 63 (56-70) years and 1304 (82%) were male. Of the 1043 patients with available data, 709 (68%) had at least 1 comorbidity and 509 (49%) had hypertension. Among 1300 patients with available respiratory support data, 1287 (99% [95% CI, 98%-99%]) needed respiratory support, including 1150 (88% [95% CI, 87%-90%]) who received mechanical ventilation and 137 (11% [95% CI, 9%-12%]) who received noninvasive ventilation. The median positive end-expiratory pressure (PEEP) was 14 (IQR, 12-16) cm H2O, and Fio2was greater than 50% in 89% of patients. The median Pao2/Fio2was 160 (IQR, 114-220). The median PEEP level was not different between younger patients (n\u2009=\u2009503 aged \u226463 years) and older patients (n\u2009=\u2009514 aged \u226564 years) (14 [IQR, 12-15] vs 14 [IQR, 12-16] cm H2O, respectively; median difference, 0 [95% CI, 0-0];P\u2009=\u2009.94). Median Fio2was lower in younger patients: 60% (IQR, 50%-80%) vs 70% (IQR, 50%-80%) (median difference, \u221210% [95% CI, \u221214% to 6%];P\u2009=\u2009.006), and median Pao2/Fio2was higher in younger patients: 163.5 (IQR, 120-230) vs 156 (IQR, 110-205) (median difference, 7 [95% CI, \u22128 to 22];P\u2009=\u2009.02). Patients with hypertension (n\u2009=\u2009509) were older than those without hypertension (n\u2009=\u2009526) (median [IQR] age, 66 years [60-72] vs 62 years [54-68];P\u2009 Conclusions and Relevance In this case series of critically ill patients with laboratory-confirmed COVID-19 admitted to ICUs in Lombardy, Italy, the majority were older men, a large proportion required mechanical ventilation and high levels of PEEP, and ICU mortality was 26%.",
    "date": "2020",
    "authors": [
        "Giacomo Grasselli",
        "Alberto Zangrillo",
        "Alberto Zanella",
        "Massimo Antonelli",
        "Luca Cabrini",
        "Antonio Castelli",
        "Danilo Cereda",
        "Antonio Coluccello",
        "Giuseppe Foti",
        "Roberto Fumagalli",
        "Giorgio Iotti",
        "Nicola Latronico",
        "Luca Lorini",
        "Stefano Merler",
        "Giuseppe Natalini",
        "Alessandra Piatti",
        "Marco Vito Ranieri",
        "Anna Mara Scandroglio",
        "Enrico Storti",
        "Maurizio Cecconi",
        "Antonio Pesenti"
    ],
    "related_topics": [
        "Intensive care",
        "Intensive care unit",
        "Respiratory failure"
    ],
    "citation_count": "3,036",
    "reference_count": "9",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3009885589",
        "3008090866",
        "3011508296",
        "3011559677",
        "3014538785",
        "2158525457"
    ]
},{
    "id": "2120419212",
    "title": "A discriminatively trained, multiscale, deformable part model",
    "abstract": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose.",
    "date": "2008",
    "authors": [
        "P. Felzenszwalb",
        "D. McAllester",
        "D. Ramanan"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Support vector machine",
        "Discriminative model"
    ],
    "citation_count": "3,069",
    "reference_count": "24",
    "references": [
        "2161969291",
        "2154422044",
        "1576520375",
        "2030536784",
        "2112020727",
        "2186094539",
        "2101534792",
        "1518641734",
        "1970255615",
        "2166770390"
    ]
},{
    "id": "2152826865",
    "title": "Active appearance models",
    "abstract": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.",
    "date": "2001",
    "authors": [
        "T.F. Cootes",
        "G.J. Edwards",
        "C.J. Taylor"
    ],
    "related_topics": [
        "Active appearance model",
        "Active shape model",
        "Point distribution model"
    ],
    "citation_count": "10,255",
    "reference_count": "28",
    "references": [
        "2138451337",
        "2152826865",
        "2038952578",
        "2408227189",
        "2095757522",
        "2103876808",
        "2159173611",
        "2129150631",
        "2293264518",
        "2133001582"
    ]
},{
    "id": "2145072179",
    "title": "PCA-SIFT: a more distinctive representation for local image descriptors",
    "abstract": "Stable local feature detection and representation is a fundamental component of many image registration and object recognition algorithms. Mikolajczyk and Schmid (June 2003) recently evaluated a variety of approaches and identified the SIFT [D. G. Lowe, 1999] algorithm as being the most resistant to common image deformations. This paper examines (and improves upon) the local image descriptor used by SIFT. Like SIFT, our descriptors encode the salient aspects of the image gradient in the feature point's neighborhood; however, instead of using SIFT's smoothed weighted histograms, we apply principal components analysis (PCA) to the normalized gradient patch. Our experiments demonstrate that the PCA-based local descriptors are more distinctive, more robust to image deformations, and more compact than the standard SIFT representation. We also present results showing that using these descriptors in an image retrieval application results in increased accuracy and faster matching.",
    "date": "2004",
    "authors": [
        "Yan Ke",
        "R. Sukthankar"
    ],
    "related_topics": [
        "Principal curvature-based region detector",
        "Feature detection (computer vision)",
        "GLOH"
    ],
    "citation_count": "4,915",
    "reference_count": "17",
    "references": [
        "2151103935",
        "2124386111",
        "2177274842",
        "1902027874",
        "2154422044",
        "2148694408",
        "2119747362",
        "2111308925",
        "2098693229",
        "1541642243"
    ]
},{
    "id": "1576520375",
    "title": "Making large scale SVM learning practical",
    "abstract": "Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains.",
    "date": "1999",
    "authors": [
        "Thorsten Joachims"
    ],
    "related_topics": [
        "Ranking SVM",
        "Support vector machine",
        "Quadratic programming"
    ],
    "citation_count": "15,933",
    "reference_count": "0",
    "references": []
},{
    "id": "2115763357",
    "title": "A general framework for object detection",
    "abstract": "This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general.",
    "date": "1998",
    "authors": [
        "C.P. Papageorgiou",
        "M. Oren",
        "T. Poggio"
    ],
    "related_topics": [
        "Object-class detection",
        "Object detection",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "2,117",
    "reference_count": "16",
    "references": [
        "2132984323",
        "2087347434",
        "2124351082",
        "2125848778",
        "2104671481",
        "2159173611",
        "2137346077",
        "2056695679",
        "1676612073",
        "2030989822"
    ]
},{
    "id": "2161381512",
    "title": "Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks",
    "abstract": "Convolutional neural networks (CNN) have recently shown outstanding image classification performance in the large- scale visual recognition challenge (ILSVRC2012). The suc- cess of CNNs is attributed to their ability to learn rich mid- level image representations as opposed to hand-designed low-level features used in other image classification meth- ods. Learning CNNs, however, amounts to estimating mil- lions of parameters and requires a very large number of annotated image samples. This property currently prevents application of CNNs to problems with limited training data. In this work we show how image representations learned with CNNs on large-scale annotated datasets can be effi- ciently transferred to other visual recognition tasks with limited amount of training data. We design a method to reuse layers trained on the ImageNet dataset to compute mid-level image representation for images in the PASCAL VOC dataset. We show that despite differences in image statistics and tasks in the two datasets, the transferred rep- resentation leads to significantly improved results for object and action classification, outperforming the current state of the art on Pascal VOC 2007 and 2012 datasets. We also show promising results for object and action localization.",
    "date": "2014",
    "authors": [
        "Maxime Oquab",
        "Leon Bottou",
        "Ivan Laptev",
        "Josef Sivic"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Contextual image classification",
        "Pascal (programming language)"
    ],
    "citation_count": "2,959",
    "reference_count": "53",
    "references": [
        "2618530766",
        "2151103935",
        "2102605133",
        "2108598243",
        "2161969291",
        "2168356304",
        "1849277567",
        "2963542991",
        "2310919327",
        "2031489346"
    ]
},{
    "id": "2166851633",
    "title": "Stochastic variational inference",
    "abstract": "We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.",
    "date": "2012",
    "authors": [
        "Matthew D. Hoffman",
        "David M. Blei",
        "Chong Wang",
        "John Paisley"
    ],
    "related_topics": [
        "Frequentist inference",
        "Variational message passing",
        "Fiducial inference"
    ],
    "citation_count": "1,963",
    "reference_count": "97",
    "references": [
        "1880262756",
        "1503398984",
        "2125838338",
        "1506806321",
        "1511986666",
        "1981457167",
        "2159080219",
        "2001082470",
        "2174706414",
        "2158266063"
    ]
},{
    "id": "2097268041",
    "title": "Deep AutoRegressive Networks",
    "abstract": "We introduce a deep, generative autoencoder capable of learning hierarchies of distributed representations from data. Successive deep stochastic hidden layers are equipped with autoregressive connections, which enable the model to be sampled from quickly and exactly via ancestral sampling. We derive an efficient approximate parameter estimation method based on the minimum description length (MDL) principle, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference. We demonstrate state-of-the-art generative performance on a number of classic data sets, including several UCI data sets, MNIST and Atari 2600 games.",
    "date": "2014",
    "authors": [
        "Karol Gregor",
        "Ivo Danihelka",
        "Andriy Mnih",
        "Charles Blundell",
        "Daan Wierstra"
    ],
    "related_topics": [
        "Autoencoder",
        "Approximate inference",
        "Feedforward neural network"
    ],
    "citation_count": "223",
    "reference_count": "28",
    "references": [
        "2310919327",
        "3120740533",
        "2025768430",
        "3140968660",
        "1810943226",
        "2952509347",
        "189596042",
        "2096192494",
        "2108677974",
        "2134842679"
    ]
},{
    "id": "2963173382",
    "title": "Black Box Variational Inference",
    "abstract": "Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires signicant model-specic analysis. These eorts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a \\black box\" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid dicult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We nd that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data.",
    "date": "2014",
    "authors": [
        "Rajesh Ranganath",
        "Sean Gerrish",
        "David M. Blei"
    ],
    "related_topics": [
        "Inference",
        "Black box",
        "Stochastic optimization"
    ],
    "citation_count": "799",
    "reference_count": "20",
    "references": [
        "1663973292",
        "1959608418",
        "2146502635",
        "2166851633",
        "2120340025",
        "1516111018",
        "2951493172",
        "2128925311",
        "2119196781",
        "3104819538"
    ]
},{
    "id": "2951493172",
    "title": "Variational Bayesian Inference with Stochastic Search",
    "abstract": "Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.",
    "date": "2012",
    "authors": [
        "John Paisley",
        "David Blei",
        "Michael Jordan"
    ],
    "related_topics": [
        "Bayesian inference",
        "Stochastic optimization",
        "Marginal likelihood"
    ],
    "citation_count": "306",
    "reference_count": "10",
    "references": [
        "1880262756",
        "2158266063",
        "2108677974",
        "2115979064",
        "2127498532",
        "2187741934",
        "2117111086",
        "1496451467",
        "2142508340",
        "2162995719"
    ]
},{
    "id": "2171490498",
    "title": "Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition",
    "abstract": "Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model also provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks.",
    "date": "2010",
    "authors": [
        "Koray Kavukcuoglu",
        "Marc'Aurelio Ranzato",
        "Yann LeCun"
    ],
    "related_topics": [
        "Sparse approximation",
        "3D single-object recognition",
        "Neural coding"
    ],
    "citation_count": "305",
    "reference_count": "18",
    "references": [
        "2310919327",
        "2100495367",
        "2116064496",
        "2063978378",
        "2078204800",
        "2166049352",
        "2151693816",
        "2113606819",
        "2154332973",
        "2139427956"
    ]
},{
    "id": "2119196781",
    "title": "Variational Bayesian Inference with Stochastic Search",
    "abstract": "Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.",
    "date": "2012",
    "authors": [
        "David M. Blei",
        "Michael I. Jordan",
        "John W. Paisley"
    ],
    "related_topics": [
        "Bayesian linear regression",
        "Bayesian inference",
        "Stochastic optimization"
    ],
    "citation_count": "404",
    "reference_count": "14",
    "references": [
        "1880262756",
        "2158266063",
        "2108677974",
        "1516111018",
        "2165599843",
        "2115979064",
        "2127498532",
        "2187741934",
        "2117111086",
        "1496451467"
    ]
},{
    "id": "3104819538",
    "title": "Fixed-form variational posterior approximation through stochastic linear regression",
    "abstract": "textabstractWe propose a general algorithm for approximating nonstandard Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler divergence of an approximating distribution to the intractable posterior distribu- tion. Our method can be used to approximate any posterior distribution, provided that it is given in closed form up to the proportionality constant. The approxi- mation can be any distribution in the exponential family or any mixture of such distributions, which means that it can be made arbitrarily precise. Several exam- ples illustrate the speed and accuracy of our approximation method in practice.",
    "date": "2013",
    "authors": [
        "Tim Salimans",
        "David A. Knowles"
    ],
    "related_topics": [
        "Exponential family",
        "Posterior probability",
        "Stochastic approximation"
    ],
    "citation_count": "187",
    "reference_count": "37",
    "references": [
        "1663973292",
        "114517082",
        "2166851633",
        "2120340025",
        "1992208280",
        "1516111018",
        "1545319692",
        "2165599843",
        "3125096521",
        "1515272691"
    ]
},{
    "id": "4919037",
    "title": "Regularization of Neural Networks using DropConnect",
    "abstract": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.",
    "date": "2013",
    "authors": [
        "Li Wan",
        "Matthew Zeiler",
        "Sixin Zhang",
        "Yann Le Cun",
        "Rob Fergus"
    ],
    "related_topics": [
        "Artificial neural network",
        "Pattern recognition",
        "Regularization (mathematics)"
    ],
    "citation_count": "2,315",
    "reference_count": "13",
    "references": [
        "3118608800",
        "2310919327",
        "1904365287",
        "1665214252",
        "2131241448",
        "2335728318",
        "2141125852",
        "2134557905",
        "2963574257",
        "188867022"
    ]
},{
    "id": "2206858481",
    "title": "Visualizing and Understanding Convolutional Neural Networks",
    "abstract": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky \\etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
    "date": "2013",
    "authors": [
        "Matthew D Zeiler",
        "Rob Fergus"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Softmax function",
        "Classifier (linguistics)"
    ],
    "citation_count": "474",
    "reference_count": "0",
    "references": []
},{
    "id": "2120480077",
    "title": "Building high-level features using large scale unsupervised learning",
    "abstract": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a deep sparse autoencoder on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200\u00d7200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting from these learned features, we trained our network to recognize 22,000 object categories from ImageNet and achieve a leap of 70% relative improvement over the previous state-of-the-art.",
    "date": "2013",
    "authors": [
        "Quoc V. Le"
    ],
    "related_topics": [
        "Autoencoder",
        "Unsupervised learning",
        "Object detection"
    ],
    "citation_count": "2,551",
    "reference_count": "47",
    "references": [
        "2108598243",
        "2136922672",
        "3118608800",
        "2310919327",
        "2100495367",
        "2168231600",
        "2546302380",
        "2110798204",
        "1782590233",
        "2130325614"
    ]
},{
    "id": "2150165932",
    "title": "How to Explain Individual Classification Decisions",
    "abstract": "After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most influential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classification method.",
    "date": "2010",
    "authors": [
        "David Baehrens",
        "Timon Schroeter",
        "Stefan Harmeling",
        "Motoaki Kawanabe",
        "Katja Hansen",
        "Klaus-Robert M\u00fcller"
    ],
    "related_topics": [
        "Decision tree",
        "Classifier (UML)",
        "Black box"
    ],
    "citation_count": "668",
    "reference_count": "39",
    "references": [
        "2156909104",
        "1746819321",
        "1554663460",
        "1480376833",
        "2119479037",
        "3023786531",
        "740415",
        "2108995755",
        "1618905105",
        "1564947197"
    ]
},{
    "id": "1948751323",
    "title": "Hypercolumns for object segmentation and fine-grained localization",
    "abstract": "Recognition algorithms based on convolutional networks (CNNs) typically use the output of the last layer as a feature representation. However, the information in this layer may be too coarse spatially to allow precise localization. On the contrary, earlier layers may be precise in localization but will not capture semantics. To get the best of both worlds, we define the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel. Using hypercolumns as pixel descriptors, we show results on three fine-grained localization tasks: simultaneous detection and segmentation [22], where we improve state-of-the-art from 49.7 mean APr [22] to 60.0, keypoint localization, where we get a 3.3 point boost over [20], and part labeling, where we show a 6.6 point gain over a strong baseline.",
    "date": "2015",
    "authors": [
        "Bharath Hariharan",
        "Pablo Arbelaez",
        "Ross Girshick",
        "Jitendra Malik"
    ],
    "related_topics": [
        "Image segmentation",
        "Pixel",
        "Feature (computer vision)"
    ],
    "citation_count": "1,476",
    "reference_count": "42",
    "references": [
        "2618530766",
        "2962835968",
        "2102605133",
        "1903029394",
        "2168356304",
        "2109255472",
        "2156303437",
        "2022508996",
        "2118585731",
        "1507506748"
    ]
},{
    "id": "2167510172",
    "title": "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images",
    "abstract": "We address a central problem of neuroanatomy, namely, the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efficiently map 3D brain structure and connectivity. To segment biological neuron membranes, we use a special type of deep artificial neural network as a pixel classifier. The label of each pixel (membrane or non-membrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classifier is trained by plain gradient descent on a 512 \u00d7 512 \u00d7 30 stack with known ground truth, and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-specific postprocessing, our approach outperforms competing techniques by a large margin in all three considered metrics, i.e. rand error, warping error and pixel error. For pixel error, our approach is the only one outperforming a second human observer.",
    "date": "2012",
    "authors": [
        "Dan Ciresan",
        "Alessandro Giusti",
        "Luca M. Gambardella",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Pixel",
        "Ground truth",
        "Artificial neural network"
    ],
    "citation_count": "1,455",
    "reference_count": "28",
    "references": [
        "2310919327",
        "2141125852",
        "2143516773",
        "2156163116",
        "2148461049",
        "1624854622",
        "2132424367",
        "1969013163",
        "1523493493",
        "2149194912"
    ]
},{
    "id": "1893585201",
    "title": "Learning to generate chairs with convolutional neural networks",
    "abstract": "We train a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color. We train the network in a supervised manner on a dataset of rendered 3D chair models. Our experiments show that the network does not merely learn all images by heart, but rather finds a meaningful representation of a 3D chair model allowing it to assess the similarity of different chairs, interpolate between given viewpoints to generate the missing ones, or invent new chair styles by interpolating between chairs from the training set. We show that the network can be used to find correspondences between different chairs from the dataset, outperforming existing approaches on this task.",
    "date": "2015",
    "authors": [
        "Alexey Dosovitskiy",
        "Jost Tobias Springenberg",
        "Thomas Brox"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Representation (mathematics)",
        "Artificial intelligence"
    ],
    "citation_count": "682",
    "reference_count": "35",
    "references": [
        "2618530766",
        "2102605133",
        "2099471712",
        "2155893237",
        "2136922672",
        "1849277567",
        "2963542991",
        "1959608418",
        "2100495367",
        "2155541015"
    ]
},{
    "id": "2148349024",
    "title": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
    "abstract": "Current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training. In this paper we present an approach for training a convolutional neural network using only unlabeled data. We train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. We find that this simple feature learning algorithm is surprisingly successful when applied to visual object recognition. The feature representation learned by our algorithm achieves classification results matching or outperforming the current state-of-the-art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101).",
    "date": "2014",
    "authors": [
        "Alexey Dosovitskiy",
        "Jost Tobias Springenberg",
        "Martin Riedmiller",
        "Thomas Brox"
    ],
    "related_topics": [
        "Deep learning",
        "Unsupervised learning",
        "Semi-supervised learning"
    ],
    "citation_count": "657",
    "reference_count": "32",
    "references": [
        "2618530766",
        "2102605133",
        "2155893237",
        "1849277567",
        "2109255472",
        "3118608800",
        "1904365287",
        "2155541015",
        "2158899491",
        "2963911037"
    ]
},{
    "id": "2159269332",
    "title": "A universal image quality index",
    "abstract": "We propose a new universal objective image quality index, which is easy to calculate and applicable to various image processing applications. Instead of using traditional error summation methods, the proposed index is designed by modeling any image distortion as a combination of three factors: loss of correlation, luminance distortion, and contrast distortion. Although the new index is mathematically defined and no human visual system model is explicitly employed, our experiments on various image distortion types indicate that it performs significantly better than the widely used distortion metric mean squared error. Demonstrative images and an efficient MATLAB implementation of the algorithm are available online at http://anchovy.ece.utexas.edu//spl sim/zwang/research/quality_index/demo.html.",
    "date": "2002",
    "authors": [
        "Zhou Wang",
        "A.C. Bovik"
    ],
    "related_topics": [
        "Distortion",
        "Image quality",
        "Image processing"
    ],
    "citation_count": "5,955",
    "reference_count": "3",
    "references": [
        "2153777140",
        "2912116903",
        "1543242897"
    ]
},{
    "id": "2142276208",
    "title": "A new, fast, and efficient image codec based on set partitioning in hierarchical trees",
    "abstract": "Embedded zerotree wavelet (EZW) coding, introduced by Shapiro (see IEEE Trans. Signal Processing, vol.41, no.12, p.3445, 1993), is a very effective and computationally simple technique for image compression. We offer an alternative explanation of the principles of its operation, so that the reasons for its excellent performance can be better understood. These principles are partial ordering by magnitude with a set partitioning sorting algorithm, ordered bit plane transmission, and exploitation of self-similarity across different scales of an image wavelet transform. Moreover, we present a new and different implementation based on set partitioning in hierarchical trees (SPIHT), which provides even better performance than our previously reported extension of EZW that surpassed the performance of the original EZW. The image coding results, calculated from actual file sizes and images reconstructed by the decoding algorithm, are either comparable to or surpass previous results obtained through much more sophisticated and computationally complex methods. In addition, the new coding and decoding procedures are extremely fast, and they can be made even faster, with only small loss in performance, by omitting entropy coding of the bit stream by the arithmetic code.",
    "date": "1996",
    "authors": [
        "A. Said",
        "W.A. Pearlman"
    ],
    "related_topics": [
        "Set partitioning in hierarchical trees",
        "Data compression",
        "Entropy encoding"
    ],
    "citation_count": "8,615",
    "reference_count": "16",
    "references": [
        "2053691921",
        "2148593155",
        "2103504761",
        "2129652681",
        "1931641413",
        "2166087152",
        "2058719583",
        "1592970628",
        "2147399030",
        "2117465325"
    ]
},{
    "id": "2118217749",
    "title": "JPEG2000 : image compression fundamentals, standards, and practice",
    "abstract": "This is nothing less than a totally essential reference for engineers and researchers in any field of work that involves the use of compressed imagery. Beginning with a thorough and up-to-date overview of the fundamentals of image compression, the authors move on to provide a complete description of the JPEG2000 standard. They then devote space to the implementation and exploitation of that standard. The final section describes other key image compression systems. This work has specific applications for those involved in the development of software and hardware solutions for multimedia, internet, and medical imaging applications.",
    "date": "2001",
    "authors": [
        "David S. Taubman",
        "Michael W. Marcellin"
    ],
    "related_topics": [
        "Image compression",
        "The Internet",
        "Software"
    ],
    "citation_count": "4,971",
    "reference_count": "0",
    "references": []
},{
    "id": "2053691921",
    "title": "Embedded image coding using zerotrees of wavelet coefficients",
    "abstract": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >",
    "date": "1993",
    "authors": [
        "J.M. Shapiro"
    ],
    "related_topics": [
        "Data compression",
        "Set partitioning in hierarchical trees",
        "Lossless compression"
    ],
    "citation_count": "7,975",
    "reference_count": "33",
    "references": [
        "2132984323",
        "2098914003",
        "2140196014",
        "1996021349",
        "2156447271",
        "1970352604",
        "2103504761",
        "2129652681",
        "2166982406",
        "2186435531"
    ]
},{
    "id": "2153777140",
    "title": "Image quality measures and their performance",
    "abstract": "A number of quality measures are evaluated for gray scale image compression. They are all bivariate, exploiting the differences between corresponding pixels in the original and degraded images. It is shown that although some numerical measures correlate well with the observers' response for a given compression technique, they are not reliable for an evaluation across different techniques. A graphical measure called Hosaka plots, however, can be used to appropriately specify not only the amount, but also the type of degradation in reconstructed images.",
    "date": "1995",
    "authors": [
        "A.M. Eskicioglu",
        "P.S. Fisher"
    ],
    "related_topics": [
        "Image quality",
        "Image compression",
        "Data compression"
    ],
    "citation_count": "2,002",
    "reference_count": "3",
    "references": [
        "3021180913",
        "1487065163",
        "2170745401"
    ]
},{
    "id": "2912116903",
    "title": "Image dissimilarity",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Jean-Bernard Martens",
        "Lydia Meesters"
    ],
    "related_topics": [
        "Image (mathematics)",
        "Computer vision",
        "Computer science"
    ],
    "citation_count": "141",
    "reference_count": "24",
    "references": [
        "2103504761",
        "1991605728",
        "2103232506",
        "2134774992",
        "42232744",
        "1990873664",
        "2108657140",
        "1551978325",
        "2056930330",
        "2118491738"
    ]
},{
    "id": "2107790757",
    "title": "Shiftable multiscale transforms",
    "abstract": "One of the major drawbacks of orthogonal wavelet transforms is their lack of translation invariance: the content of wavelet subbands is unstable under translations of the input signal. Wavelet transforms are also unstable with respect to dilations of the input signal and, in two dimensions, rotations of the input signal. The authors formalize these problems by defining a type of translation invariance called shiftability. In the spatial domain, shiftability corresponds to a lack of aliasing; thus, the conditions under which the property holds are specified by the sampling theorem. Shiftability may also be applied in the context of other domains, particularly orientation and scale. Jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored. Two examples of jointly shiftable transforms are designed and implemented: a 1-D transform that is jointly shiftable in position and scale, and a 2-D transform that is jointly shiftable in position and orientation. The usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated. >",
    "date": "1992",
    "authors": [
        "E.P. Simoncelli",
        "W.T. Freeman",
        "E.H. Adelson",
        "D.J. Heeger"
    ],
    "related_topics": [
        "Wavelet",
        "Orthogonal wavelet",
        "Wavelet transform"
    ],
    "citation_count": "1,960",
    "reference_count": "47",
    "references": [
        "2170120409",
        "2132984323",
        "2098914003",
        "1996021349",
        "2103504761",
        "1991605728",
        "2118877769",
        "2109863423",
        "2166982406",
        "1627054999"
    ]
},{
    "id": "2158564760",
    "title": "Why is image quality assessment so difficult",
    "abstract": "Image quality assessment plays an important role in various image processing applications. A great deal of effort has been made in recent years to develop objective image quality metrics that correlate with perceived quality measurement. Unfortunately, only limited success has been achieved. In this paper, we provide some insights on why image quality assessment is so difficult by pointing out the weaknesses of the error sensitivity based framework, which has been used by most image quality assessment approaches in the literature. Furthermore, we propose a new philosophy in designing image quality metrics: The main function of the human eyes is to extract structural information from the viewing field, and the human visual system is highly adapted for this purpose. Therefore, a measurement of structural distortion should be a good approximation of perceived image distortion. Based on the new philosophy, we implemented a simple but effective image quality indexing algorithm, which is very promising as shown by our current results.",
    "date": "2002",
    "authors": [
        "Zhou Wang",
        "Alan C. Bovik",
        "Ligang Lu"
    ],
    "related_topics": [
        "Image quality",
        "Subjective video quality",
        "Image processing"
    ],
    "citation_count": "926",
    "reference_count": "10",
    "references": [
        "2159269332",
        "2153777140",
        "2912116903",
        "2145792107",
        "1543242897",
        "2015937190",
        "1527289589",
        "42232744",
        "2029826041",
        "1990873664"
    ]
},{
    "id": "2124731682",
    "title": "Image compression via joint statistical characterization in the wavelet domain",
    "abstract": "We develop a probability model for natural images, based on empirical observation of their statistics in the wavelet transform domain. Pairs of wavelet coefficients, corresponding to basis functions at adjacent spatial locations, orientations, and scales, are found to be non-Gaussian in both their marginal and joint statistical properties. Specifically, their marginals are heavy-tailed, and although they are typically decorrelated, their magnitudes are highly correlated. We propose a Markov model that explains these dependencies using a linear predictor for magnitude coupled with both multiplicative and additive uncertainties, and show that it accounts for the statistics of a wide variety of images including photographic images, graphical images, and medical images. In order to directly demonstrate the power of the model, we construct an image coder called EPWIC (embedded predictive wavelet image coder), in which subband coefficients are encoded one bitplane at a time using a nonadaptive arithmetic encoder that utilizes conditional probabilities calculated from the model. Bitplanes are ordered using a greedy algorithm that considers the MSE reduction per encoded bit. The decoder uses the statistical model to predict coefficient values based on the bits it has received. Despite the simplicity of the model, the rate-distortion performance of the coder is roughly comparable to the best image coders in the literature.",
    "date": "1999",
    "authors": [
        "R.W. Buccigrossi",
        "E.P. Simoncelli"
    ],
    "related_topics": [
        "Wavelet transform",
        "Wavelet",
        "Statistical model"
    ],
    "citation_count": "779",
    "reference_count": "39",
    "references": [
        "2132984323",
        "2151693816",
        "2053691921",
        "2408227189",
        "2148593155",
        "2156447271",
        "2103504761",
        "1490632837",
        "2107790757",
        "2180838288"
    ]
},{
    "id": "2115838129",
    "title": "Linear transform for simultaneous diagonalization of covariance and perceptual metric matrix in image coding",
    "abstract": "Two types ofredundancies are contained in images: statistical redundancy and psychovisual redundancy. Image representation techniques for image coding should remove both redundancies in order to obtain good results. In order to establish an appropriate representation, the standard approach to transform coding only considers the statistical redundancy, whereas the psychovisual factors are introduced after the selection ofthe representation as a simple scalar weighting in the transform domain. In this work, we take into account the psychovisual factors in the de8nition of the representation together with the statistical factors, by means of the perceptual metric and the covariance matrix, respectively. In general the ellipsoids described by these matrices are not aligned. Therefore, the optimal basis for image representation should simultaneously diagonalize both matrices. This approach to the basis selection problem has several advantages in the particular application ofimage coding. As the transform domain is Euclidean (by de8nition), the quantizer design is highly simpli8ed and at the same time, the use ofscalar quantizers is truly justi8ed. The proposed representation is compared to covariance-based representations such as the DCT and the KLT or PCA using standard JPEG-like and Max-Lloyd quantizers. ? 2003 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.",
    "date": "2003",
    "authors": [
        "Irene Epifanio",
        "Jaime Gutierrez",
        "Jesus Malo"
    ],
    "related_topics": [
        "Transform coding",
        "Covariance matrix",
        "Covariance"
    ],
    "citation_count": "28",
    "reference_count": "31",
    "references": [
        "1548802052",
        "2798909945",
        "2140196014",
        "1634005169",
        "2145889472",
        "3017143921",
        "2137234026",
        "2134383396",
        "98769269",
        "1500256440"
    ]
},{
    "id": "2131975293",
    "title": "Resilient distributed datasets: a fault-tolerant abstraction for in-memory cluster computing",
    "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
    "date": "2012",
    "authors": [
        "Matei Zaharia",
        "Mosharaf Chowdhury",
        "Tathagata Das",
        "Ankur Dave",
        "Justin Ma",
        "Murphy McCauley",
        "Michael J. Franklin",
        "Scott Shenker",
        "Ion Stoica"
    ],
    "related_topics": [
        "Distributed memory",
        "Shared memory",
        "Computer cluster"
    ],
    "citation_count": "5,211",
    "reference_count": "39",
    "references": [
        "2173213060",
        "1554944419",
        "3013264884",
        "2170616854",
        "2100830825",
        "2098935637",
        "2096125134",
        "2163961697",
        "2060204338",
        "2109722477"
    ]
},{
    "id": "2125389028",
    "title": "Conditional Generative Adversarial Nets",
    "abstract": "Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.",
    "date": "2014",
    "authors": [
        "Mehdi Mirza",
        "Simon Osindero"
    ],
    "related_topics": [
        "Generative model",
        "Generative Design",
        "MNIST database"
    ],
    "citation_count": "6,725",
    "reference_count": "15",
    "references": [
        "2097117768",
        "2099471712",
        "1614298861",
        "1904365287",
        "2546302380",
        "2294059674",
        "2123024445",
        "2951446714",
        "154472438",
        "1496559305"
    ]
},{
    "id": "2962897886",
    "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models",
    "abstract": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent an approximate posterior distribution and uses this for optimisation of a variational lower bound. We develop stochastic backpropagation - rules for gradient backpropagation through stochastic variables - and derive an algorithm that allows for joint optimisation of the parameters of both the generative and recognition models. We demonstrate on several real-world data sets that by using stochastic backpropagation and variational inference, we obtain models that are able to generate realistic samples of data, allow for accurate imputations of missing data, and provide a useful tool for high-dimensional data visualisation.",
    "date": "2014",
    "authors": [
        "Danilo Jimenez Rezende",
        "Shakir Mohamed",
        "Daan Wierstra"
    ],
    "related_topics": [
        "Approximate inference",
        "Bayesian inference",
        "Backpropagation"
    ],
    "citation_count": "3,173",
    "reference_count": "33",
    "references": [
        "1959608418",
        "2145094598",
        "2335728318",
        "2166851633",
        "2951446714",
        "2044758663",
        "2108677974",
        "2097268041",
        "2963173382",
        "2167433878"
    ]
},{
    "id": "2136504847",
    "title": "Semi-Supervised Learning Literature Survey",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Xiaojin Zhu"
    ],
    "related_topics": [
        "Literature survey",
        "Semi-supervised learning",
        "Co-training"
    ],
    "citation_count": "4,476",
    "reference_count": "157",
    "references": [
        "1880262756",
        "2148603752",
        "2053186076",
        "2121947440",
        "2001141328",
        "2125838338",
        "2165874743",
        "2097308346",
        "2114524997",
        "1479807131"
    ]
},{
    "id": "1676820704",
    "title": "Solving multiclass learning problems via error-correcting output codes",
    "abstract": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.",
    "date": "1994",
    "authors": [
        "Thomas G. Dietterich",
        "Ghulum Bakiri"
    ],
    "related_topics": [
        "Multiclass classification",
        "Multi-task learning",
        "Semi-supervised learning"
    ],
    "citation_count": "3,561",
    "reference_count": "23",
    "references": [
        "2154642048",
        "1594031697",
        "2147800946",
        "2173629880",
        "2019363670",
        "2093717447",
        "3036751298",
        "2176028050",
        "1667614912",
        "1980501707"
    ]
},{
    "id": "2407712691",
    "title": "Deep Learning via Semi-Supervised Embedding",
    "abstract": "We show how nonlinear embedding algorithms popular for use with \"shallow\" semi-supervised learning techniques such as kernel methods can be easily applied to deep multi-layer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This trick provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques.",
    "date": "2011",
    "authors": [
        "Jason Weston",
        "Fr\u00e9d\u00e9ric Ratle",
        "Hossein Mobahi",
        "Ronan Collobert"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Kernel method",
        "Embedding"
    ],
    "citation_count": "1,016",
    "reference_count": "13",
    "references": [
        "2136922672",
        "2310919327",
        "2001141328",
        "2097308346",
        "1479807131",
        "2139427956",
        "2914746235",
        "2159291644",
        "2145038566",
        "2148029428"
    ]
},{
    "id": "2158049734",
    "title": "Semi-Supervised Learning for Natural Language",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Percy Liang"
    ],
    "related_topics": [
        "Informatics engineering",
        "Semi-supervised learning",
        "Applied science"
    ],
    "citation_count": "408",
    "reference_count": "74",
    "references": [
        "2147880316",
        "2139212933",
        "2121947440",
        "2048679005",
        "2008652694",
        "2097089247",
        "2138745909",
        "2156515921",
        "2107008379",
        "2144578941"
    ]
},{
    "id": "2122457239",
    "title": "Semi-Supervised Learning in Gigantic Image Collections",
    "abstract": "With the advent of the Internet it is now possible to collect hundreds of millions of images. These images come with varying degrees of label information. \"Clean labels\" can be manually obtained on a small fraction, \"noisy labels\" may be extracted automatically from surrounding text, while for most images there are no labels at all. Semi-supervised learning is a principled framework for combining these different label sources. However, it scales polynomially with the number of images, making it impractical for use on gigantic collections with hundreds of millions of images and thousands of classes. In this paper we show how to utilize recent results in machine learning to obtain highly efficient approximations for semi-supervised learning that are linear in the number of images. Specifically, we use the convergence of the eigenvectors of the normalized graph Laplacian to eigenfunctions of weighted Laplace-Beltrami operators. Our algorithm enables us to apply semi-supervised learning to a database of 80 million images gathered from the Internet.",
    "date": "2009",
    "authors": [
        "Rob Fergus",
        "Yair Weiss",
        "Antonio Torralba"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Laplacian matrix",
        "Pattern recognition"
    ],
    "citation_count": "325",
    "reference_count": "27",
    "references": [
        "3118608800",
        "2110764733",
        "2145607950",
        "1566135517",
        "2293597654",
        "1560724230",
        "1479807131",
        "2111993661",
        "2154455818",
        "2104290444"
    ]
},{
    "id": "2963207607",
    "title": "Explaining and Harnessing Adversarial Examples",
    "abstract": "Abstract: Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.",
    "date": "2014",
    "authors": [
        "Ian J. Goodfellow",
        "Jonathon Shlens",
        "Christian Szegedy"
    ],
    "related_topics": [
        "Adversarial machine learning",
        "Overfitting",
        "MNIST database"
    ],
    "citation_count": "7,443",
    "reference_count": "0",
    "references": []
},{
    "id": "2963382180",
    "title": "Striving for Simplicity: The All Convolutional Net",
    "abstract": "Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \"deconvolution approach\" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.",
    "date": "2014",
    "authors": [
        "Jost Tobias Springenberg",
        "Alexey Dosovitskiy",
        "Thomas Brox",
        "Martin A. Riedmiller"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Cognitive neuroscience of visual object recognition",
        "Pipeline (computing)"
    ],
    "citation_count": "2,236",
    "reference_count": "0",
    "references": []
},{
    "id": "1479807131",
    "title": "Semi-Supervised Learning",
    "abstract": "In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research. Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications and offers guidelines for SSL practitioners by analyzing the results of extensive benchmark experiments. Finally, the book looks at interesting directions for SSL research. The book closes with a discussion of the relationship between semi-supervised learning and transduction. Adaptive Computation and Machine Learning series",
    "date": "2010",
    "authors": [
        "Olivier Chapelle",
        "Bernhard Schlkopf",
        "Alexander Zien"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Supervised learning"
    ],
    "citation_count": "5,990",
    "reference_count": "374",
    "references": [
        "2296319761",
        "2156909104",
        "2158714788",
        "2055043387",
        "1480376833",
        "2119821739",
        "2053186076",
        "2121947440",
        "3124955340",
        "2912934387"
    ]
},{
    "id": "2112076978",
    "title": "Experiments with a new boosting algorithm",
    "abstract": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem.",
    "date": "1996",
    "authors": [
        "Yoav Freund",
        "Robert E. Schapire"
    ],
    "related_topics": [
        "BrownBoost",
        "Boosting (machine learning)",
        "Gradient boosting"
    ],
    "citation_count": "10,827",
    "reference_count": "19",
    "references": []
},{
    "id": "1975846642",
    "title": "Boosting the margin: a new explanation for the effectiveness of voting methods",
    "abstract": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance decomposition.",
    "date": "1998",
    "authors": [
        "Robert E. Schapire",
        "Yoav Freund",
        "Peter Bartlett",
        "Wee Sun Lee"
    ],
    "related_topics": [
        "Margin classifier",
        "BrownBoost",
        "LPBoost"
    ],
    "citation_count": "3,525",
    "reference_count": "36",
    "references": [
        "2156909104",
        "2119821739",
        "3124955340",
        "2912934387",
        "1594031697",
        "2112076978",
        "2087347434",
        "1605688901",
        "2032210760",
        "2982720039"
    ]
},{
    "id": "2152761983",
    "title": "An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants",
    "abstract": "Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purpose of the study is to improve our understanding of why and when these algorithms, which use perturbation, reweighting, and combination techniques, affect classification error. We provide a bias and variance decomposition of the error to show how different methods and variants influence these two terms. This allowed us to determine that Bagging reduced variance of unstable methods, while boosting methods (AdaBoost and Arc-x4) reduced both the bias and variance of unstable methods but increased the variance for Naive-Bayes, which was very stable. We observed that Arc-x4 behaves differently than AdaBoost if reweighting is used instead of resampling, indicating a fundamental difference. Voting variants, some of which are introduced in this paper, include: pruning versus no pruning, use of probabilistic estimates, weight perturbations (Wagging), and backfitting of data. We found that Bagging improves when probabilistic estimates in conjunction with no-pruning are used, as well as when the data was backfit. We measure tree sizes and show an interesting positive correlation between the increase in the average tree size in AdaBoost trials and its success in reducing the error. We compare the mean-squared error of voting methods to non-voting methods and show that the voting methods lead to large and significant reductions in the mean-squared errors. Practical problems that arise in implementing boosting algorithms are explored, including numerical instabilities and underflows. We use scatterplots that graphically show how AdaBoost reweights instances, emphasizing not only \u201chard\u201d areas but also outliers and noise.",
    "date": "1999",
    "authors": [
        "Eric Bauer",
        "Ron Kohavi"
    ],
    "related_topics": [
        "BrownBoost",
        "AdaBoost",
        "Boosting (machine learning)"
    ],
    "citation_count": "2,325",
    "reference_count": "50",
    "references": [
        "1995945562",
        "3124955340",
        "2912934387",
        "2125055259",
        "2084812512",
        "2112076978",
        "1975846642",
        "1680392829",
        "2140785063",
        "3017143921"
    ]
},{
    "id": "2113242816",
    "title": "The random subspace method for constructing decision forests",
    "abstract": "Much of previous attention on decision trees focuses on the splitting criteria and optimization of tree sizes. The dilemma between overfitting and achieving maximum accuracy is seldom resolved. A method to construct a decision tree based classifier is proposed that maintains highest accuracy on training data and improves on generalization accuracy as it grows in complexity. The classifier consists of multiple trees constructed systematically by pseudorandomly selecting subsets of components of the feature vector, that is, trees constructed in randomly chosen subspaces. The subspace method is compared to single-tree classifiers and other forest construction methods by experiments on publicly available datasets, where the method's superiority is demonstrated. We also discuss independence between trees in a forest and relate that to the combined classification accuracy.",
    "date": "1998",
    "authors": [
        "Tin Kam Ho"
    ],
    "related_topics": [
        "Random forest",
        "Random subspace method",
        "Decision tree"
    ],
    "citation_count": "6,197",
    "reference_count": "30",
    "references": [
        "2156909104",
        "2912934387",
        "2125055259",
        "1594031697",
        "2112076978",
        "2149706766",
        "2101522199",
        "1966280301",
        "2102734279",
        "1930624869"
    ]
},{
    "id": "1605688901",
    "title": "An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization",
    "abstract": "Bagging and boosting are methods that generate a diverse ensemble of classifiers by manipulating the training data given to a \u201cbase\u201d learning algorithm. Breiman has pointed out that they rely for their effectiveness on the instability of the base learning algorithm. An alternative approach to generating an ensemble is to randomize the internal decisions made by the base algorithm. This general approach has been studied previously by Ali and Pazzani and by Dietterich and Kong. This paper compares the effectiveness of randomization, bagging, and boosting for improving the performance of the decision-tree algorithm C4.5. The experiments show that in situations with little or no classification noise, randomization is competitive with (and perhaps slightly superior to) bagging but not as accurate as boosting. In situations with substantial classification noise, bagging is much better than boosting, and sometimes better than randomization.",
    "date": "2000",
    "authors": [
        "Thomas G. Dietterich"
    ],
    "related_topics": [
        "Gradient boosting",
        "BrownBoost",
        "Ensembles of classifiers"
    ],
    "citation_count": "3,119",
    "reference_count": "14",
    "references": [
        "2912934387",
        "2112076978",
        "2152761983",
        "2982720039",
        "1966280301",
        "2167277498",
        "2073738917",
        "2976840617",
        "1562197959",
        "1850527962"
    ]
},{
    "id": "2120240539",
    "title": "Shape quantization and recognition with randomized trees",
    "abstract": "We explore a new approach to shape recognition based on a virtually infinite family of binary features (queries) of the image data, designed to accommodate prior information about shape invariance and regularity. Each query corresponds to a spatial arrangement of several local topographic codes (or tags), which are in themselves too primitive and common to be informative about shape. All the discriminating power derives from relative angles and distances among the tags. The important attributes of the queries are a natural partial ordering corresponding to increasing structure and complexity; semi-invariance, meaning that most shapes of a given class will answer the same way to two queries that are successive in the ordering; and stability, since the queries are not based on distinguished points and substructures. No classifier based on the full feature set can be evaluated, and it is impossible to determine a priori which arrangements are informative. Our approach is to select informative features and build tree classifiers at the same time by inductive learning. In effect, each tree provides an approximation to the full posterior where the features chosen depend on the branch that is traversed. Due to the number and nature of the queries, standard decision tree construction based on a fixed-length feature vector is not feasible. Instead we entertain only a small random sample of queries at each node, constrain their complexity to increase with tree depth, and grow multiple trees. The terminal nodes are labeled by estimates of the corresponding posterior distribution over shape classes. An image is classified by sending it down every tree and aggregating the resulting distributions. The method is applied to classifying handwritten digits and synthetic linear and nonlinear deformations of three hundred L AT E X symbols. Stateof-the-art error rates are achieved on the National Institute of Standards and Technology database of digits. The principal goal of the experiments on L AT E X symbols is to analyze invariance, generalization error and related issues, and a comparison with artificial neural networks methods is presented in this context.",
    "date": "1997",
    "authors": [
        "Yali Amit",
        "Donald Geman"
    ],
    "related_topics": [
        "Feature vector",
        "Tree-depth",
        "Decision tree"
    ],
    "citation_count": "1,361",
    "reference_count": "49",
    "references": [
        "2099111195",
        "2912934387",
        "1594031697",
        "2149706766",
        "2101522199",
        "1676820704",
        "2165758113",
        "2154579312",
        "2076118331",
        "2168228682"
    ]
},{
    "id": "2099968818",
    "title": "Boosting in the limit: maximizing the margin of learned ensembles",
    "abstract": "The \"minimum margin\" of an ensemble classifier on a given training set is, roughly speaking, the smallest vote it gives to any correct training label. Recent work has shown that the Adaboost algorithm is particularly effective at producing ensembles with large minimum margins, and theory suggests that this may account for its success at reducing generalization error. We note, however, that the problem of finding good margins is closely related to linear programming, and we use this connection to derive and test new \"LPboosting\" algorithms that achieve better minimum margins than Adaboost.However, these algorithms do not always yield better generalization performance. In fact, more often the opposite is true. We report on a series of controlled experiments which show that no simple version of the minimum-margin story can be complete. We conclude that the crucial question as to why boosting works so well in practice, and how to further improve upon it, remains mostly open.Some of our experiments are interesting for another reason: we show that Adaboost sometimes does overfit--eventually. This may take a very long time to occur, however, which is perhaps why this phenomenon has gone largely unnoticed.",
    "date": "1998",
    "authors": [
        "Adam J. Grove",
        "Dale Schuurmans"
    ],
    "related_topics": [
        "BrownBoost",
        "LPBoost",
        "Boosting (machine learning)"
    ],
    "citation_count": "365",
    "reference_count": "17",
    "references": [
        "2119821739",
        "3124955340",
        "2125055259",
        "2112076978",
        "2152761983",
        "1504694836",
        "2982720039",
        "1966280301",
        "2266946488",
        "1553313034"
    ]
},{
    "id": "2067885219",
    "title": "Arcing classifier (with discussion and a rejoinder by the author)",
    "abstract": "Recent work has shown that combining multiple versions of unstable classifiers such as trees or neural nets results in reduced test set error. One of the more effective is bagging. Here, modified training sets are formed by resampling from the original training set, classifiers constructed using these training sets and then combined by voting. Freund and Schapire propose an algorithm the basis of which is to adaptively resample and combine (hence the acronym \u201carcing\u201d) so that the weights in the resampling are increased for those cases most often misclassified and the combining is done by weighted voting. Arcing is more successful than bagging in test set error reduction. We explore two arcing algorithms, compare them to each other and to bagging, and try to understand how arcing works. We introduce the definitions of bias and variance for a classifier as components of the test set error. Unstable classifiers can have low bias on a large range of data sets. Their problem is high variance. Combining multiple versions either through bagging or arcing reduces variance significantly.",
    "date": "1998",
    "authors": [
        "Leo Breiman"
    ],
    "related_topics": [
        "Test set",
        "Boosting (machine learning)",
        "Weighted voting"
    ],
    "citation_count": "1,925",
    "reference_count": "0",
    "references": []
},{
    "id": "1580948147",
    "title": "Randomizing Outputs to Increase Prediction Accuracy",
    "abstract": "Bagging and boosting reduce error by changing both the inputs and outputs to form perturbed training sets, growing predictors on these perturbed training sets and combining them. An interesting question is whether it is possible to get comparable performance by perturbing the outputs alone. Two methods of randomizing outputs are experimented with. One is called output smearing and the other output flipping. Both are shown to consistently do better than bagging.",
    "date": "2000",
    "authors": [
        "Leo Breiman"
    ],
    "related_topics": [
        "Boosting (machine learning)",
        "Machine learning",
        "Mathematics"
    ],
    "citation_count": "300",
    "reference_count": "14",
    "references": [
        "3124955340",
        "2912934387",
        "1594031697",
        "2112076978",
        "1605688901",
        "2102201073",
        "2067885219",
        "2076118331",
        "2172195373",
        "2073738917"
    ]
},{
    "id": "2145889472",
    "title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images",
    "abstract": "The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.",
    "date": "1996",
    "authors": [
        "Bruno A. Olshausen",
        "David J. Field"
    ],
    "related_topics": [
        "Efficient coding hypothesis",
        "Simple cell",
        "Sparse image"
    ],
    "citation_count": "6,525",
    "reference_count": "20",
    "references": [
        "2108384452",
        "1993845689",
        "2180838288",
        "2167034998",
        "2120838001",
        "2122925692",
        "1914401667",
        "2106884367",
        "2911607583",
        "2117731089"
    ]
},{
    "id": "2122922389",
    "title": "Self-taught learning: transfer learning from unlabeled data",
    "abstract": "We present a new machine learning framework called \"self-taught learning\" for using unlabeled data in supervised classification tasks. We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data. Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task. Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems. We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data. These features form a succinct input representation and significantly improve classification performance. When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation.",
    "date": "2007",
    "authors": [
        "Rajat Raina",
        "Alexis Battle",
        "Honglak Lee",
        "Benjamin Packer",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Multi-task learning"
    ],
    "citation_count": "1,808",
    "reference_count": "25",
    "references": [
        "1880262756",
        "2100495367",
        "2162915993",
        "2135046866",
        "2053186076",
        "2001141328",
        "2063978378",
        "2166049352",
        "2147152072",
        "2113606819"
    ]
},{
    "id": "2139427956",
    "title": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition",
    "abstract": "We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST, and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples.",
    "date": "2007",
    "authors": [
        "M.A. Ranzato",
        "Fu Jie Huang",
        "Y.-L. Boureau",
        "Yann LeCun"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Supervised learning",
        "MNIST database"
    ],
    "citation_count": "1,313",
    "reference_count": "20",
    "references": [
        "2151103935",
        "2136922672",
        "2310919327",
        "2162915993",
        "2110798204",
        "2166049352",
        "1624854622",
        "2172174689",
        "2168002178",
        "2105464873"
    ]
},{
    "id": "2118020653",
    "title": "Machine learning in automated text categorization",
    "abstract": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.",
    "date": "2002",
    "authors": [
        "Fabrizio Sebastiani"
    ],
    "related_topics": [
        "Multi-task learning",
        "Categorization",
        "Document classification"
    ],
    "citation_count": "10,883",
    "reference_count": "165",
    "references": [
        "1574901103",
        "2149684865",
        "2147152072",
        "2435251607",
        "2097089247",
        "2053463056",
        "2114535528",
        "2005422315",
        "2140785063",
        "1978394996"
    ]
},{
    "id": "2493916176",
    "title": "Enriching Word Vectors with Subword Information",
    "abstract": "Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models to learn such representations  ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram, words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.",
    "date": "2017",
    "authors": [
        "Piotr Bojanowski",
        "Edouard Grave",
        "Armand Joulin",
        "Tomas Mikolov"
    ],
    "related_topics": [
        "Word lists by frequency",
        "Word embedding",
        "Word (computer architecture)"
    ],
    "citation_count": "5,864",
    "reference_count": "47",
    "references": [
        "2153579005",
        "1614298861",
        "2117130368",
        "2962784628",
        "1810943226",
        "2963012544",
        "2251012068",
        "2147152072",
        "1662133657",
        "1938755728"
    ]
},{
    "id": "2113459411",
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term--document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "date": "2011",
    "authors": [
        "Andrew L. Maas",
        "Raymond E. Daly",
        "Peter T. Pham",
        "Dan Huang",
        "Andrew Y. Ng",
        "Christopher Potts"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Natural language processing",
        "Information retrieval"
    ],
    "citation_count": "2,792",
    "reference_count": "28",
    "references": [
        "1880262756",
        "2117130368",
        "2118585731",
        "2166706824",
        "2132339004",
        "2158139315",
        "2147152072",
        "2114524997",
        "1662133657",
        "2163455955"
    ]
},{
    "id": "2164019165",
    "title": "Improving Word Representations via Global Context and Multiple Word Prototypes",
    "abstract": "Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models.",
    "date": "2012",
    "authors": [
        "Eric Huang",
        "Richard Socher",
        "Christopher Manning",
        "Andrew Ng"
    ],
    "related_topics": [
        "Word lists by frequency",
        "Word (computer architecture)",
        "Language model"
    ],
    "citation_count": "1,364",
    "reference_count": "36",
    "references": [
        "1532325895",
        "2117130368",
        "2132339004",
        "2118020653",
        "2158139315",
        "1423339008",
        "71795751",
        "2081580037",
        "1970381522",
        "2131462252"
    ]
},{
    "id": "1544827683",
    "title": "Teaching machines to read and comprehend",
    "abstract": "Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.",
    "date": "2015",
    "authors": [
        "Karl Moritz Hermann",
        "Tom\u00e1\u0161 Ko\u010disk\u00fd",
        "Edward Grefenstette",
        "Lasse Espeholt",
        "Will Kay",
        "Mustafa Suleyman",
        "Phil Blunsom"
    ],
    "related_topics": [
        "Reading comprehension",
        "Natural language",
        "Class (computer programming)"
    ],
    "citation_count": "1,994",
    "reference_count": "19",
    "references": [
        "2964308564",
        "2130942839",
        "2064675550",
        "2158899491",
        "2120615054",
        "1793121960",
        "2962741254",
        "2147527908",
        "2144499799",
        "2125436846"
    ]
},{
    "id": "2125436846",
    "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
    "abstract": "We present MCTest, a freely available set of stories and associated questions intended for research on the machine comprehension of text. Previous work on machine comprehension (e.g., semantic modeling) has made great strides, but primarily focuses either on limited-domain datasets, or on solving a more restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension. Reading comprehension can test advanced abilities such as causal reasoning and understanding the world, yet, by being multiple-choice, still provide a clear metric. By being fictional, the answer typically can be found only in the story itself. The stories and questions are also carefully limited to those a young child would understand, reducing the world knowledge that is required for the task. We present the scalable crowd-sourcing methods that allow us to cheaply construct a dataset of 500 stories and 2000 questions. By screening workers (with grammar tests) and stories (with grading), we have ensured that the data is the same quality as another set that we manually edited, but at one tenth the editing cost. By being open-domain, yet carefully restricted, we hope MCTest will serve to encourage research and provide a clear metric for advancement on the machine comprehension of text. 1 Reading Comprehension A major goal for NLP is for machines to be able to understand text as well as people. Several research disciplines are focused on this problem: for example, information extraction, relation extraction, semantic role labeling, and recognizing textual entailment. Yet these techniques are necessarily evaluated individually, rather than by how much they advance us towards the end goal. On the other hand, the goal of semantic parsing is the machine comprehension of text (MCT), yet its evaluation requires adherence to a specific knowledge representation, and it is currently unclear what the best representation is, for open-domain text. We believe that it is useful to directly tackle the top-level task of MCT. For this, we need a way to measure progress. One common method for evaluating someone\u2019s understanding of text is by giving them a multiple-choice reading comprehension test. This has the advantage that it is objectively gradable (vs. essays) yet may test a range of abilities such as causal or counterfactual reasoning, inference among relations, or just basic understanding of the world in which the passage is set. Therefore, we propose a multiple-choice reading comprehension task as a way to evaluate progress on MCT. We have built a reading comprehension dataset containing 500 fictional stories, with 4 multiple choice questions per story. It was built using methods which can easily scale to at least 5000 stories, since the stories were created, and the curation was done, using crowd sourcing almost entirely, at a total of $4.00 per story. We plan to periodically update the dataset to ensure that methods are not overfitting to the existing data. The dataset is open-domain, yet restricted to concepts and words that a 7 year old is expected to understand. This task is still beyond the capability of today\u2019s computers and algorithms.",
    "date": "2013",
    "authors": [
        "Matthew Richardson",
        "Christopher J.C. Burges",
        "Erin Renshaw"
    ],
    "related_topics": [
        "Reading comprehension",
        "Comprehension",
        "Relationship extraction"
    ],
    "citation_count": "529",
    "reference_count": "25",
    "references": [
        "3122078363",
        "2525127255",
        "2126631960",
        "2167090521",
        "3126123353",
        "1979532929",
        "2989499211",
        "2096979215",
        "2097550833",
        "2142898321"
    ]
},{
    "id": "2964267515",
    "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations",
    "abstract": "Abstract: We introduce a new test of how well language models capture meaning in children's books. Unlike standard language modelling benchmarks, it distinguishes the task of predicting syntactic function words from that of predicting lower-frequency words, which carry greater semantic content. We compare a range of state-of-the-art models, each with a different way of encoding what has been previously read. We show that models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words, although this advantage is not observed for syntactic function words. Interestingly, we find that the amount of text encoded in a single memory representation is highly influential to the performance: there is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled. Further, the attention over such window-based memories can be trained effectively through self-supervision. We then assess the generality of this principle by applying it to the CNN QA benchmark, which involves identifying named entities in paraphrased summaries of news articles, and achieve state-of-the-art performance.",
    "date": "2015",
    "authors": [
        "Felix Hill",
        "Antoine Bordes",
        "Sumit Chopra",
        "Jason Weston"
    ],
    "related_topics": [
        "Language model",
        "Reading (process)",
        "Encoding (memory)"
    ],
    "citation_count": "437",
    "reference_count": "0",
    "references": []
},{
    "id": "2962809918",
    "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
    "abstract": "Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 72.4% and 75.8% on these two datasets, exceeding current state-of-the-art results by over 5% and approaching what we believe is the ceiling for performance on this task.1",
    "date": "2015",
    "authors": [
        "Danqi Chen",
        "Jason Bolton",
        "Christopher D. Manning"
    ],
    "related_topics": [
        "Task (project management)",
        "Reading comprehension",
        "Natural language processing"
    ],
    "citation_count": "447",
    "reference_count": "19",
    "references": [
        "2250539671",
        "1902237438",
        "1544827683",
        "1793121960",
        "2250861254",
        "2125436846",
        "2964267515",
        "2584341106",
        "2964091467",
        "2962790689"
    ]
},{
    "id": "2171278097",
    "title": "Building Watson: An Overview of the DeepQA Project",
    "abstract": "IBM Research undertook a challenge to build a computer system that could compete at the human champion level in real time on the American TV Quiz show, Jeopardy! The extent of the challenge includes fielding a real-time automatic contestant on the show, not merely a laboratory exercise. The Jeopardy! Challenge helped us address requirements that led to the design of the DeepQA architecture and the implementation of Watson. After 3 years of intense research and development by a core team of about 20 researches, Watson is performing at human expert-levels in terms of precision, confidence and speed at the Jeopardy! Quiz show. Our results strongly suggest that DeepQA is an effective and extensible architecture that may be used as a foundation for combining, deploying, evaluating and advancing a wide range of algorithmic techniques to rapidly advance the field of QA.",
    "date": "2010",
    "authors": [
        "David A. Ferrucci",
        "Eric W. Brown",
        "Jennifer Chu-Carroll",
        "James Fan",
        "David Gondek",
        "Aditya Kalyanpur",
        "Adam Lally",
        "J. William Murdock",
        "Eric Nyberg",
        "John M. Prager",
        "Nico Schlaefer",
        "Christopher A. Welty"
    ],
    "related_topics": [
        "Watson",
        "IBM",
        "Champion"
    ],
    "citation_count": "1,764",
    "reference_count": "22",
    "references": [
        "2081580037",
        "2047221353",
        "2096797897",
        "2150884987",
        "2087064593",
        "2988119488",
        "2107658650",
        "2158823144",
        "2122537498",
        "2080278171"
    ]
},{
    "id": "2962790689",
    "title": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
    "abstract": "Abstract: One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks.",
    "date": "2015",
    "authors": [
        "Jason Weston",
        "Antoine Bordes",
        "Sumit Chopra",
        "Alexander M. Rush",
        "Bart van Merri\u00ebnboer",
        "Armand Joulin",
        "Tomas Mikolov"
    ],
    "related_topics": [
        "Question answering",
        "Set (psychology)",
        "AI-complete"
    ],
    "citation_count": "654",
    "reference_count": "0",
    "references": []
},{
    "id": "2251818205",
    "title": "WikiQA: A Challenge Dataset for Open-Domain Question Answering",
    "abstract": "We describe the WIKIQA dataset, a new publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. Most previous work on answer sentence selection focuses on a dataset created using the TREC-QA data, which includes editor-generated questions and candidate answer sentences selected by matching content words in the question. WIKIQA is constructed using a more natural process and is more than an order of magnitude larger than the previous dataset. In addition, the WIKIQA dataset also includes questions for which there are no correct sentences, enabling researchers to work on answer triggering, a critical component in any QA system. We compare several systems on the task of answer sentence selection on both datasets and also describe the performance of a system on the problem of answer triggering using the WIKIQA dataset.",
    "date": "2015",
    "authors": [
        "Yi Yang",
        "Wen-tau Yih",
        "Christopher Meek"
    ],
    "related_topics": [
        "Sentence",
        "Question answering",
        "Selection (linguistics)"
    ],
    "citation_count": "554",
    "reference_count": "10",
    "references": [
        "2153579005",
        "2131744502",
        "2070246124",
        "2118091490",
        "1591825359",
        "1514986335",
        "2125313055",
        "2989499211",
        "2120735855",
        "2251921768"
    ]
},{
    "id": "2251349042",
    "title": "Learning to Automatically Solve Algebra Word Problems",
    "abstract": "We present an approach for automatically learning to solve algebra word problems. Our algorithm reasons across sentence boundaries to construct and solve a system of linear equations, while simultaneously recovering an alignment of the variables and numbers in these equations to the problem text. The learning algorithm uses varied supervision, including either full equations or just the final answers. We evaluate performance on a newly gathered corpus of algebra word problems, demonstrating that the system can correctly answer almost 70% of the questions in the dataset. This is, to our knowledge, the first learning result for this task.",
    "date": "2014",
    "authors": [
        "Nate Kushman",
        "Yoav Artzi",
        "Luke Zettlemoyer",
        "Regina Barzilay"
    ],
    "related_topics": [
        "Word problem (mathematics education)",
        "System of linear equations",
        "Task (project management)"
    ],
    "citation_count": "227",
    "reference_count": "30",
    "references": [
        "2252136820",
        "1508977358",
        "2163561827",
        "2123661878",
        "1496189301",
        "2189089430",
        "2251673953",
        "2118781169",
        "1923162067",
        "1559723967"
    ]
},{
    "id": "2169415915",
    "title": "Constructing free-energy approximations and generalized belief propagation algorithms",
    "abstract": "Important inference problems in statistical physics, computer vision, error-correcting coding theory, and artificial intelligence can all be reformulated as the computation of marginal probabilities on factor graphs. The belief propagation (BP) algorithm is an efficient way to solve these problems that is exact when the factor graph is a tree, but only approximate when the factor graph has cycles. We show that BP fixed points correspond to the stationary points of the Bethe approximation of the free energy for a factor graph. We explain how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms. We emphasize the conditions a free energy approximation must satisfy in order to be a \"valid\" or \"maxent-normal\" approximation. We describe the relationship between four different methods that can be used to generate valid approximations: the \"Bethe method\", the \"junction graph method\", the \"cluster variation method\", and the \"region graph method\". Finally, we explain how to tell whether a region-based approximation, and its corresponding GBP algorithm, is likely to be accurate, and describe empirical results showing that GBP can significantly outperform BP.",
    "date": "2005",
    "authors": [
        "J.S. Yedidia",
        "W.T. Freeman",
        "Y. Weiss"
    ],
    "related_topics": [
        "Belief propagation",
        "Approximation algorithm",
        "Factor graph"
    ],
    "citation_count": "1,755",
    "reference_count": "56",
    "references": [
        "2099111195",
        "2125838338",
        "2798766386",
        "2137813581",
        "2159080219",
        "2121606987",
        "2987657883",
        "1516111018",
        "1530042113",
        "1746680969"
    ]
},{
    "id": "2158164339",
    "title": "Modeling Human Motion Using Binary Latent Variables",
    "abstract": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture.",
    "date": "2006",
    "authors": [
        "Graham W. Taylor",
        "Geoffrey E. Hinton",
        "Sam T. Roweis"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent variable",
        "Latent class model"
    ],
    "citation_count": "878",
    "reference_count": "14",
    "references": [
        "2136922672",
        "2310919327",
        "2116064496",
        "2124914669",
        "2293741035",
        "2114153178",
        "2147010501",
        "2248685949",
        "1991942383",
        "2123236823"
    ]
},{
    "id": "66838807",
    "title": "On Contrastive Divergence Learning.",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Computer science",
        "Linguistics",
        "Pattern recognition"
    ],
    "citation_count": "794",
    "reference_count": "15",
    "references": [
        "2116064496",
        "2130416410",
        "2157444450",
        "1651266332",
        "2095844239",
        "1802356529",
        "1568229137",
        "1813659000",
        "2482531687",
        "2130313186"
    ]
},{
    "id": "2064630666",
    "title": "Representational power of restricted boltzmann machines and deep belief networks",
    "abstract": "Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs.",
    "date": "2008",
    "authors": [
        "Nicolas Le Roux",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Restricted Boltzmann machine",
        "Deep belief network",
        "Boltzmann machine"
    ],
    "citation_count": "782",
    "reference_count": "21",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2110798204",
        "2137983211",
        "3146803896",
        "2172174689",
        "2613634265",
        "2124914669",
        "205159212"
    ]
},{
    "id": "1513873506",
    "title": "Annealed importance sampling",
    "abstract": "Simulated annealing\u2014moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions\u2014has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.",
    "date": "2001",
    "authors": [
        "Radford M. Neal"
    ],
    "related_topics": [
        "Slice sampling",
        "Importance sampling",
        "Markov chain Monte Carlo"
    ],
    "citation_count": "1,299",
    "reference_count": "19",
    "references": [
        "2581275558",
        "2130416410",
        "1567512734",
        "2149801992",
        "2615953416",
        "2057565703",
        "2013164703",
        "1565709818",
        "2138309709",
        "2033057584"
    ]
},{
    "id": "2135094946",
    "title": "A new class of upper bounds on the log partition function",
    "abstract": "We introduce a new class of upper bounds on the log partition function of a Markov random field (MRF). This quantity plays an important role in various contexts, including approximating marginal distributions, parameter estimation, combinatorial enumeration, statistical decision theory, and large-deviations bounds. Our derivation is based on concepts from convex duality and information geometry: in particular, it exploits mixtures of distributions in the exponential domain, and the Legendre mapping between exponential and mean parameters. In the special case of convex combinations of tree-structured distributions, we obtain a family of variational problems, similar to the Bethe variational problem, but distinguished by the following desirable properties: i) they are convex, and have a unique global optimum; and ii) the optimum gives an upper bound on the log partition function. This optimum is defined by stationary conditions very similar to those defining fixed points of the sum-product algorithm, or more generally, any local optimum of the Bethe variational problem. As with sum-product fixed points, the elements of the optimizing argument can be used as approximations to the marginals of the original model. The analysis extends naturally to convex combinations of hypertree-structured distributions, thereby establishing links to Kikuchi approximations and variants.",
    "date": "2005",
    "authors": [
        "M.J. Wainwright",
        "T.S. Jaakkola",
        "A.S. Willsky"
    ],
    "related_topics": [
        "Partition function (quantum field theory)",
        "Upper and lower bounds",
        "Fixed point"
    ],
    "citation_count": "582",
    "reference_count": "40",
    "references": [
        "2798766386",
        "2137813581",
        "2004308928",
        "1516111018",
        "2169415915",
        "1530042113",
        "2914659449",
        "2019599312",
        "1515272691",
        "1513861746"
    ]
},{
    "id": "2102381086",
    "title": "Introduction to WordNet: An On-line Lexical Database",
    "abstract": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought.",
    "date": "1990",
    "authors": [
        "George A. Miller",
        "Richard Beckwith",
        "Christiane Fellbaum",
        "Derek Gross",
        "Katherine J. Miller"
    ],
    "related_topics": [
        "Lexical database",
        "WordNet",
        "eXtended WordNet"
    ],
    "citation_count": "6,740",
    "reference_count": "81",
    "references": [
        "1933657216",
        "2103318667",
        "2090626368",
        "1483126227",
        "2017668967",
        "2123987305",
        "2040300040",
        "2013596317",
        "2052262800",
        "2059799772"
    ]
},{
    "id": "2103318667",
    "title": "Contextual correlates of semantic similarity",
    "abstract": "Abstract The relationship between semantic and contextual similarity is investigated for pairs of nouns that vary from high to low semantic similarity. Semantic similarity is estimated by subjective ratings; contextual similarity is estimated by the method of sorting sentential contexts. The results show an inverse linear relationship between similarity of meaning and the discriminability of contexts. This relation, is obtained for two separate corpora of sentence contexts. It is concluded that, on average, for words in the same language drawn from the same syntactic and semantic categories, the more often two words can be substituted into the same contexts the more similar in meaning they are judged to be.",
    "date": "1990",
    "authors": [
        "George A. Miller",
        "Walter G. Charles"
    ],
    "related_topics": [
        "Semantic similarity",
        "Similarity (psychology)",
        "Contextual Associations"
    ],
    "citation_count": "2,009",
    "reference_count": "31",
    "references": [
        "1483126227",
        "1971220772",
        "2017580301",
        "2114826854",
        "13823885",
        "2109334311",
        "2064332540",
        "1536719366",
        "1634667895",
        "2020159140"
    ]
},{
    "id": "2065157922",
    "title": "A semantic concordance",
    "abstract": "A semantic concordance is a textual corpus and a lexicon so combined that every substantive word in the text is linked to its appropriate sense in the lexicon. Thus it can be viewed either as a corpus in which words have been tagged syntactically and semantically, or as a lexicon in which example sentences can be found for many definitions. A semantic concordance is being constructed to use in studies of sense resolution in context (semantic disambiguation). The Brown Corpus is the text and WordNet is the lexicon. Semantic tags (pointers to WordNet synsets) are inserted in the text manually using an interface, ConText, that was designed to facilitate the task. Another interface supports searches of the tagged text. Some practical uses for semantic concordances am proposed.",
    "date": "1993",
    "authors": [
        "George A. Miller",
        "Claudia Leacock",
        "Randee Tengi",
        "Ross T. Bunker"
    ],
    "related_topics": [
        "Explicit semantic analysis",
        "Semantic similarity",
        "Semantic compression"
    ],
    "citation_count": "791",
    "reference_count": "6",
    "references": [
        "2102381086",
        "2081687495",
        "1483126227",
        "2017668967",
        "2007780422",
        "2012908435"
    ]
},{
    "id": "1483126227",
    "title": "FREQUENCY ANALYSIS OF ENGLISH USAGE: LEXICON AND GRAMMAR",
    "abstract": "",
    "date": "1982",
    "authors": [
        "W. Nelson Francis",
        "Henry Ku\u010dera",
        "Andrew W. Mackie"
    ],
    "related_topics": [
        "Lexicon",
        "Grammar",
        "Brown Corpus"
    ],
    "citation_count": "2,935",
    "reference_count": "0",
    "references": []
},{
    "id": "1518768680",
    "title": "Towards building contextual representations of word senses using statistical models",
    "abstract": "A b s t r a c t Automatic corpus-based sense resolution, or sense dlsambiguation, techniques tend to focus either on very local context or on topical context. Both components axe needed for word sense resolution. A contextual representation of a word sense consists of topical context and local context. Our goal is to construct contextual representations by automatically extracting topical and local information from textual corpora. We review an experiment evaluating three statistical classifiers that automatically extract topical context. An experiment designed to examine human subject performance with similar input is described. Finally, we investigate a method for automatically extracting local context from a corpus. Preliminary results show improved perfor-",
    "date": "1996",
    "authors": [
        "Claudia Leacock",
        "Geoffrey Towell",
        "Ellen M. Voorhees"
    ],
    "related_topics": [
        "Context (language use)",
        "Natural language processing",
        "Word (computer architecture)"
    ],
    "citation_count": "100",
    "reference_count": "9",
    "references": [
        "2154642048",
        "2103318667",
        "1977182536",
        "2165612380",
        "2047620598",
        "1999114220",
        "2066444522",
        "2148426685",
        "2090543924"
    ]
},{
    "id": "13823885",
    "title": "The categorization of sentential contexts",
    "abstract": "A new experimental method, involving the sorting of linguistic contexts, is shown to be effective in discriminating the contexts of polysemous words as well as the contexts of synonyms of those words. These results are interpreted as support for the claim that the method of sorting linguistic contexts is a valid technique for studying the contextual information available to support inferences about word meanings.",
    "date": "1988",
    "authors": [
        "Walter G. Charles"
    ],
    "related_topics": [
        "Context (archaeology)",
        "Categorization",
        "Psycholinguistics"
    ],
    "citation_count": "9",
    "reference_count": "4",
    "references": [
        "2017580301",
        "1995875735",
        "2045585593",
        "2316811974"
    ]
},{
    "id": "1997063559",
    "title": "Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images*",
    "abstract": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, non-linear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low-energy states (\u2018annealing\u2019), or what is the same thing, the most probable states under the Gib...",
    "date": "1992",
    "authors": [
        "Stuart Geman",
        "Donald Geman"
    ],
    "related_topics": [
        "Gibbs sampling",
        "Categorical distribution",
        "Boltzmann distribution"
    ],
    "citation_count": "26,469",
    "reference_count": "48",
    "references": [
        "2581275558",
        "2150060382",
        "1622620102",
        "2154061444",
        "2114220616",
        "1979622972",
        "2065301447",
        "2107792892",
        "2056760934",
        "1567885833"
    ]
},{
    "id": "2049633694",
    "title": "Maximum likelihood from incomplete data via the EM algorithm",
    "abstract": "",
    "date": "1977",
    "authors": [
        "Arthur P. Dempster",
        "Nan M. Laird",
        "Donald B. Rubin"
    ],
    "related_topics": [
        "Maximum likelihood sequence estimation",
        "Expectation\u2013maximization algorithm",
        "MM algorithm"
    ],
    "citation_count": "65,759",
    "reference_count": "74",
    "references": [
        "2100358124",
        "2327022120",
        "2074673068",
        "2403035479",
        "1982585616",
        "1575431606",
        "2086699924",
        "2144578442",
        "2000084758",
        "2121493622"
    ]
},{
    "id": "1507849272",
    "title": "A learning algorithm for Boltzmann machines",
    "abstract": "The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.",
    "date": "1987",
    "authors": [
        "David H. Ackley",
        "Geoffrey E. Hinton",
        "Terrence J. Sejnowski"
    ],
    "related_topics": [
        "Massively parallel",
        "Learning rule",
        "Constraint satisfaction"
    ],
    "citation_count": "4,783",
    "reference_count": "10",
    "references": [
        "2581275558",
        "1997063559",
        "2293063825",
        "2112325651",
        "2056760934",
        "2157629899",
        "2098205603",
        "1597474747",
        "2414854470",
        "807785616"
    ]
},{
    "id": "1964724001",
    "title": "Exploratory Projection Pursuit",
    "abstract": "Abstract A new projection pursuit algorithm for exploring multivariate data is presented that has both statistical and computational advantages over previous methods. A number of practical issues concerning its application are addressed. A connection to multivariate density estimation is established, and its properties are investigated through simulation studies and application to real data. The goal of exploratory projection pursuit is to use the data to find low- (one-, two-, or three-) dimensional projections that provide the most revealing views of the full-dimensional data. With these views the human gift for pattern recognition can be applied to help discover effects that may not have been anticipated in advance. Since linear effects are directly captured by the covariance structure of the variable pairs (which are straightforward to estimate) the emphasis here is on the discovery of nonlinear effects such as clustering or other general nonlinear associations among the variables. Although arbitrary ...",
    "date": "1987",
    "authors": [
        "Jerome H. Friedman"
    ],
    "related_topics": [
        "Projection pursuit",
        "Exploratory data analysis",
        "Cluster analysis"
    ],
    "citation_count": "1,161",
    "reference_count": "16",
    "references": [
        "2954064014",
        "2800289289",
        "2155199877",
        "2029469881",
        "2082612735",
        "1573763320",
        "1968104963",
        "2161831609",
        "2052740976",
        "1983993791"
    ]
},{
    "id": "2121407732",
    "title": "Finite Mixture Distributions",
    "abstract": "1 General introduction.- 1.1 Introduction.- 1.2 Some applications of finite mixture distributions.- 1.3 Definition.- 1.4 Estimation methods.- 1.4.1 Maximum likelihood.- 1.4.2 Bayesian estimation.- 1.4.3 Inversion and error minimization.- 1.4.4 Other methods.- 1.4.5 Estimating the number of components.- 1.5 Summary.- 2 Mixtures of normal distributions.- 2.1 Introduction.- 2.2 Some descriptive properties of mixtures of normal distributions.- 2.3 Estimating the parameters in normal mixture distributions.- 2.3.1 Method of moments estimation.- 2.3.2 Maximum likelihood estimation.- 2.3.3 Maximum likelihood estimates for grouped data.- 2.3.4 Obtaining initial parameter values for the maximum likelihood estimation algorithms.- 2.3.5 Graphical estimation techniques.- 2.3.6 Other estimation methods.- 2.4 Summary.- 3 Mixtures of exponential and other continuous distributions.- 3.1 Exponential mixtures.- 3.2 Estimating exponential mixture parameters.- 3.2.1 The method of moments and generalizations.- 3.2.2 Maximum likelihood.- 3.3 Properties of exponential mixtures.- 3.4 Other continuous distributions.- 3.4.1 Non-central chi-squared distribution.- 3.4.2 Non-central F distribution.- 3.4.3 Beta distributions.- 3.4.4 Doubly non-central t distribution.- 3.4.5 Planck's distribution.- 3.4.6 Logistic.- 3.4.7 Laplace.- 3.4.8 Weibull.- 3.4.9 Gamma.- 3.5 Mixtures of different component types.- 3.6 Summary.- 4 Mixtures of discrete distributions.- 4.1 Introduction.- 4.2 Mixtures of binomial distributions.- 4.2.1 Moment estimators for binomial mixtures.- 4.2.2 Maximum likelihood estimators for mixtures of binomial distributions.- 4.2.3 Other estimation methods for mixtures of binomial distributions.- 4.3 Mixtures of Poisson distributions.- 4.3.1 Moment estimators for mixtures of Poisson distributions.- 4.3.2 Maximum likelihood estimators for a Poisson mixture.- 4.4 Mixtures of Poisson and binomial distributions.- 4.5 Mixtures of other discrete distributions.- 4.6 Summary.- 5 Miscellaneous topics.- 5.1 Introduction.- 5.2 Determining the number of components in a mixture.- 5.2.1 Informal diagnostic tools for the detection of mixtures.- 5.2.2 Testing hypotheses on the number of components in a mixture.- 5.3 Probability density function estimation.- 5.4 Miscellaneous problems.- 5.5 Summary.- References.",
    "date": "1981",
    "authors": [
        "Brian Everitt",
        "D. J. Hand"
    ],
    "related_topics": [
        "Estimating equations",
        "Normal distribution",
        "Poisson distribution"
    ],
    "citation_count": "2,046",
    "reference_count": "0",
    "references": []
},{
    "id": "2725061391",
    "title": "A mean field theory learning algorithm for neural networks",
    "abstract": "",
    "date": "1986",
    "authors": [
        "Carsten Peterson",
        "James R. Anderson"
    ],
    "related_topics": [
        "Types of artificial neural networks",
        "Wake-sleep algorithm",
        "Deep learning"
    ],
    "citation_count": "682",
    "reference_count": "3",
    "references": [
        "2154642048",
        "2293063825",
        "1507849272"
    ]
},{
    "id": "2315016682",
    "title": "Feature extraction using an unsupervised neural network",
    "abstract": "A novel unsupervised neural network for dimensionality reduction which seeks directions emphasizing distinguishing features in the data is presented. A statistical framework for the parameter estimation problem associated with this neural network is given and its connection to exploratory projection pursuit methods is established. The network is shown to minimize a loss function (projection index) over a set of parameters, yielding an optimal decision rule under some norm. A specific projection index that favors directions possessing multimodality is presented. This leads to a similar form to the synaptic modification equations governing learning in Bienenstock, Cooper, and Munro (BCM) neurons (1982). The importance of a dimensionality reduction principal based, solely on distinguishing features, is demonstrated using a linguistically motivated phoneme recognition experiment, and compared with feature extraction using principal components and back-propagation network.",
    "date": "1999",
    "authors": [
        "Nathan Intrator"
    ],
    "related_topics": [
        "Dimensionality reduction",
        "Time delay neural network",
        "Projection pursuit"
    ],
    "citation_count": "121",
    "reference_count": "0",
    "references": []
},{
    "id": "1991848143",
    "title": "Self-Organization and Associative Memory",
    "abstract": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References.",
    "date": "1983",
    "authors": [
        "Teuvo Kohonen"
    ],
    "related_topics": [
        "Holographic associative memory",
        "Content-addressable memory",
        "Autoassociative memory"
    ],
    "citation_count": "12,606",
    "reference_count": "0",
    "references": []
},{
    "id": "2107636931",
    "title": "GTM: the generative topographic mapping",
    "abstract": "Latent variable models represent the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. A familiar example is factor analysis which is based on a linear transformations between the latent space and the data space. In this paper we introduce a form of non-linear latent variable model called the Generative Topographic Mapping, for which the parameters of the model can be determined using the EM algorithm. GTM provides a principled alternative to the widely used Self-Organizing Map (SOM) of Kohonen (1982), and overcomes most of the significant limitations of the SOM. We demonstrate the performance of the GTM algorithm on a toy problem and on simulated data from flow diagnostics for a multi-phase oil pipeline.",
    "date": "1997",
    "authors": [
        "Christopher M. Bishop",
        "Markus Svens\u00e9n",
        "Christopher K. I. Williams"
    ],
    "related_topics": [
        "Generative topographic map",
        "Latent variable model",
        "Probabilistic latent semantic analysis"
    ],
    "citation_count": "1,760",
    "reference_count": "38",
    "references": [
        "1554663460",
        "1679913846",
        "2049633694",
        "2044758663",
        "2125027820",
        "65738273",
        "2146610201",
        "2166698530",
        "2137969290",
        "2051719061"
    ]
},{
    "id": "2122538988",
    "title": "Nonlinear principal component analysis using autoassociative neural networks",
    "abstract": "Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal \u201cbottleneck\u201d layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.",
    "date": "1991",
    "authors": [
        "Mark A. Kramer"
    ],
    "related_topics": [
        "Dimensionality reduction",
        "Principal component analysis",
        "Feedforward neural network"
    ],
    "citation_count": "2,538",
    "reference_count": "21",
    "references": [
        "2154642048",
        "1965324089",
        "2103496339",
        "3017143921",
        "2158863190",
        "1507849272",
        "2131329059",
        "3121126077",
        "2078626246",
        "145476170"
    ]
},{
    "id": "2047870719",
    "title": "Topology representing networks",
    "abstract": "Abstract A Hebbian adaptation rule with winner-take-all like competition is introduced. It is shown that this competitive Hebbian rule forms so-called Delaunay triangulations, which play an important role in computational geometry for efficiently solving proximity problems. Given a set of neural units i, i = 1,\u2026, N, the synaptic weights of which can be interpreted as pointers wi, i = 1,\u2026, N in RD, the competitive Hebbian rule leads to a connectivity structure between the units i that corresponds to the Delaunay triangulation of the set of pointers wi. Such competitive Hebbian rule develops connections (Cij > 0) between neural units i, j with neighboring receptive fields (Voronoi polygons) Vi, Vj, whereas between all other units i, j no connections evolve (Cij = 0). Combined with a procedure that distributes the pointers wi over a given feature manifold M, for example, a submanifold M \u2282 RD, the competitive Hebbian rule provides a novel approach to the problem of constructing topology preserving feature maps and representing intricately structured manifolds. The competitive Hebbian rule connects only neural units, the receptive fields (Voronoi polygons) Vi, Vj of which are adjacent on the given manifold M. This leads to a connectivity structure that defines a perfectly topology preserving map and forms a discrete, path preserving representation of M, also in cases where M has an intricate topology. This makes this novel approach particularly useful in all applications where neighborhood relations have to be exploited or the shape and topology of submanifolds have to be take into account.",
    "date": "1994",
    "authors": [
        "Thomas Martinetz",
        "Klaus Schulten"
    ],
    "related_topics": [
        "Hebbian theory",
        "Delaunay triangulation",
        "Proximity problems"
    ],
    "citation_count": "1,130",
    "reference_count": "48",
    "references": [
        "2046079134",
        "1991848143",
        "3017143921",
        "65738273",
        "22297218",
        "2913399920",
        "2005314985",
        "2166322089",
        "2002182716",
        "2098929365"
    ]
},{
    "id": "2070320140",
    "title": "Image representations for visual learning.",
    "abstract": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induce a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics).",
    "date": "1996",
    "authors": [
        "David Beymer",
        "Tomaso Poggio"
    ],
    "related_topics": [
        "Image-based modeling and rendering",
        "Image processing",
        "Scale-space axioms"
    ],
    "citation_count": "402",
    "reference_count": "24",
    "references": [
        "2138451337",
        "2123977795",
        "2095757522",
        "2138835141",
        "2135463994",
        "2142912032",
        "94523489",
        "1981025032",
        "2053197265",
        "1963565426"
    ]
},{
    "id": "1513400187",
    "title": "Data Structures and Network Algorithms",
    "abstract": "Foundations Disjoint Sets Heaps Search Trees Linking and Cutting Trees Minimum Spanning Trees Shortest Paths Network Flows Matchings.",
    "date": "1982",
    "authors": [
        "Robert Endre Tarjan"
    ],
    "related_topics": [
        "Weight-balanced tree",
        "Spanning tree",
        "Disjoint sets"
    ],
    "citation_count": "3,065",
    "reference_count": "0",
    "references": []
},{
    "id": "2019020850",
    "title": "Data Visualization by Multimensional Scaling: A Deterministic Annealing Approach",
    "abstract": "Abstract Multidimensional scaling addresses the problem how proximity data can be faithfully visualized as points in a low-dimensional Euclidean space. The quality of a data embedding is measured by a stress function which compares proximity values with Euclidean distances of the respective points. The corresponding minimization problem is non-convex and sensitive to local minima. We present a novel deterministic annealing algorithm for the frequently used objective SSTRESS and for Sammon mapping, derived in the framework of maximum entropy estimation. Experimental results demonstrate the superiority of our optimization technique compared to conventional gradient descent methods.",
    "date": "1996",
    "authors": [
        "Hansjoerg Klock",
        "Joachim M. Buhmann"
    ],
    "related_topics": [
        "Nonlinear dimensionality reduction",
        "Sammon mapping",
        "Stress majorization"
    ],
    "citation_count": "85",
    "reference_count": "36",
    "references": [
        "2117812871",
        "2581275558",
        "1997063559",
        "2049633694",
        "3017143921",
        "2095757522",
        "2159537329",
        "2045682702",
        "2077990749",
        "2148394752"
    ]
},{
    "id": "2099741732",
    "title": "Independent component analysis, a new concept?",
    "abstract": "Abstract The independent component analysis (ICA) of a random vector consists of searching for a linear transformation that minimizes the statistical dependence between its components. In order to define suitable search criteria, the expansion of mutual information is utilized as a function of cumulants of increasing orders. An efficient algorithm is proposed, which allows the computation of the ICA of a data matrix within a polynomial time. The concept of ICA may actually be seen as an extension of the principal component analysis (PCA), which can only impose independence up to the second order and, consequently, defines directions that are orthogonal. Potential applications of ICA include data analysis and compression, Bayesian detection, localization of sources, and blind identification and deconvolution.",
    "date": "1994",
    "authors": [
        "Pierre Comon"
    ],
    "related_topics": [
        "Independent component analysis",
        "FastICA",
        "Principal component analysis"
    ],
    "citation_count": "11,026",
    "reference_count": "49",
    "references": [
        "1996355918",
        "2171074980",
        "2018388266",
        "2098301339",
        "2114018052",
        "1560089794",
        "2796930440",
        "2225937484",
        "1995963238",
        "2140352766"
    ]
},{
    "id": "2108384452",
    "title": "An information-maximization approach to blind separation and blind deconvolution",
    "abstract": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing.",
    "date": "1995",
    "authors": [
        "Anthony J. Bell",
        "Terrence J. Sejnowski"
    ],
    "related_topics": [
        "Blind signal separation",
        "Blind deconvolution",
        "Independent component analysis"
    ],
    "citation_count": "11,116",
    "reference_count": "50",
    "references": [
        "2124776405",
        "2099741732",
        "2019502123",
        "1996355918",
        "2038085771",
        "2180838288",
        "1667165204",
        "2096789154",
        "2006544565",
        "2056211671"
    ]
},{
    "id": "2123977795",
    "title": "Visual learning and recognition of 3-D objects from appearance",
    "abstract": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image. A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology.",
    "date": "1994",
    "authors": [
        "Hiroshi Murase",
        "Shree K. Nayar"
    ],
    "related_topics": [
        "3D pose estimation",
        "Pose",
        "3D single-object recognition"
    ],
    "citation_count": "3,032",
    "reference_count": "24",
    "references": [
        "2170120409",
        "2098693229",
        "2143956139",
        "2130259898",
        "2135346934",
        "2053197265",
        "1996773532",
        "2086479969",
        "2026311529",
        "2105815873"
    ]
},{
    "id": "2587818897",
    "title": "Decadal trends in the North Atlantic oscillation: regional temperatures and precipitation",
    "abstract": "Greenland ice-core data have revealed large decadal climate variations over the North Atlantic that can be related to a major source of low-frequency variability, the North Atlantic Oscillation. Over the past decade, the Oscillation has remained in one extreme phase during the winters, contributing significantly to the recent wintertime warmth across Europe and to cold conditions in the northwest Atlantic. An evaluation of the atmospheric moisture budget reveals coherent large-scale changes since 1980 that are linked to recent dry conditions over southern Europe and the Mediterranean, whereas northern Europe and parts of Scandinavia have generally experienced wetter than normal conditions.",
    "date": "1995",
    "authors": [
        "J. W. Hurrell"
    ],
    "related_topics": [
        "North Atlantic oscillation",
        "Atlantic Equatorial mode",
        "Atlantic multidecadal oscillation"
    ],
    "citation_count": "8,837",
    "reference_count": "0",
    "references": []
},{
    "id": "2137983211",
    "title": "Multilayer feedforward networks are universal approximators",
    "abstract": "Abstract This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.",
    "date": "1989",
    "authors": [
        "K. Hornik",
        "M. Stinchcombe",
        "H. White"
    ],
    "related_topics": [
        "Universal approximation theorem",
        "Borel measure",
        "Feed forward"
    ],
    "citation_count": "19,241",
    "reference_count": "9",
    "references": [
        "2103496339",
        "3146803896",
        "2056099894",
        "2416739038",
        "2090270852",
        "1654142532",
        "1581292930",
        "2097415784",
        "135768573"
    ]
},{
    "id": "3004157836",
    "title": "Numerical Recipes, The Art of Scientific Computing",
    "abstract": "",
    "date": "1986",
    "authors": [
        "William H. Press",
        "Brian P. Flannery",
        "Saul A. Teukolsky",
        "William T. Vetterling",
        "Harvey Gould"
    ],
    "related_topics": [
        "Data science",
        "Physics"
    ],
    "citation_count": "20,866",
    "reference_count": "0",
    "references": []
},{
    "id": "2140196014",
    "title": "The JPEG still picture compression standard",
    "abstract": "A joint ISO/CCITT committee known as JPEG (Joint Photographic Experts Group) has been working to establish the first international compression standard for continuous-tone still images, both grayscale and color. JPEG's proposed standard aims to be generic, to support a wide variety of applications for continuous-tone images. To meet the differing needs of many applications, the JPEG standard includes two basic compression methods, each with various modes of operation. A DCT (discrete cosine transform)-based method is specified for 'lossy' compression, and a predictive method for 'lossless' compression. JPEG features a simple lossy technique known as the Baseline method, a subset of the other DCT-based modes of operation. The Baseline method has been by far the most widely implemented JPEG method to date, and is sufficient in its own right for a large number of applications. The author provides an overview of the JPEG standard, and focuses in detail on the Baseline method. >",
    "date": "1992",
    "authors": [
        "G.K. Wallace"
    ],
    "related_topics": [
        "Lossless JPEG",
        "JPEG 2000",
        "JPEG"
    ],
    "citation_count": "7,448",
    "reference_count": "9",
    "references": [
        "2019972422",
        "2026723094",
        "1501108238",
        "2073501560",
        "2162168771",
        "1572731687",
        "1561761812",
        "2150013946",
        "1992371956"
    ]
},{
    "id": "1634005169",
    "title": "Vector Quantization and Signal Compression",
    "abstract": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems.",
    "date": "1990",
    "authors": [
        "Allen Gersho",
        "Robert M. Gray"
    ],
    "related_topics": [
        "Vector quantization",
        "Quantization (signal processing)",
        "Linde\u2013Buzo\u2013Gray algorithm"
    ],
    "citation_count": "9,317",
    "reference_count": "0",
    "references": []
},{
    "id": "3146803896",
    "title": "Multilayer feedforward networks are universal approximators",
    "abstract": "",
    "date": "1989",
    "authors": [
        "HornikK.",
        "StinchcombeM.",
        "WhiteH."
    ],
    "related_topics": [
        "Universal approximation theorem",
        "Feed forward",
        "Computer science"
    ],
    "citation_count": "14,971",
    "reference_count": "0",
    "references": []
},{
    "id": "1971735090",
    "title": "On the approximate realization of continuous mappings by neural networks",
    "abstract": "Abstract In this paper, we prove that any continuous mapping can be approximately realized by Rumelhart-Hinton-Williams' multilayer neural networks with at least one hidden layer whose output functions are sigmoid functions. The starting point of the proof for the one hidden layer case is an integral formula recently proposed by Irie-Miyake and from this, the general case (for any number of hidden layers) can be proved by induction. The two hidden layers case is proved also by using the Kolmogorov-Arnold-Sprecher theorem and this proof also gives non-trivial realizations.",
    "date": "1989",
    "authors": [
        "K. Funahashi"
    ],
    "related_topics": [
        "Universal approximation theorem",
        "Sigmoid function",
        "Artificial neural network"
    ],
    "citation_count": "6,215",
    "reference_count": "15",
    "references": [
        "2154642048",
        "2042264548",
        "1554576613",
        "3036751298",
        "1613359937",
        "3108739439",
        "2152088994",
        "3040500874",
        "2105393299",
        "2189011649"
    ]
},{
    "id": "2913399920",
    "title": "Vector quantization",
    "abstract": "A vector quantizer is a system for mapping a sequence of continuous or discrete vectors into a digital sequence suitable for communication over or storage in a digital channel. The goal of such a system is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital storage memory requirements while maintaining the necessary fidelity of the data. The mapping for each vector may or may not have memory in the sense of depending on past actions of the coder, just as in well established scalar techniques such as PCM, which has no memory, and predictive quantization, which does. Even though information theory implies that one can always obtain better performance by coding vectors instead of scalars, scalar quantizers have remained by far the most common data compression system because of their simplicity and good performance when the communication rate is sufficiently large. In addition, relatively few design techniques have existed for vector quantizers. During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes. It is the purpose of this article to survey some of these design techniques and their applications.",
    "date": "1984",
    "authors": [
        "R. Gray"
    ],
    "related_topics": [
        "Vector quantization",
        "Quantization (signal processing)",
        "Speech coding"
    ],
    "citation_count": "4,332",
    "reference_count": "44",
    "references": [
        "2134383396",
        "2127218421",
        "1995875735",
        "2583466288",
        "2142228262",
        "2021760654",
        "2164240509",
        "2150418026",
        "2119352491",
        "2040336387"
    ]
},{
    "id": "2096710051",
    "title": "Detection of signals by information theoretic criteria",
    "abstract": "A new approach is presented to the problem of detecting the number of signals in a multichannel time-series, based on the application of the information theoretic criteria for model selection introduced by Akaike (AIC) and by Schwartz and Rissanen (MDL). Unlike the conventional hypothesis testing based approach, the new approach does not requite any subjective threshold settings; the number of signals is obtained merely by minimizing the AIC or the MDL criteria. Simulation results that illustrate the performance of the new method for the detection of the number of signals received by a sensor array are presented.",
    "date": "1985",
    "authors": [
        "M. Wax",
        "T. Kailath"
    ],
    "related_topics": [
        "Akaike information criterion",
        "Statistical hypothesis testing",
        "Model selection"
    ],
    "citation_count": "4,238",
    "reference_count": "24",
    "references": [
        "2168175751",
        "2142635246",
        "2113638573",
        "2058815839",
        "2054658115",
        "2106596127",
        "1974513581",
        "2019833178",
        "2165887549",
        "1500470240"
    ]
},{
    "id": "2017977879",
    "title": "Locally Weighted Regression: An Approach to Regression Analysis by Local Fitting",
    "abstract": "Abstract Locally weighted regression, or loess, is a way of estimating a regression surface through a multivariate smoothing procedure, fitting a function of the independent variables locally and in a moving fashion analogous to how a moving average is computed for a time series. With local fitting we can estimate a much wider class of regression surfaces than with the usual classes of parametric functions, such as polynomials. The goal of this article is to show, through applications, how loess can be used for three purposes: data exploration, diagnostic checking of parametric models, and providing a nonparametric regression surface. Along the way, the following methodology is introduced: (a) a multivariate smoothing procedure that is an extension of univariate locally weighted regression; (b) statistical procedures that are analogous to those used in the least-squares fitting of parametric functions; (c) several graphical methods that are useful tools for understanding loess estimates and checking the a...",
    "date": "1988",
    "authors": [
        "William S. Cleveland",
        "Susan J. Devlin"
    ],
    "related_topics": [
        "Local regression",
        "Nonparametric regression",
        "Regression diagnostic"
    ],
    "citation_count": "5,937",
    "reference_count": "40",
    "references": [
        "2611591252",
        "1506069954",
        "2024081693",
        "2166163519",
        "2091886411",
        "2801830100",
        "2030748132",
        "3000332379",
        "2112081648",
        "2025320861"
    ]
},{
    "id": "2166116275",
    "title": "Universal approximation bounds for superpositions of a sigmoidal function",
    "abstract": "Approximation properties of a class of artificial neural networks are established. It is shown that feedforward networks with one layer of sigmoidal nonlinearities achieve integrated squared error of order O(1/n), where n is the number of nodes. The approximated function is assumed to have a bound on the first moment of the magnitude distribution of the Fourier transform. The nonlinear parameters associated with the sigmoidal nodes, as well as the parameters of linear combination, are adjusted in the approximation. In contrast, it is shown that for series expansions with n terms, in which only the parameters of linear combination are adjusted, the integrated squared approximation error cannot be made smaller than order 1/n/sup 2/d/ uniformly for functions satisfying the same smoothness assumption, where d is the dimension of the input to the function. For the class of functions examined, the approximation rate and the parsimony of the parameterization of the networks are shown to be advantageous in high-dimensional settings. >",
    "date": "1993",
    "authors": [
        "A.R. Barron"
    ],
    "related_topics": [
        "Approximation error",
        "Linear approximation",
        "Function approximation"
    ],
    "citation_count": "2,956",
    "reference_count": "25",
    "references": [
        "2137983211",
        "2103496339",
        "2084544490",
        "2095734615",
        "1559907478",
        "2044828368",
        "2108959409",
        "2095546965",
        "2112027492",
        "2151029520"
    ]
},{
    "id": "5731987",
    "title": "Original Contribution: Principal components, minor components, and linear neural networks",
    "abstract": "Many neural network realizations have been recently proposed for the statistical technique of Principal Component Analysis (PCA). Explicit connections between numerical constrained adaptive algorithms and neural networks with constrained Hebbian learning rules are reviewed. The Stochastic Gradient Ascent (SGA) neural network is proposed and shown to be closely related to the Generalized Hebbian Algorithm (GHA). The SGA behaves better for extracting the less dominant eigenvectors. The SGA algorithm is further extended to the case of learning minor components. The symmetrical Subspace Network is known to give a rotated basis of the dominant eigenvector subspace, but usually not the true eigenvectors themselves. Two extensions are proposed: in the first one, each neuron has a scalar parameter which breaks the symmetry. True eigenvectors are obtained in a local and fully parallel learning rule. In the second one, the case of an arbitrary number of parallel neurons is considered, not necessarily less than the input vector dimension.",
    "date": "1992",
    "authors": [
        "Erkki Oja"
    ],
    "related_topics": [
        "Generalized Hebbian Algorithm",
        "Oja's rule",
        "Artificial neural network"
    ],
    "citation_count": "1,164",
    "reference_count": "27",
    "references": [
        "2115907784",
        "2131329059",
        "2122925692",
        "2078626246",
        "2432567885",
        "2023963201",
        "2017257315",
        "1564660545",
        "2133884101",
        "1981479913"
    ]
},{
    "id": "2142228262",
    "title": "Asymptotically optimal block quantization",
    "abstract": "In 1948 W. R. Bennett used a companding model for nonuniform quantization and proposed the formula D \\: = \\: \\frac{1}{12N^{2}} \\: \\int \\: p(x) [ E(x) ]^{-2} \\dx for the mean-square quantizing error where N is the number of levels, p (x) is the probability density of the input, and E \\prime (x) is the slope of the compressor curve. The formula, an approximation based on the assumption that the number of levels is large and overload distortion is negligible, is a useful tool for analytical studies of quantization. This paper gives a heuristic argument generalizing Bennett's formula to block quantization where a vector of random variables is quantized. The approach is again based on the asymptotic situation where N , the number of quantized output vectors, is very large. Using the resulting heuristic formula, an optimization is performed leading to an expression for the minimum quantizing noise attainable for any block quantizer of a given block size k . The results are consistent with Zador's results and specialize to known results for the one- and two-dimensional cases and for the case of infinite block length (k \\rightarrow \\infty) . The same heuristic approach also gives an alternate derivation of a bound of Elias for multidimensional quantization. Our approach leads to a rigorous method for obtaining upper bounds on the minimum distortion for block quantizers. In particular, for k = 3 we give a tight upper bound that may in fact be exact. The idea of representing a block quantizer by a block \"compressor\" mapping followed with an optimal quantizer for uniformly distributed random vectors is also explored. It is not always possible to represent an optimal quantizer with this block companding model.",
    "date": "1979",
    "authors": [
        "A. Gersho"
    ],
    "related_topics": [
        "Quantization (signal processing)",
        "Upper and lower bounds",
        "Heuristic argument"
    ],
    "citation_count": "1,342",
    "reference_count": "12",
    "references": [
        "1978382377",
        "2146519989",
        "2004003571",
        "2156908459",
        "2001968606",
        "2137263269",
        "1589055062",
        "2068071220",
        "1972736931",
        "2152316618"
    ]
},{
    "id": "2063971957",
    "title": "Self-organizing neural network that discovers surfaces in random-dot stereograms",
    "abstract": "THE standard form of back-propagation learning1 is implausible as a model of perceptual learning because it requires an external teacher to specify the desired output of the network. We show how the external teacher can be replaced by internally derived teaching signals. These signals are generated by using the assumption that different parts of the perceptual input have common causes in the external world. Small modules that look at separate but related parts of the perceptual input discover these common causes by striving to produce outputs that agree with each other (Fig. la). The modules may look at different modalities (such as vision and touch), or the same modality at different times (for example, the consecutive two-dimensional views of a rotating three-dimensional object), or even spatially adjacent parts of the same image. Our simulations show that when our learning procedure is applied to adjacent patches of two-dimensional images, it allows a neural network that has no prior knowledge of the third dimension to discover depth in random dot stereograms of curved surfaces.",
    "date": "1992",
    "authors": [
        "Suzanna Becker",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Perceptual learning",
        "Modality (human\u2013computer interaction)",
        "Artificial neural network"
    ],
    "citation_count": "466",
    "reference_count": "3",
    "references": [
        "1498436455",
        "2797583072",
        "1944592753"
    ]
},{
    "id": "2079782346",
    "title": "Statistical theory of learning curves under entropic loss criterion",
    "abstract": "The present paper elucidates a universal property of learning curves, which shows how the generalization error, training error, and the complexity of the underlying stochastic machine are related and how the behavior of a stochastic machine is improved as the number of training examples increases. The error is measured by the entropic loss. It is proved that the generalization error converges to H0, the entropy of the conditional distribution of the true machine, as H0 + m*/(2t), while the training error converges as H0-m*/(2t), where t is the number of examples and m* shows the complexity of the network. When the model is faithful, implying that the true machine is in the model, m* is reduced to m, the number of modifiable parameters. This is a universal law because it holds for any regular machine irrespective of its structure under the maximum likelihood estimator. Similar relations are obtained for the Bayes and Gibbs learning algorithms. These learning curves show the relation among the accuracy of learning, the complexity of a model, and the number of training examples.",
    "date": "1992",
    "authors": [
        "Shun-Ichi Amari",
        "Noboru Murata"
    ],
    "related_topics": [
        "Early stopping",
        "Artificial neural network",
        "Generalization"
    ],
    "citation_count": "213",
    "reference_count": "47",
    "references": [
        "2154642048",
        "2142635246",
        "2165758113",
        "2019363670",
        "2020246210",
        "1520168181",
        "1968908999",
        "2098545770",
        "3137895569",
        "2322002063"
    ]
},{
    "id": "2089419199",
    "title": "Asymptotic quantization error of continuous signals and the quantization dimension",
    "abstract": "Extensions of the limiting qnanfizafion error formula of Bennet are proved. These are of the form D_{s,k}(N,F)=N^{-\\beta}B , where N is the number of output levels, D_{s,k}(N,F) is the s th moment of the metric distance between quantizer input and output, \\beta,B>0,k=s/\\beta is the signal space dimension, and F is the signal distribution. If a suitably well-behaved k -dimensional signal density f(x) exists, B=b_{s,k}[\\int f^{\\rho}(x)dx]^{1/ \\rho},\\rho=k/(s+k) , and b_{s,k} does not depend on f . For k=1,s=2 this reduces to Bennett's formula. If F is the Cantor distribution on [0,1],0 and this k equals the fractal dimension of the Cantor set [12,13] . Random quantization, optimal quantization in the presence of an output information constraint, and quantization noise in high dimensional spaces are also investigated.",
    "date": "1982",
    "authors": [
        "P. Zador"
    ],
    "related_topics": [
        "Cantor distribution",
        "Quantization (signal processing)",
        "Cantor set"
    ],
    "citation_count": "631",
    "reference_count": "4",
    "references": [
        "2142228262",
        "1973387369",
        "1976356564",
        "2001968606"
    ]
},{
    "id": "2162604518",
    "title": "Uniform and piecewise uniform lattice vector quantization for memoryless Gaussian and Laplacian sources",
    "abstract": "Lattice vector quantizer design procedures for nonuniform sources are presented. The procedures yield lattice vector quantizers with excellent performance and retaining the structure required for fast quantization. Analytical methods for truncating and scaling lattices to be used in vector quantizations are given, and their utility is demonstrated for independent and identically distributed (i.i.d.) Gaussian and Laplacian sources. An analytical technique for piecewise linear multidimensional compandor designs is evaluated for i.i.d. Gaussian and Laplacian sources by comparing its performance to that of the other vector quantizers. >",
    "date": "1993",
    "authors": [
        "D.G. Jeong",
        "J.D. Gibson"
    ],
    "related_topics": [
        "Vector Laplacian",
        "Vector quantization",
        "Quantization (signal processing)"
    ],
    "citation_count": "132",
    "reference_count": "39",
    "references": [
        "1634005169",
        "2134383396",
        "2186435531",
        "1565930783",
        "2142228262",
        "2801840425",
        "2119352491",
        "2063678710",
        "2089419199",
        "2029495080"
    ]
},{
    "id": "2155487652",
    "title": "On Edge Detection",
    "abstract": "Edge detection is the process that attempts to characterize the intensity changes in the image in terms of the physical processes that have originated them. A critical, intermediate goal of edge detection is the detection and characterization of significant intensity changes. This paper discusses this part of the edge detection problem. To characterize the types of intensity changes derivatives of different types, and possibly different scales, are needed. Thus, we consider this part of edge detection as a problem in numerical differentiation. We show that numerical differentiation of images is an ill-posed problem in the sense of Hadamard. Differentiation needs to be regularized by a regularizing filtering operation before differentiation. This shows that this part of edge detection consists of two steps, a filtering step and a differentiation step. Following this perspective, the paper discusses in detail the following theoretical aspects of edge detection. 1) The properties of different types of filters-with minimal uncertainty, with a bandpass spectrum, and with limited support-are derived. Minimal uncertainty filters optimize a tradeoff between computational efficiency and regularizing properties. 2) Relationships among several 2-D differential operators are established. In particular, we characterize the relation between the Laplacian and the second directional derivative along the gradient. Zero crossings of the Laplacian are not the only features computed in early vision. 3) Geometrical and topological properties of the zero crossings of differential operators are studied in terms of transversality and Morse theory.",
    "date": "1986",
    "authors": [
        "Vincent Torre",
        "Tomaso A. Poggio"
    ],
    "related_topics": [
        "Edge detection",
        "Numerical differentiation",
        "Laplace operator"
    ],
    "citation_count": "1,324",
    "reference_count": "27",
    "references": [
        "2740373864",
        "2109863423",
        "2003370853",
        "2006500012",
        "1995756857",
        "2133155955",
        "2007057443",
        "2121203842",
        "2038584908",
        "2073974819"
    ]
},{
    "id": "1995169133",
    "title": "Boltzmann machines for speech recognition",
    "abstract": "Boltzmann machines offer a new and exciting approach to automatic speech recognition, and provide a rigorous mathematical formalism for parallel computing arrays. In this paper we briefly summarize Boltzmann machine theory, and present results showing their ability to recognize both static and time-varying speech patterns. A machine with 2000 units was able to distinguish between the 11 steady-state vowels in English with an accuracy of 85%. The stability of the learning algorithm and methods of preprocessing and coding speech data before feeding it to the machine are also discussed. A new type of unit called a carry input unit, which involves a type of state-feedback, was developed for the processing of time-varying patterns and this was tested on a few short sentences. Use is made of the implications of recent work into associative memory, and the modelling of neural arrays to suggest a good configuration of Boltzmann machines for this sort of pattern recognition.",
    "date": "1986",
    "authors": [
        "R. W. Prager",
        "T. D. Harrison",
        "F. Fallside"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Content-addressable memory",
        "sort"
    ],
    "citation_count": "101",
    "reference_count": "15",
    "references": [
        "2581275558",
        "1652505363",
        "1997063559",
        "2293063825",
        "1507849272",
        "2171850596",
        "2112325651",
        "2056760934",
        "2157629899",
        "1981025738"
    ]
},{
    "id": "2591802459",
    "title": "G\u2010maximization: an unsupervised learning procedure for discovering regularities",
    "abstract": "Hill climbing is used to maximize an information theoretic measure of the difference betwen the actual behavior of a unit and the behavior that would be predicted by a statistician who knew the first order statistics of the inputs but believed them to be independent. This causes the unit to detect higher order correlations among its inputs. Initial simulations are presented, and seem encouraging. We describe an extension of the basic idea which makes it resemble competitive learning and which causes members of a population of these units to differentiate, each extracting different structure from the input.",
    "date": "2008",
    "authors": [
        "Barak A. Pearlmutter",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Competitive learning",
        "Unsupervised learning",
        "Population"
    ],
    "citation_count": "32",
    "reference_count": "0",
    "references": []
},{
    "id": "2010581677",
    "title": "A Theory of Adaptive Pattern Classifiers",
    "abstract": "This paper describes error-correction adjustment procedures for determining the weight vector of linear pattern classifiers under general pattern distribution. It is mainly aimed at clarifying theoretically the performance of adaptive pattern classifiers. In the case where the loss depends on the distance between a pattern vector and a decision boundary and where the average risk function is unimodal, it is proved that, by the procedures proposed here, the weight vector converges to the optimal one even under nonseparable pattern distributions. The speed and the accuracy of convergence are analyzed, and it is shown that there is an important tradeoff between speed and accuracy of convergence. Dynamical behaviors, when the probability distributions of patterns are changing, are also shown. The theory is generalized and made applicable to the case with general discriminant functions, including piecewise-linear discriminant functions.",
    "date": "1967",
    "authors": [
        "Shunichi Amari"
    ],
    "related_topics": [
        "Probability distribution",
        "Decision boundary",
        "Distribution (mathematics)"
    ],
    "citation_count": "706",
    "reference_count": "5",
    "references": [
        "2161278885",
        "2160133692",
        "2065973527",
        "2041273609",
        "2079724156"
    ]
},{
    "id": "2121947440",
    "title": "Normalized cuts and image segmentation",
    "abstract": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.",
    "date": "2000",
    "authors": [
        "Jianbo Shi",
        "J. Malik"
    ],
    "related_topics": [
        "Image segmentation",
        "Spectral clustering",
        "Minimum spanning tree-based segmentation"
    ],
    "citation_count": "19,408",
    "reference_count": "25",
    "references": [
        "2121947440",
        "2798909945",
        "1578099820",
        "1997063559",
        "1971784203",
        "2114487471",
        "2913192828",
        "2114030927",
        "2132603077",
        "100944330"
    ]
},{
    "id": "1578099820",
    "title": "Spectral Graph Theory",
    "abstract": "Eigenvalues and the Laplacian of a graph Isoperimetric problems Diameters and eigenvalues Paths, flows, and routing Eigenvalues and quasi-randomness Expanders and explicit constructions Eigenvalues of symmetrical graphs Eigenvalues of subgraphs with boundary conditions Harnack inequalities Heat kernels Sobolev inequalities Advanced techniques for random walks on graphs Bibliography Index.",
    "date": "1996",
    "authors": [
        "Fan R K Chung"
    ],
    "related_topics": [
        "Integral graph",
        "Spectral graph theory",
        "Laplacian matrix"
    ],
    "citation_count": "5,967",
    "reference_count": "3",
    "references": [
        "2901284226",
        "2053631808",
        "2027808858"
    ]
},{
    "id": "108654854",
    "title": "Higher eigenvalues and isoperimetric inequalities on Riemannian manifolds and graphs",
    "abstract": "5 Analysis on weighted graphs 23 5.1 Measures on graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5.2 Discrete Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.3 Green\u2019s formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.4 Integration versus Summation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5.5 Eigenvalues of Laplacian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5.6 Heat kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 5.7 Co-area formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Research supported in part by NSF Grant No. DMS 98-01446 Supported by EPSRC Fellowship B/94/AF/1782 Supported in part by NSF Grant No. DMS 95-04834",
    "date": "1999",
    "authors": [
        "Fan Chung",
        "Alexander Grigor\u2019yan",
        "Shing-Tung Yau"
    ],
    "related_topics": [
        "Isoperimetric inequality",
        "Isoperimetric dimension",
        "Laplacian matrix"
    ],
    "citation_count": "114",
    "reference_count": "31",
    "references": [
        "1578099820",
        "100944330",
        "2131183115",
        "181601562",
        "1522020530",
        "1567771969",
        "2237678354",
        "638069330",
        "2051616415",
        "2139320601"
    ]
},{
    "id": "3029645440",
    "title": "Numerical Optimization",
    "abstract": "Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems. For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side.",
    "date": "2008",
    "authors": [
        "Jorge Nocedal",
        "Stephen J. Wright"
    ],
    "related_topics": [
        "Continuous optimization",
        "Nonlinear programming",
        "Field (computer science)"
    ],
    "citation_count": "14,223",
    "reference_count": "0",
    "references": []
},{
    "id": "2104095591",
    "title": "Snakes : Active Contour Models",
    "abstract": "A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.",
    "date": "1987",
    "authors": [
        "Michael Kass",
        "Andrew P. Witkin",
        "Demetri Terzopoulos"
    ],
    "related_topics": [
        "Active contour model",
        "Active shape model",
        "Match moving"
    ],
    "citation_count": "25,185",
    "reference_count": "23",
    "references": [
        "2109863423",
        "2003370853",
        "1995756857",
        "1531060698",
        "2139762693",
        "2107198582",
        "2582614493",
        "2045798786",
        "1631253743",
        "1977699267"
    ]
},{
    "id": "2150134853",
    "title": "Scale-space and edge detection using anisotropic diffusion",
    "abstract": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image. >",
    "date": "1990",
    "authors": [
        "P. Perona",
        "J. Malik"
    ],
    "related_topics": [
        "Anisotropic diffusion",
        "Edge-preserving smoothing",
        "Smoothing"
    ],
    "citation_count": "15,978",
    "reference_count": "18",
    "references": [
        "2145023731",
        "1997063559",
        "2109863423",
        "2114487471",
        "2913192828",
        "2022735534",
        "2133155955",
        "2002312729",
        "1968245656",
        "1973976434"
    ]
},{
    "id": "2165874743",
    "title": "On Spectral Clustering: Analysis and an algorithm",
    "abstract": "Despite many empirical successes of spectral clustering methods\u2014 algorithms that cluster points using eigenvectors of matrices derived from the data\u2014there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
    "date": "2001",
    "authors": [
        "Andrew Y. Ng",
        "Michael I. Jordan",
        "Yair Weiss"
    ],
    "related_topics": [
        "Cluster analysis",
        "Correlation clustering",
        "Fuzzy clustering"
    ],
    "citation_count": "9,813",
    "reference_count": "13",
    "references": [
        "2140095548",
        "1578099820",
        "2141376824",
        "2160167256",
        "658559791",
        "2130891992",
        "2067976091",
        "2171009857",
        "2123320529",
        "1981193610"
    ]
},{
    "id": "2154579312",
    "title": "Handwritten Digit Recognition with a Back-Propagation Network",
    "abstract": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service.",
    "date": "1988",
    "authors": [
        "Yann LeCun",
        "Bernhard E. Boser",
        "John S. Denker",
        "Donnie Henderson",
        "R. E. Howard",
        "Wayne E. Hubbard",
        "Lawrence D. Jackel"
    ],
    "related_topics": [
        "Word error rate",
        "Task (project management)",
        "Backpropagation"
    ],
    "citation_count": "4,071",
    "reference_count": "11",
    "references": [
        "2154642048",
        "2147800946",
        "2114766824",
        "169539560",
        "56903235",
        "2157475639",
        "1965770722",
        "2091987367",
        "2153988646",
        "2058841211"
    ]
},{
    "id": "2122837498",
    "title": "Partially labeled classification with Markov random walks",
    "abstract": "To classify a large number of unlabeled examples we combine a limited number of labeled examples with a Markov random walk representation over the unlabeled examples. The random walk representation exploits any low dimensional structure in the data in a robust, probabilistic manner. We develop and compare several estimation criteria/algorithms suited to this representation. This includes in particular multi-way classification with an average margin criterion which permits a closed form solution. The time scale of the random walk regularizes the representation and can be set through a margin-based criterion favoring unambiguous classification. We also extend this basic regularization by adapting time scales for individual examples. We demonstrate the approach on synthetic examples and on text classification problems.",
    "date": "2001",
    "authors": [
        "Martin Szummer",
        "Tommi Jaakkola"
    ],
    "related_topics": [
        "Random walk",
        "Markov chain",
        "Margin (machine learning)"
    ],
    "citation_count": "739",
    "reference_count": "6",
    "references": [
        "2001141328",
        "1585385982",
        "2017753243",
        "2161813919",
        "2127086485",
        "2120720283"
    ]
},{
    "id": "1511160855",
    "title": "Diffusion Kernels on Graphs and Other Discrete Input Spaces",
    "abstract": "The application of kernel-based learning algorithms has, so far, largely been confined to realvalued data and a few special data types, such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea. In particular, we focus on generating kernels on graphs, for which we propose a special class of exponential kernels called diffusion kernels, which are based on the heat equation and can be regarded as the discretization of the familiar Gaussian kernel of Euclidean space.",
    "date": "2002",
    "authors": [
        "Risi Imre Kondor",
        "John D. Lafferty"
    ],
    "related_topics": [
        "Kernel (category theory)",
        "Discretization",
        "Heat kernel"
    ],
    "citation_count": "1,079",
    "reference_count": "19",
    "references": [
        "2124637492",
        "2139212933",
        "3023786531",
        "2149684865",
        "2097308346",
        "1578099820",
        "2009570821",
        "2122837498",
        "1576213419",
        "1979711143"
    ]
},{
    "id": "1585385982",
    "title": "Learning from Labeled and Unlabeled Data using Graph Mincuts",
    "abstract": "Many application domains suffer from not having enough labeled training data for learning. However, large amounts of unlabeled examples can often be gathered cheaply. As a result, there has been a great deal of work in recent years on how unlabeled data can be used to aid classification. We consider an algorithm based on finding minimum cuts in graphs, that uses pairwise relationships among the examples in order to learn from both labeled and unlabeled data.",
    "date": "2001",
    "authors": [
        "Avrim Blum",
        "Shuchi Chawla"
    ],
    "related_topics": [
        "Pairwise comparison",
        "Machine learning",
        "Computer science"
    ],
    "citation_count": "1,338",
    "reference_count": "0",
    "references": []
},{
    "id": "1979711143",
    "title": "Large margin classification using the perceptron algorithm",
    "abstract": "We introduce and analyze a new algorithm for linear classification which combines Rosenblatt\u2018s perceptron algorithm with Helmbold and Warmuth\u2018s leave-one-out method. Like Vapnik\u2018s maximal-margin classifier, our algorithm takes advantage of data that are linearly separable with large margins. Compared to Vapnik\u2018s algorithm, however, ours is much simpler to implement, and much more efficient in terms of computation time. We also show that our algorithm can be efficiently used in very high dimensional spaces using kernel functions. We performed some experiments using our algorithm, and some variants of it, for classifying images of handwritten digits. The performance of our algorithm is close to, but not as good as, the performance of maximal-margin classifiers on the same problem, while saving significantly on computation time and programming effort.",
    "date": "1998",
    "authors": [
        "Yoav Freund",
        "Robert E. Schapire"
    ],
    "related_topics": [
        "Perceptron",
        "Linear classifier",
        "Linear separability"
    ],
    "citation_count": "1,618",
    "reference_count": "22",
    "references": [
        "2156909104",
        "2148603752",
        "2119821739",
        "2087347434",
        "1530699444",
        "2069317438",
        "1979675141",
        "1496612019",
        "1667072054",
        "2011395874"
    ]
},{
    "id": "2113592823",
    "title": "Cluster Kernels for Semi-Supervised Learning",
    "abstract": "We propose a framework to incorporate unlabeled data in kernel classifier, based on the idea that two points in the same cluster are more likely to have the same label. This is achieved by modifying the eigenspectrum of the kernel matrix. Experimental results assess the validity of this approach.",
    "date": "2001",
    "authors": [
        "Olivier Chapelle",
        "Jason Weston",
        "Bernhard Sch\u00f6lkopf"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Kernel (linear algebra)",
        "Classifier (UML)"
    ],
    "citation_count": "642",
    "reference_count": "13",
    "references": [
        "2165874743",
        "2140095548",
        "2048679005",
        "2158001550",
        "2107008379",
        "2160167256",
        "2166473218",
        "2122837498",
        "2139578439",
        "1574877594"
    ]
},{
    "id": "200434350",
    "title": "A Random Walks View of Spectral Segmentation.",
    "abstract": "We present a new view of clustering and segmentation by pairwise similarities. We interpret the similarities as edge ows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This view shows that spectral methods for clustering and segmentation have a probabilistic foundation. We prove that the Normalized Cut method arises naturally from our framework and we provide a complete characterization of the cases when the Normalized Cut algorithm is exact. Then we discuss other spectral segmentation and clustering methods showing that several of them are essentially the same as NCut.",
    "date": "2000",
    "authors": [
        "Marina Meila",
        "Jianbo Shi"
    ],
    "related_topics": [
        "Cluster analysis",
        "Random walk",
        "Heterogeneous random walk in one dimension"
    ],
    "citation_count": "839",
    "reference_count": "10",
    "references": [
        "2121947440",
        "2138621811",
        "2147152072",
        "1578099820",
        "2160167256",
        "2130891992",
        "2171009857",
        "1640070940",
        "2065060195",
        "2323009482"
    ]
},{
    "id": "1497256448",
    "title": "Adaptation in natural and artificial systems",
    "abstract": "",
    "date": "1991",
    "authors": [
        "John H. Holland"
    ],
    "related_topics": [
        "Artificial development",
        "Artificial creation",
        "Adaptation (computer science)"
    ],
    "citation_count": "61,021",
    "reference_count": "0",
    "references": []
},{
    "id": "2148694408",
    "title": "Principal Component Analysis",
    "abstract": "Introduction * Properties of Population Principal Components * Properties of Sample Principal Components * Interpreting Principal Components: Examples * Graphical Representation of Data Using Principal Components * Choosing a Subset of Principal Components or Variables * Principal Component Analysis and Factor Analysis * Principal Components in Regression Analysis * Principal Components Used with Other Multivariate Techniques * Outlier Detection, Influential Observations and Robust Estimation * Rotation and Interpretation of Principal Components * Principal Component Analysis for Time Series and Other Non-Independent Data * Principal Component Analysis for Special Types of Data * Generalizations and Adaptations of Principal Component Analysis",
    "date": "1986",
    "authors": [
        "Ian Jolliffe"
    ],
    "related_topics": [
        "Principal component analysis",
        "Multilinear principal component analysis",
        "Kernel principal component analysis"
    ],
    "citation_count": "55,709",
    "reference_count": "0",
    "references": []
},{
    "id": "23758216",
    "title": "Self-organization and associative memory: 3rd edition",
    "abstract": "",
    "date": "1989",
    "authors": [
        "T. Kohonen"
    ],
    "related_topics": [
        "Content-addressable memory",
        "Computer science",
        "Cognitive science"
    ],
    "citation_count": "2,014",
    "reference_count": "0",
    "references": []
},{
    "id": "2100659887",
    "title": "A database for handwritten text recognition research",
    "abstract": "An image database for handwritten text recognition research is described. Digital images of approximately 5000 city names, 5000 state names, 10000 ZIP Codes, and 50000 alphanumeric characters are included. Each image was scanned from mail in a working post office at 300 pixels/in in 8-bit gray scale on a high-quality flat bed digitizer. The data were unconstrained for the writer, style, and method of preparation. These characteristics help overcome the limitations of earlier databases that contained only isolated characters or were prepared in a laboratory setting under prescribed circumstances. Also, the database is divided into explicit training and testing sets to facilitate the sharing of results among researchers as well as performance comparisons. >",
    "date": "1994",
    "authors": [
        "J.J. Hull"
    ],
    "related_topics": [
        "Alphanumeric",
        "Pattern recognition (psychology)",
        "Digital image"
    ],
    "citation_count": "1,770",
    "reference_count": "5",
    "references": [
        "2092642599",
        "2164371886",
        "2093439427",
        "1579840964",
        "2156113848"
    ]
},{
    "id": "2159174312",
    "title": "Mapping a Manifold of Perceptual Observations",
    "abstract": "Nonlinear dimensionality reduction is formulated here as the problem of trying to find a Euclidean feature-space embedding of a set of observations that preserves as closely as possible their intrinsic metric structure - the distances between points on the observation manifold as measured along geodesic paths. Our isometric feature mapping procedure, or isomap, is able to reliably recover low-dimensional nonlinear structure in realistic perceptual data sets, such as a manifold of face images, where conventional global mapping methods find only local minima. The recovered map provides a canonical set of globally meaningful features, which allows perceptual transformations such as interpolation, extrapolation, and analogy - highly nonlinear transformations in the original observation space - to be computed with simple linear operations in feature space.",
    "date": "1997",
    "authors": [
        "Joshua B. Tenenbaum"
    ],
    "related_topics": [
        "Isomap",
        "Nonlinear dimensionality reduction",
        "Diffusion map"
    ],
    "citation_count": "335",
    "reference_count": "11",
    "references": [
        "2124776405",
        "1991848143",
        "2107636931",
        "2143956139",
        "2047870719",
        "23758216",
        "1580684925",
        "2114309103",
        "2123421115",
        "2151391352"
    ]
},{
    "id": "2106346128",
    "title": "Learning distributed representations of concepts using linear relational embedding",
    "abstract": "We introduce linear relational embedding as a means of learning a distributed representation of concepts from data consisting of binary relations between these concepts. The key idea is to represent concepts as vectors, binary relations as matrices, and the operation of applying a relation to a concept as a matrix-vector multiplication that produces an approximation to the related concept. A representation for concepts and relations is learned by maximizing an appropriate discriminative goodness function using gradient ascent. On a task involving family relationships, learning is fast and leads to good generalization.",
    "date": "2001",
    "authors": [
        "A. Paccanaro",
        "G.E. Hinton"
    ],
    "related_topics": [
        "Relational algebra",
        "Feature learning",
        "Concept learning"
    ],
    "citation_count": "117",
    "reference_count": "16",
    "references": [
        "2154642048",
        "2147152072",
        "2110485445",
        "1983578042",
        "2051812123",
        "183625566",
        "145476170",
        "1971844566",
        "2121553911",
        "1982370770"
    ]
},{
    "id": "1746680969",
    "title": "Learning in graphical models",
    "abstract": "Part 1 Inference: introduction to inference for Bayesian networks, Robert Cowell advanced inference in Bayesian networks, Robert Cowell inference in Bayesian networks using nested junction trees, Uffe Kjoerulff bucket elimination - a unifying framework for probabilistic inference, R. Dechter an introduction to variational methods for graphical models, Michael I. Jordan et al improving the mean field approximation via the use of mixture distributions, Tommi S. Jaakkola and Michael I. Jordan introduction to Monte Carlo methods, D.J.C. MacKay suppressing random walls in Markov chain Monte Carlo using ordered overrelaxation, Radford M. Neal. Part 2 Independence: chain graphs and symmetric associations, Thomas S. Richardson the multiinformation function as a tool for measuring stochastic dependence, M. Studeny and J. Vejnarova. Part 3 Foundations for learning: a tutorial on learning with Bayesian networks, David Heckerman a view of the EM algorithm that justifies incremental, sparse and other variants, Radford M. Neal and Geoffrey E. Hinton. Part 4 Learning from data: latent variable models, Christopher M. Bishop stochastic algorithms for exploratory data analysis - data clustering and data visualization, Joachim M. Buhmann learning Bayesian networks with local structure, Nir Friedman and Moises Goldszmidt asymptotic model selection for directed networks with hidden variables, Dan Geiger et al a hierarchical community of experts, Geoffrey E. Hinton et al an information-theoretic analysis of hard and soft assignment methods for clustering, Michael J. Kearns et al learning hybrid Bayesian networks from data, Stefano Monti and Gregory F. Cooper a mean field learning algorithm for unsupervised neural networks, Lawrence Saul and Michael Jordan edge exclusion tests for graphical Gaussian models, Peter W.F. Smith and Joe Whittaker hepatitis B - a case study in MCMC, D.J. Spiegelhalter et al prediction with Gaussian processes - from linear regression to linear prediction and beyond, C.K.I. Williams.",
    "date": "1999",
    "authors": [
        "Michael I. Jordan"
    ],
    "related_topics": [
        "Graphical model",
        "Bayesian network",
        "Markov chain Monte Carlo"
    ],
    "citation_count": "2,681",
    "reference_count": "0",
    "references": []
},{
    "id": "2083380015",
    "title": "Connectionist learning of belief networks",
    "abstract": "Abstract Connectionist learning procedures are presented for \u201csigmoid\u201d and \u201cnoisy-OR\u201d varieties of probabilistic belief networks. These networks have previously been seen primarily as a means of representing knowledge derived from experts. Here it is shown that the \u201cGibbs sampling\u201d simulation procedure for such networks can support maximum-likelihood learning from empirical data through local gradient ascent. This learning procedure resembles that used for \u201cBoltzmann machines\u201d, and like it, allows the use of \u201chidden\u201d variables to model correlations between visible variables. Due to the directed nature of the connections in a belief network, however, the \u201cnegative phase\u201d of Boltzmann machine learning is unnecessary. Experimental results show that, as a result, learning in a sigmoid belief network can be faster than in a Boltzmann machine. These networks have other advantages over Boltzmann machines in pattern classification and decision making applications, are naturally applicable to unsupervised learning problems, and provide a link between work on connectionist learning and work on the representation of expert knowledge.",
    "date": "1992",
    "authors": [
        "Radford M. Neal"
    ],
    "related_topics": [
        "Restricted Boltzmann machine",
        "Boltzmann machine",
        "Computational learning theory"
    ],
    "citation_count": "682",
    "reference_count": "21",
    "references": [
        "2159080219",
        "1652505363",
        "1498436455",
        "2049633694",
        "2083875149",
        "1593793857",
        "1507849272",
        "2166698530",
        "1992880122",
        "1547224907"
    ]
},{
    "id": "2114153178",
    "title": "Rate-coded Restricted Boltzmann Machines for Face Recognition",
    "abstract": "We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.",
    "date": "1999",
    "authors": [
        "Yee Whye Teh",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Feature (computer vision)",
        "Generative model",
        "Posterior probability"
    ],
    "citation_count": "161",
    "reference_count": "12",
    "references": [
        "2116064496",
        "2138451337",
        "1902027874",
        "2121647436",
        "2159080219",
        "2113341759",
        "2125027820",
        "2128716185",
        "1547224907",
        "1813659000"
    ]
},{
    "id": "1547224907",
    "title": "Learning and relearning in Boltzmann machines",
    "abstract": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References",
    "date": "1986",
    "authors": [
        "G. E. Hinton",
        "T. J. Sejnowski"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Computation",
        "Relaxation (approximation)"
    ],
    "citation_count": "2,055",
    "reference_count": "0",
    "references": []
},{
    "id": "2101706260",
    "title": "Recognizing handwritten digits using hierarchical products of experts",
    "abstract": "The product of experts learning procedure can discover a set of stochastic binary features that constitute a nonlinear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, a hierarchy of separate models can be learned, for each digit class. Each model in the hierarchy learns a layer of binary feature detectors that model the probability distribution of vectors of activity of feature detectors in the layer below. The models in the hierarchy are trained sequentially and each model uses a layer of binary feature detectors to learn a generative model of the patterns of feature activities in the preceding layer. After training, each layer of feature detectors produces a separate, unnormalized log probability score. With three layers of feature detectors for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data.",
    "date": "2002",
    "authors": [
        "G. Mayraz",
        "G.E. Hinton"
    ],
    "related_topics": [
        "Generative model",
        "Feature (computer vision)",
        "Discriminative model"
    ],
    "citation_count": "84",
    "reference_count": "15",
    "references": [
        "2912934387",
        "2116064496",
        "2159080219",
        "2150884987",
        "28412257",
        "1547224907",
        "2104867159",
        "1667072054",
        "1813659000",
        "2100559472"
    ]
},{
    "id": "2124351082",
    "title": "Training support vector machines: an application to face detection",
    "abstract": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.",
    "date": "1997",
    "authors": [
        "E. Osuna",
        "R. Freund",
        "F. Girosit"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Least squares support vector machine",
        "Support vector machine"
    ],
    "citation_count": "3,885",
    "reference_count": "13",
    "references": [
        "2156909104",
        "2119821739",
        "2087347434",
        "2159686933",
        "26816478",
        "2159173611",
        "2137346077",
        "2084844503",
        "2056695679",
        "2125713050"
    ]
},{
    "id": "2155511848",
    "title": "A statistical method for 3D object detection applied to faces and cars",
    "abstract": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.",
    "date": "2000",
    "authors": [
        "H. Schneiderman",
        "T. Kanade"
    ],
    "related_topics": [
        "Viola\u2013Jones object detection framework",
        "Object detection",
        "Face detection"
    ],
    "citation_count": "1,889",
    "reference_count": "10",
    "references": [
        "2156909104",
        "3124955340",
        "2117812871",
        "2217896605",
        "1658679052",
        "2159686933",
        "2140785063",
        "2166713160",
        "2138560582",
        "2151777012"
    ]
},{
    "id": "2160225842",
    "title": "Learning a Sparse Representation for Object Detection",
    "abstract": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches.",
    "date": "2002",
    "authors": [
        "Shivani Agarwal",
        "Dan Roth"
    ],
    "related_topics": [
        "Object-class detection",
        "Object detection",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "766",
    "reference_count": "21",
    "references": [
        "2164598857",
        "2217896605",
        "2152473410",
        "2124087378",
        "2124351082",
        "2155511848",
        "1949116567",
        "1564419782",
        "2156406284",
        "2124722975"
    ]
},{
    "id": "2295106276",
    "title": "Matching shapes",
    "abstract": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.",
    "date": "2000",
    "authors": [
        "S. Belongie",
        "J. Malik",
        "J. Puzicha"
    ],
    "related_topics": [
        "Shape analysis (digital geometry)",
        "Shape context",
        "Similarity (geometry)"
    ],
    "citation_count": "511",
    "reference_count": "22",
    "references": [
        "2310919327",
        "2123977795",
        "2101522199",
        "2095757522",
        "2089181482",
        "2062104878",
        "2106404777",
        "2108444897",
        "2100318434",
        "2096840836"
    ]
},{
    "id": "2141376824",
    "title": "Contour and Texture Analysis for Image Segmentation",
    "abstract": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown.",
    "date": "2001",
    "authors": [
        "Jitendra Malik",
        "Serge Belongie",
        "Thomas Leung",
        "Jianbo Shi"
    ],
    "related_topics": [
        "Image texture",
        "Texture filtering",
        "Texture compression"
    ],
    "citation_count": "1,595",
    "reference_count": "38",
    "references": [
        "2121947440",
        "2145023731",
        "1578099820",
        "1997063559",
        "2121927366",
        "1634005169",
        "3017143921",
        "2114487471",
        "2160167256",
        "1490632837"
    ]
},{
    "id": "1612003148",
    "title": "Probabilistic latent semantic analysis",
    "abstract": "Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.",
    "date": "1999",
    "authors": [
        "Thomas Hofmann"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent semantic analysis",
        "Document-term matrix"
    ],
    "citation_count": "3,337",
    "reference_count": "13",
    "references": [
        "2147152072",
        "2107743791",
        "2049633694",
        "1956559956",
        "1983578042",
        "2134731454",
        "2127314673",
        "2056029990",
        "2143144851",
        "2140842551"
    ]
},{
    "id": "2122090912",
    "title": "Maximum-Margin Matrix Factorization",
    "abstract": "We present a novel approach to collaborative prediction, using low-norm instead of low-rank factorizations. The approach is inspired by, and has strong connections to, large-margin linear discrimination. We show how to learn low-norm factorizations by solving a semi-definite program, and discuss generalization error bounds for them.",
    "date": "2004",
    "authors": [
        "Nathan Srebro",
        "Jason Rennie",
        "Tommi S. Jaakkola"
    ],
    "related_topics": [
        "Matrix decomposition",
        "Margin (machine learning)",
        "Algebra"
    ],
    "citation_count": "1,246",
    "reference_count": "14",
    "references": [
        "1902027874",
        "2145295623",
        "2134731454",
        "2049455633",
        "2165395308",
        "1966096622",
        "2151052953",
        "2118079529",
        "2135001774",
        "1999613943"
    ]
},{
    "id": "205159212",
    "title": "Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure",
    "abstract": "",
    "date": "2007",
    "authors": [
        "Ruslan Salakhutdinov",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "k-nearest neighbors algorithm",
        "Neighbourhood (mathematics)",
        "Theoretical computer science"
    ],
    "citation_count": "385",
    "reference_count": "18",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2117154949",
        "2130556178",
        "2157364932",
        "2144935315",
        "2159737176",
        "2124914669",
        "2157444450"
    ]
},{
    "id": "2165395308",
    "title": "Weighted low-rank approximations",
    "abstract": "We study the common problem of approximating a target matrix with a matrix of lower rank. We provide a simple and efficient (EM) algorithm for solving weighted low-rank approximation problems, which, unlike their unweighted version, do not admit a closed-form solution in general. We analyze, in addition, the nature of locally optimal solutions that arise in this context, demonstrate the utility of accommodating the weights in reconstructing the underlying low-rank representation, and extend the formulation to non-Gaussian noise models such as logistic models. Finally, we apply the methods developed to a collaborative filtering task.",
    "date": "2003",
    "authors": [
        "Nathan Srebro",
        "Tommi Jaakkola"
    ],
    "related_topics": [
        "Rank (linear algebra)",
        "Matrix (mathematics)",
        "Context (language use)"
    ],
    "citation_count": "920",
    "reference_count": "13",
    "references": [
        "2117354486",
        "1673941785",
        "2170653751",
        "2021680564",
        "2135001774",
        "1496451467",
        "1516172206",
        "1568698519",
        "2139451327",
        "2252194958"
    ]
},{
    "id": "1989702938",
    "title": "Face recognition: A literature survey",
    "abstract": "As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.",
    "date": "2003",
    "authors": [
        "W. Zhao",
        "R. Chellappa",
        "P. J. Phillips",
        "A. Rosenfeld"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face Recognition Grand Challenge",
        "Literature survey"
    ],
    "citation_count": "9,005",
    "reference_count": "162",
    "references": [
        "2156909104",
        "2164598857",
        "2138451337",
        "2217896605",
        "2121647436",
        "2152826865",
        "2108384452",
        "2033419168",
        "2121601095",
        "2038952578"
    ]
},{
    "id": "2098947662",
    "title": "View-based and modular eigenspaces for face recognition",
    "abstract": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated. >",
    "date": "1994",
    "authors": [
        "Pentland",
        "Moghaddam",
        "Starner"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "3D single-object recognition",
        "Feature (machine learning)"
    ],
    "citation_count": "2,971",
    "reference_count": "13",
    "references": [
        "2138451337",
        "2113341759",
        "2135463994",
        "2138313032",
        "2130506643",
        "2157418942",
        "1993867646",
        "2112684592",
        "2121863133",
        "2030234875"
    ]
},{
    "id": "2905573712",
    "title": "Face recognition: A Literature Survey",
    "abstract": "",
    "date": "2007",
    "authors": [
        "W. Zhao",
        "R. Rosenfeld",
        "R. Chellappa"
    ],
    "related_topics": [
        "Literature survey",
        "Business intelligence",
        "Facial recognition system"
    ],
    "citation_count": "1,625",
    "reference_count": "0",
    "references": []
},{
    "id": "2155759509",
    "title": "The CMU Pose, Illumination, and Expression (PIE) database",
    "abstract": "Between October 2000 and December 2000, we collected a database of over 40,000 facial images of 68 people. Using the CMU (Carnegie Mellon University) 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this database the CMU Pose, Illumination and Expression (PIE) database. In this paper, we describe the imaging hardware, the collection procedure, the organization of the database, several potential uses of the database, and how to obtain the database.",
    "date": "2002",
    "authors": [
        "T. Sim",
        "S. Baker",
        "M. Bsat"
    ],
    "related_topics": [
        "Facial recognition system",
        "Computer vision",
        "Computer graphics (images)"
    ],
    "citation_count": "3,888",
    "reference_count": "9",
    "references": [
        "2125127226",
        "2118774738",
        "2102760078",
        "2120420721",
        "2110822444",
        "2121114545",
        "2106143125",
        "2141503314",
        "2144855601"
    ]
},{
    "id": "2095757522",
    "title": "Distortion invariant object recognition in the dynamic link architecture",
    "abstract": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >",
    "date": "1993",
    "authors": [
        "M. Lades",
        "J.C. Vorbruggen",
        "J. Buhmann",
        "J. Lange",
        "C. von der Malsburg",
        "R.P. Wurtz",
        "W. Konen"
    ],
    "related_topics": [
        "Dynamic link matching",
        "3D single-object recognition",
        "Facial recognition system"
    ],
    "citation_count": "2,688",
    "reference_count": "31",
    "references": [
        "2011039300",
        "3144368627",
        "1991848143",
        "2135463994",
        "2130259898",
        "2079948225",
        "2167034998",
        "23758216",
        "2051719061",
        "1914401667"
    ]
},{
    "id": "2144354855",
    "title": "Face recognition: a convolutional neural-network approach",
    "abstract": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.",
    "date": "1996",
    "authors": [
        "S. Lawrence",
        "C.L. Giles",
        "Ah Chung Tsoi",
        "A.D. Back"
    ],
    "related_topics": [
        "Convolutional neural network",
        "Multilayer perceptron",
        "Self-organizing map"
    ],
    "citation_count": "3,297",
    "reference_count": "43",
    "references": [
        "2124776405",
        "1679913846",
        "2138451337",
        "2046079134",
        "2115689562",
        "2098947662",
        "2113341759",
        "1770825568",
        "2095757522",
        "2012352340"
    ]
},{
    "id": "2107369107",
    "title": "Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class",
    "abstract": "The classical way of attempting to solve the face (or object) recognition problem is by using large and representative data sets. In many applications, though, only one sample per class is available to the system. In this contribution, we describe a probabilistic approach that is able to compensate for imprecisely localized, partially occluded, and expression-variant faces even when only one single training sample per class is available to the system. To solve the localization problem, we find the subspace (within the feature space, e.g., eigenspace) that represents this error for each of the training images. To resolve the occlusion problem, each face is divided into k local regions which are analyzed in isolation. In contrast with other approaches where a simple voting space is used, we present a probabilistic method that analyzes how \"good\" a local match is. To make the recognition system less sensitive to the differences between the facial expression displayed on the training and the testing images, we weight the results obtained on each local area on the basis of how much of this local area is affected by the expression displayed on the current test image.",
    "date": "2002",
    "authors": [
        "A.M. Martinez"
    ],
    "related_topics": [
        "Facial recognition system",
        "Feature vector",
        "Standard test image"
    ],
    "citation_count": "1,001",
    "reference_count": "79",
    "references": [
        "2156909104",
        "2148603752",
        "2138451337",
        "2217896605",
        "2121647436",
        "2033419168",
        "2132549764",
        "2121601095",
        "2049633694",
        "2914885528"
    ]
},{
    "id": "10021998",
    "title": "Loss Functions for Discriminative Training of Energy-Based Models.",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Yann LeCun",
        "Fu Jie Huang"
    ],
    "related_topics": [
        "Discriminative model",
        "Speech recognition",
        "Pattern recognition"
    ],
    "citation_count": "104",
    "reference_count": "12",
    "references": [
        "2310919327",
        "2147880316",
        "2132339004",
        "2137813581",
        "2134557905",
        "2008652694",
        "2105644991",
        "1802356529",
        "2148099973",
        "2175582831"
    ]
},{
    "id": "2145096794",
    "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information",
    "abstract": "This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.",
    "date": "2006",
    "authors": [
        "E.J. Candes",
        "J. Romberg",
        "T. Tao"
    ],
    "related_topics": [
        "Convex optimization",
        "Free probability",
        "Trigonometric polynomial"
    ],
    "citation_count": "17,448",
    "reference_count": "31",
    "references": [
        "3029645440",
        "2078204800",
        "2798909945",
        "2116148865",
        "2099641086",
        "2103559027",
        "2154332973",
        "2136235822",
        "2012365979",
        "2158537680"
    ]
},{
    "id": "2078204800",
    "title": "Atomic Decomposition by Basis Pursuit",
    "abstract": "The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries---stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis pursuit (BP) is a principle for decomposing a signal into an \"optimal\"' superposition of dictionary elements, where optimal means having the smallest l1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear and quadratic programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.",
    "date": "2000",
    "authors": [
        "Scott Shaobing Chen",
        "David L. Donoho",
        "Michael A. Saunders"
    ],
    "related_topics": [
        "Basis pursuit",
        "Basis pursuit denoising",
        "Wavelet packet decomposition"
    ],
    "citation_count": "25,068",
    "reference_count": "43",
    "references": [
        "2062024414",
        "2798909945",
        "2146842127",
        "2099641086",
        "2151693816",
        "2103559027",
        "2152328854",
        "2156447271",
        "2611147814",
        "2128659236"
    ]
},{
    "id": "2116148865",
    "title": "Greed is good: algorithmic results for sparse approximation",
    "abstract": "This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.",
    "date": "2004",
    "authors": [
        "J.A. Tropp"
    ],
    "related_topics": [
        "Sparse approximation",
        "Matching pursuit",
        "Basis pursuit"
    ],
    "citation_count": "4,028",
    "reference_count": "30",
    "references": [
        "2078204800",
        "2610857016",
        "2099641086",
        "2151693816",
        "2154332973",
        "2136235822",
        "2156447271",
        "391578156",
        "1605417594",
        "2167839759"
    ]
},{
    "id": "2099641086",
    "title": "Uncertainty principles and ideal atomic decomposition",
    "abstract": "Suppose a discrete-time signal S(t), 0/spl les/t<N, is a superposition of atoms taken from a combined time-frequency dictionary made of spike sequences 1/sub {t=/spl tau/}/ and sinusoids exp{2/spl pi/iwt/N}//spl radic/N. Can one recover, from knowledge of S alone, the precise collection of atoms going to make up S? Because every discrete-time signal can be represented as a superposition of spikes alone, or as a superposition of sinusoids alone, there is no unique way of writing S as a sum of spikes and sinusoids in general. We prove that if S is representable as a highly sparse superposition of atoms from this time-frequency dictionary, then there is only one such highly sparse representation of S, and it can be obtained by solving the convex optimization problem of minimizing the l/sup 1/ norm of the coefficients among all decompositions. Here \"highly sparse\" means that N/sub t/+N/sub w/</spl radic/N/2 where N/sub t/ is the number of time atoms, N/sub w/ is the number of frequency atoms, and N is the length of the discrete-time signal. Underlying this result is a general l/sup 1/ uncertainty principle which says that if two bases are mutually incoherent, no nonzero signal can have a sparse representation in both bases simultaneously. For the above setting, the bases are sinusoids and spikes, and mutual incoherence is measured in terms of the largest inner product between different basis elements. The uncertainty principle holds for a variety of interesting basis pairs, not just sinusoids and spikes. The results have idealized applications to band-limited approximation with gross errors, to error-correcting encryption, and to separation of uncoordinated sources. Related phenomena hold for functions of a real variable, with basis pairs such as sinusoids and wavelets, and for functions of two variables, with basis pairs such as wavelets and ridgelets. In these settings, if a function f is representable by a sufficiently sparse superposition of terms taken from both bases, then there is only one such sparse representation; it may be obtained by minimum l/sup 1/ norm atomic decomposition. The condition \"sufficiently sparse\" becomes a multiscale condition; for example, that the number of wavelets at level j plus the number of sinusoids in the jth dyadic frequency band are together less than a constant times 2/sup j/2/.",
    "date": "2001",
    "authors": [
        "D.L. Donoho",
        "X. Huo"
    ],
    "related_topics": [
        "Sparse approximation",
        "Superposition principle",
        "Norm (mathematics)"
    ],
    "citation_count": "2,363",
    "reference_count": "30",
    "references": [
        "2115755118",
        "2062024414",
        "2078204800",
        "2151693816",
        "1916685473",
        "1604810369",
        "2066462711",
        "2125455772",
        "1997149618",
        "2033367330"
    ]
},{
    "id": "2097323375",
    "title": "Stable recovery of sparse overcomplete representations in the presence of noise",
    "abstract": "Overcomplete representations are attracting interest in signal processing theory, particularly due to their potential to generate sparse representations of signals. However, in general, the problem of finding sparse representations must be unstable in the presence of noise. This paper establishes the possibility of stable recovery under a combination of sufficient sparsity and favorable structure of the overcomplete system. Considering an ideal underlying signal that has a sufficiently sparse representation, it is assumed that only a noisy version of it can be observed. Assuming further that the overcomplete system is incoherent, it is shown that the optimally sparse approximation to the noisy data differs from the optimally sparse decomposition of the ideal noiseless signal by at most a constant multiple of the noise level. As this optimal-sparsity method requires heavy (combinatorial) computational effort, approximation algorithms are considered. It is shown that similar stability is also available using the basis and the matching pursuit algorithms. Furthermore, it is shown that these methods result in sparse approximation of the noisy data that contains only terms also appearing in the unique sparsest representation of the ideal noiseless sparse signal.",
    "date": "2003",
    "authors": [
        "D.L. Donoho",
        "M. Elad",
        "V.N. Temlyakov"
    ],
    "related_topics": [
        "Sparse approximation",
        "K-SVD",
        "Matching pursuit"
    ],
    "citation_count": "2,616",
    "reference_count": "46",
    "references": [
        "2135046866",
        "2078204800",
        "2610857016",
        "2116148865",
        "2099641086",
        "2151693816",
        "2154332973",
        "2132680427",
        "2136235822",
        "2069912449"
    ]
},{
    "id": "2136235822",
    "title": "Sparse representations in unions of bases",
    "abstract": "The purpose of this correspondence is to generalize a result by Donoho and Huo and Elad and Bruckstein on sparse representations of signals in a union of two orthonormal bases for R/sup N/. We consider general (redundant) dictionaries for R/sup N/, and derive sufficient conditions for having unique sparse representations of signals in such dictionaries. The special case where the dictionary is given by the union of L/spl ges/2 orthonormal bases for R/sup N/ is studied in more detail. In particular, it is proved that the result of Donoho and Huo, concerning the replacement of the /spl lscr//sup 0/ optimization problem with a linear programming problem when searching for sparse representations, has an analog for dictionaries that may be highly redundant.",
    "date": "2003",
    "authors": [
        "R. Gribonval",
        "M. Nielsen"
    ],
    "related_topics": [
        "Sparse approximation",
        "Orthonormal basis",
        "Optimization problem"
    ],
    "citation_count": "1,023",
    "reference_count": "6",
    "references": [
        "2099641086",
        "2154332973",
        "2167839759",
        "2086869478",
        "2133866430",
        "2115090644"
    ]
},{
    "id": "2147656689",
    "title": "Just relax: convex programming methods for identifying sparse signals in noise",
    "abstract": "This paper studies a difficult and fundamental problem that arises throughout electrical engineering, applied mathematics, and statistics. Suppose that one forms a short linear combination of elementary signals drawn from a large, fixed collection. Given an observation of the linear combination that has been contaminated with additive noise, the goal is to identify which elementary signals participated and to approximate their coefficients. Although many algorithms have been proposed, there is little theory which guarantees that these algorithms can accurately and efficiently solve the problem. This paper studies a method called convex relaxation, which attempts to recover the ideal sparse signal by solving a convex program. This approach is powerful because the optimization can be completed in polynomial time with standard scientific software. The paper provides general conditions which ensure that convex relaxation succeeds. As evidence of the broad impact of these results, the paper describes how convex relaxation can be used for several concrete signal recovery problems. It also describes applications to channel coding, linear regression, and numerical analysis",
    "date": "2006",
    "authors": [
        "J.A. Tropp"
    ],
    "related_topics": [
        "Convex optimization",
        "Proper convex function",
        "Relaxation (iterative method)"
    ],
    "citation_count": "1,268",
    "reference_count": "64",
    "references": [
        "2296319761",
        "2145096794",
        "2099111195",
        "2115755118",
        "2129638195",
        "2135046866",
        "2122825543",
        "2078204800",
        "2610857016",
        "2116148865"
    ]
},{
    "id": "2012365979",
    "title": "Near-optimal sparse fourier representations via sampling",
    "abstract": "(MATH) We give an algorithm for finding a Fourier representation R of B terms for a given discrete signal signal A of length N, such that $\\|\\signal-\\repn\\|_2^2$ is within the factor (1 +e) of best possible $\\|\\signal-\\repn_\\opt\\|_2^2$. Our algorithm can access A by reading its values on a sample set T \u2286[0,N), chosen randomly from a (non-product) distribution of our choice, independent of A. That is, we sample non-adaptively. The total time cost of the algorithm is polynomial in B log(N)log(M)e (where M is the ratio of largest to smallest numerical quantity encountered), which implies a similar bound for the number of samples.",
    "date": "2002",
    "authors": [
        "A. C. Gilbert",
        "S. Guha",
        "P. Indyk",
        "S. Muthukrishnan",
        "M. Strauss"
    ],
    "related_topics": [
        "Polynomial",
        "Discrete-time signal",
        "Fourier transform"
    ],
    "citation_count": "355",
    "reference_count": "17",
    "references": [
        "2151693816",
        "2080745194",
        "2125455772",
        "1979750072",
        "2047424291",
        "1970950689",
        "2095546965",
        "2042194938",
        "2101610102",
        "1899006432"
    ]
},{
    "id": "2096613063",
    "title": "Data compression and harmonic analysis",
    "abstract": "In this paper we review some recent interactions between harmonic analysis and data compression. The story goes back of course to Shannon's R(D) theory in the case of Gaussian stationary processes, which says that transforming into a Fourier basis followed by block coding gives an optimal lossy compression technique; practical developments like transform-based image compression have been inspired by this result. In this paper we also discuss connections perhaps less familiar to the information theory community, growing out of the field of harmonic analysis. Recent harmonic analysis constructions, such as wavelet transforms and Gabor transforms, are essentially optimal transforms for transform coding in certain settings. Some of these transforms are under consideration for future compression standards. We discuss some of the lessons of harmonic analysis in this century. Typically, the problems and achievements of this field have involved goals that were not obviously related to practical data compression, and have used a language not immediately accessible to outsiders. Nevertheless, through an extensive generalization of what Shannon called the \"sampling theorem\", harmonic analysis has succeeded in developing new forms of functional representation which turn out to have significant data compression interpretations. We explain why harmonic analysis has interacted with data compression, and we describe some interesting recent ideas in the field that may affect data compression in the future.",
    "date": "1998",
    "authors": [
        "D.L. Donoho",
        "M. Vetterli",
        "R.A. DeVore",
        "I. Daubechies"
    ],
    "related_topics": [
        "Data compression",
        "Image compression",
        "Lossy compression"
    ],
    "citation_count": "587",
    "reference_count": "84",
    "references": [
        "2099111195",
        "2062024414",
        "2132984323",
        "2142276208",
        "2098914003",
        "2053691921",
        "1634005169",
        "2037612300",
        "1996021349",
        "1584610719"
    ]
},{
    "id": "2050880896",
    "title": "Unconditional Bases Are Optimal Bases for Data Compression and for Statistical Estimation",
    "abstract": "Abstract An orthogonal basis of L2 which is also an unconditional basis of a functional space F is an optimal basis for compressing, estimating, and recovering functions in F . Simple thresholding operations, applied in the unconditional basis, work essentially better for compressing, estimating, and recovering than they do in any other orthogonal basis. In fact, simple thresholding in an unconditional basis works essentially better for recovery and estimation than other methods, period. (Performance is measured in an asymptotic minimax sense.) As an application, we formalize and prove Mallat\u2032s Heuristic, which says that wavelet bases are optimal for representing functions containing singularities, when there may be an arbitrary number of singularities, arbitrarily distributed.",
    "date": "1993",
    "authors": [
        "David L. Donoho"
    ],
    "related_topics": [
        "Orthogonal basis",
        "Basis (linear algebra)",
        "Thresholding"
    ],
    "citation_count": "576",
    "reference_count": "0",
    "references": []
},{
    "id": "2129638195",
    "title": "Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?",
    "abstract": "Suppose we are given a vector f in a class FsubeRopfN , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr2) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f|(n)lesRmiddotn-1p/, where R>0 and p>0. Suppose that we take measurements yk=langf# ,Xkrang,k=1,...,K, where the Xk are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0<p<1 and with overwhelming probability, our reconstruction ft, defined as the solution to the constraints yk=langf# ,Xkrang with minimal lscr1 norm, obeys parf-f#parlscr2lesCp middotRmiddot(K/logN)-r, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed",
    "date": "2006",
    "authors": [
        "E.J. Candes",
        "T. Tao"
    ],
    "related_topics": [
        "Norm (mathematics)",
        "Restricted isometry property",
        "Random projection"
    ],
    "citation_count": "7,837",
    "reference_count": "45",
    "references": [
        "2296616510",
        "2145096794",
        "2115755118",
        "2129131372",
        "2078204800",
        "2099641086",
        "2103559027",
        "2050834445",
        "2154332973",
        "2136235822"
    ]
},{
    "id": "2050834445",
    "title": "For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution",
    "abstract": "We consider linear equations y = \u03a6x where y is a given vector in \u211dn and \u03a6 is a given n \u00d7 m matrix with n 0 so that for large n and for all \u03a6's except a negligible fraction, the following property holds: For every y having a representation y = \u03a6x0by a coefficient vector x0 \u2208 \u211dmwith fewer than \u03c1 \u00b7 n nonzeros, the solution x1of the 1-minimization problem is unique and equal to x0. In contrast, heuristic attempts to sparsely solve such systems\u2014greedy algorithms and thresholding\u2014perform poorly in this challenging setting. The techniques include the use of random proportional embeddings and almost-spherical sections in Banach space theory, and deviation bounds for the eigenvalues of random Wishart matrices. \u00a9 2006 Wiley Periodicals, Inc.",
    "date": "2006",
    "authors": [
        "David L. Donoho"
    ],
    "related_topics": [
        "Underdetermined system",
        "Eigenvalues and eigenvectors",
        "Norm (mathematics)"
    ],
    "citation_count": "3,732",
    "reference_count": "26",
    "references": [
        "2145096794",
        "2078204800",
        "2116148865",
        "2099641086",
        "2151693816",
        "2097323375",
        "2154332973",
        "2136235822",
        "2156447271",
        "1573820523"
    ]
},{
    "id": "2154332973",
    "title": "Optimally sparse representation in general (nonorthogonal) dictionaries via 1 minimization",
    "abstract": "Given a dictionary D = {dk} of vectors dk, we seek to represent a signal S as a linear combination S = \u2211k \u03b3(k)dk, with scalar coefficients \u03b3(k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the l1 norm of the coefficients \u03b3. In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.",
    "date": "2003",
    "authors": [
        "David L. Donoho",
        "Michael Elad"
    ],
    "related_topics": [
        "Sparse approximation",
        "Convex optimization",
        "Linear combination"
    ],
    "citation_count": "3,400",
    "reference_count": "19",
    "references": [
        "2115755118",
        "2078204800",
        "2610857016",
        "2099641086",
        "2151693816",
        "2136235822",
        "2167839759",
        "1604810369",
        "2125455772",
        "1995963238"
    ]
},{
    "id": "2087347434",
    "title": "A training algorithm for optimal margin classifiers",
    "abstract": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.",
    "date": "1992",
    "authors": [
        "Bernhard E. Boser",
        "Isabelle M. Guyon",
        "Vladimir N. Vapnik"
    ],
    "related_topics": [
        "Margin (machine learning)",
        "Decision boundary",
        "Stability (learning theory)"
    ],
    "citation_count": "13,540",
    "reference_count": "20",
    "references": [
        "3017143921",
        "2171277043",
        "2165758113",
        "2154579312",
        "2266946488",
        "1530699444",
        "2076118331",
        "2086472796",
        "2111494971",
        "1965770722"
    ]
},{
    "id": "1530699444",
    "title": "Estimation of Dependences Based on Empirical Data",
    "abstract": "Realism and Instrumentalism: Classical Statistics and VC Theory (1960-1980).- Falsifiability and Parsimony: VC Dimension and the Number of Entities (1980-2000).- Noninductive Methods of Inference: Direct Inference Instead of Generalization (2000-...).- The Big Picture.",
    "date": "2010",
    "authors": [
        "Vladimir Naumovich Vapnik"
    ],
    "related_topics": [
        "Inference",
        "VC dimension",
        "Generalization"
    ],
    "citation_count": "5,080",
    "reference_count": "0",
    "references": []
},{
    "id": "2168228682",
    "title": "Comparison of classifier methods: a case study in handwritten digit recognition",
    "abstract": "This paper compares the performance of several classifier algorithms on a standard database of handwritten digits. We consider not only raw accuracy, but also training time, recognition time, and memory requirements. When available, we report measurements of the fraction of patterns that must be rejected so that the remaining patterns have misclassification rates less than a given threshold.",
    "date": "1994",
    "authors": [
        "L. Bottou",
        "C. Cortes",
        "J.S. Denker",
        "H. Drucker",
        "I. Guyon",
        "L.D. Jackel",
        "Y. LeCun",
        "U.A. Muller",
        "E. Sackinger",
        "P. Simard",
        "V. Vapnik"
    ],
    "related_topics": [
        "Handwriting recognition",
        "Classifier (UML)",
        "Pattern recognition"
    ],
    "citation_count": "937",
    "reference_count": "8",
    "references": [
        "2087347434",
        "2093717447",
        "2137291015",
        "2166501286",
        "2056763477",
        "2162363099",
        "2093465006",
        "2151328054"
    ]
},{
    "id": "2504871398",
    "title": "Learning representations by back-propagation errors, nature",
    "abstract": "",
    "date": "1985",
    "authors": [
        "DE Rumelhart",
        "GE Hinton",
        "RJ William"
    ],
    "related_topics": [
        "Cognitive science",
        "Backpropagation",
        "Psychology"
    ],
    "citation_count": "1,464",
    "reference_count": "0",
    "references": []
},{
    "id": "1568787085",
    "title": "Neural-Network and k-Nearest-neighbor Classifiers",
    "abstract": "The performance of a state-of-the-art neural network classifier for hand-written digits is compared to that of a k-nearest-neighbor classifier and to human performance. The neural network has a clear advantage over the k-nearest-neighbor method, but at the same time does not yet reach human performance. Two methods for combining neural-network ideas and the k-nearest-neighbor algorithm are proposed. Numerical experiments for these methods show an improvement in performance.",
    "date": "1991",
    "authors": [
        "J. Bromley",
        "E. Sackinger"
    ],
    "related_topics": [
        "Time delay neural network",
        "Probabilistic neural network",
        "Artificial neural network"
    ],
    "citation_count": "24",
    "reference_count": "0",
    "references": []
},{
    "id": "5594912",
    "title": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)",
    "abstract": "",
    "date": "1982",
    "authors": [
        "Vladimir Vapnik"
    ],
    "related_topics": [
        "Series (mathematics)",
        "Computer science",
        "Estimation"
    ],
    "citation_count": "452",
    "reference_count": "0",
    "references": []
},{
    "id": "2152473410",
    "title": "Example-based object detection in images by components",
    "abstract": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background.",
    "date": "2001",
    "authors": [
        "A. Mohan",
        "C. Papageorgiou",
        "T. Poggio"
    ],
    "related_topics": [
        "One-class classification",
        "Object detection",
        "Classifier (UML)"
    ],
    "citation_count": "1,431",
    "reference_count": "24",
    "references": [
        "2156909104",
        "2139212933",
        "2912934387",
        "2132984323",
        "2217896605",
        "2149684865",
        "2112076978",
        "2115763357",
        "2152761983",
        "2159686933"
    ]
},{
    "id": "1992825118",
    "title": "Detecting Pedestrians Using Patterns of Motion and Appearance",
    "abstract": "This paper describes a pedestrian detection system that integratesimage intensity information with motion information.We use a detection style algorithm that scans a detectorover two consecutive frames of a video sequence. Thedetector is trained (using AdaBoost) to take advantage ofboth motion and appearance information to detect a walkingperson. Past approaches have built detectors based onmotion information or detectors based on appearance information,but ours is the first to combine both sources ofinformation in a single detector. The implementation describedruns at about 4 frames/second, detects pedestriansat very small scales (as small as 20x15 pixels), and has avery low false positive rate.Our approach builds on the detection work of Viola andJones. Novel contributions of this paper include: i) developmentof a representation of image motion which is extremelyefficient, and ii) implementation of a state of theart pedestrian detection system which operates on low resolutionimages under difficult conditions (such as rain andsnow).",
    "date": "2003",
    "authors": [
        "Paul Viola",
        "Michael J. Jones",
        "Daniel Snow"
    ],
    "related_topics": [
        "Pedestrian detection",
        "AdaBoost",
        "Pixel"
    ],
    "citation_count": "3,193",
    "reference_count": "14",
    "references": [
        "2164598857",
        "3124955340",
        "2217896605",
        "2115763357",
        "2032210760",
        "2155511848",
        "2145073242",
        "2162919312",
        "2089181482",
        "2143023146"
    ]
},{
    "id": "1608462934",
    "title": "A Trainable System for Object Detection",
    "abstract": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system.",
    "date": "2000",
    "authors": [
        "Constantine Papageorgiou",
        "Tomaso Poggio"
    ],
    "related_topics": [
        "Object-class detection",
        "Object detection",
        "Viola\u2013Jones object detection framework"
    ],
    "citation_count": "1,778",
    "reference_count": "33",
    "references": [
        "2156909104",
        "2148603752",
        "2139212933",
        "2132984323",
        "2128272608",
        "2217896605",
        "2140235142",
        "2124351082",
        "2159686933",
        "26816478"
    ]
},{
    "id": "2156539399",
    "title": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors",
    "abstract": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors.",
    "date": "2004",
    "authors": [
        "Krystian Mikolajczyk",
        "Cordelia Schmid",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Face detection",
        "AdaBoost",
        "Feature selection"
    ],
    "citation_count": "961",
    "reference_count": "23",
    "references": [
        "2164598857",
        "2124386111",
        "2177274842",
        "2154422044",
        "2152473410",
        "1608462934",
        "2155511848",
        "2502277634",
        "1555563476",
        "2097041931"
    ]
},{
    "id": "2914885528",
    "title": "Color indexing",
    "abstract": "Computer vision is moving into a new era in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, unconstrained environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the identity of an object with a known location, and determining the location of a known object. Color can be successfully used for both tasks. This dissertation demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique called Histogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection which allows real-time indexing into a large database of stored models. It demonstrates techniques for dealing with crowded scenes and with models with similar color signatures. For solving the location problem it introduces an algorithm called Histogram Backprojection which performs this task efficiently in crowded scenes.",
    "date": "1991",
    "authors": [
        "Michael James Swain",
        "Dana H. Ballard"
    ],
    "related_topics": [
        "Color normalization",
        "Content-based image retrieval",
        "Histogram"
    ],
    "citation_count": "8,613",
    "reference_count": "23",
    "references": [
        "2115738369",
        "2913703059",
        "3021212382",
        "2415527960",
        "2125756925",
        "2119204143",
        "2172373809",
        "2489504689",
        "2069266228",
        "2136654525"
    ]
},{
    "id": "2134731454",
    "title": "Unsupervised Learning by Probabilistic Latent Semantic Analysis",
    "abstract": "This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis.",
    "date": "2000",
    "authors": [
        "Thomas Hofmann"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent semantic analysis",
        "Latent Dirichlet allocation"
    ],
    "citation_count": "3,175",
    "reference_count": "23",
    "references": [
        "1902027874",
        "2798909945",
        "2147152072",
        "2049633694",
        "1956559956",
        "1983578042",
        "2072773380",
        "1524704912",
        "2127314673",
        "2064580901"
    ]
},{
    "id": "2165828254",
    "title": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition",
    "abstract": "We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(\u00b10.56%) at 15 training images per class, and 66.23%(\u00b10.48%) at 30 training images.",
    "date": "2006",
    "authors": [
        "Hao Zhang",
        "A.C. Berg",
        "M. Maire",
        "J. Malik"
    ],
    "related_topics": [
        "k-nearest neighbors algorithm",
        "Support vector machine",
        "Caltech 101"
    ],
    "citation_count": "1,532",
    "reference_count": "40",
    "references": [
        "2151103935",
        "2310919327",
        "2162915993",
        "2057175746",
        "2166049352",
        "2104978738",
        "1624854622",
        "2147800946",
        "2168002178",
        "1484228140"
    ]
},{
    "id": "2113606819",
    "title": "Efficient sparse coding algorithms",
    "abstract": "Sparse coding provides a class of algorithms for finding succinct representations of stimuli; given only unlabeled input data, it discovers basis functions that capture higher-level features in the data. However, finding sparse codes remains a very difficult computational problem. In this paper, we present efficient sparse coding algorithms that are based on iteratively solving two convex optimization problems: an L1-regularized least squares problem and an L2-constrained least squares problem. We propose novel algorithms to solve both of these optimization problems. Our algorithms result in a significant speedup for sparse coding, allowing us to learn larger sparse codes than possible with previously described algorithms. We apply these algorithms to natural images and demonstrate that the inferred sparse codes exhibit end-stopping and non-classical receptive field surround suppression and, therefore, may provide a partial explanation for these two phenomena in V1 neurons.",
    "date": "2006",
    "authors": [
        "Honglak Lee",
        "Alexis Battle",
        "Rajat Raina",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Sparse approximation",
        "K-SVD",
        "Neural coding"
    ],
    "citation_count": "3,221",
    "reference_count": "14",
    "references": [
        "2063978378",
        "2078204800",
        "2145889472",
        "2105464873",
        "2140499889",
        "2004915807",
        "2101933716",
        "16591383",
        "2074376560",
        "2146672645"
    ]
},{
    "id": "2161516371",
    "title": "Image super-resolution as sparse representation of raw image patches",
    "abstract": "This paper addresses the problem of generating a super-resolution (SR) image from a single low-resolution input image. We approach this problem from the perspective of compressed sensing. The low-resolution image is viewed as downsampled version of a high-resolution image, whose patches are assumed to have a sparse representation with respect to an over-complete dictionary of prototype signal-atoms. The principle of compressed sensing ensures that under mild conditions, the sparse representation can be correctly recovered from the downsampled signal. We will demonstrate the effectiveness of sparsity as a prior for regularizing the otherwise ill-posed super-resolution problem. We further show that a small set of randomly chosen raw patches from training images of similar statistical nature to the input image generally serve as a good dictionary, in the sense that the computed representation is sparse and the recovered high-resolution image is competitive or even superior in quality to images produced by other SR methods.",
    "date": "2008",
    "authors": [
        "Jianchao Yang",
        "J. Wright",
        "T. Huang",
        "Yi Ma"
    ],
    "related_topics": [
        "K-SVD",
        "Sparse approximation",
        "Image processing"
    ],
    "citation_count": "1,795",
    "reference_count": "26",
    "references": [
        "2296616510",
        "2053186076",
        "2160547390",
        "2153663612",
        "2050834445",
        "2118963448",
        "2165939075",
        "2097074225",
        "2149760002",
        "2105464873"
    ]
},{
    "id": "1624854622",
    "title": "Object recognition with features inspired by visual cortex",
    "abstract": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex.",
    "date": "2005",
    "authors": [
        "T. Serre",
        "L. Wolf",
        "T. Poggio"
    ],
    "related_topics": [
        "Cognitive neuroscience of visual object recognition",
        "3D single-object recognition",
        "Feature (machine learning)"
    ],
    "citation_count": "1,203",
    "reference_count": "24",
    "references": [
        "3097096317",
        "2124386111",
        "2057175746",
        "2154422044",
        "2134557905",
        "2152473410",
        "2155511848",
        "1949116567",
        "2149194912",
        "2171188998"
    ]
},{
    "id": "1516111018",
    "title": "An introduction to variational methods for graphical models",
    "abstract": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.",
    "date": "1999",
    "authors": [
        "Michael I. Jordan",
        "Zoubin Ghahramani",
        "Tommi S. Jaakkola",
        "Lawrence K. Saul"
    ],
    "related_topics": [
        "Graphical model",
        "Variational Bayesian methods",
        "Variational message passing"
    ],
    "citation_count": "3,107",
    "reference_count": "59",
    "references": [
        "2099111195",
        "2159080219",
        "1573186872",
        "2049633694",
        "2171265988",
        "2982720039",
        "1746680969",
        "2567948266",
        "2397866408",
        "1993845689"
    ]
},{
    "id": "1699734612",
    "title": "Saliency, Scale and Image Description",
    "abstract": "Many computer vision problems can be considered to consist of two main tasks: the extraction of image content descriptions and their subsequent matching. The appropriate choice of type and level of description is of course task dependent, yet it is generally accepted that the low-level or so called early vision layers in the Human Visual System are context independent. This paper concentrates on the use of low-level approaches for solving computer vision problems and discusses three inter-related aspects of this: saliencys scale selection and content description. In contrast to many previous approaches which separate these tasks, we argue that these three aspects are intrinsically related. Based on this observation, a multiscale algorithm for the selection of salient regions of an image is introduced and its application to matching type problems such as tracking, object recognition and image retrieval is demonstrated.",
    "date": "2001",
    "authors": [
        "Timor Kadir",
        "Michael Brady"
    ],
    "related_topics": [
        "Automatic image annotation",
        "Human visual system model",
        "Visual Word"
    ],
    "citation_count": "1,196",
    "reference_count": "39",
    "references": [
        "2115755118",
        "2150134853",
        "2914885528",
        "2124087378",
        "2111308925",
        "2156447271",
        "2103504761",
        "2109863423",
        "2098152234",
        "2003370853"
    ]
},{
    "id": "2101926813",
    "title": "Neocognitron: A Self Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position",
    "abstract": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.",
    "date": "1980",
    "authors": [
        "Kunihiko Fukushima"
    ],
    "related_topics": [
        "Neocognitron",
        "Form perception",
        "Stimulus (physiology)"
    ],
    "citation_count": "5,024",
    "reference_count": "12",
    "references": [
        "2116360511",
        "2322002063",
        "2053120614",
        "1588340522",
        "1594551768",
        "2010315761",
        "2272360941",
        "22889343",
        "2324189819",
        "2091546412"
    ]
},{
    "id": "2073257493",
    "title": "An interactive activation model of context effects in letter perception: I. An account of basic findings.",
    "abstract": "",
    "date": "1981",
    "authors": [
        "James L. McClelland",
        "David E. Rumelhart"
    ],
    "related_topics": [
        "Context effect",
        "Visual perception",
        "Perception"
    ],
    "citation_count": "6,664",
    "reference_count": "45",
    "references": [
        "1509703770",
        "2007780422",
        "2045597501",
        "2068868410",
        "2053127376",
        "2147311265",
        "2098683904",
        "2040187703",
        "2006769754",
        "2154634575"
    ]
},{
    "id": "2021878536",
    "title": "User Centered System Design: New Perspectives on Human-Computer Interaction",
    "abstract": "Contents: S.W. Draper, D.A. Norman, C. Lewis, Introduction. Part I:User Centered System Design. K. Hooper, Architectural Design: An Analogy. L.J. Bannon, Issues in Design: Some Notes. D.A. Norman, Cognitive Engineering. Part II:The Interface Experience. B.K. Laurel, Interface as Mimesis. E.L. Hutchins, J.D. Hollan, D.A. NormanDirect Manipulation Interfaces. A.A. diSessa, Notes on the Future of Programming: Breaking the Utility Barrier. Part III:Users' Understandings. M.S. Riley, User Understanding. C. Lewis, Understanding What's Happening in System Interactions. D. Owen, Naive Theories of Computation. A.A. diSessa, Models of Computation. W. Mark, Knowledge-Based Interface Design. Part IV:User Activities. A. Cypher, The Structure of Users' Activities. Y. Miyata, D.A. Norman, Psychological Issues in Support of Multiple Activities. R. Reichman, Communication Paradigms for a Window System. Part V:Toward a Pragmatics of Human-Machine Communication. W. Buxton, There's More to Interaction Than Meets the Eye: Some Issues in Manual Input. S.W. Draper, Display Managers as the Basis for User-Machine Communication. Part VI:Information Flow. D. Owen, Answers First, Then Questions. C.E. O'Malley, Helping Users Help Themselves. L.J. Bannon, Helping Users Help Each Other. C. Lewis, D.A. Norman, Designing for Error. L.J. Bannon, Computer-Mediated Communication. Part VII:The Context of Computing. J.S. Brown, From Cognitive to Social Ergonomics and Beyond.",
    "date": "1985",
    "authors": [
        "Donald A. Norman",
        "Stephen W. Draper"
    ],
    "related_topics": [
        "User experience design",
        "User interface",
        "Cognitive ergonomics"
    ],
    "citation_count": "4,674",
    "reference_count": "0",
    "references": []
},{
    "id": "1490454746",
    "title": "Feature discovery by competitive learning",
    "abstract": "This paper reporis the results of our studies with an unsupervised learning paradigm which we have called \u201cCompetitive Learning.\u201d We have examined competitive learning using both computer simulation and formal analysis and hove found that when it is applied to parallel networks of neuron-like elements, many potentially useful learning tasks can be accomplished. We were attracted to competitive learning because it seems to provide o way to discover the salient, general features which can be used to classify o set of patterns. We show how o very simply competitive mechanism con discover a set of feature detectors which capture important aspects of the set of stimulus input patterns. We 0150 show how these feature detectors con form the basis of o multilayer system that con serve to learn categorizations of stimulus sets which ore not linearly separable. We show how the use of correlated stimuli con serve IX o kind of \u201cteaching\u201d input to the system to allow the development of feature detectors which would not develop otherwise. Although we find the competitive learning mechanism o very interesting and powerful learning principle, we do not, of course, imagine thot it is the only learning principle. Competitive learning is cm essentially nonassociative stotisticol learning scheme. We certainly imagine that other kinds of learning mechanisms will be involved in the building of associations among patterns of activation in o more complete neural network. We offer this analysis of these competitive learning mechanisms to further our understanding of how simple adaptive networks can discover features importont in the description of the stimulus environment in which the system finds itself.",
    "date": "1988",
    "authors": [
        "David E. Rumelhart",
        "David Zipser"
    ],
    "related_topics": [
        "Competitive learning",
        "Feature learning",
        "Instance-based learning"
    ],
    "citation_count": "1,784",
    "reference_count": "5",
    "references": [
        "2073257493",
        "1514711945",
        "2113653296",
        "2010315761",
        "2103170504"
    ]
},{
    "id": "2115647291",
    "title": "Direct manipulation interfaces",
    "abstract": "Direct manipulation has been lauded as a good form of interface design, and some interfaces that have this property have been well received by users. In this article we seek a cognitive account of both the advantages and disadvantages of direct manipulation interfaces. We identify two underlying phenomena that give rise to the feeling of directness. One deals with the information processing distance between the user's intentions and the facilities provided by the machine. Reduction of this distance makes the interface feel direct by reducing the effort required of the user to accomplish goals. The second phenomenon concerns the relation between the input and output vocabularies of the interface language. In particular, direct manipulation requires that the system provide representations of objects that behave as if they are the objects themselves. This provides the feeling of directness of manipulation.",
    "date": "1985",
    "authors": [
        "Edwin L. Hutchins",
        "James D. Hollan",
        "Donald A. Norman"
    ],
    "related_topics": [
        "Direct manipulation interface",
        "Interface (Java)",
        "Information processing"
    ],
    "citation_count": "2,213",
    "reference_count": "20",
    "references": [
        "2099305423",
        "2021878536",
        "2175030280",
        "2005639687",
        "1539777654",
        "1979887415",
        "2954951251",
        "2037893691",
        "121934918",
        "2064302241"
    ]
},{
    "id": "1505136099",
    "title": "Learning by statistical cooperation of self-interested neuron-like computing elements.",
    "abstract": "Since the usual approaches to cooperative computation in networks of neuron-like computating elements do not assume that network components have any \"preferences\", they do not make substantive contact with game theoretic concepts, despite their use of some of the same terminology. In the approach presented here, however, each network component, or adaptive element, is a self-interested agent that prefers some inputs over others and \"works\" toward obtaining the most highly preferred inputs. Here we describe an adaptive element that is robust enough to learn to cooperate with other elements like itself in order to further its self-interests. It is argued that some of the longstanding problems concerning adaptation and learning by networks might be solvable by this form of cooperativity, and computer simulation experiments are described that show how networks of self-interested components that are sufficiently robust can solve rather difficult learning problems. We then place the approach in its proper historical and theoretical perspective through comparison with a number of related algorithms. A secondary aim of this article is to suggest that beyond what is explicitly illustrated here, there is a wealth of ideas from game theory and allied disciplines such as mathematical economics that can be of use in thinking about cooperative computation in both nervous systems and man-made systems.",
    "date": "1984",
    "authors": [
        "Barto Ag"
    ],
    "related_topics": [
        "Game theory",
        "Terminology",
        "Adaptation (computer science)"
    ],
    "citation_count": "265",
    "reference_count": "0",
    "references": []
},{
    "id": "2895674046",
    "title": "Adaptive Signal Processing",
    "abstract": "GENERAL INTRODUCTION. Adaptive Systems. The Adaptive Linear Combiner. THEORY OF ADAPTATION WITH STATIONARY SIGNALS. Properties of the Quadratic Performance Surface. Searching the Performance Surface. Gradient Estimation and Its Effects on Adaptation. ADAPTIVE ALGORITHMS AND STRUCTURES. The LMS Algorithm. The Z-Transform in Adaptive Signal Processing. Other Adaptive Algorithms and Structures. Adaptive Lattice Filters. APPLICATIONS. Adaptive Modeling and System Identification. Inverse Adaptive Modeling, Deconvolution, and Equalization. Adaptive Control Systems. Adaptive Interference Cancelling. Introduction to Adaptive Arrays and Adaptive Beamforming. Analysis of Adaptive Beamformers.",
    "date": "1984",
    "authors": [
        "Bernard Widrow",
        "Samuel D. Stearns"
    ],
    "related_topics": [
        "Adaptive filter",
        "Adaptive beamformer",
        "Adaptive control"
    ],
    "citation_count": "11,334",
    "reference_count": "0",
    "references": []
},{
    "id": "1596324102",
    "title": "Machine Learning: An Artificial Intelligence Approach",
    "abstract": "This book contains tutorial overviews and research papers on contemporary trends in the area of machine learning viewed from an AI perspective. Research directions covered include: learning from examples, modeling human learning strategies, knowledge acquisition for expert systems, learning heuristics, discovery systems, and conceptual data analysis.",
    "date": "2013",
    "authors": [
        "R. S. Michalski",
        "J. G. Carbonell",
        "T. M. Mitchell"
    ],
    "related_topics": [
        "Robot learning",
        "Explanation-based learning",
        "Algorithmic learning theory"
    ],
    "citation_count": "2,555",
    "reference_count": "0",
    "references": []
},{
    "id": "1583833196",
    "title": "Neuronlike adaptive elements that can solve difficult learning control problems",
    "abstract": "It is shown how a system consisting of two neuronlike adaptive elements can solve a difficult learning control problem. The task is to balance a pole that is hinged to a movable cart by applying forces to the cart's base. It is argued that the learning problems faced by adaptive elements that are components of adaptive networks are at least as difficult as this version of the pole-balancing problem. The learning system consists of a single associative search element (ASE) and a single adaptive critic element (ACE). In the course of learning to balance the pole, the ASE constructs associations between input and output by searching under the influence of reinforcement feedback, and the ACE constructs a more informative evaluation function than reinforcement feedback alone can provide. The differences between this approach and other attempts to solve problems using neurolike elements are discussed, as is the relation of this work to classical and instrumental conditioning in animal learning studies and its possible implications for research in the neurosciences.",
    "date": "1990",
    "authors": [
        "Andrew G. Barto",
        "Richard S. Sutton",
        "Charles W. Anderson"
    ],
    "related_topics": [
        "Evaluation function",
        "Relation (database)",
        "Machine learning"
    ],
    "citation_count": "4,287",
    "reference_count": "0",
    "references": []
},{
    "id": "1569296262",
    "title": "Temporal credit assignment in reinforcement learning",
    "abstract": "",
    "date": "1983",
    "authors": [
        "Richard Stuart Sutton"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Computer science",
        "Machine learning"
    ],
    "citation_count": "957",
    "reference_count": "0",
    "references": []
},{
    "id": "2075379212",
    "title": "Finite Markov chains",
    "abstract": "",
    "date": "1976",
    "authors": [
        "John G. Kemeny",
        "J. Laurie Snell"
    ],
    "related_topics": [
        "Examples of Markov chains",
        "Markov chain",
        "Markov chain mixing time"
    ],
    "citation_count": "5,046",
    "reference_count": "0",
    "references": []
},{
    "id": "2122410182",
    "title": "Artificial Intelligence: A Modern Approach",
    "abstract": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence.",
    "date": "2019",
    "authors": [
        "Stuart J. Russell",
        "Peter Norvig"
    ],
    "related_topics": [
        "Symbolic artificial intelligence",
        "Artificial Intelligence System",
        "Artificial intelligence, situated approach"
    ],
    "citation_count": "42,343",
    "reference_count": "0",
    "references": []
},{
    "id": "2168405694",
    "title": "Finite-time Analysis of the Multiarmed Bandit Problem",
    "abstract": "Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.",
    "date": "2002",
    "authors": [
        "Peter Auer",
        "Nicol\u00f2 Cesa-Bianchi",
        "Paul Fischer"
    ],
    "related_topics": [
        "Regret",
        "Multi-armed bandit",
        "Thompson sampling"
    ],
    "citation_count": "5,589",
    "reference_count": "13",
    "references": [
        "1497256448",
        "2121863487",
        "1515851193",
        "2010029425",
        "2000080679",
        "2009551863",
        "2317700292",
        "1983962754",
        "1977823770",
        "1970097186"
    ]
},{
    "id": "1714211023",
    "title": "Efficient selectivity and backup operators in Monte-Carlo tree search",
    "abstract": "A Monte-Carlo evaluation consists in estimating a position by averaging the outcome of several random continuations. The method can serve as an evaluation function at the leaves of a min-max tree. This paper presents a new framework to combine tree search with Monte-Carlo evaluation, that does not separate between a min-max phase and a Monte-Carlo phase. Instead of backing-up the min-max value close to the root, and the average value at some depth, a more general backup operator is defined that progressively changes from averaging to minmax as the number of simulations grows. This approach provides a finegrained control of the tree growth, at the level of individual simulations, and allows efficient selectivity. The resulting algorithm was implemented in a 9 \u00d7 9 Go-playing program, Crazy Stone, that won the 10th KGS computer-Go tournament.",
    "date": "2006",
    "authors": [
        "R\u00e9mi Coulom"
    ],
    "related_topics": [
        "Interval tree",
        "Search tree",
        "Segment tree"
    ],
    "citation_count": "1,260",
    "reference_count": "29",
    "references": [
        "2121863487",
        "1515851193",
        "2100677568",
        "2312609093",
        "1536615069",
        "1512919909",
        "1551466210",
        "2033016725",
        "2016647253",
        "1532172966"
    ]
},{
    "id": "131069610",
    "title": "Rapidly-exploring random trees : a new tool for path planning",
    "abstract": "",
    "date": "1997",
    "authors": [
        "S. Lavalle"
    ],
    "related_topics": [
        "Any-angle path planning",
        "Random tree",
        "Probabilistic roadmap"
    ],
    "citation_count": "3,234",
    "reference_count": "0",
    "references": []
},{
    "id": "2171084228",
    "title": "Monte-Carlo Planning in Large POMDPs",
    "abstract": "This paper introduces a Monte-Carlo algorithm for online planning in large POMDPs. The algorithm combines a Monte-Carlo update of the agent's belief state with a Monte-Carlo tree search from the current belief state. The new algorithm, POMCP, has two important properties. First, Monte-Carlo sampling is used to break the curse of dimensionality both during belief state updates and during planning. Second, only a black box simulator of the POMDP is required, rather than explicit probability distributions. These properties enable POMCP to plan effectively in significantly larger POMDPs than has previously been possible. We demonstrate its effectiveness in three large POMDPs. We scale up a well-known benchmark problem, rocksample, by several orders of magnitude. We also introduce two challenging new POMDPs: 10 x 10 battleship and partially observable PacMan, with approximately 1018 and 1056 states respectively. Our Monte-Carlo planning algorithm achieved a high level of performance with no prior knowledge, and was also able to exploit simple domain knowledge to achieve better results with less search. POMCP is the first general purpose planner to achieve high performance in such large and unfactored POMDPs.",
    "date": "2010",
    "authors": [
        "David Silver",
        "Joel Veness"
    ],
    "related_topics": [
        "Partially observable Markov decision process",
        "Black box",
        "Domain knowledge"
    ],
    "citation_count": "931",
    "reference_count": "16",
    "references": [
        "2168405694",
        "1625390266",
        "2168359464",
        "1714211023",
        "2020135152",
        "2099430963",
        "2144913588",
        "2134802714",
        "2122659384",
        "2110962519"
    ]
},{
    "id": "2020135152",
    "title": "Combining online and offline knowledge in UCT",
    "abstract": "The UCT algorithm learns a value function online using sample-based search. The TD(\u03bb) algorithm can learn a value function offline for the on-policy distribution. We consider three approaches for combining offline and online value functions in the UCT algorithm. First, the offline value function is used as a default policy during Monte-Carlo simulation. Second, the UCT value function is combined with a rapid online estimate of action values. Third, the offline value function is used as prior knowledge in the UCT search tree. We evaluate these algorithms in 9 x 9 Go against GnuGo 3.7.10. The first algorithm performs better than UCT with a random simulation policy, but surprisingly, worse than UCT with a weaker, handcrafted simulation policy. The second algorithm outperforms UCT altogether. The third algorithm outperforms UCT with handcrafted prior knowledge. We combine these algorithms in MoGo, the world's strongest 9 x 9 Go program. Each technique significantly improves MoGo's playing strength.",
    "date": "2007",
    "authors": [
        "Sylvain Gelly",
        "David Silver"
    ],
    "related_topics": [
        "Monte Carlo tree search",
        "Online and offline",
        "Computer Go"
    ],
    "citation_count": "701",
    "reference_count": "16",
    "references": [
        "2121863487",
        "2168405694",
        "1515851193",
        "1625390266",
        "1714211023",
        "2100677568",
        "1888434271",
        "1491843047",
        "2124175081",
        "1778554682"
    ]
},{
    "id": "1888434271",
    "title": "Modi\ufb01cation of UCT with Patterns in Monte-Carlo Go",
    "abstract": "Algorithm UCB1 for multi-armed bandit problem has already been extended to Algorithm UCT (Upper bound Confidence for Tree) which works for minimax tree search. We have developed a Monte-Carlo Go program, MoGo, which is the first computer Go program using UCT. We explain our modification of UCT for Go application and also the intelligent random simulation with patterns which has improved significantly the performance of MoGo. UCT combined with pruning techniques for large Go board is discussed, as well as parallelization of UCT. MoGo is now a top level Go program on $9\\times9$ and $13\\times13$ Go boards.",
    "date": "2005",
    "authors": [
        "Sylvain Gelly",
        "Yizao Wang",
        "R\u00e9mi Munos",
        "Olivier Teytaud"
    ],
    "related_topics": [
        "Computer Go",
        "Minimax",
        "Tree (data structure)"
    ],
    "citation_count": "508",
    "reference_count": "14",
    "references": [
        "2121863487",
        "2168405694",
        "1625390266",
        "1714211023",
        "3122363772",
        "2033016725",
        "2123932647",
        "183472599",
        "202670472",
        "55358780"
    ]
},{
    "id": "1510812122",
    "title": "Minimax policies for adversarial and stochastic bandits",
    "abstract": "We fill in a long open gap in the characterization of the minimax rate for the multi-armed bandit prob- lem. Concretely, we remove an extraneous loga- rithmic factor in the previously known upper bound and propose a new family of randomized algorithms based on an implicit normalization, as well as a new analysis. We also consider the stochastic case, and prove that an appropriate modification of the upper confidence bound policy UCB1 (Auer et al., 2002) achieves the distribution-free optimal rate while still having a distribution-dependent rate log- arithmic in the number of plays.",
    "date": "2009",
    "authors": [
        "Jean-Yves Audibert",
        "S\u00e9bastien Bubeck"
    ],
    "related_topics": [
        "Normalization (statistics)",
        "Minimax",
        "Upper and lower bounds"
    ],
    "citation_count": "359",
    "reference_count": "7",
    "references": [
        "2168405694",
        "1570963478",
        "3122363772",
        "2009551863",
        "2098339418",
        "2103012681",
        "1998498767"
    ]
},{
    "id": "1500868819",
    "title": "COMPUTING \u201cELO RATINGS\u201d OF MOVE PATTERNS IN THE GAME OF GO",
    "abstract": "Move patterns are an essential method to incorporate do- main knowledge into Go-playing programs. This paper presents a new Bayesian technique for supervised learning of such patterns from game records, based on a generalization of Elo ratings. Each sample move in the training data is considered as a victory of a team of pattern features. Elo ratings of individual pattern features are computed from these victo- ries, and can be used in previously unseen positions to compute a prob- ability distribution over legal moves. In this approach, several pattern features may be combined, without an exponential cost in the number of features. Despite a very small number of training games (652), this algorithm outperforms most previous pattern-learning algorithms, both in terms of mean log-evidence ( 2.69), and prediction rate (34.9%). A 19\u25ca 19 Monte-Carlo program improved with these patterns reached the level of the strongest classical programs. and little domain expertise. This paper presents a new supervised pattern-learning algorithm, based on the Bradley-Terry model. The Bradley-Terry model is the theoretical basis of the Elo rating system. The principle of Elo ratings, as applied to chess, is that each player gets a numerical strength estimation, computed from the observation of past game results. From the ratings of players, it is possible to estimate a probability distribution over the outcome of future games. The same principle",
    "date": "2006",
    "authors": [
        "R\u00e9mi Coulom"
    ],
    "related_topics": [
        "Computer Go",
        "Supervised learning",
        "Outcome (game theory)"
    ],
    "citation_count": "440",
    "reference_count": "17",
    "references": [
        "1714211023",
        "2153975459",
        "1888434271",
        "2075848246",
        "2160637580",
        "2135129960",
        "2123932647",
        "2107650339",
        "202670472",
        "1492505991"
    ]
},{
    "id": "2077902449",
    "title": "The Nonstochastic Multiarmed Bandit Problem",
    "abstract": "In the multiarmed bandit problem, a gambler must decide which arm of K nonidentical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the per-round payoff of our algorithm approaches that of the best arm at the rate O(T-1/2). We show by a matching lower bound that this is the best possible. We also prove that our algorithm approaches the per-round payoff of any set of strategies at a similar rate: if the best strategy is chosen from a pool of N strategies, then our algorithm approaches the per-round payoff of the strategy at the rate O((log N1/2 T-1/2). Finally, we apply our results to the problem of playing an unknown repeated matrix game. We show that our algorithm approaches the minimax payoff of the unknown game at the rate O(T-1/2).",
    "date": "2002",
    "authors": [
        "Peter Auer",
        "Nicol\u00f2 Cesa-Bianchi",
        "Yoav Freund",
        "Robert E. Schapire"
    ],
    "related_topics": [
        "Multi-armed bandit",
        "Stochastic game",
        "Minimax"
    ],
    "citation_count": "2,122",
    "reference_count": "16",
    "references": [
        "2099111195",
        "3124955340",
        "3124873412",
        "1979675141",
        "2009551863",
        "2742819845",
        "2106887613",
        "2611627047",
        "3125873018",
        "2317700292"
    ]
},{
    "id": "2101861158",
    "title": "The challenge of poker",
    "abstract": "Poker is an interesting test-bed for artificial intelligence research. It is a game of imperfect information, where multiple competing agents must deal with probabilistic knowledge, risk assessment, and possible deception, not unlike decisions made in the real world. Opponent modeling is another difficult problem in decision-making applications, and it is essential to achieving high performance in poker. This paper describes the design considerations and architecture of the poker program Poki. In addition to methods for hand evaluation and betting strategy, Poki uses learning techniques to construct statistical models of each opponent, and dynamically adapts to exploit observed patterns and tendencies. The result is a program capable of playing reasonably strong poker, but there remains considerable research to be done to play at world-class level. Copyright 2001 Elsevier Science B.V.",
    "date": "2002",
    "authors": [
        "Darse Billings",
        "Aaron Davidson",
        "Jonathan Schaeffer",
        "Duane Szafron"
    ],
    "related_topics": [
        "Texas hold 'em",
        "Planning poker",
        "Perfect information"
    ],
    "citation_count": "425",
    "reference_count": "35",
    "references": [
        "2131600418",
        "1978304080",
        "1863869622",
        "2083347533",
        "2145224651",
        "1561981064",
        "2014932765",
        "1532584713",
        "2146628995",
        "1630331242"
    ]
},{
    "id": "2009551863",
    "title": "Asymptotically efficient adaptive allocation rules",
    "abstract": "",
    "date": "1985",
    "authors": [
        "T.L Lai",
        "Herbert Robbins"
    ],
    "related_topics": [
        "Mathematical optimization",
        "Multi-armed bandit",
        "Thompson sampling"
    ],
    "citation_count": "2,667",
    "reference_count": "3",
    "references": [
        "2035879260",
        "2104912596",
        "1998498767"
    ]
},{
    "id": "1512919909",
    "title": "A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes",
    "abstract": "A critical issue for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP. In stochastic environments with very large or infinite state spaces, traditional planning and reinforcement learning algorithms may be inapplicable, since their running time typically grows linearly with the state space size in the worst case. In this paper we present a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states. The running time is exponential in the horizon time (which depends only on the discount factor \u03b3 and the desired degree of approximation to the optimal policy). Our algorithm thus provides a different complexity trade-off than classical algorithms such as value iteration\u2014rather than scaling linearly in both horizon time and state space size, our running time trades an exponential dependence on the former in exchange for no dependence on the latter. Our algorithm is based on the idea of sparse sampling. We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suffices to compute near-optimal actions from any state of an MDP. Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs (Kearns, Mansour, & Ng. Neural information processing systems 13, to appear).",
    "date": "2002",
    "authors": [
        "Michael Kearns",
        "Yishay Mansour",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Partially observable Markov decision process",
        "Markov decision process",
        "Q-learning"
    ],
    "citation_count": "822",
    "reference_count": "18",
    "references": [
        "2122410182",
        "2914656440",
        "1655990431",
        "2911283634",
        "2009533501",
        "1575388622",
        "2021061679",
        "3139578191",
        "1650504995",
        "2161521419"
    ]
},{
    "id": "1551466210",
    "title": "MONTE-CARLO GO DEVELOPMENTS",
    "abstract": "We describe two Go programs, Olga and Oleg, developed by a Monte-Carlo approach that is simpler than Bruegmann\u2019s (1993) approach. Our method is based on Abramson (1990). We performed experiments, to assess ideas on (1) progressive pruning, (2) all moves as first heuristic, (3) temperature, (4) simulated annealing, and (5) depth-two tree search within the Monte-Carlo framework. Progressive pruning and the all moves as first heuristic are good speed-up enhancements that do not deteriorate the level of the program too much. Then, using a constant temperature is an adequate and simple heuristic that is about as good as simulated annealing. The depth-two heuristic gives deceptive results at the moment. The results of our Monte-Carlo programs against knowledge-based programs on 9x9 boards are promising. Finally, the ever-increasing power of computers lead us to think that Monte-Carlo approaches are worth considering for computer Go in the future.",
    "date": "2003",
    "authors": [
        "Bruno Bouzy",
        "Bernard Helmstetter"
    ],
    "related_topics": [
        "Null-move heuristic",
        "Computer Go",
        "Heuristic"
    ],
    "citation_count": "216",
    "reference_count": "12",
    "references": [
        "2581275558",
        "1969481231",
        "2101861158",
        "2033016725",
        "1863869622",
        "2014932765",
        "2107549951",
        "2134440396",
        "2787384486",
        "2014969765"
    ]
},{
    "id": "1863869622",
    "title": "World-championship-caliber Scrabble",
    "abstract": "Computer Scrabble programs have achieved a level of performance that exceeds that of the strongest human players. MAVEN was the first program to demonstrate this against human opposition. Scrabble is a game of imperfect information with a large branching factor. The techniques successfully applied in two-player games such as chess do not work here. MAVEN combines a selective move generator, simulations of likely game scenarios, and the B* algorithm to produce a world-championship-caliber Scrabble-playing program.",
    "date": "2002",
    "authors": [
        "Brian Sheppard"
    ],
    "related_topics": [
        "World championship",
        "Perfect information",
        "Computer science"
    ],
    "citation_count": "187",
    "reference_count": "16",
    "references": [
        "1655990431",
        "2100677568",
        "2131600418",
        "2101861158",
        "3139578191",
        "2135997697",
        "2468925818",
        "1532584713",
        "1976776761",
        "2107549951"
    ]
},{
    "id": "2016647253",
    "title": "An Adaptive Sampling Algorithm for Solving Markov Decision Processes",
    "abstract": "Based on recent results for multiarmed bandit problems, we propose an adaptive sampling algorithm that approximates the optimal value of a finite-horizon Markov decision process (MDP) with finite state and action spaces. The algorithm adaptively chooses which action to sample as the sampling process proceeds and generates an asymptotically unbiased estimator, whose bias is bounded by a quantity that converges to zero at rate (lnN)/ N, whereN is the total number of samples that are used per state sampled in each stage. The worst-case running-time complexity of the algorithm isO(( |A|N) H ), independent of the size of the state space, where | A| is the size of the action space andH is the horizon length. The algorithm can be used to create an approximate receding horizon control to solve infinite-horizon MDPs. To illustrate the algorithm, computational results are reported on simple examples from inventory control.",
    "date": "2004",
    "authors": [
        "Hyeong Soo Chang",
        "Michael C. Fu",
        "Jiaqiao Hu",
        "Steven I. Marcus"
    ],
    "related_topics": [
        "Markov process",
        "Adaptive algorithm",
        "Markov decision process"
    ],
    "citation_count": "143",
    "reference_count": "18",
    "references": [
        "3145128584",
        "2752885492",
        "2168405694",
        "2098432798",
        "2140481308",
        "2000080679",
        "2009551863",
        "2113789941",
        "1976625337",
        "1512919909"
    ]
},{
    "id": "1562282139",
    "title": "Monte Carlo Planning in RTS Games.",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Michael Chung",
        "Michael Buro",
        "Jonathan Schaeffer"
    ],
    "related_topics": [
        "Monte Carlo method",
        "Monte Carlo tree search",
        "Computer science"
    ],
    "citation_count": "155",
    "reference_count": "10",
    "references": [
        "2914656440",
        "2911283634",
        "2131600418",
        "1551466210",
        "1532584713",
        "2153367522",
        "2785370368",
        "2120032275",
        "2995879998",
        "2173567424"
    ]
},{
    "id": "2135997697",
    "title": "On-line Policy Improvement using Monte-Carlo Search",
    "abstract": "We present a Monte-Carlo simulation algorithm for real-time policy improvement of an adaptive controller. In the Monte-Carlo simulation, the long-term expected reward of each possible action is statistically measured, using the initial policy to make decisions in each step of the simulation. The action maximizing the measured expected reward is then taken, resulting in an improved policy. Our algorithm is easily parallelizable and has been implemented on the IBM SP1 and SP2 parallel-RISC supercomputers. We have obtained promising initial results in applying this algorithm to the domain of backgammon. Results are reported for a wide variety of initial policies, ranging from a random policy to TD-Gammon, an extremely strong multi-layer neural network. In each case, the Monte-Carlo algorithm gives a substantial reduction, by as much as a factor of 5 or more, in the error rate of the base players. The algorithm is also potentially useful in many other adaptive control applications in which it is possible to simulate the environment.",
    "date": "1996",
    "authors": [
        "Gerald Tesauro",
        "Gregory R. Galperin"
    ],
    "related_topics": [
        "Adaptive control",
        "Monte Carlo method",
        "Reduction (complexity)"
    ],
    "citation_count": "277",
    "reference_count": "8",
    "references": [
        "2098432798",
        "2100677568",
        "2131600418",
        "2103626435",
        "2117341272",
        "2148173263",
        "2151368309",
        "2202514763"
    ]
},{
    "id": "2295428206",
    "title": "Randomized Algorithms",
    "abstract": "For many applications, a randomized algorithm is either the simplest or the fastest algorithm available, and sometimes both. This book introduces the basic concepts in the design and analysis of randomized algorithms. The first part of the text presents basic tools such as probability theory and probabilistic analysis that are frequently used in algorithmic applications. Algorithmic examples are also given to illustrate the use of each tool in a concrete setting. In the second part of the book, each chapter focuses on an important area to which randomized algorithms can be applied, providing a comprehensive and representative selection of the algorithms that might be used in each of these areas. Although written primarily as a text for advanced undergraduates and graduate students, this book should also prove invaluable as a reference for professionals and researchers.",
    "date": "1994",
    "authors": [
        "Rajeev Motwani",
        "Prabhakar Raghavan"
    ],
    "related_topics": [
        "Probabilistic analysis of algorithms",
        "Randomized algorithm",
        "Seven Basic Tools of Quality"
    ],
    "citation_count": "7,279",
    "reference_count": "50",
    "references": [
        "2068871408",
        "1963547452",
        "1979740015",
        "2052207834",
        "2070991879",
        "1972418517",
        "1593563200",
        "2148043549",
        "2069816168",
        "1568495775"
    ]
},{
    "id": "1956559956",
    "title": "Introduction to Modern Information Retrieval",
    "abstract": "",
    "date": "1983",
    "authors": [
        "Gerard Salton",
        "Michael J. McGill"
    ],
    "related_topics": [
        "Human\u2013computer information retrieval",
        "Term Discrimination",
        "Vector space model"
    ],
    "citation_count": "15,116",
    "reference_count": "0",
    "references": []
},{
    "id": "2125148312",
    "title": "Texture features for browsing and retrieval of image data",
    "abstract": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated.",
    "date": "1996",
    "authors": [
        "B.S. Manjunath",
        "W.Y. Ma"
    ],
    "related_topics": [
        "Image texture",
        "Content-based image retrieval",
        "Visual Word"
    ],
    "citation_count": "5,342",
    "reference_count": "20",
    "references": [
        "1996021349",
        "2102796633",
        "2095757522",
        "2093191240",
        "2008297189",
        "2138313032",
        "2168977926",
        "2103384342",
        "2171181782",
        "2021751319"
    ]
},{
    "id": "2160066518",
    "title": "Query by image and video content: the QBIC system",
    "abstract": "Research on ways to extend and improve query methods for image databases is widespread. We have developed the QBIC (Query by Image Content) system to explore content-based retrieval methods. QBIC allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information. Two key properties of QBIC are (1) its use of image and video content-computable properties of color, texture, shape and motion of images, videos and their objects-in the queries, and (2) its graphical query language, in which queries are posed by drawing, selecting and other graphical means. This article describes the QBIC system and demonstrates its query capabilities. QBIC technology is part of several IBM products. >",
    "date": "1997",
    "authors": [
        "Myron Flickner",
        "Harpreet Sawhney",
        "Wayne Niblack",
        "Jonathan Ashley",
        "Qian Huang",
        "Byron Dom",
        "Monika Gorkani",
        "Jim Hafner",
        "Denis Lee",
        "Dragutin Petkovic",
        "David Steele",
        "Peter Yanker"
    ],
    "related_topics": [
        "Information retrieval",
        "Computer science",
        "Key (cryptography)"
    ],
    "citation_count": "8,569",
    "reference_count": "0",
    "references": []
},{
    "id": "2074429597",
    "title": "The design and analysis of spatial data structures",
    "abstract": "",
    "date": "1989",
    "authors": [
        "Hanan Samet"
    ],
    "related_topics": [
        "Spatial analysis",
        "Computer science",
        "Remote sensing"
    ],
    "citation_count": "4,149",
    "reference_count": "0",
    "references": []
},{
    "id": "1541459201",
    "title": "A Quantitative Analysis and Performance Study for Similarity-Search Methods in High-Dimensional Spaces",
    "abstract": "For similarity search in high-dimensional vector spaces (or \u2018HDVSs\u2019), researchers have proposed a number of new methods (or adaptations of existing methods) based, in the main, on data-space partitioning. However, the performance of these methods generally degrades as dimensionality increases. Although this phenomenon-known as the \u2018dimensional curse\u2019-is well known, little or no quantitative a.nalysis of the phenomenon is available. In this paper, we provide a detailed analysis of partitioning and clustering techniques for similarity search in HDVSs. We show formally that these methods exhibit linear complexity at high dimensionality, and that existing methods are outperformed on average by a simple sequential scan if the number of dimensions exceeds around 10. Consequently, we come up with an alternative organization based on approximations to make the unavoidable sequential scan as fast as possible. We describe a simple vector approximation scheme, called VA-file, and report on an experimental evaluation of this and of two tree-based index methods (an R*-tree and an X-tree).",
    "date": "1998",
    "authors": [
        "Roger Weber",
        "Hans-J\u00f6rg Schek",
        "Stephen Blott"
    ],
    "related_topics": [
        "Nearest neighbor search",
        "iDistance",
        "Curse of dimensionality"
    ],
    "citation_count": "2,343",
    "reference_count": "35",
    "references": [
        "2160066518",
        "2151135734",
        "2118269922",
        "2074429597",
        "2238624099",
        "1969294188",
        "2157092487",
        "1992810975",
        "2145725688",
        "2104128006"
    ]
},{
    "id": "1981627423",
    "title": "Planning in a hierarchy of abstraction spaces",
    "abstract": "Abstract A problem domain can be represented as a hierarchy of abstraction spaces in which successively finer levels of detail are introduced. The problem solver ABSTRIPS, a modification of STRIPS, can define an abstraction space hierarchy from the STRIPS representation of a problem domain, and it can utilize the hierarchy in solving problems. Examples of the system's performance are presented that demonstrate the significant increases in problem-solving power that this approach provides. Then some further implications of the hierarchical planning approach are explored.",
    "date": "1974",
    "authors": [
        "Earl D. Sacerdoti"
    ],
    "related_topics": [
        "Analytical hierarchy",
        "Hierarchy",
        "Problem domain"
    ],
    "citation_count": "1,930",
    "reference_count": "8",
    "references": [
        "2138162238",
        "2402164836",
        "2020149918",
        "1541540802",
        "3139316869",
        "1512426208",
        "145832685",
        "1492160417"
    ]
},{
    "id": "1572038152",
    "title": "Search reduction in hierarchical problem solving",
    "abstract": "It has long been recognized that hierarchical problem solving can be used to reduce search. Yet, there has been little analysis of the problem-solving method and few experimental results. This paper provides the first comprehensive analytical and empirical demonstrations of the effectiveness of hierarchical problem solving. First, the paper shows analytically that hierarchical problem solving can reduce the size of the search space from exponential to linear in the solution length and identifies a sufficient set of assumptions for such reductions in search. Second, it presents empirical results both in a domain that meets all of these assumptions as well as in domains in which these assumptions do not strictly hold. Third, the paper explores the conditions under which hierarchical problem solving will be effective in practice.",
    "date": "1991",
    "authors": [
        "Craig A. Knoblock"
    ],
    "related_topics": [
        "General Group Problem Solving (GGPS) Model",
        "Reduction (complexity)",
        "Set (abstract data type)"
    ],
    "citation_count": "100",
    "reference_count": "13",
    "references": [
        "2293009092",
        "1613651675",
        "2021337406",
        "2009328995",
        "2084335986",
        "2051567680",
        "1981627423",
        "125130877",
        "1567972407",
        "2017626051"
    ]
},{
    "id": "2119409989",
    "title": "Programs with common sense",
    "abstract": "Abstract : This paper discusses programs to manipulate in a suitable formal language (most likely a part of the predicate calculus) common instrumental statements. The basic program will draw immediate conclusions from a list of premises. These conclusions will be either declarative or imperative sentences. When an imperative sentence is deduced the program takes a corresponding action. These actions may include printing sentences, moving sentences on lists, and reinitiating the basic deduction process on these lists.",
    "date": "1960",
    "authors": [
        "John McCarthy"
    ],
    "related_topics": [
        "Imperative logic",
        "Sentence",
        "Formal language"
    ],
    "citation_count": "1,281",
    "reference_count": "3",
    "references": [
        "1970001627",
        "2479583503",
        "2112161977"
    ]
},{
    "id": "3025398977",
    "title": "Time Enough for Love",
    "abstract": "",
    "date": "1973",
    "authors": [
        "Robert A. Heinlein"
    ],
    "related_topics": [],
    "citation_count": "69",
    "reference_count": "0",
    "references": []
},{
    "id": "1506806321",
    "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)",
    "abstract": "",
    "date": "2006",
    "authors": [
        "Christopher M. Bishop"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Unsupervised learning",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "11,386",
    "reference_count": "0",
    "references": []
},{
    "id": "2119567691",
    "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming",
    "abstract": "From the Publisher: The past decade has seen considerable theoretical and applied research on Markov decision processes, as well as the growing use of these models in ecology, economics, communications engineering, and other fields where outcomes are uncertain and sequential decision-making processes are needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, and rigorous treatment of the theoretical, computational, and applied research on Markov decision process models. It discusses all major research directions in the field, highlights many significant applications of Markov decision processes models, and explores numerous important topics that have previously been neglected or given cursory coverage in the literature. Markov Decision Processes focuses primarily on infinite horizon discrete time models and models with discrete time spaces while also examining models with arbitrary state spaces, finite horizon models, and continuous-time discrete state models. The book is organized around optimality criteria, using a common framework centered on the optimality (Bellman) equation for presenting results. The results are presented in a \"theorem-proof\" format and elaborated on through both discussion and examples, including results that are not available in any other book. A two-state Markov decision process model, presented in Chapter 3, is analyzed repeatedly throughout the book and demonstrates many results and algorithms. Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria. It also explores several topics that have received little or no attention in other books, including modified policy iteration, multichain models with average reward criterion, and sensitive optimality. In addition, a Bibliographic Remarks section in each chapter comments on relevant historic",
    "date": "1994",
    "authors": [
        "Martin L. Puterman"
    ],
    "related_topics": [
        "Partially observable Markov decision process",
        "Markov decision process",
        "Markov model"
    ],
    "citation_count": "14,934",
    "reference_count": "12",
    "references": [
        "3038830718",
        "2035446426",
        "2341171179",
        "2096630263",
        "2130184319",
        "1571552128",
        "2319878520",
        "2067733412",
        "2036791211",
        "154446778"
    ]
},{
    "id": "2107726111",
    "title": "Reinforcement learning: a survey",
    "abstract": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.",
    "date": "1995",
    "authors": [
        "Leslie Pack Kaelbling",
        "Michael L. Littman",
        "Andrew W. Moore"
    ],
    "related_topics": [
        "Learning classifier system",
        "Reinforcement learning",
        "Robot learning"
    ],
    "citation_count": "8,631",
    "reference_count": "110",
    "references": [
        "1639032689",
        "1497256448",
        "1652505363",
        "2098432798",
        "2119567691",
        "2100677568",
        "2000836282",
        "2119717200",
        "1963547452",
        "2019363670"
    ]
},{
    "id": "1576452626",
    "title": "Neuro-dynamic programming",
    "abstract": "From the Publisher: This is the first textbook that fully explains the neuro-dynamic programming/reinforcement learning methodology, which is a recent breakthrough in the practical application of neural networks and dynamic programming to complex problems of planning, optimal decision making, and intelligent control.",
    "date": "1995",
    "authors": [
        "Dimitri P. Bertsekas",
        "John N. Tsitsiklis"
    ],
    "related_topics": [
        "Inductive programming",
        "Functional logic programming",
        "Functional reactive programming"
    ],
    "citation_count": "6,993",
    "reference_count": "0",
    "references": []
},{
    "id": "2168359464",
    "title": "Planning and Acting in Partially Observable Stochastic Domains",
    "abstract": "In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.",
    "date": "1998",
    "authors": [
        "Leslie Pack Kaelbling",
        "Michael L. Littman",
        "Anthony R. Cassandra"
    ],
    "related_topics": [
        "Partially observable Markov decision process",
        "Predictive state representation",
        "Markov decision process"
    ],
    "citation_count": "4,355",
    "reference_count": "70",
    "references": [
        "2125838338",
        "1576818901",
        "2098432798",
        "2119567691",
        "1963547452",
        "2025460523",
        "2105934661",
        "1978304080",
        "1552169927",
        "4789806"
    ]
},{
    "id": "2109910161",
    "title": "Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning",
    "abstract": "Learning, planning, and representing knowledge at multiple levels of temporal ab- straction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforce- ment learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options\u2014closed-loop policies for taking ac- tion over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as mus- cle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning frame- work in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic pro- gramming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: 1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, 2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and 3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro-utility problem.",
    "date": "1999",
    "authors": [
        "Richard S. Sutton",
        "Doina Precup",
        "Satinder Singh"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Markov decision process",
        "Abstraction (linguistics)"
    ],
    "citation_count": "2,873",
    "reference_count": "75",
    "references": [
        "2121863487",
        "2131600418",
        "2009533501",
        "73143588",
        "2911432472",
        "2017103958",
        "1595483645",
        "2333196491",
        "1979071892",
        "1598634407"
    ]
},{
    "id": "2075268401",
    "title": "Fast gradient-descent methods for temporal-difference learning with linear function approximation",
    "abstract": "Sutton, Szepesvari and Maei (2009) recently introduced the first temporal-difference learning algorithm compatible with both linear function approximation and off-policy training, and whose complexity scales only linearly in the size of the function approximator. Although their gradient temporal difference (GTD) algorithm converges reliably, it can be very slow compared to conventional linear TD (on on-policy problems where TD is convergent), calling into question its practical utility. In this paper we introduce two new related algorithms with better convergence rates. The first algorithm, GTD2, is derived and proved convergent just as GTD was, but uses a different objective function and converges significantly faster (but still not as fast as conventional TD). The second new algorithm, linear TD with gradient correction, or TDC, uses the same update rule as conventional TD except for an additional term which is initially zero. In our experiments on small test problems and in a Computer Go application with a million features, the learning rate of this algorithm was comparable to that of conventional TD. This algorithm appears to extend linear TD to off-policy learning with no penalty in performance while only doubling computational requirements.",
    "date": "2009",
    "authors": [
        "Richard S. Sutton",
        "Hamid Reza Maei",
        "Doina Precup",
        "Shalabh Bhatnagar",
        "David Silver",
        "Csaba Szepesv\u00e1ri",
        "Eric Wiewiora"
    ],
    "related_topics": [
        "Gradient descent",
        "Temporal difference learning",
        "Linear function"
    ],
    "citation_count": "517",
    "reference_count": "19",
    "references": [
        "2100677568",
        "2109910161",
        "2139418546",
        "1646707810",
        "1778554682",
        "2071983464",
        "2072931156",
        "2065134213",
        "2132351269",
        "2104753538"
    ]
},{
    "id": "2062937587",
    "title": "Neo: learning conceptual knowledge by sensorimotor interaction with an environment",
    "abstract": "Recent developments in philosophy, linguistics, developmental psychology and arti cial intelligence make it possible to envision a developmental path for an arti cial agent, grounded in activity-based sensorimotor representations. This paper describes how Neo, an arti cial agent, learns concepts by interacting with its simulated environment. Relatively little prior structure is required to learn fairly accurate representations of objects, activities, locations and other aspects of Neo's experience. We show how classes (categories) can be abstracted from these representations, and discuss how our representation might be extended to express physical schemas, general, domain-independent activities that could be the building blocks of concept formation.",
    "date": "1997",
    "authors": [
        "Paul R. Cohen",
        "Marc S. Atkin",
        "Tim Oates",
        "Carole R. Beal"
    ],
    "related_topics": [
        "Concept learning",
        "Cognitive science",
        "Representation (arts)"
    ],
    "citation_count": "97",
    "reference_count": "20",
    "references": [
        "2052417512",
        "1993750641",
        "266716723",
        "2140243223",
        "2228018563",
        "2059039791",
        "2137171066",
        "1601336606",
        "3022135529",
        "1992764401"
    ]
},{
    "id": "1491843047",
    "title": "Integrated architecture for learning, planning, and reacting based on approximating dynamic programming",
    "abstract": "This paper extends previous work with Dyna, a class of architectures for intelligent systems based on approximating dynamic programming methods. Dyna architectures integrate trial-and-error (reinforcement) learning and execution-time planning into a single process operating alternately on the world and on a learned model of the world. In this paper, I present and show results for two Dyna architectures. The Dyna-PI architecture is based on dynamic programming's policy iteration method and can be related to existing AI ideas such as evaluation functions and universal plans (reactive systems). Using a navigation task, results are shown for a simple Dyna-PI system that simultaneously learns by trial and error, learns a world model, and plans optimal routes using the evolving world model. The Dyna-Q architecture is based on Watkins's Q-learning, a new kind of reinforcement learning. Dyna-Q uses a less familiar set of data structures than does Dyna-PI, but is arguably simpler to implement and use. We show that Dyna-Q architectures are easy to adapt for use in changing environments.",
    "date": "1990",
    "authors": [
        "Richard S. Sutton"
    ],
    "related_topics": [
        "Reinforcement learning",
        "Temporal difference learning",
        "Intelligent decision support system"
    ],
    "citation_count": "1,753",
    "reference_count": "17",
    "references": [
        "2121863487",
        "2100677568",
        "1583833196",
        "2021061679",
        "1569296262",
        "2225341423",
        "1610678877",
        "1969166509",
        "1551329771",
        "1506514354"
    ]
},{
    "id": "2149390907",
    "title": "Learning symbolic models of stochastic domains",
    "abstract": "In this article, we work towards the goal of developing agents that can learn to act in complex worlds. We develop a probabilistic, relational planning rule representation that compactly models noisy, nondeterministic action effects, and show how such rules can be effectively learned. Through experiments in simple planning domains and a 3D simulated blocks world with realistic physics, we demonstrate that this learning algorithm allows agents to effectively model world dynamics.",
    "date": "2007",
    "authors": [
        "Hanna M. Pasula",
        "Luke S. Zettlemoyer",
        "Leslie Pack Kaelbling"
    ],
    "related_topics": [
        "Blocks world",
        "Nondeterministic algorithm",
        "Probabilistic logic"
    ],
    "citation_count": "251",
    "reference_count": "35",
    "references": [
        "2798766386",
        "2011039300",
        "1977970897",
        "2334782222",
        "3022778360",
        "1575388622",
        "2121075864",
        "2170400507",
        "2225341423",
        "2009207944"
    ]
},{
    "id": "2134042548",
    "title": "Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation",
    "abstract": "We introduce the first temporal-difference learning algorithms that converge with smooth value function approximators, such as neural networks. Conventional temporal-difference (TD) methods, such as TD(\u03bb), Q-learning and Sarsa have been used successfully with function approximation in many applications. However, it is well known that off-policy sampling, as well as nonlinear function approximation, can cause these algorithms to become unstable (i.e., the parameters of the approximator may diverge). Sutton et al. (2009a, 2009b) solved the problem of off-policy learning with linear TD algorithms by introducing a new objective function, related to the Bellman error, and algorithms that perform stochastic gradient-descent on this function. These methods can be viewed as natural generalizations to previous TD methods, as they converge to the same limit points when used with linear function approximation methods. We generalize this work to nonlinear function approximation. We present a Bellman error objective function and two gradient-descent TD algorithms that optimize it. We prove the asymptotic almost-sure convergence of both algorithms, for any finite Markov decision process and any smooth value function approximator, to a locally optimal solution. The algorithms are incremental and the computational complexity per time step scales linearly with the number of parameters of the approximator. Empirical results obtained in the game of Go demonstrate the algorithms' effectiveness.",
    "date": "2009",
    "authors": [
        "Shalabh Bhatnagar",
        "Doina Precup",
        "David Silver",
        "Richard S Sutton",
        "Hamid R. Maei",
        "Csaba Szepesv\u00e1ri"
    ],
    "related_topics": [
        "Function approximation",
        "Approximation algorithm",
        "Bellman equation"
    ],
    "citation_count": "243",
    "reference_count": "17",
    "references": [
        "2121863487",
        "1515851193",
        "2100677568",
        "2531891978",
        "2139418546",
        "2075268401",
        "2103626435",
        "1646707810",
        "2006903949",
        "2117341272"
    ]
},{
    "id": "13294968",
    "title": "Toward Off-Policy Learning Control with Function Approximation",
    "abstract": "We present the first temporal-difference learning algorithm for off-policy control with unrestricted linear function approximation whose per-time-step complexity is linear in the number of features. Our algorithm, Greedy-GQ, is an extension of recent work on gradient temporal-difference learning, which has hitherto been restricted to a prediction (policy evaluation) setting, to a control setting in which the target policy is greedy with respect to a linear approximation to the optimal action-value function. A limitation of our control setting is that we require the behavior policy to be stationary. We call this setting latent learning because the optimal policy, though learned, is not manifest in behavior. Popular off-policy algorithms such as Q-learning are known to be unstable in this setting when used with linear function approximation.",
    "date": "2010",
    "authors": [
        "Hamid R. Maei",
        "Csaba Szepesv ri",
        "Shalabh Bhatnagar",
        "Richard S. Sutton"
    ],
    "related_topics": [
        "Q-learning",
        "Function approximation",
        "Linear approximation"
    ],
    "citation_count": "255",
    "reference_count": "19",
    "references": [
        "2121863487",
        "1515851193",
        "1592648094",
        "594357522",
        "2130005627",
        "2075268401",
        "1646707810",
        "1547105496",
        "2134042548",
        "2104753538"
    ]
},{
    "id": "2096072088",
    "title": "A Joint Language Model With Fine-grain Syntactic Tags",
    "abstract": "We present a scalable joint language model designed to utilize fine-grain syntactic tags. We discuss challenges such a design faces and describe our solutions that scale well to large tagsets and corpora. We advocate the use of relatively simple tags that do not require deep linguistic knowledge of the language but provide more structural information than POS tags and can be derived from automatically generated parse trees - a combination of properties that allows easy adoption of this model for new languages. We propose two fine-grain tagsets and evaluate our model using these tags, as well as POS tags and SuperARV tags in a speech recognition task and discuss future directions.",
    "date": "2009",
    "authors": [
        "Denis Filimonov",
        "Mary Harper"
    ],
    "related_topics": [
        "Language model",
        "Parsing",
        "Syntax"
    ],
    "citation_count": "35",
    "reference_count": "17",
    "references": [
        "2158195707",
        "2121227244",
        "2056250865",
        "2113691817",
        "2099345940",
        "1924403233",
        "2080018251",
        "2155280192",
        "2143866356",
        "2116625254"
    ]
},{
    "id": "2468573742",
    "title": "The 2005 AMI system for the transcription of speech in meetings",
    "abstract": "In this paper we describe the 2005 AMI system for the transcription of speech in meetings used in the 2005 NIST RT evaluations. The system was designed for participation in the speech to text part of the evaluations, in particular for transcription of speech recorded with multiple distant microphones and independent headset microphones. System performance was tested on both conference room and lecture style meetings. Although input sources are processed using different front-ends, the recognition process is based on a unified system architecture. The system operates in multiple passes and makes use of state of the art technologies such as discriminative training, vocal tract length normalisation, heteroscedastic linear discriminant analysis, speaker adaptation with maximum likelihood linear regression and minimum word error rate decoding. In this paper we describe the system performance on the official development and test sets for the NIST RT05s evaluations. The system was jointly developed in less than 10 months by a multi-site team and was shown to achieve competitive performance.",
    "date": "2005",
    "authors": [
        "Thomas Hain",
        "Lukas Burget",
        "John Dines",
        "Giulia Garau",
        "Martin Karafiat",
        "Mike Lincoln",
        "Iain McCowan",
        "Darren Moore",
        "Vincent Wan",
        "Roeland Ordelman",
        "Steve Renals"
    ],
    "related_topics": [
        "Speech synthesis",
        "Word error rate",
        "Transcription (software)"
    ],
    "citation_count": "75",
    "reference_count": "21",
    "references": [
        "2100969003",
        "2150907703",
        "1591607137",
        "2125336414",
        "2046317813",
        "2093225945",
        "1569447338",
        "2037740282",
        "1571931074",
        "2094971681"
    ]
},{
    "id": "2152808281",
    "title": "Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model",
    "abstract": "Previous work on statistical language modeling has shown that it is possible to train a feedforward neural network to approximate probabilities over sequences of words, resulting in significant error reduction when compared to standard baseline models based on n-grams. However, training the neural network model with the maximum-likelihood criterion requires computations proportional to the number of words in the vocabulary. In this paper, we introduce adaptive importance sampling as a way to accelerate training of the model. The idea is to use an adaptive n-gram model to track the conditional distributions produced by the neural network. We show that a very significant speedup can be obtained on standard problems.",
    "date": "2008",
    "authors": [
        "Y. Bengio",
        "J.-S. Senecal"
    ],
    "related_topics": [
        "Time delay neural network",
        "Probabilistic neural network",
        "Feedforward neural network"
    ],
    "citation_count": "228",
    "reference_count": "32",
    "references": [
        "2116064496",
        "2132339004",
        "1574901103",
        "1985093013",
        "2096175520",
        "2069739265",
        "1802356529",
        "2134237567",
        "1934041838",
        "2140679639"
    ]
},{
    "id": "2292896937",
    "title": "A guide to recurrent neural networks and backpropagation",
    "abstract": "This paper provides guidance to some of the concepts surrounding recurrent neural networks. Contrary to feedforward networks, recurrent networks can be sensitive, and be adapted to past inputs. Backpropagation learning is described for feedforward networks, adapted to suit our (probabilistic) modeling needs, and extended to cover recurrent networks. The aim of this brief paper is to set the scene for applying and understanding recurrent neural networks.",
    "date": "2000",
    "authors": [
        "Mikael Boden"
    ],
    "related_topics": [
        "Deep learning",
        "Feedforward neural network",
        "Types of artificial neural networks"
    ],
    "citation_count": "288",
    "reference_count": "20",
    "references": [
        "2110485445",
        "2107878631",
        "2339378878",
        "2016589492",
        "1979684610",
        "3036751298",
        "2151834591",
        "1959983357",
        "2121553911",
        "2468203291"
    ]
},{
    "id": "2027499299",
    "title": "The AMI System for the Transcription of Speech in Meetings",
    "abstract": "This paper describes the AMI transcription system for speech in meetings developed in collaboration by five research groups. The system includes generic techniques such as discriminative and speaker adaptive training, vocal tract length normalisation, heteroscedastic linear discriminant analysis, maximum likelihood linear regression, and phone posterior based features, as well as techniques specifically designed for meeting data. These include segmentation and cross-talk suppression, beam-forming, domain adaptation, Web-data collection, and channel adaptive training. The system was improved by more than 20% relative in word error rate compared to our previous system and was used in the NIST RT106 evaluations where it was found to yield competitive performance.",
    "date": "2007",
    "authors": [
        "T. Hain",
        "V. Wan",
        "L. Burget",
        "M. Karafiat",
        "J. Dines",
        "J. Vepa",
        "G. Garau",
        "M. Lincoln"
    ],
    "related_topics": [
        "Speech processing",
        "Word error rate",
        "Linear predictive coding"
    ],
    "citation_count": "142",
    "reference_count": "32",
    "references": [
        "2100969003",
        "2150907703",
        "1591607137",
        "2468573742",
        "2125336414",
        "2046317813",
        "2093225945",
        "1569447338",
        "2037740282",
        "1571931074"
    ]
},{
    "id": "2437096199",
    "title": "Training Neural Network Language Models on Very Large Corpora",
    "abstract": "During the last years there has been growing interest in using neural networks for language modeling. In contrast to the well known back-off n-gram language models, the neural network approach attempts to overcome the data sparseness problem by performing the estimation in a continuous space. This type of language model was mostly used for tasks for which only a very limited amount of in-domain training data is available.In this paper we present new algorithms to train a neural network language model on very large text corpora. This makes possible the use of the approach in domains where several hundreds of millions words of texts are available. The neural network language model is evaluated in a state-of-the-art real-time continuous speech recognizer for French Broadcast News. Word error reductions of 0.5% absolute are reported using only a very limited amount of additional processing time.",
    "date": "2005",
    "authors": [
        "Holger Schwenk",
        "Jean-Luc Gauvain"
    ],
    "related_topics": [
        "Time delay neural network",
        "Cache language model",
        "Language model"
    ],
    "citation_count": "161",
    "reference_count": "20",
    "references": [
        "2156909104",
        "2148603752",
        "2132339004",
        "1631260214",
        "2158195707",
        "2121227244",
        "2134237567",
        "2070534370",
        "2140679639",
        "2056590938"
    ]
},{
    "id": "1984565341",
    "title": "The vocabulary problem in human-system communication",
    "abstract": "In almost all computer applications, users must enter correct words for the desired objects or actions. For success without extensive training, or in first-tries for new targets, the system must recognize terms that will be chosen spontaneously. We studied spontaneous word choice for objects in five application-related domains, and found the variability to be surprisingly large. In every case two people favored the same term with probability",
    "date": "1987",
    "authors": [
        "G. W. Furnas",
        "T. K. Landauer",
        "L. M. Gomez",
        "S. T. Dumais"
    ],
    "related_topics": [
        "Vocabulary",
        "Vocabulary mismatch",
        "Term (time)"
    ],
    "citation_count": "2,055",
    "reference_count": "7",
    "references": [
        "3090556797",
        "50190571",
        "1988337648",
        "2104115112",
        "2051279338",
        "1997042879",
        "2046760690"
    ]
},{
    "id": "1964262399",
    "title": "Computer methods for mathematical computations",
    "abstract": "",
    "date": "1976",
    "authors": [
        "George E. Forsythe",
        "Michael A. Malcolm",
        "Cleve B. Moler"
    ],
    "related_topics": [
        "Computational resource",
        "Computational number theory",
        "Computational model"
    ],
    "citation_count": "4,256",
    "reference_count": "0",
    "references": []
},{
    "id": "2000215628",
    "title": "Analysis of individual differences in multidimensional scaling via an n-way generalization of 'eckart-young' decomposition",
    "abstract": "An individual differences model for multidimensional scaling is outlined in which individuals are assumed differentially to weight the several dimensions of a common \u201cpsychological space\u201d. A corresponding method of analyzing similarities data is proposed, involving a generalization of \u201cEckart-Young analysis\u201d to decomposition of three-way (or higher-way) tables. In the present case this decomposition is applied to a derived three-way table of scalar products between stimuli for individuals. This analysis yields a stimulus by dimensions coordinate matrix and a subjects by dimensions matrix of weights. This method is illustrated with data on auditory stimuli and on perception of nations.",
    "date": "1970",
    "authors": [
        "J. Douglas Carroll",
        "Jih-Jie Chang"
    ],
    "related_topics": [
        "Multidimensional scaling",
        "Tucker decomposition",
        "Matricization"
    ],
    "citation_count": "6,101",
    "reference_count": "15",
    "references": [
        "2185761757",
        "2056930330",
        "1963826206",
        "2024971339",
        "2083795909",
        "1997153468",
        "1979317087",
        "1977063224",
        "2056640768",
        "1572268863"
    ]
},{
    "id": "2114804204",
    "title": "The cluster hypothesis revisited",
    "abstract": "A new means of evaluating the cluster hypothesis is introduced and the results of such an evaluation are presented for four collections. The results of retrieval experiments comparing a sequential search, a cluster-based search, and a search of the clustered collection in which individual documents are scored against the query are also presented. These results indicate that while the absolute performance of a search on a particular collection is dependent on the pairwise similarity of the relevant documents, the relative effectiveness of clustered retrieval versus sequential retrieval is independent of this factor. However, retrieval of entire clusters in response to a query usually results in a poorer performance than retrieval of individual documents from clusters.",
    "date": "1985",
    "authors": [
        "Ellen M. Vdorhees"
    ],
    "related_topics": [
        "Cluster hypothesis",
        "Ranking (information retrieval)",
        "Concept search"
    ],
    "citation_count": "265",
    "reference_count": "11",
    "references": [
        "2068632118",
        "120261275",
        "2041565863",
        "2065938637",
        "2053256916",
        "73128518",
        "2045584315",
        "2007154686",
        "1980849928",
        "1546473629"
    ]
},{
    "id": "2151561903",
    "title": "Subject access in online catalogs: A design model",
    "abstract": "A model based on strikingly different philosophical as. sumptions from those currently popular is proposed for the design of online subject catalog access. Three design principles are presented and discussed: uncertainty (subject indexing is indeterminate and probabilistic beyond a certain point), variety (by Ashby\u2019s law of requisite variety, variety of searcher query must equal variety of document indexing), and complexity (the search process, particularly during the entry and orientation phases, is subtler and more complex, on several grounds, than current models assume). Design features presented are an access phase, including entry and orientation, a hunting phase, and a selection phase. An end-user thesaurus and a front-end system mind are presented as examples of online catalog system components to improve searcher success during entry and orientation. The proposed model is \u201cwrapped around\u201d existing Library of Congress subject-heading indexing in such a way as to enhance access greatly without requiring reindexing. It is argued that both for cost reasons and in principle this is a superior approach to other design philosophies.",
    "date": "1986",
    "authors": [
        "Marcia J. Bates"
    ],
    "related_topics": [
        "Subject access",
        "Subject indexing",
        "Search engine indexing"
    ],
    "citation_count": "564",
    "reference_count": "56",
    "references": [
        "1969340322",
        "1530533107",
        "2993383518",
        "2111030512",
        "1964653871",
        "1521517187",
        "2315179971",
        "2011386395",
        "2006423836",
        "2110416104"
    ]
},{
    "id": "3012395598",
    "title": "Data preprocessing and the extended PARAFAC model",
    "abstract": "",
    "date": "1983",
    "authors": [
        "R. A. Harshman"
    ],
    "related_topics": [
        "Data pre-processing",
        "Pattern recognition",
        "Computer science"
    ],
    "citation_count": "216",
    "reference_count": "0",
    "references": []
},{
    "id": "1965061793",
    "title": "A critical analysis of vector space model for information retrieval",
    "abstract": "Notations and definitions necessary to identify the concepts and relationships that are important in modelling information retrieval objects and processes in the context of vector spaces are presented. Earlier work on the use of vector model is evaluated in terms of the concepts introduced and certain problems and inconsistencies are identified. More importantly, this investigation should lead to a clear understanding of the issues and problems in using the vector space model in information retrieval. \u00a9 1986 John Wiley & Sons, Inc.",
    "date": "1986",
    "authors": [
        "Vijay V. Raghavan",
        "S. K. M. Wong"
    ],
    "related_topics": [
        "Vector space model",
        "Relevance (information retrieval)",
        "Document retrieval"
    ],
    "citation_count": "517",
    "reference_count": "8",
    "references": [
        "1956559956",
        "1974406477",
        "2024472735",
        "2004913349",
        "2049577316",
        "2074876593",
        "2052842312",
        "1985414707"
    ]
},{
    "id": "2024683548",
    "title": "Forsythe, G. E. / Malcolm, M. A. / Moler, C. B., Computer Methods for Mathematical Computations. Englewood Cliffs, New Jersey 07632. Prentice Hall, Inc., 1977. XI, 259 S",
    "abstract": "",
    "date": "1978",
    "authors": [
        "F. Grund"
    ],
    "related_topics": [
        "Mathematics",
        "Discrete mathematics",
        "Engineering physics"
    ],
    "citation_count": "666",
    "reference_count": "0",
    "references": []
},{
    "id": "2096411881",
    "title": "A THEORETICAL BASIS FOR THE USE OF CO\u2010OCCURRENCE DATA IN INFORMATION RETRIEVAL",
    "abstract": "This paper provides a foundation for a practical way of improving the effectiveness of an automatic retrieval system. Its main concern is with the weighting of index terms as a device for increasing retrieval effectiveness. Previously index terms have been assumed to be independent for the good reason that then a very simple weighting scheme can be used. In reality index terms are most unlikely to be independent. This paper explores one way of removing the independence assumption. Instead the extent of the dependence between index terms is measured and used to construct a non\u2010linear weighting function. In a practical situation the values of some of the parameters of such a function must be estimated from small samples of documents. So a number of estimation rules are discussed and one in particular is recommended. Finally the feasibility of the computations required for a non\u2010linear weighting scheme is examined.",
    "date": "1977",
    "authors": [
        "C.J. Van Rijsbergen"
    ],
    "related_topics": [
        "Weighting",
        "Statistical assumption",
        "Function (mathematics)"
    ],
    "citation_count": "653",
    "reference_count": "21",
    "references": [
        "3017143921",
        "2156273867",
        "2043909051",
        "2947000318",
        "2123838014",
        "2163166770",
        "2098057602",
        "1966365186",
        "149585942",
        "2107668593"
    ]
},{
    "id": "2099247782",
    "title": "A stochastic parts program and noun phrase parser for unrestricted text",
    "abstract": "A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct. >",
    "date": "1989",
    "authors": [
        "K.W. Church"
    ],
    "related_topics": [
        "Speech synthesis",
        "Part of speech",
        "Noun phrase"
    ],
    "citation_count": "3,360",
    "reference_count": "6",
    "references": [
        "2134237567",
        "2155818555",
        "1571096757",
        "2055438451",
        "1526508180",
        "2124479173"
    ]
},{
    "id": "2439178139",
    "title": "INSIDE-OUTSIDE REESTIMATION FROM PARTIALLY BRACKETED CORPORA",
    "abstract": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modeling of hierarchical structure than the original one. In particular, over 90% test set bracketing accuracy was achieved for grammars inferred by our algorithm from a training set of handparsed part-of-speech strings for sentences in the Air Travel Information System spoken language corpus. Finally, the new algorithm has better time complexity than the original one when sufficient bracketing is provided.",
    "date": "1992",
    "authors": [
        "Fernando Pereira",
        "Yves Schabes"
    ],
    "related_topics": [
        "Parsing",
        "Natural language",
        "Rule-based machine translation"
    ],
    "citation_count": "672",
    "reference_count": "11",
    "references": [
        "2125838338",
        "2087165009",
        "2077302143",
        "1978470410",
        "2110190189",
        "2012837062",
        "1541301615",
        "1982944197",
        "2047706513",
        "2047067573"
    ]
},{
    "id": "2334801970",
    "title": "The computational analysis of English : a corpus-based approach",
    "abstract": "",
    "date": "1989",
    "authors": [
        "Roger Garside",
        "Geoffrey N. Leech",
        "Geoffrey Sampson"
    ],
    "related_topics": [
        "Computer science",
        "Natural language processing",
        "Artificial intelligence"
    ],
    "citation_count": "310",
    "reference_count": "0",
    "references": []
},{
    "id": "900993354",
    "title": "Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision)",
    "abstract": "This manual addresses the linguistic issues that arise in connection with annotating texts by part of speech (\"tagging\"). Section 2 is an alphabetical list of the parts of speech encoded in the annotation systems of the Penn Treebank Project, along with their corresponding abbreviations (\"tags\") and some information concerning their definition. This section allows you to find an unfamiliar tag by looking up a familiar part of speech. Section 3 recapitulates the information in Section 2, but this time the information is alphabetically ordered by tags. This is the section to consult in order to find out what an unfamiliar tag means. Since the parts of speech are probably familiar to you from high school English, you should have little difficulty in assimilating the tags themselves. However, it is often quite difficult to decide which tag is appropriate in a particular context. The two sections 4 and 5 therefore include examples and guidelines on how to tag problematic cases. If you are uncertain about whether a given tag is correct or not, refer to these sections in order to ensure a consistently annotated text. Section 4 discusses parts of speech that are easily confused and gives guidelines on how to tag such cases, while Section 5 contains an alphabetical list of specific problematic words and collocations. Finally, Section 6 discusses some general tagging conventions. One general rule, however, is so important that we state it here. Many texts are not models of good prose, and some contain outright errors and slips of the pen. Do not be tempted to correct a tag to what it would be if the text were correct; rather, it is the incorrect word that should be tagged correctly. Disciplines Computer Sciences Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-90-47. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/570 Part-of-S peech Tagging Guidelines For The Penn Treebank Project (3rd Revision) MS-CIS-90-47 LINC LAB 178",
    "date": "1989",
    "authors": [
        "Beatrice Santorini"
    ],
    "related_topics": [
        "Treebank",
        "Section (typography)",
        "Part of speech"
    ],
    "citation_count": "620",
    "reference_count": "0",
    "references": []
},{
    "id": "2110190189",
    "title": "Parsing a natural language using mutual information statistics",
    "abstract": "The purpose of this paper is to characterize a constituent boundary parsing algorithm, using an information-theoretic measure called generalized mutual information, which serves as an alternative to traditional grammar-based parsing methods. This method is based on the hypothesis that constituent boundaries can be extracted from a given sentence (or word sequence) by analyzing the mutual information values of the part of speech n-grams within the sentence. This hypothesis is supported by the performance of an implementation of this parsing algorithm which determines a recursive unlabeled bracketing of unrestricted English text with a relatively low error rate. This paper derives the generalized mutual information statistic, describes the parsing algorithm, and presents results and sample output from the parser.",
    "date": "1990",
    "authors": [
        "David M. Magerman",
        "Mitchell P. Marcus"
    ],
    "related_topics": [
        "Top-down parsing",
        "Bottom-up parsing",
        "Parser combinator"
    ],
    "citation_count": "222",
    "reference_count": "7",
    "references": [
        "2099247782",
        "1593045043",
        "2134237567",
        "1483126227",
        "2017580301",
        "2034274945",
        "2126477387"
    ]
},{
    "id": "2012837062",
    "title": "Deducing linguistic structure from the statistics of large corpora",
    "abstract": "Within the last two years, approaches using both stochastic and symbolic techniques have proved adequate to deduce lexical ambiguity resolution rules with less than 3-4% error rate, when trained on moderate sized (500K word) corpora of English text (e.g. Church, 1988; Hindle, 1989). The success of these techniques suggests that much of the grammatical structure of language may be derived automatically through distributional analysis, an approach attempted and abandoned in the 1950s.",
    "date": "1990",
    "authors": [
        "Eric Brill",
        "David Magerman",
        "Mitchell Marcus",
        "Beatrice Santorini"
    ],
    "related_topics": [
        "Word error rate",
        "Natural language processing",
        "Structure (mathematical logic)"
    ],
    "citation_count": "193",
    "reference_count": "12",
    "references": [
        "2099247782",
        "1593045043",
        "2134237567",
        "1483126227",
        "2110190189",
        "3044664353",
        "2034274945",
        "2126477387",
        "1528321674",
        "2065585771"
    ]
},{
    "id": "2121407024",
    "title": "ACQUIRING DISAMBIGUATION RULES FROM TEXT",
    "abstract": "An effective procedure for automatically acquiring a new set of disambiguation rules for an existing deterministic parser on the basis of tagged text is presented. Performance of the automatically acquired rules is much better than the existing hand-written disambiguation rules. The success of the acquired rules depends on using the linguistic information encoded in the parser; enhancements to various components of the parser improves the acquired rule set. This work suggests a path toward more robust and comprehensive syntactic analyzers.",
    "date": "1989",
    "authors": [
        "Donald Hindle"
    ],
    "related_topics": [
        "Parsing",
        "Rule-based machine translation",
        "Syntax"
    ],
    "citation_count": "145",
    "reference_count": "9",
    "references": [
        "2099247782",
        "2017580301",
        "1571096757",
        "1981724541",
        "1487155516",
        "2158652440",
        "2124102576",
        "1590656471",
        "2015773474"
    ]
},{
    "id": "2076526090",
    "title": "Studies in part of speech labelling",
    "abstract": "We report here on our experiments with POST (Part of Speech Tagger) to address problems of ambiguity and of understanding unknown words. Part of speech tagging, per se, is a well understood problem. Our paper reports experiments in three important areas: handling unknown words, limiting the size of the training set, and returning a set of the most likely tags for each word rather than a single tag. We describe the algorithms that we used and the specific results of our experiments on Wall Street Journal articles and on MUC terrorist messages.",
    "date": "1991",
    "authors": [
        "Marie Meteer",
        "Richard Schwartz",
        "Ralph Weischedel"
    ],
    "related_topics": [
        "Part of speech",
        "Ambiguity",
        "Set (psychology)"
    ],
    "citation_count": "23",
    "reference_count": "7",
    "references": [
        "2099247782",
        "2127836646",
        "2122214306",
        "2006002820",
        "2064910499",
        "2112323378",
        "2083607646"
    ]
},{
    "id": "2166675302",
    "title": "Discovering the Lexical Features of a Language",
    "abstract": "This paper examines the possibility of automatically discovering the lexieal features of a language. There is strong evidence that the set of possible lexical features which can be used in a language is unbounded, and thus not innate. Lakoff [Lakoff 87] describes a language in which the feature -I-woman-or-fire-ordangerons-thing exists. This feature is based upon ancient folklore of the society in which it is used. If the set of possible lexieal features is indeed unbounded, then it cannot be par t of the innate Universal Grammar and must be learned. Even if the set is not unbounded, the child is still left with the challenging task of determining which features are used in her language. If a child does not know a priori what lexical features are used in her language, there are two sources for acquiring this information: semantic and syntactic cues. A learner using semantic cues could recognize that words often refer to objects, actions, and properties, and from this deduce the lexical features: noun, verb and adjective. Pinker [Pinker 89] proposes that a combination of semantic cues and innate semantic primitives could account for the acquisition of verb features. He believes that the child can discover semantic properties of a verb by noticing the types of actions typically taking place when the verb is uttered. Once these properties are known, says Pinker, they can be used to reliably predict the distributional behavior of the verb. However, Gleitman [Gleitman 90] presents evidence that semantic cues axe not sufficient for a child to acquire verb features and believes that the use of this semantic information in conjunction with information about the subcategorization properties of the verb may be sufficient for learning verb features. This paper takes Glei tman's suggestion to the extreme, in hope of determining whether syntactic cues may not just aid in feature discovery, but may be all tha t is necessary. We present evidence for the sufficiency of a strictly syntax-based model for discovering",
    "date": "1991",
    "authors": [
        "Eric Brill"
    ],
    "related_topics": [
        "Verb",
        "Lexical item",
        "Syntax"
    ],
    "citation_count": "20",
    "reference_count": "5",
    "references": [
        "2055460448",
        "1483126227",
        "2052262800",
        "1541301615",
        "3044664353"
    ]
},{
    "id": "2148603752",
    "title": "Statistical learning theory",
    "abstract": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more.",
    "date": "1997",
    "authors": [
        "Vladimir Naumovich Vapnik"
    ],
    "related_topics": [
        "Algorithmic learning theory",
        "Statistical learning theory",
        "Stability (learning theory)"
    ],
    "citation_count": "67,327",
    "reference_count": "1",
    "references": [
        "2156909104"
    ]
},{
    "id": "1480376833",
    "title": "The Elements of Statistical Learning",
    "abstract": "",
    "date": "2000",
    "authors": [
        "Trevor Hastie",
        "Robert Tibshirani",
        "Jerome H. Friedman"
    ],
    "related_topics": [
        "Algorithmic learning theory",
        "Semi-supervised learning",
        "Ensemble learning"
    ],
    "citation_count": "15,816",
    "reference_count": "0",
    "references": []
},{
    "id": "2154455818",
    "title": "Learning with Local and Global Consistency",
    "abstract": "We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data.",
    "date": "2003",
    "authors": [
        "Dengyong Zhou",
        "Olivier Bousquet",
        "Thomas N. Lal",
        "Jason Weston",
        "Bernhard Sch\u00f6lkopf"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Unsupervised learning",
        "Machine learning"
    ],
    "citation_count": "4,402",
    "reference_count": "19",
    "references": [
        "2148603752",
        "2053186076",
        "2001141328",
        "2165874743",
        "1578099820",
        "2139823104",
        "1708874574",
        "2159737176",
        "1966949944",
        "2122837498"
    ]
},{
    "id": "2048679005",
    "title": "Combining labeled and unlabeled data with co-training",
    "abstract": "We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm\u2019s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu",
    "date": "1998",
    "authors": [
        "Avrim Blum",
        "Tom Mitchell"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Co-training",
        "Web page"
    ],
    "citation_count": "6,427",
    "reference_count": "14",
    "references": [
        "2049633694",
        "3017143921",
        "2101210369",
        "2167044614",
        "2128221272",
        "1995897489",
        "2103555337",
        "2150516767",
        "2020764470",
        "1550302919"
    ]
},{
    "id": "2097089247",
    "title": "Text Classification from Labeled and Unlabeled Documents using EM",
    "abstract": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available. We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in practice, and poor performance can result. We present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. Experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%.",
    "date": "2000",
    "authors": [
        "Kamal Nigam",
        "Andrew Kachites McCallum",
        "Sebastian Thrun",
        "Tom Mitchell"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Co-training",
        "Naive Bayes classifier"
    ],
    "citation_count": "3,923",
    "reference_count": "47",
    "references": [
        "2099111195",
        "2149684865",
        "2049633694",
        "2435251607",
        "2048679005",
        "2117853077",
        "2114535528",
        "1550206324",
        "2138745909",
        "2140785063"
    ]
},{
    "id": "2010353172",
    "title": "Weak Convergence and Empirical Processes",
    "abstract": "",
    "date": "1995",
    "authors": [
        "Thomas Mikosch",
        "Aad W. Van der Vaart",
        "Jon A. Wellner"
    ],
    "related_topics": [
        "Weak convergence",
        "Mathematics",
        "Applied mathematics"
    ],
    "citation_count": "6,517",
    "reference_count": "1",
    "references": [
        "2802739963"
    ]
},{
    "id": "2101210369",
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "date": "1995",
    "authors": [
        "David Yarowsky"
    ],
    "related_topics": [
        "SemEval",
        "Unsupervised learning",
        "Bootstrapping (linguistics)"
    ],
    "citation_count": "2,982",
    "reference_count": "23",
    "references": [
        "2049633694",
        "2102381086",
        "2099247782",
        "2040004971",
        "1971220772",
        "1977182536",
        "2129139611",
        "2428981601",
        "1554031433",
        "2156202195"
    ]
},{
    "id": "1535015163",
    "title": "A maximum-entropy-inspired parser",
    "abstract": "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less, and 89.5% for sentences of length 100 and less when trained and tested on the previously established [5, 9, 10, 15, 17] \"standard\" sections of the Wall Street Journal treebank. This represents a 13% decrease in error rate over the best single-parser results on this corpus [9]. The major technical innovation is the use of a \"maximum-entropy-inspired\" model for conditioning and smoothing that let us successfully to test and combine many different conditioning events. We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head.",
    "date": "2000",
    "authors": [
        "Eugene Charniak"
    ],
    "related_topics": [
        "Parsing",
        "Statistical parsing",
        "Treebank"
    ],
    "citation_count": "2,405",
    "reference_count": "16",
    "references": [
        "1632114991",
        "2096175520",
        "2092654472",
        "1986543644",
        "1567570606",
        "2153439141",
        "1551104980",
        "2161204834",
        "1953828586",
        "2166394306"
    ]
},{
    "id": "2092654472",
    "title": "Head-Driven Statistical Models for Natural Language Parsing",
    "abstract": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models.",
    "date": "2003",
    "authors": [
        "Michael Collins"
    ],
    "related_topics": [
        "Data-oriented parsing",
        "Statistical parsing",
        "S-attributed grammar"
    ],
    "citation_count": "2,528",
    "reference_count": "61",
    "references": [
        "2147880316",
        "1574901103",
        "1632114991",
        "1535015163",
        "2107890099",
        "1773803948",
        "2002089154",
        "3021452258",
        "2110882317",
        "1986543644"
    ]
},{
    "id": "2115792525",
    "title": "The Berkeley FrameNet Project",
    "abstract": "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \"Tools for Lexicon Building\"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \"frame elements\" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work.",
    "date": "1998",
    "authors": [
        "Collin F. Baker",
        "Charles J. Fillmore",
        "John B. Lowe"
    ],
    "related_topics": [
        "FrameNet",
        "Semantic role labeling",
        "PropBank"
    ],
    "citation_count": "3,737",
    "reference_count": "2",
    "references": [
        "3088277579",
        "2154890447"
    ]
},{
    "id": "2151170651",
    "title": "Automatic labeling of semantic roles",
    "abstract": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Given an input sentence and a target word and frame, the system labels constituents with either abstract semantic roles, such as AGENT or PATIENT, or more domain-specific semantic roles, such as SPEAKER, MESSAGE, and TOPIC.The system is based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project. We then parsed each training sentence into a syntactic tree and extracted various lexical and syntactic features, including the phrase type of each constituent, its grammatical function, and its position in the sentence. These features were combined with knowledge of the predicate verb, noun, or adjective, as well as information such as the prior probabilities of various combinations of semantic roles. We used various lexical clustering algorithms to generalize across possible fillers of roles. Test sentences were parsed, were annotated with these features, and were then passed through the classifiers.Our system achieves 82% accuracy in identifying the semantic role of presegmented constituents. At the more difficult task of simultaneously segmenting constituents and identifying their semantic role, the system achieved 65% precision and 61% recall.Our study also allowed us to compare the usefulness of different features and feature combination methods in the semantic role labeling task. We also explore the integration of role labeling with statistical syntactic parsing and attempt to generalize to predicates unseen in the training data.",
    "date": "2002",
    "authors": [
        "Daniel Gildea",
        "Daniel Jurafsky"
    ],
    "related_topics": [
        "Semantic role labeling",
        "FrameNet",
        "Semantic similarity"
    ],
    "citation_count": "2,457",
    "reference_count": "41",
    "references": [
        "2038721957",
        "1632114991",
        "2092654472",
        "2115792525",
        "2160842254",
        "2038248725",
        "1986543644",
        "2039217078",
        "1567570606",
        "2127314673"
    ]
},{
    "id": "3021452258",
    "title": "Discriminative Reranking for Natural Language Parsing",
    "abstract": "",
    "date": "2000",
    "authors": [
        "Michael Collins"
    ],
    "related_topics": [
        "Statistical parsing",
        "Data-oriented parsing",
        "Discriminative model"
    ],
    "citation_count": "718",
    "reference_count": "0",
    "references": []
},{
    "id": "2039217078",
    "title": "English Verb Classes and Alternations: A Preliminary Investigation",
    "abstract": "In this rich reference work, Beth Levin classifies over 3,000 English verbs according to shared meaning and behavior. Levin starts with the hypothesis that a verb's meaning influences its syntactic behavior and develops it into a powerful tool for studying the English verb lexicon. She shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning. The first part of the book sets out alternate ways in which verbs can express their arguments. The second presents classes of verbs that share a kernel of meaning and explores in detail the behavior of each class, drawing on the alternations in the first part. Levin's discussion of each class and alternation includes lists of relevant verbs, illustrative examples, comments on noteworthy properties, and bibliographic references. The result is an original, systematic picture of the organization of the verb inventory. Easy to use, \"English Verb Classes and Alternations\" sets the stage for further explorations of the interface between lexical semantics and syntax. It will prove indispensable for theoretical and computational linguists, psycholinguists, cognitive scientists, lexicographers, and teachers of English as a second language. Beth Levin is associate professor of linguistics at Northwestern University.",
    "date": "1993",
    "authors": [
        "Beth Levin"
    ],
    "related_topics": [
        "Modal verb",
        "English verbs",
        "Verb"
    ],
    "citation_count": "3,746",
    "reference_count": "0",
    "references": []
},{
    "id": "2126851059",
    "title": "Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling",
    "abstract": "In this paper we describe the CoNLL-2005 shared task on Semantic Role Labeling. We introduce the specification and goals of the task, describe the data sets and evaluation methods, and present a general overview of the 19 systems that have contributed to the task, providing a comparative description and results.",
    "date": "2005",
    "authors": [
        "Xavier Carreras",
        "Llu'is M`arquez"
    ],
    "related_topics": [
        "Semantic computing",
        "Semantic role labeling",
        "Task (project management)"
    ],
    "citation_count": "953",
    "reference_count": "37",
    "references": [
        "1632114991",
        "2158847908",
        "1535015163",
        "2092654472",
        "2144578941",
        "2151170651",
        "2145310422",
        "2138043057",
        "204260652",
        "2116786260"
    ]
},{
    "id": "2154626406",
    "title": "The Necessity of Parsing for Predicate Argument Recognition",
    "abstract": "Broad-coverage corpora annotated with semantic role, or argument structure, information are becoming available for the first time. Statistical systems have been trained to automatically label semantic roles from the output of statistical parsers on unannotated text. In this paper, we quantify the effect of parser accuracy on these systems' performance, and examine the question of whether a flatter \"chunked\" representation of the input can be as effective for the purposes of semantic role identification.",
    "date": "2002",
    "authors": [
        "Daniel Gildea",
        "Martha Palmer"
    ],
    "related_topics": [
        "Semantic role labeling",
        "Parsing",
        "PropBank"
    ],
    "citation_count": "317",
    "reference_count": "14",
    "references": [
        "2147880316",
        "1934019294",
        "2115792525",
        "2151170651",
        "1986543644",
        "1567570606",
        "2163918411",
        "12836875",
        "2098921539",
        "1667964228"
    ]
},{
    "id": "2166776180",
    "title": "Automatic Retrieval and Clustering of Similar Words",
    "abstract": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is.",
    "date": "1998",
    "authors": [
        "Dekang Lin"
    ],
    "related_topics": [
        "Thesaurus (information retrieval)",
        "WordNet",
        "Similarity measure"
    ],
    "citation_count": "2,437",
    "reference_count": "18",
    "references": [
        "2102381086",
        "1997841190",
        "2127314673",
        "2163953154",
        "1940278502",
        "2123084125",
        "2123489126",
        "2016001305",
        "2109779030",
        "2102997946"
    ]
},{
    "id": "1520377376",
    "title": "An Algorithm that Learns What\u2018s in a Name",
    "abstract": "In this paper, we present IdentiFinderTM, a hidden Markov model that learns to recognize and classify names, dates, times, and numerical quantities. We have evaluated the model in English (based on data from the Sixth and Seventh Message Understanding Conferences [MUC-6, MUC-7] and broadcast news) and in Spanish (based on data distributed through the First Multilingual Entity Task [MET-1]), and on speech input (based on broadcast news). We report results here on standard materials only to quantify performance on data available to the community, namely, MUC-6 and MET-1. Results have been consistently better than reported by any other learning algorithm. IdentiFinder\u2018s performance is competitive with approaches based on handcrafted rules on mixed case text and superior on text where case information is not available. We also present a controlled experiment showing the effect of training set size on performance, demonstrating that as little as 100,000 words of training data is adequate to get performance around 90% on newswire. Although we present our understanding of why this algorithm performs so well on this class of problems, we believe that significant improvement in performance may still be possible.",
    "date": "1999",
    "authors": [
        "Daniel M. Bikel",
        "Richard Schwartz",
        "Ralph M. Weischedel"
    ],
    "related_topics": [
        "Hidden Markov model",
        "Class (computer programming)",
        "Machine learning"
    ],
    "citation_count": "1,101",
    "reference_count": "14",
    "references": [
        "2125838338",
        "2117400858",
        "2099247782",
        "1718065290",
        "1991133427",
        "1971763646",
        "1568620938",
        "2080856991",
        "2033209333",
        "1568095077"
    ]
},{
    "id": "1988995507",
    "title": "Chunking with support vector machines",
    "abstract": "We apply Support Vector Machines (SVMs) to identify English base phrases (chunks). SVMs are known to achieve high generalization performance even with input data of high dimensional feature spaces. Furthermore, by the Kernel principle, SVMs can carry out training with smaller computational overhead independent of their dimensionality. We apply weighted voting of 8 SVMs-based systems trained with distinct chunk representations. Experimental results show that our approach achieves higher accuracy than previous approaches.",
    "date": "2001",
    "authors": [
        "Taku Kudo",
        "Yuji Matsumoto"
    ],
    "related_topics": [
        "Relevance vector machine",
        "Support vector machine",
        "Kernel (linear algebra)"
    ],
    "citation_count": "729",
    "reference_count": "24",
    "references": [
        "2148603752",
        "2119821739",
        "2149684865",
        "2112076978",
        "2107008379",
        "2101276256",
        "1676820704",
        "2117400858",
        "2153104898",
        "1553313034"
    ]
},{
    "id": "2145310422",
    "title": "Using Predicate-Argument Structures for Information Extraction",
    "abstract": "In this paper we present a novel, customizable IE paradigm that takes advantage of predicate-argument structures. We also introduce a new way of automatically identifying predicate argument structures, which is central to our IE paradigm. It is based on: (1) an extended set of features; and (2) inductive decision tree learning. The experimental results prove our claim that accurate predicate-argument structures enable high quality IE results.",
    "date": "2003",
    "authors": [
        "Mihai Surdeanu",
        "Sanda Harabagiu",
        "John Williams",
        "Paul Aarseth"
    ],
    "related_topics": [
        "Predicate (grammar)",
        "Decision tree learning",
        "Information extraction"
    ],
    "citation_count": "511",
    "reference_count": "13",
    "references": [
        "2115792525",
        "2151170651",
        "2117400858",
        "1986543644",
        "2039217078",
        "2124634352",
        "2154626406",
        "2085606725",
        "1667964228",
        "1971563386"
    ]
},{
    "id": "2155693943",
    "title": "Immediate-Head Parsing for Language Models",
    "abstract": "We present two language models based upon an \"immediate-head\" parser --- our name for a parser that conditions all events below a constituent c upon the head of c. While all of the most accurate statistical parsers are of the immediate-head variety, no previous grammatical language model uses this technology. The perplexity for both of these models significantly improve upon the trigram model base-line as well as the best previous grammar-based language model. For the better of our two models these improvements are 24% and 14% respectively. We also suggest that improvement of the underlying parser should significantly improve the model's perplexity and that even in the near term there is a lot of potential for improvement in immediate-head language models.",
    "date": "2001",
    "authors": [
        "Eugene Charniak"
    ],
    "related_topics": [
        "Perplexity",
        "LR parser",
        "Simple LR parser"
    ],
    "citation_count": "456",
    "reference_count": "18",
    "references": [
        "1632114991",
        "1535015163",
        "2092654472",
        "3021452258",
        "1986543644",
        "2153439141",
        "2108321481",
        "2949237929",
        "2161204834",
        "2123893795"
    ]
},{
    "id": "2093647425",
    "title": "The Penn Treebank: annotating predicate argument structure",
    "abstract": "The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles.",
    "date": "1994",
    "authors": [
        "Mitchell Marcus",
        "Grace Kim",
        "Mary Ann Marcinkiewicz",
        "Robert MacIntyre",
        "Ann Bies",
        "Mark Ferguson",
        "Karen Katz",
        "Britta Schasberger"
    ],
    "related_topics": [
        "Treebank",
        "Semantic role labeling",
        "Predicate (grammar)"
    ],
    "citation_count": "1,042",
    "reference_count": "11",
    "references": [
        "1632114991",
        "2796493717",
        "1483126227",
        "2062837929",
        "1859173823",
        "2334801970",
        "2087165009",
        "2102924265",
        "2167434254",
        "2021758792"
    ]
},{
    "id": "2040909025",
    "title": "Use of support vector learning for chunk identification",
    "abstract": "In this paper, we explore the use of Support Vector Machines (SVMs) for CoNLL-2000 shared task, chunk identification. SVMs are so-called large margin classifiers and are well-known as their good generalization performance. We investigate how SVMs with a very large number of features perform with the classification task of chunk labelling.",
    "date": "2000",
    "authors": [
        "Taku Kudoh",
        "Yuji Matsumoto"
    ],
    "related_topics": [
        "Support vector machine",
        "Margin (machine learning)",
        "Identification (information)"
    ],
    "citation_count": "419",
    "reference_count": "6",
    "references": [
        "2156909104",
        "2119821739",
        "2149684865",
        "1574862351",
        "2153104898",
        "1490175418"
    ]
},{
    "id": "2150203234",
    "title": "Semantic role parsing: adding semantic structure to unstructured text",
    "abstract": "There is an ever-growing need to add structure in the form of semantic markup to the huge amounts of unstructured text data now available. We present the technique of shallow semantic parsing, the process of assigning a simple WHO did WHAT to WHOM, etc., structure to sentences in text, as a useful tool in achieving this goal. We formulate the semantic parsing problem as a classification problem using support vector machines. Using a hand-labeled training set and a set of features drawn from earlier work together with some feature enhancements, we demonstrate a system that performs better than all other published results on shallow semantic parsing.",
    "date": "2003",
    "authors": [
        "Sameer Pradhan",
        "K. Hacioglu",
        "W. Ward",
        "J.H. Martin",
        "D. Jurafsky"
    ],
    "related_topics": [
        "Semantic computing",
        "S-attributed grammar",
        "Bottom-up parsing"
    ],
    "citation_count": "121",
    "reference_count": "17",
    "references": [
        "2156909104",
        "2138745909",
        "2115792525",
        "2151170651",
        "2166776180",
        "2885050925",
        "1520377376",
        "2154626406",
        "12836875",
        "2145310422"
    ]
},{
    "id": "2125838338",
    "title": "A tutorial on hidden Markov models and selected applications in speech recognition",
    "abstract": "This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described. >",
    "date": "1989",
    "authors": [
        "L.R. Rabiner"
    ],
    "related_topics": [
        "Layered hidden Markov model",
        "Hidden semi-Markov model",
        "Hierarchical hidden Markov model"
    ],
    "citation_count": "32,632",
    "reference_count": "62",
    "references": [
        "2049633694",
        "2105594594",
        "1966812932",
        "2142384583",
        "2022554507",
        "2002182716",
        "1966264494",
        "2171850596",
        "1991133427",
        "1877570817"
    ]
},{
    "id": "2008652694",
    "title": "Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms",
    "abstract": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger.",
    "date": "2002",
    "authors": [
        "Michael Collins"
    ],
    "related_topics": [
        "Maximum-entropy Markov model",
        "Hidden Markov model",
        "Viterbi algorithm"
    ],
    "citation_count": "2,502",
    "reference_count": "12",
    "references": [
        "2147880316",
        "1632114991",
        "1934019294",
        "1773803948",
        "2117400858",
        "2127713198",
        "1979711143",
        "2131297983",
        "1623072288",
        "2144087279"
    ]
},{
    "id": "1934019294",
    "title": "Maximum Entropy Markov Models for Information Extraction and Segmentation",
    "abstract": "Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling sequential data, and have been applied with success to many text-related tasks, such as part-of-speech tagging, text segmentation and information extraction. In these cases, the observations are usually modeled as multinomial distributions over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood of the observations. This paper presents a new Markovian sequence model, closely related to HMMs, that allows observations to be represented as arbitrary overlapping features (such as word, capitalization, formatting, part-of-speech), and defines the conditional probability of state sequences given observation sequences. It does this by using the maximum entropy framework to fit a set of exponential models that represent the probability of a state given an observation and the previous state. We present positive experimental results on the segmentation of FAQ\u2019s.",
    "date": "2000",
    "authors": [
        "Andrew McCallum",
        "Dayne Freitag",
        "Fernando C. N. Pereira"
    ],
    "related_topics": [
        "Maximum-entropy Markov model",
        "Variable-order Markov model",
        "Principle of maximum entropy"
    ],
    "citation_count": "1,915",
    "reference_count": "21",
    "references": [
        "2125838338",
        "2049633694",
        "2160842254",
        "2117400858",
        "1520377376",
        "1528056001",
        "1557074680",
        "2158873310",
        "1597379537",
        "1592796124"
    ]
},{
    "id": "1567570606",
    "title": "Statistical parsing with a context-free grammar and word statistics",
    "abstract": "We describe a parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence. This model is used in a parsing system by finding the parse for the sentence with the highest probability. This system outperforms previous schemes. As this is the third in a series of parsers by different authors that are similar enough to invite detailed comparisons but different enough to give rise to different levels of performance, we also report on some experiments designed to identify what aspects of these systems best explain their relative performance.",
    "date": "1997",
    "authors": [
        "Eugene Charniak"
    ],
    "related_topics": [
        "Statistical parsing",
        "Top-down parsing",
        "Bottom-up parsing"
    ],
    "citation_count": "760",
    "reference_count": "7",
    "references": [
        "1632114991",
        "2110882317",
        "2127314673",
        "2153439141",
        "2161204834",
        "2787704407",
        "170869742"
    ]
},{
    "id": "2125712079",
    "title": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking",
    "abstract": "Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000). A discriminative reranker requires a source of candidate parses for each sentence. This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000). This method generates 50-best lists that are of substantially higher quality than previously obtainable. We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less.",
    "date": "2005",
    "authors": [
        "Eugene Charniak",
        "Mark Johnson"
    ],
    "related_topics": [
        "Statistical parsing",
        "Parsing",
        "Discriminative model"
    ],
    "citation_count": "1,348",
    "reference_count": "18",
    "references": [
        "2097606805",
        "1535015163",
        "3021452258",
        "1986543644",
        "2102667697",
        "2098379588",
        "2123893795",
        "1985754308",
        "2037894654",
        "2143458716"
    ]
},{
    "id": "2729906263",
    "title": "Linguistic Data Consortium",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Treebank Penn"
    ],
    "related_topics": [
        "Linguistic Data Consortium",
        "Computer science",
        "Linguistics"
    ],
    "citation_count": "1,024",
    "reference_count": "0",
    "references": []
},{
    "id": "2098379588",
    "title": "Estimators for Stochastic \"Unification-Based\" Grammars",
    "abstract": "Log-linear models provide a statistically sound framework for Stochastic \"Unification-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars. We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar.",
    "date": "1999",
    "authors": [
        "Mark Johnson",
        "Stuart Geman",
        "Stephen Canon",
        "Zhiyi Chi",
        "Stefan Riezler"
    ],
    "related_topics": [
        "Tree-adjoining grammar",
        "Phrase structure grammar",
        "Context-sensitive grammar"
    ],
    "citation_count": "260",
    "reference_count": "11",
    "references": [
        "2159080219",
        "2096175520",
        "1508165687",
        "2150218618",
        "2114220616",
        "1734853756",
        "28766783",
        "1976711294",
        "160680375",
        "1533001652"
    ]
},{
    "id": "2037894654",
    "title": "Better k-best Parsing",
    "abstract": "We discuss the relevance of k-best parsing to recent applications in natural language processing, and develop efficient algorithms for k-best trees in the framework of hypergraph parsing. To demonstrate the efficiency, scalability and accuracy of these algorithms, we present experiments on Bikel's implementation of Collins' lexicalized PCFG model, and on Chiang's CFG-based decoder for hierarchical phrase-based translation. We show in particular how the improved output of our algorithms has the potential to improve results from parse reranking systems and other applications.",
    "date": "2005",
    "authors": [
        "Liang Huang",
        "David Chiang"
    ],
    "related_topics": [
        "Bottom-up parsing",
        "Top-down parsing",
        "S-attributed grammar"
    ],
    "citation_count": "402",
    "reference_count": "42",
    "references": [
        "3145128584",
        "2159080219",
        "1632114991",
        "301824129",
        "2146574666",
        "1535015163",
        "2092654472",
        "2152263452",
        "2151170651",
        "2116410915"
    ]
},{
    "id": "1904457459",
    "title": "A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)",
    "abstract": "Describes a system developed at NIST to produce a composite automatic speech recognition (ASR) system output when the outputs of multiple ASR systems are available, and for which, in many cases, the composite ASR output has a lower error rate than any of the individual systems. The system implements a \"voting\" or rescoring process to reconcile differences in ASR system outputs. We refer to this system as the NIST Recognizer Output Voting Error Reduction (ROVER) system. As additional knowledge sources are added to an ASR system (e.g. acoustic and language models), error rates are typically decreased. This paper describes a post-recognition process which models the output generated by multiple ASR systems as independent knowledge sources that can be combined and used to generate an output with reduced error rate. To accomplish this, the outputs of multiple of ASR systems are combined into a single, minimal-cost word transition network (WTN) via iterative applications of dynamic programming (DP) alignments. The resulting network is searched by an automatic rescoring or \"voting\" process that selects the output sequence with the lowest score.",
    "date": "1997",
    "authors": [
        "J.G. Fiscus"
    ],
    "related_topics": [
        "Word error rate",
        "NIST",
        "Language model"
    ],
    "citation_count": "1,777",
    "reference_count": "1",
    "references": [
        "1586176709"
    ]
},{
    "id": "2594610113",
    "title": "Finding consensus in speech recognition: word error minimization and other applications of confusion networks\u2606",
    "abstract": "We describe a new framework for distilling information from word lattices to improve the accuracy of the speech recognition output and obtain a more perspicuous representation of a set of alternative hypotheses. In the standard MAP decoding approach the recognizer outputs the string of words corresponding to the path with the highest posterior probability given the acoustics and a language model. However, even given optimal models, the MAP decoder does not necessarily minimize the commonly used performance metric, word error rate (WER). We describe a method for explicitly minimizing WER by extracting word hypotheses with the highest posterior probabilities from word lattices. We change the standard problem formulation by replacing global search over a large set of sentence hypotheses with local search over a small set of word candidates. In addition to improving the accuracy of the recognizer, our method produces a new representation of a set of candidate hypotheses that specifies the sequence of word-level confusions in a compact lattice format. We study the properties of confusion networks and examine their use for other tasks, such as lattice compression, word spotting, confidence annotation, and reevaluation of recognition hypotheses using higher-level knowledge sources.",
    "date": "2000",
    "authors": [
        "Lidia Mangu",
        "Eric Brill",
        "Andreas Stolcke"
    ],
    "related_topics": [
        "Word error rate",
        "Language model",
        "Posterior probability"
    ],
    "citation_count": "885",
    "reference_count": "17",
    "references": [
        "3017143921",
        "2125529971",
        "1966812932",
        "1904457459",
        "2097978681",
        "1571931074",
        "1528470941",
        "173561343",
        "2129334286",
        "55333121"
    ]
},{
    "id": "2100506586",
    "title": "Two decades of statistical language modeling: where do we go from here?",
    "abstract": "Statistical language models estimate the distribution of various natural language phenomena for the purpose of speech recognition and other language technologies. Since the first significant model was proposed in 1980, many attempts have been made to improve the state of the art. We review them, point to a few promising directions, and argue for a Bayesian approach to integration of linguistic theories with data.",
    "date": "2000",
    "authors": [
        "R. Rosenfeld"
    ],
    "related_topics": [
        "Language identification",
        "Language model",
        "Computational linguistics"
    ],
    "citation_count": "915",
    "reference_count": "77",
    "references": [
        "2038721957",
        "1594031697",
        "2147152072",
        "1632114991",
        "2096175520",
        "1508165687",
        "2093390569",
        "2158195707",
        "2121227244",
        "2160842254"
    ]
},{
    "id": "1797288984",
    "title": "Entropy-based Pruning of Backoff Language Models",
    "abstract": "A criterion for pruning parameters from N-gram backoff language models is developed, based on the relative entropy between the original and the pruned model. It is shown that the relative entropy resulting from pruning a single N-gram can be computed exactly and efficiently for backoff models. The relative entropy measure can be expressed as a relative change in training set perplexity. This leads to a simple pruning criterion whereby all N-grams that change perplexity by less than a threshold are removed from the model. Experiments show that a production-quality Hub4 LM can be reduced to 26% its original size without increasing recognition error. We also compare the approach to a heuristic pruning criterion by Seymore and Rosenfeld (1996), and show that their approach can be interpreted as an approximation to the relative entropy criterion. Experimentally, both approaches select similar sets of N-grams (about 85% overlap), with the exact relative entropy criterion giving marginally better performance.",
    "date": "2000",
    "authors": [
        "Andreas Stolcke"
    ],
    "related_topics": [
        "Maximum entropy probability distribution",
        "Entropy (energy dispersal)",
        "Entropy (information theory)"
    ],
    "citation_count": "425",
    "reference_count": "9",
    "references": [
        "2099111195",
        "2611071497",
        "2134237567",
        "2162995740",
        "1903115690",
        "2157140289",
        "1757803263",
        "32217939",
        "2082092506"
    ]
},{
    "id": "2097978681",
    "title": "THE SRI MARCH 2000 HUB-5 CONVERSATIONAL SPEECH TRANSCRIPTION SYSTEM",
    "abstract": "We describe SRI\u2019s large vocabulary conversational speech r ecognition system as used in the March 2000 NIST Hub-5E evaluation. The system performs four recognition passes: (1) bigram recognition with phone-loop-adapted, within-word triphone acoustic models, (2) lattice generation with transcription-mod e-adapted models, (3) trigram lattice recognition with adapted cross -word triphone models, and (4) N-best rescoring and reranking with various additional knowledge sources. The system incorporates two new kinds of acoustic model: triphone models conditioned on speaking rate, and an explicit joint model of within-word phone durations. We also obtained an unusually large improvement from modeling crossword pronunciation variants in \u201cmultiword\u201d vocabulary items. The language model (LM) was enhanced with an \u201canti-LM\u201d representing acoustically confusable word sequences. Finally, we applied a generalized ROVER algorithm to combine the N-best hypotheses from several systems based on different acoustic models.",
    "date": "1999",
    "authors": [
        "A. Stolcke",
        "H. Bratt",
        "J. Butzberger",
        "H. Franco",
        "V. R. Rao Gadde",
        "C. Richey",
        "E. Shriberg",
        "F. Weng",
        "J. Zheng"
    ],
    "related_topics": [
        "Triphone",
        "Acoustic model",
        "Bigram"
    ],
    "citation_count": "187",
    "reference_count": "18",
    "references": [
        "2121227244",
        "1904457459",
        "1797288984",
        "2113641473",
        "2082474452",
        "1528470941",
        "2121464381",
        "173561343",
        "2104663520",
        "2144920829"
    ]
},{
    "id": "1528470941",
    "title": "Explicit word error minimization in N-Best list rescoring",
    "abstract": "We show that the standard hypothesis scoring paradigm used in maximum-likelihood-based speech recognition systems is not optimal with regard to minimizing the word error rate, the commonly used performance metric in speech recognition. This can lead to sub-optimal performance, especially in high-error-rate environments where word error and sentence error are not necessarily monotonically related. To address this discrepancy, we developed a new algorithm that explicitly minimizes expected word error for recognition hypotheses. First, we approximate the posterior hypothesis probabilities using N-best lists. We then compute the expected word error for each hypothesis with respect to the posterior distribution, and choose the hypothesis with the lowest error. Experiments show improved recognition rates on two spontaneous speech corpora.",
    "date": "1996",
    "authors": [
        "Andreas Stolcke",
        "Yochai Konig",
        "Mitchel Weintraub"
    ],
    "related_topics": [
        "Word error rate",
        "Word (computer architecture)",
        "Posterior probability"
    ],
    "citation_count": "223",
    "reference_count": "5",
    "references": [
        "3017143921",
        "1966812932",
        "2166637769",
        "2144920829",
        "1990387894"
    ]
},{
    "id": "2127836646",
    "title": "A cache-based natural language model for speech recognition",
    "abstract": "Speech-recognition systems must often decide between competing ways of breaking up the acoustic input into strings of words. Since the possible strings may be acoustically similar, a language model is required; given a word string, the model returns its linguistic probability. Several Markov language models are discussed. A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented. The model also contains a 3g-gram component of the traditional type. The combined model and a pure 3g-gram model were tested on samples drawn from the Lancaster-Oslo/Bergen (LOB) corpus of English text. The relative performance of the two models is examined, and suggestions for the future improvements are made. >",
    "date": "1990",
    "authors": [
        "R. Kuhn",
        "R. De Mori"
    ],
    "related_topics": [
        "Cache language model",
        "Language model",
        "Cache"
    ],
    "citation_count": "756",
    "reference_count": "10",
    "references": [
        "2105594594",
        "1966812932",
        "2751601659",
        "1597533204",
        "2159782014",
        "1521239006",
        "2055528812",
        "1507680813",
        "2076639289",
        "340893908"
    ]
},{
    "id": "2099111195",
    "title": "Elements of information theory",
    "abstract": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index.",
    "date": "1990",
    "authors": [
        "Thomas M. Cover",
        "Joy A. Thomas"
    ],
    "related_topics": [
        "Shannon's source coding theorem",
        "Entropy rate",
        "Joint entropy"
    ],
    "citation_count": "62,092",
    "reference_count": "0",
    "references": []
},{
    "id": "2160842254",
    "title": "Inducing features of random fields",
    "abstract": "We present a technique for constructing random fields from a set of training samples. The learning paradigm builds increasingly complex fields by allowing potential functions, or features, that are supported by increasingly large subgraphs. Each feature has a weight that is trained by minimizing the Kullback-Leibler divergence between the model and the empirical distribution of the training data. A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights. The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated. Relations to other learning approaches, including decision trees, are given. As a demonstration of the method, we describe its application to the problem of automatic word classification in natural language processing.",
    "date": "1997",
    "authors": [
        "S. Della Pietra",
        "V. Della Pietra",
        "J. Lafferty"
    ],
    "related_topics": [
        "Random field",
        "Generalized iterative scaling",
        "Greedy algorithm"
    ],
    "citation_count": "1,624",
    "reference_count": "20",
    "references": [
        "1594031697",
        "1997063559",
        "2049633694",
        "2096175520",
        "2121227244",
        "2097333193",
        "107938046",
        "2167837909",
        "2089969354",
        "2035301451"
    ]
},{
    "id": "2097333193",
    "title": "A statistical approach to machine translation",
    "abstract": "In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results.",
    "date": "1990",
    "authors": [
        "Peter F. Brown",
        "John Cocke",
        "Stephen A. Della Pietra",
        "Vincent J. Della Pietra",
        "Fredrick Jelinek",
        "John D. Lafferty",
        "Robert L. Mercer",
        "Paul S. Roossin"
    ],
    "related_topics": [
        "Example-based machine translation",
        "Machine translation software usability",
        "Rule-based machine translation"
    ],
    "citation_count": "2,545",
    "reference_count": "8",
    "references": [
        "2049633694",
        "1966812932",
        "2334801970",
        "1597533204",
        "1575431606",
        "2029825515",
        "2008506796",
        "2021021293"
    ]
},{
    "id": "1597533204",
    "title": "Interpolated estimation of Markov source parameters from sparse data",
    "abstract": "",
    "date": "1979",
    "authors": [
        "F. Jelinek"
    ],
    "related_topics": [
        "Markov model",
        "Variable-order Markov model",
        "Markov chain"
    ],
    "citation_count": "1,327",
    "reference_count": "0",
    "references": []
},{
    "id": "2099345940",
    "title": "A tree-based statistical language model for natural language speech recognition",
    "abstract": "The problem of predicting the next word a speaker will say, given the words already spoken; is discussed. Specifically, the problem is to estimate the probability that a given word will be the next word uttered. Algorithms are presented for automatically constructing a binary decision tree designed to estimate these probabilities. At each node of the tree there is a yes/no question relating to the words already spoken, and at each leaf there is a probability distribution over the allowable vocabulary. Ideally, these nodal questions can take the form of arbitrarily complex Boolean expressions, but computationally cheaper alternatives are also discussed. Some results obtained on a 5000-word vocabulary with a tree designed to predict the next word spoken from the preceding 20 words are included. The tree is compared to an equivalent trigram model and shown to be superior. >",
    "date": "1989",
    "authors": [
        "L.R. Bahl",
        "P.F. Brown",
        "P.V. de Souza",
        "R.L. Mercer"
    ],
    "related_topics": [
        "Incremental decision tree",
        "Language model",
        "Vocabulary"
    ],
    "citation_count": "479",
    "reference_count": "9",
    "references": [
        "2581275558",
        "1966812932",
        "1990005915",
        "1990822176",
        "1521239006",
        "193579291",
        "2120234416",
        "1995564620",
        "2079145130"
    ]
},{
    "id": "2167434254",
    "title": "Towards History-based Grammars: Using Richer Models for Probabilistic Parsing",
    "abstract": "We describe a generative probabilistic model of natural language, which we call HBG, that takes advantage of detailed linguistic information to resolve ambiguity. HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way. We use a corpus of bracketed sentences, called a Treebank, in combination with decision tree building to tease out the relevant aspects of a parse tree that will determine the correct parse of a sentence. This stands in contrast to the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating the correct parse. In head-to-head tests against one of the best existing robust probabilistic parsing models, which we call P-CFG, the HBG model significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error.",
    "date": "1993",
    "authors": [
        "Ezra Black",
        "Fred Jelinek",
        "John Lafrerty",
        "David M. Magerman",
        "Robert Mercer",
        "Salim Roukos"
    ],
    "related_topics": [
        "Parse tree",
        "Top-down parsing",
        "Parsing"
    ],
    "citation_count": "226",
    "reference_count": "12",
    "references": [
        "2121227244",
        "2099247782",
        "1859173823",
        "2012837062",
        "1535681052",
        "2021758792",
        "2029825515",
        "2127009519",
        "1973021928",
        "2008506796"
    ]
},{
    "id": "1976241232",
    "title": "Tagging text with a probabilistic model",
    "abstract": "Experiments on the use of a probabilistic model to tag English text, that is, to assign to each word the correct tag (part of speech) in the context of the sentence, are presented. A simple triclass Markov model is used, and the best way to estimate the parameters of this model, depending on the kind and amount of training data that is provided, is found. Two approaches are compared: the use of text that has been tagged by hand and comparing relative frequency counts; and use text without tags and training the model as a hidden Markov process, according to a maximum likelihood principle. Experiments show that the best training is obtained by using as much tagged text as is available, a maximum likelihood training may improve the accuracy of the tagging. >",
    "date": "1991",
    "authors": [
        "B. Merialdo"
    ],
    "related_topics": [
        "Markov model",
        "Hidden Markov model",
        "Markov process"
    ],
    "citation_count": "118",
    "reference_count": "6",
    "references": [
        "1571096757",
        "2055528812",
        "2093099215",
        "2152428909",
        "62444100",
        "2109621219"
    ]
},{
    "id": "2016589492",
    "title": "A learning algorithm for continually running fully recurrent neural networks",
    "abstract": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length.",
    "date": "1989",
    "authors": [
        "Ronald J. Williams",
        "David Zipser"
    ],
    "related_topics": [
        "Deep learning",
        "Recurrent neural network",
        "Backpropagation through time"
    ],
    "citation_count": "5,375",
    "reference_count": "14",
    "references": [
        "2154642048",
        "2293063825",
        "2110485445",
        "2143503258",
        "1881179843",
        "1959983357",
        "1984205520",
        "1984375561",
        "2119796132",
        "1527772862"
    ]
},{
    "id": "3036751298",
    "title": "Parallel Networks that Learn to Pronounce English Text",
    "abstract": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations.",
    "date": "1988",
    "authors": [
        "T. J. Sejnowski"
    ],
    "related_topics": [
        "NETtalk",
        "Speech synthesis",
        "Network model"
    ],
    "citation_count": "2,671",
    "reference_count": "0",
    "references": []
},{
    "id": "2118373646",
    "title": "Connectionism and cognitive architecture: a critical analysis",
    "abstract": "Abstract This paper explores differences between Connectionist proposals for cognitive architecture and the sorts of models that have traditionally been assumed in cognitive science. We claim that the major distinction is that, while both Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a \u2018language of thought\u2019: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the \u2018systematicity\u2019 of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or \u2018abstract neurological\u2019) structures in which Classical cognitive architecture is implemented. We survey a number of the standard arguments that have been offered in favor of Connectionism, and conclude that they are coherent only on this interpretation.",
    "date": "1988",
    "authors": [
        "Jerry A. Fodor",
        "Zenon W. Pylyshyn"
    ],
    "related_topics": [
        "Cognitive architecture",
        "Language of thought hypothesis",
        "Cognitive model"
    ],
    "citation_count": "5,402",
    "reference_count": "50",
    "references": [
        "1652505363",
        "2158365276",
        "2083137466",
        "2112325651",
        "2122988375",
        "2170716495",
        "2094249282",
        "2912225506",
        "2144862731",
        "1529681538"
    ]
},{
    "id": "2046432185",
    "title": "Learning the hidden structure of speech",
    "abstract": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition.",
    "date": "1988",
    "authors": [
        "Jeffery Locke Elman",
        "David Zipser"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Phonetics",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "428",
    "reference_count": "0",
    "references": []
},{
    "id": "2122988375",
    "title": "On the proper treatment of connectionism",
    "abstract": "A set of hypotheses is formulated for a connectionist approach to cognitive modeling. These hypotheses are shown to be incompatible with the hypotheses underlying traditional cognitive models. The connectionist models considered are massively parallel numerical computational systems that are a kind of continuous dynamical system. The numerical variables in the system correspond semantically to fine-grained features below the level of the concepts consciously used to describe the task domain. The level of analysis is intermediate between those of symbolic cognitive models and neural models. The explanations of behavior provided are like those traditional in the physical sciences, unlike the explanations provided by symbolic models.",
    "date": "1993",
    "authors": [
        "Paul Smolensky"
    ],
    "related_topics": [
        "Cognitive model",
        "Connectionism",
        "Dynamicism"
    ],
    "citation_count": "3,082",
    "reference_count": "150",
    "references": [
        "2154642048",
        "1652505363",
        "1997063559",
        "2293063825",
        "1708874574",
        "1991848143",
        "2177721432",
        "22297218",
        "2002089154",
        "2266946488"
    ]
},{
    "id": "2170716495",
    "title": "Aspects of the Theory of Syntax",
    "abstract": "Abstract : Contents: Methodological preliminaries: Generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammars; formal and substantive grammars; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning; generative capacity and its linguistic relevance Categories and relations in syntactic theory: Scope of the base; aspects of deep structure; illustrative fragment of the base component; types of base rules Deep structures and grammatical transformations Residual problems: Boundaries of syntax and semantics; structure of the lexicon",
    "date": "1965",
    "authors": [
        "Noam Chomsky"
    ],
    "related_topics": [
        "Generative grammar",
        "c-command",
        "Phrase structure grammar"
    ],
    "citation_count": "42,244",
    "reference_count": "0",
    "references": []
},{
    "id": "2094249282",
    "title": "Language learnability and language development",
    "abstract": "Language learnability and language devlopment revisited the acquisition theory - assumptions and postulates phrase structure rules phrase stucture rules - developmental considerations inflection complementation and control auxiliaries lexical entries and lexical rules.",
    "date": "1983",
    "authors": [
        "Steven Pinker"
    ],
    "related_topics": [
        "Learnability",
        "Phrase structure rules",
        "Object language"
    ],
    "citation_count": "2,930",
    "reference_count": "0",
    "references": []
},{
    "id": "1480928214",
    "title": "Lapack Users' Guide",
    "abstract": "Preface to the third edition Preface to the secondedition Part 1. Guide. 1. Essentials 2. Contents of LAPACK 3. Performance of LAPACK 4. Accuracy and Stability 5. Documentation and Software Conventions 6. Installing LAPACK Routines 7. Troubleshooting Appendix A. Index of Driver and Computational Routines Appendix B. Index of Auxiliary Routines Appendix C. Quick Reference Guide to the BLAS Appendix D. Converting from LINPACK or EISPACK Appendix E. LAPACK Working Notes Part 2. Specifications of Routines. Bibliography Index by Keyword Index by Routine Name.",
    "date": "1995",
    "authors": [
        "Ed Anderson"
    ],
    "related_topics": [
        "ScaLAPACK",
        "EISPACK",
        "Index (publishing)"
    ],
    "citation_count": "9,593",
    "reference_count": "0",
    "references": []
},{
    "id": "1521571223",
    "title": "The High Performance Fortran Handbook",
    "abstract": "From the Publisher: High Performance Fortran (HPF) is a set of extensions to Fortran expressing parallel execution at a relatively high level. For the thousands of scientists, engineers, and others who wish to take advantage of the power of both vector and parallel supercomputers, five of the principal authors of HPF have teamed up here to write a tutorial for the language. There is an increasing need for a common parallel Fortran that can serve as a programming interface with the new parallel machines that are appearing on the market. While HPF does not solve all the problems of parallel programming, it does provide a portable, high-level expression for data- parallel algorithms that brings the convenience of sequential Fortran a step closer to today's complex parallel machines.",
    "date": "1993",
    "authors": [
        "Charles H. Koelbel",
        "David B. Loveman",
        "Robert S. Schreiber",
        "Guy L. Steele",
        "Mary E. Zosel"
    ],
    "related_topics": [
        "High Performance Fortran",
        "Parallel programming model",
        "Fortran"
    ],
    "citation_count": "1,068",
    "reference_count": "0",
    "references": []
},{
    "id": "1964564149",
    "title": "Monitors, messages, and clusters: the p4 parallel programming system",
    "abstract": "p4 is a portable library of C and Fortran subroutines for programming parallel computers. It is the current version of a system that has been in use since 1984. It includes features for explicit parallel programming of shared-memory machines, distributed-memory machines (including heterogeneous networks of workstations), and clusters, by which we mean shared-memory multiprocessors communicating via message passing. We discuss here the design goals, history, and system architecture of p4 and describe briefly a diverse collection of applications that have demonstrated the utility of p4.",
    "date": "1994",
    "authors": [
        "Ralph M. Butler",
        "Ewing L. Lusk"
    ],
    "related_topics": [
        "Procedural programming",
        "Subroutine",
        "Message passing"
    ],
    "citation_count": "381",
    "reference_count": "17",
    "references": [
        "1966285605",
        "2127218465",
        "1537293292",
        "351767304",
        "2018802931",
        "2026896213",
        "2106879254",
        "2110256578",
        "1600264885",
        "2137902979"
    ]
},{
    "id": "1978513924",
    "title": "Disk-directed I/O for MIMD multiprocessors",
    "abstract": "Many scientific applications that run on today's multiprocessors, such as weather forecasting and seismic analysis, are bottlenecked by their file-I/O needs. Even if the multiprocessor is configured with sufficient I/O hardware, the file system software often fails to provide the available bandwidth to the application. Although libraries and enhanced file system interfaces can make a significant improvement, we believe that fundamental changes are needed in the file server software. We propose a new technique, disk-directed I/O, to allow the disk servers to determine the flow of data for maximum performance. Our simulations show that tremendous performance gains are possible both for simple reads and writes and for an out-of-core application. Indeed, our disk-directed I/O technique provided consistent high performance that was largely independent of data distribution and obtained up to 93% of peak disk bandwidth. It was as much as 18 times faster than either a typical parallel file system or a two-phase-I/O library.",
    "date": "1997",
    "authors": [
        "David Kotz"
    ],
    "related_topics": [
        "Parallel I/O",
        "Device file",
        "File system"
    ],
    "citation_count": "710",
    "reference_count": "73",
    "references": [
        "2147504831",
        "1496940124",
        "2168395296",
        "1967141605",
        "2150864656",
        "2098815550",
        "2114167330",
        "1978513924",
        "2157219191",
        "2041330544"
    ]
},{
    "id": "2083200599",
    "title": "Improved parallel I/O via a two-phase run-time access strategy",
    "abstract": "As scientists expand their models to describe physical phenomena of increasingly large extent, I/O becomes crucial and a system with limited I/O capacity can severely constrain the performance of the entire program.We provide experimental results, performed on an lntel Touchtone Delta and nCUBE 2 I/O system, to show that the performance of existing parallel I/O systems can vary by several orders of magnitude as a function of the data access pattern of the parallel program. We then propose a two-phase access strategy, to be implemented in a runtime system, in which the data distribution on computational nodes is decoupled from storage distribution. Our experimental results show that performance improvements of several orders of magnitude over direct access based data distribution methods can be obtained, and that performance for most data access patterns can be improved to within a factor of 2 of the best performance. Further, the cost of redistribution is a very small fraction of the overall access cost.",
    "date": "1993",
    "authors": [
        "Juan Miguel del Rosario",
        "Rajesh Bordawekar",
        "Alok Choudhary"
    ],
    "related_topics": [
        "Parallel I/O",
        "Data access",
        "Runtime system"
    ],
    "citation_count": "380",
    "reference_count": "5",
    "references": [
        "1998657709",
        "2037535386",
        "2108000325",
        "3161155143",
        "607187418"
    ]
},{
    "id": "2090683636",
    "title": "Server-Directed Collective I/O in Panda",
    "abstract": "We present the architecture and implementation results for Panda 2.0, a library for input and output of multidimensional arrays on parallel and sequential platforms. Panda achieves remarkable performance levels on the IBM SP2, showing excellent scalability as data size increases and as the number of nodes increases, and provides throughputs close to the full capacity of the AIX file system on the SP2 we used. We argue that this good performance can be traced to Panda's use of server-directed i/o (a logical-level version of disk-directed i/o [Kotz94b]) to perform array i/o using sequential disk reads and writes, a very high level interface for collective i/o requests, and built-in facilities for arbitrary rearrangements of arrays during i/o. Other advantages of Panda's approach are ease of use, easy application portability, and a reliance on commodity system software.",
    "date": "1995",
    "authors": [
        "K. E. Seamons",
        "Y. Chen",
        "P. Jones",
        "J. Jozwiak",
        "M. Winslett"
    ],
    "related_topics": [
        "File system",
        "Interface (computing)",
        "Scalability"
    ],
    "citation_count": "325",
    "reference_count": "16",
    "references": [
        "1978513924",
        "3141437129",
        "2144413105",
        "2156359540",
        "2001948415",
        "2131610641",
        "2080413856",
        "2115394931",
        "1567735309",
        "2117645881"
    ]
},{
    "id": "2010542899",
    "title": "Integrated Pvm Framework Supports Heterogeneous Network Computing",
    "abstract": "",
    "date": "1993",
    "authors": [
        "Jack Dongarra",
        "G. A. Geist",
        "Robert Manchek",
        "V. S. Sunderam"
    ],
    "related_topics": [
        "Grid computing",
        "Network architecture",
        "Intelligent computer network"
    ],
    "citation_count": "273",
    "reference_count": "0",
    "references": []
},{
    "id": "2294265735",
    "title": "Visualization and debugging in a heterogeneous environment",
    "abstract": "The authors' experiences with visualization and debugging of parallel virtual machine (PVM) applications and two of the tools they have devised to facilitate these tasks are described. One of the tools is a graphical monitoring package called Xab that can visually display PVM activities inside an application running across a network. The other is a graphical programming environment called Hence, which helps the user write, compile, execute, and trace heterogeneous distributed programs. The authors discuss their early work, the present research, and the future directions of these experimental projects. >",
    "date": "1995",
    "authors": [
        "Adam Beguelin",
        "Jack Dongarra",
        "Al Geist",
        "Vaidy Sunderam"
    ],
    "related_topics": [
        "Debugging",
        "TRACE (psycholinguistics)",
        "Visualization"
    ],
    "citation_count": "210",
    "reference_count": "0",
    "references": []
},{
    "id": "1843937266",
    "title": "A Proposal for a User-Level, Message-Passing Interface in a Distributed Memory Environment",
    "abstract": "This paper describes Message Passing Interface 1 (MPI1), a proposed library interface standard for supporting point-to-point message passing. The intended standard will be provided with Fortran 77 and C interfaces, and will form the basis of a standard high level communication environment featuring collective communication and data distribution transformations. The standard proposed here provides blocking and nonblocking message passing between pairs of processes, with message selectivity by source process and message type. Provision is made for noncontiguous messages. Context control provides a convenient means of avoiding message selectivity conflicts between different phases of an application. The ability to form and manipulate process groups permit task parallelism to be exploited, and is a useful abstraction in controlling certain types of collective communication.",
    "date": "1992",
    "authors": [
        "Jack J. Dongarra",
        "Rolf Hempel",
        "Anthony J.G. Hey",
        "David W. Walker"
    ],
    "related_topics": [
        "Message broker",
        "Message passing",
        "Message Passing Interface"
    ],
    "citation_count": "135",
    "reference_count": "14",
    "references": [
        "2108167744",
        "2161307885",
        "2006774019",
        "2111820660",
        "2099159950",
        "2116524044",
        "1538115971",
        "90802191",
        "1532915129",
        "2142471664"
    ]
},{
    "id": "2010269868",
    "title": "The design and evolution of Zipcode",
    "abstract": "Abstract Zipcode is a message-passing and process-management system that was designed for multicomputers and homogeneous networks of computers in order to support libraries and large-scale multicomputer software. The system has evolved significantly over the last five years, based on our experiences and identified needs. Features of Zipcode that were originally unique to it, were its simulataneous support of static process groups, communication contexts, and virtual topologies, forming the \u2018mailer\u2019 data structure. Point-to-point and collective operations reference the underlying group, and use contexts to avoid mixing up messages. Recently, we have added \u2018gather-send\u2019 and \u2018receive-scatter\u2019 semantics, based on persistent Zipcode \u2018invoices\u2019, both as a means to simplify message passing, and as a means to reveal more potential runtime optimizations. Key features in Zipcode appear in the forthcoming MPI standard.",
    "date": "1994",
    "authors": [
        "Anthony Skjellum",
        "Steven G. Smith",
        "Nathan E. Doss",
        "Alvin P. Leung",
        "Manfred Morari"
    ],
    "related_topics": [
        "Message passing",
        "Context (language use)",
        "Software portability"
    ],
    "citation_count": "75",
    "reference_count": "21",
    "references": [
        "2155066383",
        "2051975225",
        "2111820660",
        "2001946794",
        "2099159950",
        "2026896213",
        "1971077560",
        "90802191",
        "2086507055",
        "2106918918"
    ]
},{
    "id": "2170120409",
    "title": "Numerical recipes in C",
    "abstract": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08",
    "date": "1993",
    "authors": [
        "William H. Press",
        "Saul A. Teukolsky",
        "William T. Vetterling",
        "Brian P. Flannery"
    ],
    "related_topics": [
        "IBM PC compatible",
        "Computer graphics (images)",
        "Computer science"
    ],
    "citation_count": "16,006",
    "reference_count": "0",
    "references": []
},{
    "id": "1966812932",
    "title": "A Maximum Likelihood Approach to Continuous Speech Recognition",
    "abstract": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them.",
    "date": "1983",
    "authors": [
        "Lalit R. Bahl",
        "Frederick Jelinek",
        "Robert L. Mercer"
    ],
    "related_topics": [
        "Speech processing",
        "Sequential decoding",
        "Decoding methods"
    ],
    "citation_count": "1,959",
    "reference_count": "17",
    "references": [
        "2142384583",
        "1597533204",
        "1575431606",
        "2341171179",
        "2163929346",
        "2157477135",
        "2029491572",
        "2035227369",
        "2137095888",
        "1989226853"
    ]
},{
    "id": "2611071497",
    "title": "Text Compression",
    "abstract": "",
    "date": "1990",
    "authors": [
        "Timothy C. Bell",
        "John G. Cleary",
        "Ian H. Witten"
    ],
    "related_topics": [
        "Prediction by partial matching",
        "Computer science",
        "Compressed pattern matching"
    ],
    "citation_count": "2,223",
    "reference_count": "0",
    "references": []
},{
    "id": "2166637769",
    "title": "SWITCHBOARD: telephone speech corpus for research and development",
    "abstract": "SWITCHBOARD is a large multispeaker corpus of conversational speech and text which should be of interest to researchers in speaker authentication and large vocabulary speech recognition. About 2500 conversations by 500 speakers from around the US were collected automatically over T1 lines at Texas Instruments. Designed for training and testing of a variety of speech processing algorithms, especially in speaker verification, it has over an 1 h of speech from each of 50 speakers, and several minutes each from hundreds of others. A time-aligned word for word transcription accompanies each recording. >",
    "date": "1992",
    "authors": [
        "J.J. Godfrey",
        "E.C. Holliman",
        "J. McDaniel"
    ],
    "related_topics": [
        "Speech corpus",
        "Speech processing",
        "VoxForge"
    ],
    "citation_count": "2,440",
    "reference_count": "3",
    "references": [
        "1643320849",
        "2077302143",
        "1976349544"
    ]
},{
    "id": "2134237567",
    "title": "Estimation of probabilities from sparse data for the language model component of a speech recognizer",
    "abstract": "The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises.",
    "date": "1987",
    "authors": [
        "S. Katz"
    ],
    "related_topics": [
        "Cache language model",
        "Speech processing",
        "Language model"
    ],
    "citation_count": "2,737",
    "reference_count": "7",
    "references": [
        "1597533204",
        "2159782014",
        "1507770639",
        "2168938909",
        "2170967986",
        "2082092506",
        "1590636096"
    ]
},{
    "id": "2075201173",
    "title": "On structuring probabilistic dependences in stochastic language modelling",
    "abstract": "Abstract In this paper, we study the problem of stochastic language modelling from the viewpoint of introducing suitable structures into the conditional probability distributions. The task of these distributions is to predict the probability of a new word by looking at M or even all predecessor words. The conventional approach is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models with a unigram model in a linear fashion. However, there are many other structures that can be used to model the probabilistic dependences between the predecessor word and the word to be predicted. The structures considered in this paper are: nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations. For the optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out method is systematically used. For the determination of word equivalence classes in a bigram model, an automatic clustering procedure has been adapted. To capture long-distance dependences, we consider various models for word-by-word dependences; the cache model may be viewed as a special type of self-association. Experimental results are presented for two text databases, a Germany database and an English database.",
    "date": "1993",
    "authors": [
        "Hermann Ney",
        "Ute Essen",
        "Reinhard Kneser"
    ],
    "related_topics": [
        "Bigram",
        "Word (computer architecture)",
        "Linear interpolation"
    ],
    "citation_count": "848",
    "reference_count": "0",
    "references": []
},{
    "id": "2142901448",
    "title": "Information Theory and Reliable Communication",
    "abstract": "Communication Systems and Information Theory. A Measure of Information. Coding for Discrete Sources. Discrete Memoryless Channels and Capacity. The Noisy-Channel Coding Theorem. Techniques for Coding and Decoding. Memoryless Channels with Discrete Time. Waveform Channels. Source Coding with a Fidelity Criterion. Index.",
    "date": "1967",
    "authors": [
        "Robert G. Gallager"
    ],
    "related_topics": [
        "Variable-length code",
        "Shannon\u2013Fano coding",
        "Information theory"
    ],
    "citation_count": "8,928",
    "reference_count": "0",
    "references": []
},{
    "id": "2751862591",
    "title": "An introduction to probability theory and its applications",
    "abstract": "",
    "date": "1949",
    "authors": [
        "William Feller"
    ],
    "related_topics": [
        "Probability and statistics",
        "Imprecise probability",
        "Tree diagram"
    ],
    "citation_count": "57,767",
    "reference_count": "0",
    "references": []
},{
    "id": "1575431606",
    "title": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process",
    "abstract": "",
    "date": "1971",
    "authors": [
        "L. Baum"
    ],
    "related_topics": [
        "Markov process",
        "Markov chain",
        "Markov renewal process"
    ],
    "citation_count": "2,350",
    "reference_count": "0",
    "references": []
},{
    "id": "2007780422",
    "title": "Computational analysis of present-day American English",
    "abstract": "",
    "date": "1966",
    "authors": [
        "Henry Ku\u010dera",
        "W. Nelson Francis",
        "W. F. Twaddell",
        "Mary Lois Marckworth",
        "Laura M. Bell",
        "John Bissell Carroll"
    ],
    "related_topics": [
        "American English",
        "Psychology",
        "Brown Corpus"
    ],
    "citation_count": "11,294",
    "reference_count": "0",
    "references": []
},{
    "id": "2016871293",
    "title": "Context based spelling correction",
    "abstract": "Abstract Some mistakes in spelling and typing produce correct words, such as typing \u201cfig\u201d when \u201cfog\u201d was intended. These errors are undetectable by traditional spelling correction techniques. In this paper we present a statistical technique capable of detecting and correcting some of these errors when they occur in sentences. Experimental results show that this technique is capable of detecting 76% of simple spelling errors and correcting 73%.",
    "date": "1991",
    "authors": [
        "Eric Mays",
        "Fred J. Damerau",
        "Robert L. Mercer"
    ],
    "related_topics": [
        "Spelling",
        "Context (language use)",
        "Orthography"
    ],
    "citation_count": "401",
    "reference_count": "5",
    "references": [
        "1966812932",
        "2109469864",
        "2066792529",
        "2002938383",
        "2065533756"
    ]
},{
    "id": "1628850721",
    "title": "Experiments with the Tangora 20,000 word speech recognizer",
    "abstract": "The Speech Recognition Group at IBM Research in Yorktown Heights has developed a real-time, isolated-utterance speech recognizer for natural language based on the IBM Personal Computer AT and IBM Signal Processors. The system has recently been enhanced by expanding the vocabulary from 5,000 words to 20,000 words and by the addition of a speech workstation to support usability studies on document creation by voice. The system supports spelling and interactive personalization to augment the vocabularies. This paper describes the implementation, user interface, and comparative performance of the recognizer.",
    "date": "1986",
    "authors": [
        "A. Averbuch",
        "L. Bahl",
        "R. Bakis",
        "P. Brown",
        "G. Daggett",
        "S. Das",
        "K. Davies",
        "S. De Gennaro",
        "P. de Souza",
        "E. Epstein",
        "D. Fraleigh",
        "F. Jelinek",
        "B. Lewis",
        "R. Mercer",
        "J. Moorhead",
        "A. Nadas",
        "D. Nahamoo",
        "M. Picheny",
        "G. Shichman",
        "P. Spinelli",
        "D. Van Compernolle",
        "H. Wilkens"
    ],
    "related_topics": [
        "Speech synthesis",
        "Speech processing",
        "Speech corpus"
    ],
    "citation_count": "146",
    "reference_count": "10",
    "references": [
        "1966812932",
        "2134237567",
        "1990005915",
        "1521239006",
        "1507770639",
        "2134587001",
        "2170967986",
        "2056809970",
        "1901281023",
        "2089661020"
    ]
},{
    "id": "2107743791",
    "title": "Probabilistic latent semantic indexing",
    "abstract": "Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{specific synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.",
    "date": "1999",
    "authors": [
        "Thomas Hofmann"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent Dirichlet allocation",
        "Document-term matrix"
    ],
    "citation_count": "6,777",
    "reference_count": "15",
    "references": [
        "2147152072",
        "2049633694",
        "1956559956",
        "1612003148",
        "2567948266",
        "2127314673",
        "1718512272",
        "2143144851",
        "2140842551",
        "2063089147"
    ]
},{
    "id": "2020842694",
    "title": "Modeling annotated data",
    "abstract": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval.",
    "date": "2003",
    "authors": [
        "David M. Blei",
        "Michael I. Jordan"
    ],
    "related_topics": [
        "Latent Dirichlet allocation",
        "Image retrieval",
        "Automatic image annotation"
    ],
    "citation_count": "1,462",
    "reference_count": "17",
    "references": [
        "1880262756",
        "2121947440",
        "1516111018",
        "2137471889",
        "2093390569",
        "2109868644",
        "2137918516",
        "2172085063",
        "3016843226",
        "2108346334"
    ]
},{
    "id": "2063392856",
    "title": "Latent semantic indexing: a probabilistic analysis",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Christos H. Papadimitriou",
        "Hisao Tamaki",
        "Prabhakar Raghavan",
        "Santosh Vempala"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Latent Dirichlet allocation",
        "Document-term matrix"
    ],
    "citation_count": "1,587",
    "reference_count": "20",
    "references": [
        "2138621811",
        "2798909945",
        "2147152072",
        "1956559956",
        "2072773380",
        "1979750072",
        "2013737143",
        "2983896310",
        "2058616517",
        "2106285343"
    ]
},{
    "id": "2001082470",
    "title": "Finding scientific topics",
    "abstract": "A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying \u201chot topics\u201d by examining temporal dynamics and tagging abstracts to illustrate semantic content.",
    "date": "2004",
    "authors": [
        "Thomas L. Griffiths",
        "Mark Steyvers"
    ],
    "related_topics": [
        "Topic model",
        "Latent Dirichlet allocation",
        "Dynamic topic model"
    ],
    "citation_count": "6,832",
    "reference_count": "10",
    "references": [
        "1574901103",
        "2130416410",
        "1997063559",
        "2069739265",
        "2134731454",
        "2104924585",
        "2753533763",
        "1666636243",
        "578760377",
        "2165554837"
    ]
},{
    "id": "2158266063",
    "title": "Hierarchical Dirichlet Processes",
    "abstract": "We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes ...",
    "date": "2006",
    "authors": [
        "Yee Whye Teh",
        "Michael I. Jordan",
        "Matthew J. Beal",
        "David M. Blei"
    ],
    "related_topics": [
        "Hierarchical Dirichlet process",
        "Dirichlet process",
        "Latent Dirichlet allocation"
    ],
    "citation_count": "4,522",
    "reference_count": "50",
    "references": [
        "1880262756",
        "2098126593",
        "2125838338",
        "2152664025",
        "2110755408",
        "2009570821",
        "1956559956",
        "2011832962",
        "2890040444",
        "2115979064"
    ]
},{
    "id": "2047804403",
    "title": "Modular toolkit for Data Processing (MDP): a Python data processing framework",
    "abstract": "Modular toolkit for Data Processing (MDP) is a data processing framework written in Python. From the user's perspective, MDP is a collection of supervised and unsupervised learning algorithms and other data processing units that can be combined into data processing sequences and more complex feed-forward network architectures. Computations are performed efficiently in terms of speed and memory requirements. From the scientific developer's perspective, MDP is a modular framework, which can easily be expanded. The implementation of new algorithms is easy and intuitive. The new implemented units are then automatically integrated with the rest of the library. MDP has been written in the context of theoretical research in neuroscience, but it has been designed to be helpful in any context where trainable data processing algorithms are used. Its simplicity on the user's side, the variety of readily available algorithms, and the reusability of the implemented units make it also a useful educational tool.",
    "date": "2007",
    "authors": [
        "Tiziano Zito",
        "Niko Wilbert",
        "Laurenz Wiskott",
        "Pietro Berkes"
    ],
    "related_topics": [
        "Python (programming language)",
        "Modular design",
        "Data processing"
    ],
    "citation_count": "143",
    "reference_count": "11",
    "references": [
        "1663973292",
        "2136922672",
        "1554663460",
        "2156838815",
        "2167217202",
        "2138754805",
        "2148856562",
        "1511812886",
        "2102724320",
        "2156141384"
    ]
},{
    "id": "2143017621",
    "title": "NLTK: The Natural Language Toolkit",
    "abstract": "The Natural Language Toolkit is a suite of program modules, data sets and tutorials supporting research and teaching in computational linguistics and natural language processing. NLTK is written in Python and distributed under the GPL open source license. Over the past year the toolkit has been rewritten, simplifying many linguistic data structures and taking advantage of recent enhancements in the Python language. This paper reports on the simplified toolkit and explains how it is used in teaching NLP.",
    "date": "2006",
    "authors": [
        "Steven Bird"
    ],
    "related_topics": [
        "Natural language programming",
        "Language technology",
        "Natural language user interface"
    ],
    "citation_count": "2,567",
    "reference_count": "15",
    "references": [
        "2038248725",
        "1549285799",
        "2953320089",
        "2161160885",
        "1548991402",
        "1625780798",
        "2045784978",
        "2042978285",
        "2136248378",
        "118140219"
    ]
},{
    "id": "2159426623",
    "title": "Reading Tea Leaves: How Humans Interpret Topic Models",
    "abstract": "Probabilistic topic models are a popular tool for the unsupervised analysis of text, providing both a predictive model of future text and a latent topic representation of the corpus. Practitioners typically assume that the latent space is semantically meaningful. It is used to check models, summarize the corpus, and guide exploration of its contents. However, whether the latent space is interpretable is in need of quantitative evaluation. In this paper, we present new quantitative methods for measuring semantic meaning in inferred topics. We back these measures with large-scale user studies, showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood. Surprisingly, topic models which perform better on held-out likelihood may infer less semantically meaningful topics.",
    "date": "2009",
    "authors": [
        "Jonathan Chang",
        "Sean Gerrish",
        "Chong Wang",
        "Jordan L. Boyd-graber",
        "David M. Blei"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Topic model",
        "Probabilistic logic"
    ],
    "citation_count": "2,155",
    "reference_count": "23",
    "references": [
        "2108598243",
        "1880262756",
        "2147152072",
        "2049633694",
        "1970381522",
        "1983578042",
        "2143017621",
        "1612003148",
        "2100935296",
        "2334889010"
    ]
},{
    "id": "2334889010",
    "title": "Probabilistic Topic Models",
    "abstract": "",
    "date": "2007",
    "authors": [
        "Mark Steyvers",
        "Tom Griffiths"
    ],
    "related_topics": [
        "Probabilistic logic",
        "Topic model",
        "Semantics (computer science)"
    ],
    "citation_count": "3,174",
    "reference_count": "23",
    "references": [
        "1880262756",
        "2098126593",
        "2001082470",
        "2158266063",
        "2130416410",
        "3143596294",
        "1983578042",
        "2158997610",
        "2134731454",
        "1612003148"
    ]
},{
    "id": "1983578042",
    "title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
    "abstract": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched.",
    "date": "1997",
    "authors": [
        "Thomas K. Landauer",
        "Susan T. Dumais"
    ],
    "related_topics": [
        "Probabilistic latent semantic analysis",
        "Similarity (psychology)",
        "Latent semantic analysis"
    ],
    "citation_count": "7,790",
    "reference_count": "106",
    "references": [
        "2147152072",
        "2293063825",
        "1898014694",
        "1593045043",
        "2001467963",
        "1540136915",
        "2059975159",
        "2152632951",
        "1594369375",
        "2163953154"
    ]
},{
    "id": "1674947250",
    "title": "Comprehension: A Paradigm for Cognition",
    "abstract": "Preface Acknowledgements 1. Introduction Part I. The Theory: 2. Cognition and representation 3. Propositional representations 4. Modeling comprehension processes: the construction-integration model Part II. Models of Comprehension: 5. Word identification in discourse 6. Textbases and situation models 7. The role of working memory in comprehension 8. Memory for text 9. Learning from text 10. Word problems 11. Beyond text References name index Subject index.",
    "date": "1998",
    "authors": [
        "Walter Kintsch"
    ],
    "related_topics": [
        "Comprehension",
        "Cognition",
        "Coh-Metrix"
    ],
    "citation_count": "5,003",
    "reference_count": "0",
    "references": []
},{
    "id": "2072773380",
    "title": "Using linear algebra for intelligent information retrieval",
    "abstract": "Currently, most approaches to retrieving textual materials from scientific databases depend on a lexical match between words in users\u2019 requests and those in or assigned to documents in a database. ...",
    "date": "1995",
    "authors": [
        "Michael W. Berry",
        "Susan T. Dumais",
        "Gavin W. O'Brien"
    ],
    "related_topics": [
        "Document retrieval",
        "Latent semantic analysis",
        "Automatic indexing"
    ],
    "citation_count": "2,401",
    "reference_count": "12",
    "references": [
        "2147152072",
        "2000672666",
        "2106365165",
        "2149671658",
        "2032840958",
        "2093432797",
        "2074965064",
        "2099708568",
        "30999966",
        "1990215053"
    ]
},{
    "id": "2056029990",
    "title": "Personalized information delivery: an analysis of information filtering methods",
    "abstract": "",
    "date": "1992",
    "authors": [
        "Peter W. Foltz",
        "Susan T. Dumais"
    ],
    "related_topics": [
        "Information filtering system",
        "Information system",
        "Information source"
    ],
    "citation_count": "953",
    "reference_count": "19",
    "references": [
        "2147152072",
        "1956559956",
        "2000672666",
        "2106365165",
        "2078875869",
        "2058616517",
        "2083605078",
        "2165978089",
        "2032840958",
        "2025172185"
    ]
},{
    "id": "1981617416",
    "title": "Producing high-dimensional semantic spaces from lexical co-occurrence",
    "abstract": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word is presented. This procedure is applied to a large corpus of natural language text taken from Usenet, and the resulting vectors are examined to determine what information is contained within them. These vectors provide the coordinates in a high-dimensional space in which word relationships can be analyzed. Analyses of both vector similarity and multidimensional scaling demonstrate that there is significant semantic information carried in the vectors. A comparison of vector similarity with human reaction times in a single-word priming experiment is presented. These vectors provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL).",
    "date": "1996",
    "authors": [
        "Kevin Lund",
        "Curt Burgess"
    ],
    "related_topics": [
        "Explicit semantic analysis",
        "Semantic similarity",
        "SemEval"
    ],
    "citation_count": "2,077",
    "reference_count": "13",
    "references": [
        "2116411927",
        "2069736034",
        "1986010321",
        "2086220442",
        "2074439471",
        "2074657344",
        "1550028225",
        "1568757443",
        "1974351977",
        "3149550307"
    ]
},{
    "id": "2059086756",
    "title": "Strategies of discourse comprehension",
    "abstract": "rhetorical schemata to be discussed in what follows. Finally, schemata are descriptions, not definitions. The \u2018bus\u2019 schema contains information that is nor-",
    "date": "1982",
    "authors": [
        "Teun Adrianus van Dijk",
        "Walter Kintsch"
    ],
    "related_topics": [
        "Schema (psychology)",
        "Rhetorical question",
        "Comprehension"
    ],
    "citation_count": "11,592",
    "reference_count": "110",
    "references": [
        "2264742718",
        "1581218697",
        "2121773050",
        "2073257493",
        "2153076044",
        "2091785129",
        "2157368609",
        "2021625970",
        "2134199742",
        "1582594879"
    ]
},{
    "id": "2092919341",
    "title": "The Adaptive Character of Thought",
    "abstract": "Contents: Part I:Introduction. Preliminaries. Levels of a Cognitive Theory. Current Formulation of the Levels Issues. The New Theoretical Framework. Is Human Cognition Rational? The Rest of This Book. Appendix: Non-Identifiability and Response Time. Part II:Memory. Preliminaries. A Rational Analysis of Human Memory. The History Factor. The Contextual Factor. Relationship of Need and Probability to Probability and Latency of Recall. Combining Information From Cues. Implementation in the ACT Framework. Effects of Subject Strategy. Conclusions. Part III:Categorization. Preliminaries. The Goal of Categorization. The Structure of the Environment. Recapitulation of Goals and Environment. The Optimal Solution. An Iterative Algorithm for Categorization. Application of the Algorithm. Survey of the Experimental Literature. Conclusion. Appendix: The Ideal Algorithm. Part IV:Causal Inference. Preliminaries. Basic Formulation of the Causal Inference Problem. Causal Estimation. Cues for Causal Inference. Integration of Statistical and Temporal Cues. Discrimination. Abstraction of Causal Laws. Implementation in a Production System. Conclusion. Appendix. Part V:Problem Solving. Preliminaries. Making a Choice Among Simple Actions. Combining Steps. Studies of Hill Climbing. Means-Ends Analysis. Instantiation of Indefinite Objects. Conclusions on Rational Analysis of Problem Solving. Implementation in ACT. Appendix: Problem Solving and Clotheslines. Part VI:Retrospective. Preliminaries. Twelve Questions About Rational Analysis.",
    "date": "1990",
    "authors": [
        "John R. Anderson"
    ],
    "related_topics": [
        "Causal inference",
        "Rational analysis",
        "Inference"
    ],
    "citation_count": "3,548",
    "reference_count": "0",
    "references": []
},{
    "id": "2928502135",
    "title": "The role of knowledge in discourse comprehension : a construction-integration model",
    "abstract": "Publisher Summary This chapter discusses data concerning the time course of word identification in a discourse context. A simulation of arithmetic word-problem understanding provides a plausible account for some well-known phenomena. The current theories use representations with several mutually constraining layers. There is typically a linguistic level of representation, conceptual levels to represent both the local and global meaning and structure of a text, and a level at which the text itself has lost its individuality and its information content. Knowledge provides part of the context within which a discourse interpreted. The integration phase is the price the model pays for the necessary flexibility in the construction process.",
    "date": "1990",
    "authors": [
        "Walter Kintsch"
    ],
    "related_topics": [
        "Context (language use)",
        "Meaning (linguistics)",
        "Process (engineering)"
    ],
    "citation_count": "5,730",
    "reference_count": "26",
    "references": [
        "2042276900",
        "2039107287",
        "2153076044",
        "2409145188",
        "2090639711",
        "2002654918",
        "1982914430",
        "1990948551",
        "2040187703",
        "2092771413"
    ]
},{
    "id": "1996650435",
    "title": "Are Good Texts Always Better? Interactions of Text Coherence, Background Knowledge, and Levels of Understanding in Learning From Text",
    "abstract": "Two experiments, theoretically motivated by the construction-integration model of text comprehension (W. Kintsch, 1988), investigated the role of text coherence in the comprehension of science texts. In Experiment 1, junior high school students' comprehension of one of three versions of a biology text was examined via free recall, written questions, and a key-word sorting task. This study demonstrates advantages for globally coherent text and for more explanatory text. In Experiment 2, interactions among local and global text coherence, readers' background knowledge, and levels of understanding were examined. Using the same methods as in Experiment 1, we examined students' comprehension of one of four versions of a text, orthogonally varying local and global coherence. We found that readers who know little about the domain of the text benefit from a coherent text, whereas high-knowledge readers benefit from a minimally coherent text. We argue that the poorly written text forces the knowledgeable readers t...",
    "date": "1996",
    "authors": [
        "Danielle S. McNamara",
        "Eileen Kintsch",
        "Nancy Butler Songer",
        "Walter Kintsch"
    ],
    "related_topics": [
        "Coherence (linguistics)",
        "Reading comprehension",
        "Coh-Metrix"
    ],
    "citation_count": "1,997",
    "reference_count": "33",
    "references": [
        "2059086756",
        "2928502135",
        "1752512628",
        "1813659000",
        "2134907585",
        "2024710858",
        "118516307",
        "2004017050",
        "2004805246",
        "2032811864"
    ]
},{
    "id": "2096765155",
    "title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling",
    "abstract": "Most current statistical natural language processing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. This technique results in an error reduction of up to 9% over state-of-the-art systems on two established information extraction tasks.",
    "date": "2005",
    "authors": [
        "Jenny Rose Finkel",
        "Trond Grenager",
        "Christopher Manning"
    ],
    "related_topics": [
        "Approximate inference",
        "Information extraction",
        "Gibbs sampling"
    ],
    "citation_count": "3,700",
    "reference_count": "23",
    "references": [
        "2147880316",
        "2125838338",
        "2581275558",
        "1997063559",
        "2160842254",
        "2135194391",
        "2962735828",
        "1513861746",
        "2171776966",
        "2129712609"
    ]
},{
    "id": "1996430422",
    "title": "Feature-rich part-of-speech tagging with a cyclic dependency network",
    "abstract": "We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.",
    "date": "2003",
    "authors": [
        "Kristina Toutanova",
        "Dan Klein",
        "Christopher D. Manning",
        "Yoram Singer"
    ],
    "related_topics": [
        "Treebank",
        "Dependency network",
        "Feature (machine learning)"
    ],
    "citation_count": "3,930",
    "reference_count": "19",
    "references": [
        "2147880316",
        "1632114991",
        "2008652694",
        "2135843243",
        "1773803948",
        "2117400858",
        "2099247782",
        "1513861746",
        "1860991815",
        "1529196404"
    ]
},{
    "id": "2148540243",
    "title": "Unsupervised named-entity extraction from the Web: An experimental study",
    "abstract": "The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., ''chemist'' and ''biologist'' are identified as sub-classes of ''scientist''). List Extraction locates lists of class instances, learns a ''wrapper'' for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer.",
    "date": "2005",
    "authors": [
        "Oren Etzioni",
        "Michael Cafarella",
        "Doug Downey",
        "Ana-Maria Popescu",
        "Tal Shaked",
        "Stephen Soderland",
        "Daniel S. Weld",
        "Alexander Yates"
    ],
    "related_topics": [
        "Information extraction",
        "Unsupervised learning",
        "Pointwise mutual information"
    ],
    "citation_count": "1,450",
    "reference_count": "54",
    "references": [
        "3146306708",
        "2048679005",
        "2097089247",
        "2140785063",
        "2155328222",
        "2168625136",
        "1567365482",
        "2068737686",
        "2103931177",
        "202303397"
    ]
},{
    "id": "2144578941",
    "title": "Introduction to the CoNLL-2003 shared task: language-independent named entity recognition",
    "abstract": "We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance.",
    "date": "2003",
    "authors": [
        "Erik F. Tjong Kim Sang",
        "Fien De Meulder"
    ],
    "related_topics": [
        "Entity linking",
        "Named-entity recognition",
        "Task (project management)"
    ],
    "citation_count": "3,104",
    "reference_count": "23",
    "references": [
        "2141099517",
        "1623072288",
        "2056451646",
        "1505083828",
        "1522263329",
        "2075635421",
        "2915429162",
        "2041614298",
        "2004384146",
        "1553244859"
    ]
},{
    "id": "2128634885",
    "title": "Simple Semi-supervised Dependency Parsing",
    "abstract": "We present a simple and effective semisupervised method for training dependency parsers. We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus. We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions. For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuracy of 92.02% to 93.16%, and in the case of Czech unlabeled second-order parsing, we improve from a baseline accuracy of 86.13% to 87.13%. In addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance.",
    "date": "2008",
    "authors": [
        "Terry Koo",
        "Xavier Carreras",
        "Michael Collins"
    ],
    "related_topics": [
        "Treebank",
        "Parsing",
        "Dependency grammar"
    ],
    "citation_count": "560",
    "reference_count": "30",
    "references": [
        "2147880316",
        "1632114991",
        "2008652694",
        "1773803948",
        "2121227244",
        "2139621418",
        "2116410915",
        "2027979924",
        "2122922578",
        "194033037"
    ]
},{
    "id": "1995945562",
    "title": "An introduction to the bootstrap",
    "abstract": "This article presents bootstrap methods for estimation, using simple arguments. Minitab macros for implementing these methods are given.",
    "date": "1992",
    "authors": [
        "Bradley Efron",
        "Robert J Tibshirani"
    ],
    "related_topics": [
        "Bootstrap aggregating",
        "Macro",
        "Computer science"
    ],
    "citation_count": "48,254",
    "reference_count": "0",
    "references": []
},{
    "id": "1773803948",
    "title": "A Maximum Entropy Model for Part-Of-Speech Tagging",
    "abstract": "This paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems",
    "date": "1995",
    "authors": [
        "Adwait Ratnaparkhi"
    ],
    "related_topics": [
        "Maximum-entropy Markov model",
        "Principle of maximum entropy",
        "Statistical model"
    ],
    "citation_count": "2,387",
    "reference_count": "12",
    "references": [
        "1632114991",
        "2096175520",
        "2121227244",
        "2160842254",
        "2153439141",
        "2170381724",
        "1718065290",
        "2112861996",
        "2015042937",
        "2069912724"
    ]
},{
    "id": "2962735828",
    "title": "Discriminative probabilistic models for relational data",
    "abstract": "In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. For example, in hypertext classification, the labels of linked pages are highly correlated. A standard approach is to classify each entity independently, ignoring the correlations between them. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy. We show how to train these models effectively, and how to use approximate probabilistic inference over the learned model for collective classification of multiple related entities. We provide experimental results on a webpage classification task, showing that accuracy can be significantly improved by modeling relational dependencies.",
    "date": "2002",
    "authors": [
        "Ben Taskar",
        "Pieter Abbeel",
        "Daphne Koller"
    ],
    "related_topics": [
        "Bayesian network",
        "Discriminative model",
        "Relational database"
    ],
    "citation_count": "829",
    "reference_count": "19",
    "references": [
        "2156909104",
        "2147880316",
        "2138621811",
        "2159080219",
        "2107008379",
        "2160842254",
        "2167044614",
        "2076008912",
        "2098678088",
        "2126185296"
    ]
},{
    "id": "2117400858",
    "title": "Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging",
    "abstract": "Recently, there has been a rebirth of empiricism in the field of natural language processing. Manual encoding of linguistic information is being challenged by automated corpus-based learning as a method of providing a natural language processing system with linguistic knowledge. Although corpus-based approaches have been successful in many different areas of natural language processing, it is often the case that these methods capture the linguistic information they are modelling indirectly in large opaque tables of statistics. This can make it difficult to analyze, understand and improve the ability of these approaches to model underlying linguistic behavior. In this paper, we will describe a simple rule-based approach to automated learning of linguistic knowledge. This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging.",
    "date": "1995",
    "authors": [
        "Eric Brill"
    ],
    "related_topics": [
        "Deep linguistic processing",
        "Language identification",
        "Brill tagger"
    ],
    "citation_count": "2,318",
    "reference_count": "40",
    "references": [
        "1594031697",
        "2149706766",
        "1632114991",
        "2102381086",
        "2099247782",
        "2097333193",
        "2081687495",
        "1489181569",
        "2046224275",
        "2170381724"
    ]
},{
    "id": "2140235142",
    "title": "Pfinder: real-time tracking of the human body",
    "abstract": "Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding.",
    "date": "1997",
    "authors": [
        "C.R. Wren",
        "A. Azarbayejani",
        "T. Darrell",
        "A.P. Pentland"
    ],
    "related_topics": [
        "Gesture recognition",
        "Foreground detection",
        "Background subtraction"
    ],
    "citation_count": "7,660",
    "reference_count": "14",
    "references": [
        "2157548127",
        "2069356045",
        "2144573889",
        "1635989058",
        "2119444142",
        "2131938593",
        "2042850474",
        "2178278515",
        "2140487300",
        "2034836133"
    ]
},{
    "id": "2099244020",
    "title": "Bilateral filtering for gray and color images",
    "abstract": "Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.",
    "date": "1998",
    "authors": [
        "C. Tomasi",
        "R. Manduchi"
    ],
    "related_topics": [
        "Color histogram",
        "Color balance",
        "Color quantization"
    ],
    "citation_count": "10,272",
    "reference_count": "15",
    "references": [
        "2150134853",
        "1667165204",
        "2101248405",
        "2104763670",
        "2064347832",
        "2067681708",
        "2008014451",
        "1526351017",
        "2051826135",
        "1602550945"
    ]
},{
    "id": "2132549764",
    "title": "Statistical pattern recognition: a review",
    "abstract": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.",
    "date": "1999",
    "authors": [
        "A.K. Jain",
        "R.P.W. Duin",
        "Jianchang Mao"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Intelligent character recognition",
        "Feature extraction"
    ],
    "citation_count": "8,673",
    "reference_count": "178",
    "references": [
        "2156909104",
        "2148603752",
        "2124776405",
        "1554663460",
        "2139212933",
        "2912934387",
        "2117812871",
        "1548802052",
        "2125838338",
        "1679913846"
    ]
},{
    "id": "2159128898",
    "title": "Real-time tracking of non-rigid objects using mean shift",
    "abstract": "A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences.",
    "date": "2000",
    "authors": [
        "D. Comaniciu",
        "V. Ramesh",
        "P. Meer"
    ],
    "related_topics": [
        "Bhattacharyya distance",
        "Mean-shift",
        "Condensation algorithm"
    ],
    "citation_count": "4,826",
    "reference_count": "24",
    "references": [
        "2140235142",
        "2161406034",
        "2914885528",
        "1874027545",
        "1964443764",
        "1687797484",
        "204885769",
        "2168682262",
        "2135346934",
        "2033009866"
    ]
},{
    "id": "1971784203",
    "title": "Algorithms for clustering data",
    "abstract": "",
    "date": "1987",
    "authors": [
        "Anil K. Jain",
        "Richard C. Dubes"
    ],
    "related_topics": [
        "Cluster analysis",
        "Correlation clustering",
        "CURE data clustering algorithm"
    ],
    "citation_count": "15,516",
    "reference_count": "16",
    "references": [
        "2913066018",
        "1975152892",
        "2118587067",
        "1572134371",
        "1576534100",
        "1533790012",
        "2018388286",
        "2086943813",
        "1978616828",
        "2120636855"
    ]
},{
    "id": "2129905273",
    "title": "Density estimation for statistics and data analysis",
    "abstract": "Introduction. Survey of Existing Methods. The Kernel Method for Univariate Data. The Kernel Method for Multivariate Data. Three Important Methods. Density Estimation in Action.",
    "date": "1985",
    "authors": [
        "Bernard. W. Silverman"
    ],
    "related_topics": [
        "Multivariate kernel density estimation",
        "Variable kernel density estimation",
        "Kernel (statistics)"
    ],
    "citation_count": "27,525",
    "reference_count": "0",
    "references": []
},{
    "id": "2999729612",
    "title": "Finding Groups in Data: An Introduction to Cluster Analysis",
    "abstract": "1. Introduction. 2. Partitioning Around Medoids (Program PAM). 3. Clustering large Applications (Program CLARA). 4. Fuzzy Analysis. 5. Agglomerative Nesting (Program AGNES). 6. Divisive Analysis (Program DIANA). 7. Monothetic Analysis (Program MONA). Appendix 1. Implementation and Structure of the Programs. Appendix 2. Running the Programs. Appendix 3. Adapting the Programs to Your Needs. Appendix 4. The Program CLUSPLOT. References. Author Index. Subject Index.",
    "date": "1989",
    "authors": [
        "Leonard Kaufman",
        "Peter J. Rousseeuw"
    ],
    "related_topics": [
        "Medoid",
        "Dunn index",
        "Cluster analysis"
    ],
    "citation_count": "20,559",
    "reference_count": "0",
    "references": []
},{
    "id": "2482402870",
    "title": "Statistical Pattern Recognition",
    "abstract": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical ap...",
    "date": "1999",
    "authors": [
        "K JainAnil",
        "P W DuinRobert",
        "MaoJianchang"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Feature extraction",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "7,328",
    "reference_count": "0",
    "references": []
},{
    "id": "182831726",
    "title": "Speech and Language Processing",
    "abstract": "is one of the most recognizablecharacters in 20th century cinema. HAL is an arti\ufb01cial agent capable of such advancedlanguage behavior as speaking and understanding English, and at a crucial moment inthe plot, even reading lips. It is now clear that HAL\u2019s creator, Arthur C. Clarke, wasa little optimistic in predicting when an arti\ufb01cial agent such as HAL would be avail-able. But just how far off was he? What would it take to create at least the language-relatedpartsofHAL?WecallprogramslikeHALthatconversewithhumansinnatural",
    "date": "1999",
    "authors": [
        "Dan Jurafsky",
        "James H. Martin"
    ],
    "related_topics": [
        "Cued speech",
        "Speech processing",
        "Language technology"
    ],
    "citation_count": "3,393",
    "reference_count": "0",
    "references": []
},{
    "id": "1994851566",
    "title": "Statistical Language Learning",
    "abstract": "From the Publisher: Eugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. New, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" Language, Speech, and Communication",
    "date": "1993",
    "authors": [
        "Eugene Charniak"
    ],
    "related_topics": [
        "Language identification",
        "Cache language model",
        "Computational linguistics"
    ],
    "citation_count": "1,726",
    "reference_count": "0",
    "references": []
},{
    "id": "2108321481",
    "title": "Exploiting Syntactic Structure for Language Modeling",
    "abstract": "The paper presents a language model that develops syntactic structure and uses it to extract meaningful information from the word history, thus enabling the use of long distance dependencies. The model assigns probability to every joint sequence of words-binary-parse-structure with headword annotation and operates in a left-to-right manner --- therefore usable for automatic speech recognition. The model, its probabilistic parameterization, and a set of experiments meant to evaluate its predictive power are presented; an improvement over standard trigram modeling is achieved.",
    "date": "1998",
    "authors": [
        "Ciprian Chelba",
        "Frederick Jelinek"
    ],
    "related_topics": [
        "Language model",
        "Trigram",
        "Headword"
    ],
    "citation_count": "254",
    "reference_count": "7",
    "references": [
        "2049633694",
        "1632114991",
        "2110882317",
        "1597533204",
        "2069912724",
        "1607229519",
        "1606548921"
    ]
},{
    "id": "1549026077",
    "title": "Natural Language Understanding",
    "abstract": "From the Publisher: In addition, this title offers coverage of two entirely new subject areas. First, the text features a new chapter on statistically-based methods using large corpora. Second, it includes an appendix on speech recognition and spoken language understanding. Also, the information on semantics that was covered in the first edition has been largely expanded in this edition to include an emphasis on compositional interpretation.",
    "date": "1986",
    "authors": [
        "James Allen"
    ],
    "related_topics": [
        "Spoken language",
        "Language identification",
        "Comprehension approach"
    ],
    "citation_count": "4,069",
    "reference_count": "0",
    "references": []
},{
    "id": "2949237929",
    "title": "Expoiting Syntactic Structure for Language Modeling",
    "abstract": "The paper presents a language model that develops syntactic structure and uses it to extract meaningful information from the word history, thus enabling the use of long distance dependencies. The model assigns probability to every joint sequence of words--binary-parse-structure with headword annotation and operates in a left-to-right manner --- therefore usable for automatic speech recognition. The model, its probabilistic parameterization, and a set of experiments meant to evaluate its predictive power are presented; an improvement over standard trigram modeling is achieved.",
    "date": "1998",
    "authors": [
        "Ciprian Chelba",
        "Frederick Jelinek"
    ],
    "related_topics": [
        "Language model",
        "Trigram",
        "Headword"
    ],
    "citation_count": "203",
    "reference_count": "5",
    "references": [
        "2049633694",
        "1632114991",
        "2110882317",
        "1607229519",
        "1606548921"
    ]
},{
    "id": "1795234945",
    "title": "Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning",
    "abstract": "This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context. The algorithms tested include statistical, neural-network, decision-tree, rule-based, and case-based classification techniques. The specific problem tested involves disambiguating six senses of the word ``line'' using the words in the current and proceeding sentence as context. The statistical and neural-network methods perform the best on this particular problem and we discuss a potential reason for this observed difference. We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems.",
    "date": "1995",
    "authors": [
        "Raymond J. Mooney"
    ],
    "related_topics": [
        "Algorithmic learning theory",
        "Instance-based learning",
        "Active learning (machine learning)"
    ],
    "citation_count": "315",
    "reference_count": "47",
    "references": [
        "2154642048",
        "1632114991",
        "3017143921",
        "2147169507",
        "2099247782",
        "1994851566",
        "2136000097",
        "2132166479",
        "1999138184",
        "2132513611"
    ]
},{
    "id": "1746620543",
    "title": "Text Information Retrieval Systems",
    "abstract": "From the Publisher: This book's purpose is to teach people who will be searching or designing text retrieval systems how the systems work. For designers, it covers problems they will face and reviews currently available solutions to provide a basis for more advanced study. For the searcher its purpose is to describe why such systems work as they do. The book is primarily about computer-based retrieval systems, but the principles apply to nonmechanized ones as well.. \"The book covers the nature of information, how it is organized for use by a computer, how search functions are carried out, and some of the theory underlying these functions. As well, it discusses the interaction between user and system and how retrieved items, users, and complete systems are evaluated. A limited knowledge of mathematics and of computing is assumed.",
    "date": "1991",
    "authors": [
        "Charles T. Meadow",
        "Donald H. Kraft",
        "Bert R. Boyce"
    ],
    "related_topics": [
        "Information retrieval",
        "Computer science",
        "Face (sociological concept)"
    ],
    "citation_count": "684",
    "reference_count": "0",
    "references": []
},{
    "id": "1736036918",
    "title": "Information Retrieval: A Health Care Perspective",
    "abstract": "As the health care industry becomes increasingly dependent on electronic information, the need for sophisticated information retrieval systems and for knowledgeable people to design, purchase and use them also increases. This book provides an overview of the theory, practical applications, evaluation and research directions of these systems. In addition to bibliographic and full-text literature retrieval, the author discusses clinical records, multimedia and networked applications.",
    "date": "2013",
    "authors": [
        "William R. Hersh"
    ],
    "related_topics": [
        "Human\u2013computer information retrieval",
        "Cognitive models of information retrieval",
        "Relevance (information retrieval)"
    ],
    "citation_count": "126",
    "reference_count": "0",
    "references": []
},{
    "id": "2117812871",
    "title": "Pattern recognition and neural networks",
    "abstract": "From the Publisher: Pattern recognition has long been studied in relation to many different (and mainly unrelated) applications, such as remote sensing, computer vision, space research, and medical imaging. In this book Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks. Unifying principles are brought to the fore, and the author gives an overview of the state of the subject. Many examples are included to illustrate real problems in pattern recognition and how to overcome them.This is a self-contained account, ideal both as an introduction for non-specialists readers, and also as a handbook for the more expert reader.",
    "date": "1995",
    "authors": [
        "Brian D. Ripley",
        "N. L. Hjort"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Intelligent character recognition",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "9,210",
    "reference_count": "102",
    "references": [
        "2156909104",
        "1554663460",
        "2119821739",
        "3124955340",
        "2912934387",
        "1679913846",
        "2112076978",
        "2046079134",
        "2147800946",
        "1536929369"
    ]
},{
    "id": "2128716185",
    "title": "Probabilistic visual learning for object representation",
    "abstract": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands.",
    "date": "1997",
    "authors": [
        "B. Moghaddam",
        "A. Pentland"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Visual modeling",
        "Visual learning"
    ],
    "citation_count": "2,338",
    "reference_count": "38",
    "references": [
        "2099111195",
        "2138451337",
        "2798909945",
        "2104095591",
        "2148694408",
        "2049633694",
        "2159686933",
        "2123977795",
        "2098947662",
        "2113341759"
    ]
},{
    "id": "2012352340",
    "title": "Using discriminant eigenfeatures for image retrieval",
    "abstract": "This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection. We demonstrate the effectiveness of these most discriminating features for view-based class retrieval from a large database of widely varying real-world objects presented as \"well-framed\" views, and compare it with that of the principal component analysis.",
    "date": "1996",
    "authors": [
        "D.L. Swets",
        "J.J. Weng"
    ],
    "related_topics": [
        "Linear discriminant analysis",
        "Optimal discriminant analysis",
        "Content-based image retrieval"
    ],
    "citation_count": "2,329",
    "reference_count": "20",
    "references": [
        "2138451337",
        "2148694408",
        "2098947662",
        "1770825568",
        "2135463994",
        "2159173611",
        "2135346934",
        "2101055828",
        "2122111042",
        "2798461040"
    ]
},{
    "id": "2130259898",
    "title": "Low-dimensional procedure for the characterization of human faces",
    "abstract": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose.",
    "date": "1987",
    "authors": [
        "L. Sirovich",
        "M. Kirby"
    ],
    "related_topics": [
        "Face (geometry)",
        "Eigenface",
        "Representation (mathematics)"
    ],
    "citation_count": "3,427",
    "reference_count": "4",
    "references": [
        "2135346934",
        "1587863748",
        "1535031115",
        "3040267042"
    ]
},{
    "id": "2156406284",
    "title": "Recognition-by-Components: A Theory of Human Image Understanding.",
    "abstract": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification).",
    "date": "1987",
    "authors": [
        "Irving Biederman"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Form perception",
        "Object model"
    ],
    "citation_count": "7,598",
    "reference_count": "73",
    "references": [
        "2740373864",
        "2149095485",
        "2059975159",
        "2073257493",
        "1513966746",
        "2059799772",
        "2032533296",
        "2125756925",
        "1501418839",
        "2081519360"
    ]
},{
    "id": "1524408959",
    "title": "Blobworld: A System for Region-Based Image Indexing and Retrieval",
    "abstract": "Blobworld is a system for image retrieval based on finding coherent image regions which roughly correspond to objects. Each image is automatically segmented into regions (\"blobs\") with associated color and texture descriptors. Queryingi s based on the attributes of one or two regions of interest, rather than a description of the entire image. In order to make large-scale retrieval feasible, we index the blob descriptions usinga tree. Because indexing in the high-dimensional feature space is computationally prohibitive, we use a lower-rank approximation to the high-dimensional distance. Experiments show encouraging results for both queryinga nd indexing.",
    "date": "1999",
    "authors": [
        "Chad Carson",
        "Megan Thomas",
        "Serge Belongie",
        "Joseph M. Hellerstein",
        "Jitendra Malik"
    ],
    "related_topics": [
        "Image texture",
        "Visual Word",
        "Automatic image annotation"
    ],
    "citation_count": "1,246",
    "reference_count": "17",
    "references": [
        "2049633694",
        "2160066518",
        "2151135734",
        "2008297189",
        "2238624099",
        "1533169541",
        "2134814621",
        "2118783153",
        "2068272887",
        "2102475035"
    ]
},{
    "id": "2180838288",
    "title": "What is the goal of sensory coding",
    "abstract": "A number of recent attempts have been made to describe early sensory coding in terms of a general information processing strategy. In this paper, two strategies are contrasted. Both strategies take advantage of the redundancy in the environment to produce more effective representations. The first is described as a \"compact\" coding scheme. A compact code performs a transform that allows the input to be represented with a reduced number of vectors (cells) with minimal RMS error. This approach has recently become popular in the neural network literature and is related to a process called Principal Components Analysis (PCA). A number of recent papers have suggested that the optimal compact code for representing natural scenes will have units with receptive field profiles much like those found in the retina and primary visual cortex. However, in this paper, it is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway. In contrast, it is proposed that the visual system is near to optimal in representing natural scenes only if optimality is defined in terms of \"sparse distributed\" coding. In a sparse distributed code, all cells in the code have an equal response probability across the class of images but have a low response probability for any single image. In such a code, the dimensionality is not reduced. Rather, the redundancy of the input is transformed into the redundancy of the firing pattern of cells. It is proposed that the signature for a sparse code is found in the fourth moment of the response distribution (i.e., the kurtosis). In measurements with 55 calibrated natural scenes, the kurtosis was found to peak when the bandwidths of the visual code matched those of cells in the mammalian visual cortex. Codes resembling \"wavelet transforms\" are proposed to be effective because the response histograms of such codes are sparse (i.e., show high kurtosis) when presented with natural scenes. It is proposed that the structure of the image that allows sparse coding is found in the phase spectrum of the image. It is suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet). Possible reasons for why sensory systems would evolve toward sparse coding are presented.",
    "date": "1999",
    "authors": [
        "David J. Field"
    ],
    "related_topics": [
        "Neural coding",
        "Code (cryptography)",
        "Wavelet"
    ],
    "citation_count": "1,664",
    "reference_count": "0",
    "references": []
},{
    "id": "2142796031",
    "title": "To See or not to See: The Need for Attention to Perceive Changes in Scenes",
    "abstract": "When looking at a scene, observers feel that they see its entire structure in great detail and can immediately notice any changes in it However, when brief blank fields are placed between alternating displays of an original and a modified scene, a striking failure of perception is induced Identification of changes becomes extremely difficult, even when changes are large and made repeatedly Identification is much faster when a verbal cue is provided showing that poor visibility is not the cause of this difficulty Identification is also faster for objects considered to be important in the scene These results support the idea that observers never form a complete, detailed representation of their surroundings In addition, the results indicate that attention is required to perceive change, and that in the absence of localized motion signals attention is guided on the basis of high-level interest",
    "date": "1997",
    "authors": [
        "Ronald A. Rensink",
        "J. Kevin O'Regan",
        "James J. Clark"
    ],
    "related_topics": [
        "Change blindness",
        "Inattentional blindness",
        "Transsaccadic memory"
    ],
    "citation_count": "3,072",
    "reference_count": "29",
    "references": [
        "2122896223",
        "2127859399",
        "2106289661",
        "1772101126",
        "2150142674",
        "2015634454",
        "2086532736",
        "2000700912",
        "657075062",
        "2780103611"
    ]
},{
    "id": "2104825706",
    "title": "Indoor-outdoor image classification",
    "abstract": "We show how high-level scene properties can be inferred from classification of low-level image features, specifically for the indoor-outdoor scene retrieval problem. We systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT. We demonstrate that performance is improved by computing features on subblocks, classifying these subblocks, and then combining these results in a way reminiscent of stacking. State of the art single-feature methods are shown to result in about 75-86% performance, while the new method results in 90.3% correct classification, when evaluated on a diverse database of over 1300 consumer images provided by Kodak.",
    "date": "1998",
    "authors": [
        "M. Szummer",
        "R.W. Picard"
    ],
    "related_topics": [
        "Contextual image classification",
        "Color histogram",
        "Image retrieval"
    ],
    "citation_count": "997",
    "reference_count": "13",
    "references": [
        "2914885528",
        "2160066518",
        "2091503252",
        "2025653905",
        "2914369697",
        "2021751319",
        "2066610120",
        "1982948355",
        "2127370936",
        "2010560725"
    ]
},{
    "id": "2167034998",
    "title": "Relations between the statistics of natural images and the response properties of cortical cells.",
    "abstract": "The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy.",
    "date": "1987",
    "authors": [
        "David J. Field"
    ],
    "related_topics": [
        "Efficient coding hypothesis",
        "Orientation (computer vision)",
        "Redundancy (engineering)"
    ],
    "citation_count": "3,980",
    "reference_count": "34",
    "references": [
        "2003370853",
        "2006500012",
        "1995875735",
        "2105672294",
        "2078498116",
        "1499486838",
        "2116360511",
        "2135587681",
        "2138100172",
        "1999908130"
    ]
},{
    "id": "2132947399",
    "title": "Make3D: Learning 3D Scene Structure from a Single Still Image",
    "abstract": "We consider the problem of estimating detailed 3D structure from a single still image of an unstructured environment. Our goal is to create 3D models that are both quantitatively accurate as well as visually pleasing. For each small homogeneous patch in the image, we use a Markov random field (MRF) to infer a set of \"plane parametersrdquo that capture both the 3D location and 3D orientation of the patch. The MRF, trained via supervised learning, models both image depth cues as well as the relationships between different parts of the image. Other than assuming that the environment is made up of a number of small planes, our model makes no explicit assumptions about the structure of the scene; this enables the algorithm to capture much more detailed 3D structure than does prior art and also give a much richer experience in the 3D flythroughs created using image-based rendering, even for scenes with significant nonvertical structure. Using this approach, we have created qualitatively correct 3D models for 64.9 percent of 588 images downloaded from the Internet. We have also extended our model to produce large-scale 3D models from a few images.",
    "date": "2009",
    "authors": [
        "A. Saxena",
        "Min Sun",
        "A.Y. Ng"
    ],
    "related_topics": [
        "Image-based modeling and rendering",
        "Image processing",
        "Rendering (computer graphics)"
    ],
    "citation_count": "1,953",
    "reference_count": "42",
    "references": [
        "2296319761",
        "2161969291",
        "1663973292",
        "1677409904",
        "2104974755",
        "1999478155",
        "2156598602",
        "1508960934",
        "2119823327",
        "2146352414"
    ]
},{
    "id": "2116877738",
    "title": "Robust higher order potentials for enforcing label consistency",
    "abstract": "This paper proposes a novel framework for labelling problems which is able to combine multiple segmentations in a principled manner. Our method is based on higher order conditional random fields and uses potentials defined on sets of pixels (image segments) generated using unsupervised segmentation algorithms. These potentials enforce label consistency in image regions and can be seen as a strict generalization of the commonly used pairwise contrast sensitive smoothness potentials. The higher order potential functions used in our framework take the form of the robust Pn model. This enables the use of powerful graph cut based move making algorithms for performing inference in the framework [14 ]. We test our method on the problem of multi-class object segmentation by augmenting the conventional CRF used for object segmentation with higher order potentials defined on image regions. Experiments on challenging data sets show that integration of higher order potentials quantitatively and qualitatively improves results leading to much better definition of object boundaries. We believe that this method can be used to yield similar improvements for many other labelling problems.",
    "date": "2008",
    "authors": [
        "P. Kohli",
        "L. Ladicky",
        "P. Torr"
    ],
    "related_topics": [
        "Image segmentation",
        "Conditional random field",
        "Segmentation"
    ],
    "citation_count": "857",
    "reference_count": "49",
    "references": [
        "2147880316",
        "2121947440",
        "2067191022",
        "2124351162",
        "1999478155",
        "2143516773",
        "2169551590",
        "2101309634",
        "1528789833",
        "2131686571"
    ]
},{
    "id": "2112301665",
    "title": "Using Multiple Segmentations to Discover Objects and their Extent in Image Collections",
    "abstract": "Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe.",
    "date": "2006",
    "authors": [
        "B.C. Russell",
        "W.T. Freeman",
        "A.A. Efros",
        "J. Sivic",
        "A. Zisserman"
    ],
    "related_topics": [
        "Segmentation-based object categorization",
        "LabelMe",
        "Image segmentation"
    ],
    "citation_count": "854",
    "reference_count": "28",
    "references": [
        "1880262756",
        "2124386111",
        "2121947440",
        "2131846894",
        "2110764733",
        "2154422044",
        "2107034620",
        "2001082470",
        "1625255723",
        "2107743791"
    ]
},{
    "id": "2119565742",
    "title": "The Google file system",
    "abstract": "We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.",
    "date": "2003",
    "authors": [
        "Sanjay Ghemawat",
        "Howard Gobioff",
        "Shun-Tak Leung"
    ],
    "related_topics": [
        "Self-certifying File System",
        "File system",
        "Distributed File System"
    ],
    "citation_count": "9,582",
    "reference_count": "14",
    "references": [
        "2073965851",
        "2131645490",
        "2147504831",
        "2007807439",
        "2005373714",
        "2133338501",
        "1566984846",
        "2025413686",
        "2137808089",
        "2157737097"
    ]
},{
    "id": "2148317584",
    "title": "Distributed computing in practice: the Condor experience",
    "abstract": "SUMMARY Since 1984, the Condor project has enabled ordinary users to do extraordinary computing. Today, the project continues to explore the social and technical problems of cooperative computing on scales ranging from the desktop to the world-wide computational Grid. In this paper, we provide the history and philosophy of the Condor project and describe how it has interacted with other projects and evolved along with the field of distributed computing. We outline the core components of the Condor system and describe how the technology of computing must correspond to social structures. Throughout, we reflect on the lessons of experience and chart the course travelled by research ideas as they grow into production systems. Copyright c \ufffd 2005 John Wiley & Sons, Ltd.",
    "date": "2005",
    "authors": [
        "Douglas Thain",
        "Todd Tannenbaum",
        "Miron Livny"
    ],
    "related_topics": [
        "Many-task computing",
        "Grid computing",
        "High-throughput computing"
    ],
    "citation_count": "2,558",
    "reference_count": "53",
    "references": [
        "2091257550",
        "2439240014",
        "2152526229",
        "2985178474",
        "1973501242",
        "2146749986",
        "2120510885",
        "1809943808",
        "2083469471",
        "2131053137"
    ]
},{
    "id": "2073965851",
    "title": "Web search for a planet: The Google cluster architecture",
    "abstract": "Amenable to extensive parallelization, Google's web search application lets different queries run on different processors and, by partitioning the overall index, also lets a single query use multiple processors. to handle this workload, Googless architecture features clusters of more than 15,000 commodity-class PCs with fault tolerant software. This architecture achieves superior performance at a fraction of the cost of a system built from fewer, but more expensive, high-end servers.",
    "date": "2003",
    "authors": [
        "L.A. Barroso",
        "J. Dean",
        "U. Holzle"
    ],
    "related_topics": [
        "Web search engine",
        "Web search query",
        "Server"
    ],
    "citation_count": "1,561",
    "reference_count": "5",
    "references": [
        "3013264884",
        "2114421447",
        "2155350341",
        "1971851724",
        "2338343669"
    ]
},{
    "id": "2109722477",
    "title": "Map-Reduce for Machine Learning on Multicore",
    "abstract": "We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and unified way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly applicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Specifically, we show that algorithms that fit the Statistical Query model [15] can be written in a certain \"summation form,\" which allows them to be easily parallelized on multicore computers. We adapt Google's map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regression (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors.",
    "date": "2006",
    "authors": [
        "Cheng-tao Chu",
        "Sang K. Kim",
        "Yi-an Lin",
        "Yuanyuan Yu",
        "Gary Bradski",
        "Kunle Olukotun",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Active learning (machine learning)",
        "Supervised learning",
        "Support vector machine"
    ],
    "citation_count": "1,793",
    "reference_count": "27",
    "references": [
        "2173213060",
        "2108384452",
        "1512098439",
        "1530699444",
        "2019363670",
        "1924689489",
        "2147898188",
        "1985690171",
        "2017977879",
        "2089468765"
    ]
},{
    "id": "1510543252",
    "title": "Using MPI: Portable Parallel Programming with the Message-Passing Interface",
    "abstract": "This book offers a thoroughly updated guide to the MPI (Message-Passing Interface) standard library for writing programs for parallel computers. Since the publication of the previous edition of Using MPI, parallel computing has become mainstream. Today, applications run on computers with millions of processors; multiple processors sharing memory and multicore processors with multiple hardware threads per core are common. The MPI-3 Forum recently brought the MPI standard up to date with respect to developments in hardware capabilities, core language evolution, the needs of applications, and experience gained over the years by vendors, implementers, and users. This third edition of Using MPI reflects these changes in both text and example code. The book takes an informal, tutorial approach, introducing each concept through easy-to-understand examples, including actual code in C and Fortran. Topics include using MPI in simple programs, virtual topologies, MPI datatypes, parallel libraries, and a comparison of MPI with sockets. For the third edition, example code has been brought up to date; applications have been updated; and references reflect the recent attention MPI has received in the literature. A companion volume, Using Advanced MPI, covers more advanced topics, including hybrid programming and coping with large data.",
    "date": "1993",
    "authors": [
        "William Gropp",
        "Ewing Lusk",
        "Anthony Skjellum"
    ],
    "related_topics": [
        "Message Passing Interface",
        "Multi-core processor",
        "Interface (Java)"
    ],
    "citation_count": "5,996",
    "reference_count": "0",
    "references": []
},{
    "id": "2044534358",
    "title": "Cluster-based scalable network services",
    "abstract": "We identify three fundamental requirements for scalable network services: incremental scalability and overflow growth provisioning, 24x7 availability through fault masking, and cost-effectiveness. We argue that clusters of commodity workstations interconnected by a high-speed SAN are exceptionally well-suited to meeting these challenges for Internet-server workloads, provided the software infrastructure for managing partial failures and administering a large cluster does not have to be reinvented for each new service. To this end, we propose a general, layered architecture for building cluster-based scalable network services that encapsulates the above requirements for reuse, and a service-programming model based on composable workers that perform transformation, aggregation, caching, and customization (TACC) of Internet content. For both performance and implementation simplicity, the architecture and TACC programming model exploit BASE, a weaker-than-ACID data semantics that results from trading consistency for availability and relying on soft state for robustness in failure management. Our architecture can be used as an off the shelf infrastructural platform for creating new network services, allowing authors to focus on the content of the service (by composing TACC building blocks) rather than its implementation. We discuss two real implementations of services based on this architecture: TranSend, a Web distillation proxy deployed to the UC Berkeley dialup IP population, and HotBot, the commercial implementation of the Inktomi search engine. We present detailed measurements of TranSend's performance based on substantial client traces, as well as anecdotal evidence from the TranSend and HotBot experience, to support the claims made for the architecture.",
    "date": "1997",
    "authors": [
        "Armando Fox",
        "Steven D. Gribble",
        "Yatin Chawathe",
        "Eric A. Brewer",
        "Paul Gauthier"
    ],
    "related_topics": [
        "Systems architecture",
        "Multitier architecture",
        "Scalability"
    ],
    "citation_count": "908",
    "reference_count": "50",
    "references": [
        "3121531027",
        "1779735989",
        "2105818147",
        "2134342348",
        "2114728910",
        "1527961683",
        "2096322909",
        "2135131646",
        "2008793926",
        "2150048640"
    ]
},{
    "id": "2045271686",
    "title": "A bridging model for parallel computation",
    "abstract": "The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel (BSP) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.",
    "date": "1990",
    "authors": [
        "Leslie G. Valiant"
    ],
    "related_topics": [
        "Bulk synchronous parallel",
        "Bridging model",
        "List ranking"
    ],
    "citation_count": "5,006",
    "reference_count": "29",
    "references": [
        "2052207834",
        "2143462372",
        "1555673550",
        "1989582918",
        "1969008575",
        "2107997203",
        "2069489095",
        "2103012681",
        "2137239103",
        "1544480906"
    ]
},{
    "id": "2798909945",
    "title": "Matrix computations",
    "abstract": "",
    "date": "1982",
    "authors": [
        "Gene H. Golub"
    ],
    "related_topics": [
        "Matrix (mathematics)",
        "LU decomposition",
        "Matrix exponential"
    ],
    "citation_count": "73,804",
    "reference_count": "0",
    "references": []
},{
    "id": "2013912476",
    "title": "A Multilinear Singular Value Decomposition",
    "abstract": "We discuss a multilinear generalization of the singular value decomposition. There is a strong analogy between several properties of the matrix and the higher-order tensor decomposition; uniqueness, link with the matrix eigenvalue decomposition, first-order perturbation effects, etc., are analyzed. We investigate how tensor symmetries affect the decomposition and propose a multilinear generalization of the symmetric eigenvalue decomposition for pair-wise symmetric tensors.",
    "date": "2000",
    "authors": [
        "Lieven De Lathauwer",
        "Bart De Moor",
        "Joos Vandewalle"
    ],
    "related_topics": [
        "Higher-order singular value decomposition",
        "Singular value decomposition",
        "Multilinear map"
    ],
    "citation_count": "4,083",
    "reference_count": "28",
    "references": [
        "2610857016",
        "2099741732",
        "1981745143",
        "2123879611",
        "2615836285",
        "2004406940",
        "1995963238",
        "32702425",
        "66060913",
        "2020062309"
    ]
},{
    "id": "2090208105",
    "title": "Eigenvalues of a real supersymmetric tensor",
    "abstract": "In this paper, we define the symmetric hyperdeterminant, eigenvalues and E-eigenvalues of a real supersymmetric tensor. We show that eigenvalues are roots of a one-dimensional polynomial, and when the order of the tensor is even, E-eigenvalues are roots of another one-dimensional polynomial. These two one-dimensional polynomials are associated with the symmetric hyperdeterminant. We call them the characteristic polynomial and the E-characteristic polynomial of that supersymmetric tensor. Real eigenvalues (E-eigenvalues) with real eigenvectors (E-eigenvectors) are called H-eigenvalues (Z-eigenvalues). When the order of the supersymmetric tensor is even, H-eigenvalues (Z-eigenvalues) exist and the supersymmetric tensor is positive definite if and only if all of its H-eigenvalues (Z-eigenvalues) are positive. An mth-order n-dimensional supersymmetric tensor where m is even has exactly n(m-1)^n^-^1 eigenvalues, and the number of its E-eigenvalues is strictly less than n(m-1)^n^-^1 when m>=4. We show that the product of all the eigenvalues is equal to the value of the symmetric hyperdeterminant, while the sum of all the eigenvalues is equal to the sum of the diagonal elements of that supersymmetric tensor, multiplied by (m-1)^n^-^1. The n(m-1)^n^-^1 eigenvalues are distributed in n disks in C. The centers and radii of these n disks are the diagonal elements, and the sums of the absolute values of the corresponding off-diagonal elements, of that supersymmetric tensor. On the other hand, E-eigenvalues are invariant under orthogonal transformations.",
    "date": "2005",
    "authors": [
        "Liqun Qi"
    ],
    "related_topics": [
        "Symmetric tensor",
        "Tensor density",
        "Hyperdeterminant"
    ],
    "citation_count": "1,091",
    "reference_count": "17",
    "references": [
        "1977415556",
        "1483218536",
        "217710249",
        "1599833186",
        "2090799283",
        "1602307574",
        "2070769763",
        "2154335661",
        "2044269663",
        "2115955567"
    ]
},{
    "id": "2752853835",
    "title": "The Art of Computer Programming",
    "abstract": "",
    "date": "1967",
    "authors": [
        "Donald Ervin Knuth"
    ],
    "related_topics": [
        "Computer network programming",
        "Symbolic programming",
        "Computer programming"
    ],
    "citation_count": "27,337",
    "reference_count": "0",
    "references": []
},{
    "id": "2113722075",
    "title": "Singular values and eigenvalues of tensors: a variational approach",
    "abstract": "We propose a theory of eigenvalues, eigenvectors, singular values, and singular vectors for tensors based on a constrained variational approach much like the Rayleigh quotient for symmetric matrix eigenvalues. These notions are particularly useful in generalizing certain areas where the spectral theory of matrices has traditionally played an important role. For illustration, we will discuss a multilinear generalization of the Perron-Frobenius theorem",
    "date": "2005",
    "authors": [
        "Lek-Heng Lim"
    ],
    "related_topics": [
        "Singular value",
        "Singular solution",
        "Invariants of tensors"
    ],
    "citation_count": "818",
    "reference_count": "10",
    "references": [
        "2013912476",
        "2090208105",
        "1509568713",
        "1500921805",
        "2018282388",
        "1973652906",
        "1602307574",
        "2074447841",
        "1993670676",
        "2000204283"
    ]
},{
    "id": "2132267493",
    "title": "Tensor Rank and the Ill-Posedness of the Best Low-Rank Approximation Problem",
    "abstract": "There has been continued interest in seeking a theorem describing optimal low-rank approximations to tensors of order 3 or higher that parallels the Eckart-Young theorem for matrices. In this paper, we argue that the naive approach to this problem is doomed to failure because, unlike matrices, tensors of order 3 or higher can fail to have best rank-$r$ approximations. The phenomenon is much more widespread than one might suspect: examples of this failure can be constructed over a wide range of dimensions, orders, and ranks, regardless of the choice of norm (or even Bregman divergence). Moreover, we show that in many instances these counterexamples have positive volume: they cannot be regarded as isolated phenomena.  In one extreme case, we exhibit a tensor space in which no rank-3 tensor has an optimal rank-2 approximation. The notable exceptions to this misbehavior are rank-1 tensors and order-2 tensors (i.e., matrices). In a more positive spirit, we propose a natural way of overcoming the ill-posedness of the low-rank approximation problem, by using weak solutions when true solutions do not exist. For this to work, it is necessary to characterize the set of weak solutions, and we do this  in the case of rank 2, order 3 (in arbitrary dimensions). In our work we emphasize the importance of closely studying concrete low-dimensional examples as a first step toward more general results. To this end, we present a detailed analysis of equivalence classes of $2 \\times 2 \\times 2$ tensors, and we develop methods for extending results upward to higher orders and dimensions. Finally, we link our work to existing studies of tensors from an algebraic geometric point of view. The rank of a tensor can in theory be given a semialgebraic description; in other words, it can be determined by a system of polynomial inequalities. We study some of these polynomials in cases of interest to us; in particular, we make extensive use of the hyperdeterminant $\\Delta$ on $\\mathbb{R}^{2\\times 2 \\times 2}$.",
    "date": "2008",
    "authors": [
        "Vin de Silva",
        "Lek-Heng Lim"
    ],
    "related_topics": [
        "Invariants of tensors",
        "Tensor",
        "Hyperdeterminant"
    ],
    "citation_count": "891",
    "reference_count": "70",
    "references": [
        "1981745143",
        "2013912476",
        "2128978199",
        "2027559251",
        "1509568713",
        "2039748980",
        "1981663184",
        "2018282388",
        "1561337879",
        "2101641981"
    ]
},{
    "id": "1499900670",
    "title": "Unsupervised audio stream segmentation and clustering via the Bayesian information criterion",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Bowen Zhou",
        "John H. L. Hansen"
    ],
    "related_topics": [
        "Determining the number of clusters in a data set",
        "Cluster analysis",
        "Bayesian information criterion"
    ],
    "citation_count": "157",
    "reference_count": "0",
    "references": []
},{
    "id": "166263196",
    "title": "Collection Selection via Lexicon Inspection",
    "abstract": "",
    "date": "1996",
    "authors": [
        "Justin Zobel"
    ],
    "related_topics": [
        "Lexicon",
        "Information retrieval",
        "Computer science"
    ],
    "citation_count": "24",
    "reference_count": "0",
    "references": []
},{
    "id": "2107745473",
    "title": "A universal algorithm for sequential data compression",
    "abstract": "A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.",
    "date": "1977",
    "authors": [
        "J. Ziv",
        "A. Lempel"
    ],
    "related_topics": [
        "Data compression ratio",
        "Lossless compression",
        "Data compression"
    ],
    "citation_count": "8,384",
    "reference_count": "10",
    "references": [
        "2142901448",
        "2077770566",
        "2131024393",
        "1992371956",
        "2109227390",
        "2094396702",
        "2141463438",
        "1995000717",
        "2159253410",
        "2126590220"
    ]
},{
    "id": "2122962290",
    "title": "Compression of individual sequences via variable-rate coding",
    "abstract": "Compressibility of individual sequences by the class of generalized finite-state information-lossless encoders is investigated. These encoders can operate in a variable-rate mode as well as a fixed-rate one, and they allow for any finite-state scheme of variable-length-to-variable-length coding. For every individual infinite sequence x a quantity \\rho(x) is defined, called the compressibility of x , which is shown to be the asymptotically attainable lower bound on the compression ratio that can be achieved for x by any finite-state encoder. This is demonstrated by means of a constructive coding theorem and its converse that, apart from their asymptotic significance, also provide useful performance criteria for finite and practical data-compression tasks. The proposed concept of compressibility is also shown to play a role analogous to that of entropy in classical information theory where one deals with probabilistic ensembles of sequences rather than with individual sequences. While the definition of \\rho(x) allows a different machine for each different sequence to be compressed, the constructive coding theorem leads to a universal algorithm that is asymptotically optimal for all sequences.",
    "date": "1978",
    "authors": [
        "J. Ziv",
        "A. Lempel"
    ],
    "related_topics": [
        "Shannon\u2013Fano coding",
        "Grammar-based code",
        "Variable-length code"
    ],
    "citation_count": "5,437",
    "reference_count": "6",
    "references": [
        "2107745473",
        "2142901448",
        "2077770566",
        "2136864990",
        "1993690617",
        "2533058580"
    ]
},{
    "id": "2037959956",
    "title": "Selected Studies of the Principle of Relative Frequency in Language",
    "abstract": "",
    "date": "2014",
    "authors": [
        "George Kingsley Zipf"
    ],
    "related_topics": [
        "Frequency",
        "Linguistics",
        "Natural language processing"
    ],
    "citation_count": "1,103",
    "reference_count": "0",
    "references": []
},{
    "id": "3146306708",
    "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews",
    "abstract": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \u201csubtle nuances\u201d) and a negative semantic orientation when it has bad associations (e.g., \u201cvery cavalier\u201d). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \u201cexcellent\u201d minus the mutual information between the given phrase and the word \u201cpoor\u201d. A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.",
    "date": "2001",
    "authors": [
        "Peter",
        "Turney"
    ],
    "related_topics": [
        "Phrase",
        "Sentiment analysis",
        "Mutual information"
    ],
    "citation_count": "7,079",
    "reference_count": "0",
    "references": []
},{
    "id": "2149684865",
    "title": "Text Categorization with Suport Vector Machines: Learning with Many Relevant Features",
    "abstract": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning.",
    "date": "1998",
    "authors": [
        "Thorsten Joachims"
    ],
    "related_topics": [
        "Support vector machine",
        "Categorization",
        "Machine learning"
    ],
    "citation_count": "11,654",
    "reference_count": "12",
    "references": [
        "2156909104",
        "2119821739",
        "2125055259",
        "2435251607",
        "740415",
        "1504694836",
        "2114535528",
        "1978394996",
        "2096152098",
        "2087614174"
    ]
},{
    "id": "1550206324",
    "title": "A comparison of event models for naive bayes text classification",
    "abstract": "Recent work in text classification has used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi-variate Bernoulli model at any vocabulary size.",
    "date": "1997",
    "authors": [
        "Andrew McCallum",
        "Kamal Nigam"
    ],
    "related_topics": [
        "Naive Bayes classifier",
        "Multinomial distribution",
        "Vocabulary"
    ],
    "citation_count": "5,018",
    "reference_count": "32",
    "references": [
        "2099111195",
        "2149684865",
        "2140785063",
        "1817561967",
        "2096152098",
        "2153283265",
        "1648885110",
        "1924689489",
        "2167044614",
        "2118234018"
    ]
},{
    "id": "2140785063",
    "title": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss",
    "abstract": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier\u2018s probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article\u2018s results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.",
    "date": "1997",
    "authors": [
        "Pedro Domingos",
        "Michael Pazzani"
    ],
    "related_topics": [
        "Margin classifier",
        "Bayesian average",
        "Quadratic classifier"
    ],
    "citation_count": "3,990",
    "reference_count": "34",
    "references": [
        "2125055259",
        "1817561967",
        "2982720039",
        "3017143921",
        "1678889691",
        "1912123407",
        "2136000097",
        "1840338487",
        "1625504505",
        "1587718046"
    ]
},{
    "id": "2155328222",
    "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews",
    "abstract": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.",
    "date": "2002",
    "authors": [
        "Peter Turney"
    ],
    "related_topics": [
        "Semantic similarity",
        "Phrase",
        "Mutual information"
    ],
    "citation_count": "4,784",
    "reference_count": "12",
    "references": [
        "1983578042",
        "2199803028",
        "1567365482",
        "1493790738",
        "1593045043",
        "1998442272",
        "1565863475",
        "3151392175",
        "2170381724",
        "1997855593"
    ]
},{
    "id": "2199803028",
    "title": "Predicting the Semantic Orientation of Adjectives",
    "abstract": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus.",
    "date": "1997",
    "authors": [
        "Vasileios Hatzivassiloglou",
        "Kathleen R. McKeown"
    ],
    "related_topics": [
        "Orientation (computer vision)",
        "Conjunction (grammar)",
        "Natural language processing"
    ],
    "citation_count": "3,482",
    "reference_count": "19",
    "references": [
        "2011039300",
        "1528905581",
        "2102381086",
        "3017143921",
        "2121227244",
        "2099247782",
        "1987971958",
        "2127314673",
        "103650626",
        "2797692640"
    ]
},{
    "id": "2912565176",
    "title": "Fuzzy sets",
    "abstract": "",
    "date": "1996",
    "authors": [
        "Lotfi A. Zadeh"
    ],
    "related_topics": [
        "Fuzzy set operations",
        "Type-2 fuzzy sets and systems",
        "Defuzzification"
    ],
    "citation_count": "66,547",
    "reference_count": "0",
    "references": []
},{
    "id": "2581275558",
    "title": "Optimization by simulated annealing",
    "abstract": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.",
    "date": "1986",
    "authors": [
        "S. Kirkpatrick",
        "C. D. Gelatt",
        "M. P. Vecchi"
    ],
    "related_topics": [
        "Optimization problem",
        "Combinatorial optimization",
        "Simulated annealing"
    ],
    "citation_count": "51,868",
    "reference_count": "14",
    "references": [
        "2042986967",
        "2022820481",
        "2114552889",
        "2022494241",
        "2143037347",
        "2056760934",
        "2148673189",
        "86906884",
        "2014952973",
        "2014068360"
    ]
},{
    "id": "2152150600",
    "title": "Genetic Algorithms in Search",
    "abstract": "",
    "date": "1988",
    "authors": [
        "D. E. Goldberg"
    ],
    "related_topics": [
        "Quality control and genetic algorithms",
        "Genetic representation",
        "Cultural algorithm"
    ],
    "citation_count": "18,629",
    "reference_count": "0",
    "references": []
},{
    "id": "2133671888",
    "title": "Introduction To The Theory Of Neural Computation",
    "abstract": "From the Publisher: This book is a comprehensive introduction to the neural network models currently under intensive study for computational applications. It is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning. It also provides coverage of neural network applications in a variety of problems of both theoretical and practical interest.",
    "date": "1990",
    "authors": [
        "John Hertz",
        "Anders Krogh",
        "Richard G. Palmer"
    ],
    "related_topics": [
        "Nervous system network models",
        "Artificial neural network",
        "Unsupervised learning"
    ],
    "citation_count": "12,431",
    "reference_count": "5",
    "references": [
        "2286699414",
        "2128499899",
        "1547224907",
        "137941959",
        "308480622"
    ]
},{
    "id": "2095897464",
    "title": "BIRCH: an efficient data clustering method for very large databases",
    "abstract": "Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.",
    "date": "1996",
    "authors": [
        "Tian Zhang",
        "Raghu Ramakrishnan",
        "Miron Livny"
    ],
    "related_topics": [
        "CURE data clustering algorithm",
        "Data stream clustering",
        "Correlation clustering"
    ],
    "citation_count": "6,415",
    "reference_count": "11",
    "references": [
        "1634005169",
        "2999729612",
        "3017143921",
        "1575476631",
        "1493454437",
        "2073308541",
        "2101616188",
        "2049631158",
        "1577072181",
        "2024868117"
    ]
},{
    "id": "2138745909",
    "title": "Data mining and knowledge discovery: making sense out of data",
    "abstract": "Current computing and storage technology is rapidly outstripping society's ability to make meaningful use of the torrent of available data. Without a concerted effort to develop knowledge discovery techniques, organizations stand to forfeit much of the value from the data they currently collect and store.",
    "date": "1996",
    "authors": [
        "U.M. Feyyad"
    ],
    "related_topics": [
        "Knowledge extraction",
        "Software mining",
        "Data warehouse"
    ],
    "citation_count": "7,038",
    "reference_count": "14",
    "references": [
        "1553696291",
        "3017143921",
        "1523293200",
        "1601529450",
        "1610836425",
        "1520252399",
        "3162744413",
        "1547515408",
        "1602329118",
        "1513282898"
    ]
},{
    "id": "2114524997",
    "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts",
    "abstract": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as \"thumbs up\" or \"thumbs down\". To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.",
    "date": "2004",
    "authors": [
        "Bo Pang",
        "Lillian Lee"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Automatic summarization",
        "Natural language processing"
    ],
    "citation_count": "4,087",
    "reference_count": "22",
    "references": [
        "2166706824",
        "2752885492",
        "2143516773",
        "3146306708",
        "1977545325",
        "2115023510",
        "2155328222",
        "2199803028",
        "2080558111",
        "2088622183"
    ]
},{
    "id": "2022204871",
    "title": "Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis",
    "abstract": "This paper presents a new approach to phrase-level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions. With this approach, the system is able to automatically identify the contextual polarity for a large subset of sentiment expressions, achieving results that are significantly better than baseline.",
    "date": "2005",
    "authors": [
        "Theresa Wilson",
        "Janyce Wiebe",
        "Paul Hoffmann"
    ],
    "related_topics": [
        "Polarity (physics)",
        "Sentiment analysis",
        "Phrase"
    ],
    "citation_count": "3,949",
    "reference_count": "22",
    "references": [
        "2160660844",
        "3146306708",
        "2114524997",
        "2115023510",
        "2053463056",
        "2014902591",
        "2155328222",
        "2199803028",
        "2112422413",
        "2080558111"
    ]
},{
    "id": "2110882317",
    "title": "A New Statistical Parser Based on Bigram Lexical Dependencies",
    "abstract": "This paper describes a new statistical parser which is based on probabilities of dependencies between head-words in the parse tree. Standard bigram probability estimation techniques are extended to calculate probabilities of dependencies between pairs of words. Tests using Wall Street Journal data show that the method performs at least as well as SPATTER (Magerman 95; Jelinek et al. 94), which has the best published results for a statistical parser on this task. The simplicity of the approach means the model trains on 40,000 sentences in under 15 minutes. With a beam search strategy parsing speed can be improved to over 200 sentences a minute with negligible loss in accuracy.",
    "date": "1996",
    "authors": [
        "Michael John Collins"
    ],
    "related_topics": [
        "Simple LR parser",
        "Top-down parsing",
        "Bigram"
    ],
    "citation_count": "909",
    "reference_count": "14",
    "references": [
        "1632114991",
        "1773803948",
        "2099247782",
        "1623072288",
        "2153439141",
        "2441154163",
        "2439178139",
        "1859173823",
        "2087165009",
        "2069912724"
    ]
},{
    "id": "2153439141",
    "title": "Statistical Decision-Tree Models for Parsing",
    "abstract": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length.",
    "date": "1995",
    "authors": [
        "David M. Magerman"
    ],
    "related_topics": [
        "Top-down parsing",
        "Statistical parsing",
        "Parser combinator"
    ],
    "citation_count": "812",
    "reference_count": "7",
    "references": [
        "1594031697",
        "2121227244",
        "2087165009",
        "1575431606",
        "2099345940",
        "1542847127",
        "1924403233"
    ]
},{
    "id": "1551104980",
    "title": "PCFG models of linguistic tree representations",
    "abstract": "The kinds of tree representations used in a treebank corpus can have a dramatic effect on performance of a parser based on the PCFG estimated from that corpus, causing the estimated likelihood of a tree to differ substantially from its frequency in the training corpus. This paper points out that the Penn II treebank representations are of the kind predicted to have such an effect, and describes a simple node relabeling transformation that improves a treebank PCFG-based parser's average precision and recall by around 8%, or approximately half of the performance difference between a simple PCFG model and the best broad-coverage parsers available today. This performance variation comes about because any PCFG, and hence the corpus of trees from which the PCFG is induced, embodies independence assumptions about the distribution of words and phrases. The particular independence assumptions implicit in a tree representation can be studied theoretically and investigated empirically by means of a tree transformation / detransformation process.",
    "date": "1998",
    "authors": [
        "Mark Johnson"
    ],
    "related_topics": [
        "Treebank",
        "Data-oriented parsing",
        "Tree (data structure)"
    ],
    "citation_count": "475",
    "reference_count": "16",
    "references": [
        "1632114991",
        "2076118331",
        "2110882317",
        "1994851566",
        "1567570606",
        "1972573551",
        "2161204834",
        "1859173823",
        "2085575316",
        "1507020546"
    ]
},{
    "id": "2161204834",
    "title": "Tree-bank Grammars",
    "abstract": "By a \"tree-bank grammar\" we mean a context-free grammar created by reading the production rules directly from hand-parsed sentences in a tree bank. Common wisdom has it that such grammars do not perform we & though we know of no published data on the issue. The primary purpose of this paper is to show that the common wisdom is wrong. In particular, we present results on a tree-bank grammar based on the Penn WaII Street Journal tree bank. To the best of our knowledge, this grammar outperforms ah other non-word-based statistical parsers/grammars on this corpus. That is, it outperforms parsers that consider the input as a string of tags and ignore the actual words of the corpus.",
    "date": "1996",
    "authors": [
        "Eugene Charniak"
    ],
    "related_topics": [
        "Tree-adjoining grammar",
        "Context-free grammar",
        "Regular tree grammar"
    ],
    "citation_count": "416",
    "reference_count": "9",
    "references": [
        "1632114991",
        "1994851566",
        "2153439141",
        "2439178139",
        "2102924265",
        "1798971027",
        "2333790164",
        "1496659931",
        "2787704407"
    ]
},{
    "id": "1859173823",
    "title": "Structural ambiguity and lexical relations",
    "abstract": "We propose that many ambiguous prepositional phrase attachments can be resolved on the basis of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus. This suggests that a distributional approach can provide an approximate solution to parsing problems that, in the worst case, call for complex reasoning.",
    "date": "1993",
    "authors": [
        "Donald Hindle",
        "Mats Rooth"
    ],
    "related_topics": [
        "Parsing",
        "Relative strength",
        "Association (object-oriented programming)"
    ],
    "citation_count": "906",
    "reference_count": "12",
    "references": [
        "2099247782",
        "1977182536",
        "1548013757",
        "80619934",
        "1981724541",
        "2056367827",
        "2132796688",
        "1794966349",
        "1967428646",
        "2162288523"
    ]
},{
    "id": "2140833774",
    "title": "Exploring Strategies for Training Deep Neural Networks",
    "abstract": "Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.",
    "date": "2009",
    "authors": [
        "Hugo Larochelle",
        "Yoshua Bengio",
        "J\u00e9r\u00f4me Louradour",
        "Pascal Lamblin"
    ],
    "related_topics": [
        "Deep learning",
        "Deep belief network",
        "Restricted Boltzmann machine"
    ],
    "citation_count": "1,069",
    "reference_count": "60",
    "references": [
        "2136922672",
        "2310919327",
        "2100495367",
        "2072128103",
        "2116064496",
        "2117130368",
        "2025768430",
        "2110798204",
        "2099741732",
        "2108384452"
    ]
},{
    "id": "1566018662",
    "title": "Corpus-based and knowledge-based measures of text semantic similarity",
    "abstract": "This paper presents a method for measuring the semantic similarity of texts, using corpus-based and knowledge-based measures of similarity. Previous work on this problem has focused mainly on either large documents (e.g. text classification, information retrieval) or individual words (e.g. synonymy tests). Given that a large fraction of the information available today, on the Web and elsewhere, consists of short text snippets (e.g. abstracts of scientific documents, imagine captions, product descriptions), in this paper we focus on measuring the semantic similarity of short texts. Through experiments performed on a paraphrase data set, we show that the semantic similarity method out-performs methods based on simple lexical matching, resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric.",
    "date": "2006",
    "authors": [
        "Rada Mihalcea",
        "Courtney Corley",
        "Carlo Strapparava"
    ],
    "related_topics": [
        "Semantic similarity",
        "Explicit semantic analysis",
        "Normalized compression distance"
    ],
    "citation_count": "1,542",
    "reference_count": "31",
    "references": [
        "2101105183",
        "2038721957",
        "2158997610",
        "1978394996",
        "1647729745",
        "2525127255",
        "1567365482",
        "2150824314",
        "2100935296",
        "2117805756"
    ]
},{
    "id": "2095739681",
    "title": "From machine learning to machine reasoning",
    "abstract": "A plausible definition of \"reasoning\" could be \"algebraically manipulating previously acquired knowledge in order to answer a new question\". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \"all-purpose\" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.",
    "date": "2014",
    "authors": [
        "L\u00e9on Bottou"
    ],
    "related_topics": [
        "Inference",
        "Transduction (machine learning)",
        "Concatenation"
    ],
    "citation_count": "257",
    "reference_count": "52",
    "references": [
        "2156909104",
        "2136922672",
        "2310919327",
        "2158899491",
        "2162915993",
        "2110764733",
        "2110798204",
        "2143891888",
        "1423339008",
        "2134557905"
    ]
},{
    "id": "1964357740",
    "title": "A tutorial on support vector regression",
    "abstract": "In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective.",
    "date": "2004",
    "authors": [
        "Alex J. Smola",
        "Bernhard Sch\u00f6lkopf"
    ],
    "related_topics": [
        "Least squares support vector machine",
        "Relevance vector machine",
        "Structured support vector machine"
    ],
    "citation_count": "11,448",
    "reference_count": "155",
    "references": [
        "2153635508",
        "2156909104",
        "2148603752",
        "2124776405",
        "1995945562",
        "1554663460",
        "2119821739",
        "2139212933",
        "1563088657",
        "2078204800"
    ]
},{
    "id": "2115023510",
    "title": "Mining the peanut gallery: opinion extraction and semantic classification of product reviews",
    "abstract": "The web contains a wealth of product reviews, but sifting through them is a daunting task. Ideally, an opinion mining tool would process a set of search results for a given item, generating a list of product attributes (quality, features, etc.) and aggregating opinions about each of them (poor, mixed, good). We begin by identifying the unique properties of this problem and develop a method for automatically distinguishing between positive and negative reviews. Our classifier draws on information retrieval techniques for feature extraction and scoring, and the results for various metrics and heuristics vary depending on the testing situation. The best methods work as well as or better than traditional machine learning. When operating on individual sentences collected from web searches, performance is limited due to noise and ambiguity. But in the context of a complete web-based tool and aided by a simple method for grouping sentences into attributes, the results are qualitatively quite useful.",
    "date": "2003",
    "authors": [
        "Kushal Dave",
        "Steve Lawrence",
        "David M. Pennock"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Heuristics",
        "Classifier (UML)"
    ],
    "citation_count": "2,991",
    "reference_count": "24",
    "references": [
        "2166706824",
        "2098162425",
        "2199803028",
        "2166776180",
        "2167435923",
        "2127314673",
        "2075718943",
        "1998442272",
        "2066590388",
        "1565863475"
    ]
},{
    "id": "2053463056",
    "title": "BoosTexter: A Boosting-based Systemfor Text Categorization",
    "abstract": "This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses.",
    "date": "2000",
    "authors": [
        "Robert E. Schapire",
        "Yoram Singer"
    ],
    "related_topics": [
        "Boosting (machine learning)",
        "Categorization",
        "Multiclass classification"
    ],
    "citation_count": "2,950",
    "reference_count": "37",
    "references": [
        "3124955340",
        "2112076978",
        "1975846642",
        "1956559956",
        "2114535528",
        "2032210760",
        "1670263352",
        "2096152098",
        "1966280301",
        "2067885219"
    ]
},{
    "id": "1587094587",
    "title": "Mixed-Effects Models in S and S-PLUS",
    "abstract": "Linear Mixed-Effects * Theory and Computational Methods for LME Models * Structure of Grouped Data * Fitting LME Models * Extending the Basic LME Model * Nonlinear Mixed-Effects * Theory and Computational Methods for NLME Models * Fitting NLME Models",
    "date": "2000",
    "authors": [
        "Josae C. Pinheiro",
        "Douglas M. Bates"
    ],
    "related_topics": [
        "Grouped data",
        "Nonlinear system",
        "Applied mathematics"
    ],
    "citation_count": "15,838",
    "reference_count": "0",
    "references": []
},{
    "id": "2120779048",
    "title": "Computing semantic relatedness using Wikipedia-based explicit semantic analysis",
    "abstract": "Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.",
    "date": "2007",
    "authors": [
        "Evgeniy Gabrilovich",
        "Shaul Markovitch"
    ],
    "related_topics": [
        "Explicit semantic analysis",
        "Semantic computing",
        "Semantic similarity"
    ],
    "citation_count": "2,813",
    "reference_count": "30",
    "references": [
        "2038721957",
        "1660390307",
        "2118020653",
        "2147152072",
        "1972644898",
        "1956559956",
        "1647729745",
        "2136930489",
        "2100935296",
        "2053921957"
    ]
},{
    "id": "2100341149",
    "title": "Learning to link with wikipedia",
    "abstract": "This paper describes how to automatically cross-reference documents with Wikipedia: the largest knowledge base ever known. It explains how machine learning can be used to identify significant terms within unstructured text, and enrich it with links to the appropriate Wikipedia articles. The resulting link detector and disambiguator performs very well, with recall and precision of almost 75%. This performance is constant whether the system is evaluated on Wikipedia articles or \"real world\" documents.This work has implications far beyond enriching documents with explanatory links. It can provide structured knowledge about any unstructured fragment of text. Any task that is currently addressed with bags of words - indexing, clustering, retrieval, and summarization to name a few - could use the techniques described here to draw on a vast network of concepts and semantics.",
    "date": "2008",
    "authors": [
        "David Milne",
        "Ian H. Witten"
    ],
    "related_topics": [
        "Automatic summarization",
        "Knowledge base",
        "Entity linking"
    ],
    "citation_count": "1,511",
    "reference_count": "17",
    "references": [
        "2125055259",
        "102708294",
        "2022166150",
        "1504694836",
        "2611471614",
        "2131357087",
        "1960027552",
        "89857650",
        "2100335205",
        "2088314245"
    ]
},{
    "id": "86887328",
    "title": "Large-Scale Named Entity Disambiguation Based on Wikipedia Data",
    "abstract": "This paper presents a large-scale system for the recognition and semantic disambiguation of named entities based on information extracted from a large encyclopedic collection and Web search results. It describes in detail the disambiguation paradigm employed and the information extraction process from Wikipedia. Through a process of maximizing the agreement between the contextual information extracted from Wikipedia and the context of a document, as well as the agreement among the category tags associated with the candidate entities, the implemented system shows high disambiguation accuracy on both news stories and Wikipedia articles.",
    "date": "2007",
    "authors": [
        "Silviu Cucerzan"
    ],
    "related_topics": [
        "Entity linking",
        "Information extraction",
        "Context (language use)"
    ],
    "citation_count": "1,430",
    "reference_count": "20",
    "references": [
        "2120779048",
        "2144578941",
        "1548663377",
        "158057341",
        "2068737686",
        "1570542661",
        "2068882115",
        "2153911474",
        "2113227740",
        "2029433174"
    ]
},{
    "id": "2096152098",
    "title": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization",
    "abstract": "Abstract : A probabilistic analysis of the Rocchio relevance feedback algorithm, one of the most popular learning methods from information retrieval, is presented in a text categorization framework. The analysis results in a probabilistic version of the Rocchio classifier and offers an explanation for the TFIDF word weighting heuristic. The Rocchio classifier, its probabilistic variant and a standard naive Bayes classifier are compared on three text categorization tasks. The results suggest that the probabilistic algorithms are preferable to the heuristic Rocchio classifier.",
    "date": "1997",
    "authors": [
        "Thorsten Joachims"
    ],
    "related_topics": [
        "Rocchio algorithm",
        "Relevance feedback",
        "Naive Bayes classifier"
    ],
    "citation_count": "2,141",
    "reference_count": "0",
    "references": []
},{
    "id": "2131357087",
    "title": "Wikify!: linking documents to encyclopedic knowledge",
    "abstract": "This paper introduces the use of Wikipedia as a resource for automatic keyword extraction and word sense disambiguation, and shows how this online encyclopedia can be used to achieve state-of-the-art results on both these tasks. The paper also shows how the two methods can be combined into a system able to automatically enrich a text with links to encyclopedic knowledge. Given an input document, the system identifies the important concepts in the text and automatically links these concepts to the corresponding Wikipedia pages. Evaluations of the system show that the automatic annotations are reliable and hardly distinguishable from manual annotations.",
    "date": "2007",
    "authors": [
        "Rada Mihalcea",
        "Andras Csomai"
    ],
    "related_topics": [
        "Keyword extraction",
        "Online encyclopedia",
        "Entity linking"
    ],
    "citation_count": "1,273",
    "reference_count": "27",
    "references": [
        "23685451",
        "1574901103",
        "2081580037",
        "1972644898",
        "1978394996",
        "1525595230",
        "1548663377",
        "2064418625",
        "158057341",
        "2145766604"
    ]
},{
    "id": "1548663377",
    "title": "Using Encyclopedic Knowledge for Named Entity Disambiguation",
    "abstract": "We present a new method for detecting and disambiguating named entities in open domain text. A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia. The resulting model significantly outperforms a less informed baseline.",
    "date": "2006",
    "authors": [
        "Razvan C. Bunescu",
        "Marius Pasca"
    ],
    "related_topics": [
        "Entity linking",
        "Online encyclopedia",
        "Support vector machine"
    ],
    "citation_count": "1,122",
    "reference_count": "8",
    "references": [
        "2148603752",
        "1660390307",
        "1576520375",
        "2047221353",
        "1523949738",
        "1502876877",
        "1521686387",
        "2287077086"
    ]
},{
    "id": "2165897980",
    "title": "The Google Similarity Distance",
    "abstract": "Words and phrases acquire meaning from the way they are used in society, from their relative semantics to other words and phrases. For computers, the equivalent of \"society\" is \"database,\" and the equivalent of \"use\" is \"a way to search the database\". We present a new theory of similarity between words and phrases based on information distance and Kolmogorov complexity. To fix thoughts, we use the World Wide Web (WWW) as the database, and Google as the search engine. The method is also applicable to other search engines and databases. This theory is then applied to construct a method to automatically extract similarity, the Google similarity distance, of words and phrases from the WWW using Google page counts. The WWW is the largest database on earth, and the context information entered by millions of independent users averages out to provide automatic semantics of useful quality. We give applications in hierarchical clustering, classification, and language translation. We give examples to distinguish between colors and numbers, cluster names of paintings by 17th century Dutch masters and names of books by English novelists, the ability to understand emergencies and primes, and we demonstrate the ability to do a simple automatic English-Spanish translation. Finally, we use the WordNet database as an objective baseline against which to judge the performance of our method. We conduct a massive randomized trial in binary classification using support vector machines to learn categories based on our Google distance, resulting in an a mean agreement of 87 percent with the expert crafted WordNet categories",
    "date": "2007",
    "authors": [
        "R.L. Cilibrasi",
        "P.M.B. Vitanyi"
    ],
    "related_topics": [
        "Normalized Google distance",
        "WordNet",
        "Information distance"
    ],
    "citation_count": "2,243",
    "reference_count": "30",
    "references": [
        "2153635508",
        "2099111195",
        "2139212933",
        "1983578042",
        "1638203394",
        "2107658650",
        "2144221002",
        "2128859735",
        "2066277072",
        "2166064672"
    ]
},{
    "id": "158057341",
    "title": "WikiRelate! computing semantic relatedness using wikipedia",
    "abstract": "Wikipedia provides a knowledge base for computing word relatedness in a more structured fashion than a search engine and with more coverage than WordNet. In this work we present experiments on using Wikipedia for computing semantic relatedness and compare it to WordNet on various benchmarking datasets. Existing relatedness measures perform better using Wikipedia than a baseline given by Google counts, and we show that Wikipedia outperforms WordNet when applied to the largest available dataset designed for that purpose. The best results on this dataset are obtained by integrating Google, WordNet and Wikipedia based measures. We also show that including Wikipedia improves the performance of an NLP application processing naturally occurring texts.",
    "date": "2006",
    "authors": [
        "Michael Strube",
        "Simone Paolo Ponzetto"
    ],
    "related_topics": [
        "Normalized Google distance",
        "WordNet",
        "Semantic similarity"
    ],
    "citation_count": "1,151",
    "reference_count": "30",
    "references": [
        "2156909104",
        "2038721957",
        "2109943925",
        "2017337590",
        "2096175520",
        "1983578042",
        "1567365482",
        "2151170651",
        "2136930489",
        "1548663377"
    ]
},{
    "id": "1960027552",
    "title": "An effective, low-cost measure of semantic relatedness obtained from Wikipedia links",
    "abstract": "This paper describes a new technique for obtaining measures of semantic relatedness. Like other recent approaches, it uses Wikipedia to provide structured world knowledge about the terms of interest. Our approach is unique in that it does so using the hyperlink structure of Wikipedia rather than its category hierarchy or textual content. Evaluation with manually defined measures of semantic relatedness reveals this to be an effective compromise between the ease of computation of the former approach and the accuracy of the latter.",
    "date": "2007",
    "authors": [
        "David Milne",
        "Ian H. Witten"
    ],
    "related_topics": [
        "Semantic similarity",
        "Hyperlink",
        "Information retrieval"
    ],
    "citation_count": "998",
    "reference_count": "15",
    "references": [
        "2120779048",
        "2158997610",
        "86887328",
        "2131357087",
        "1548663377",
        "2165897980",
        "2053921957",
        "158057341",
        "2103318667",
        "2100335205"
    ]
},{
    "id": "2123142779",
    "title": "TAGME: on-the-fly annotation of short text fragments (by wikipedia entities)",
    "abstract": "We designed and implemented TAGME, a system that is able to efficiently and judiciously augment a plain-text with pertinent hyperlinks to Wikipedia pages. The specialty of TAGME with respect to known systems [5,8] is that it may annotate texts which are short and poorly composed, such as snippets of search-engine results, tweets, news, etc.. This annotation is extremely informative, so any task that is currently addressed using the bag-of-words paradigm could benefit from using this annotation to draw upon (the millions of) Wikipedia pages and their inter-relations.",
    "date": "2010",
    "authors": [
        "Paolo Ferragina",
        "Ugo Scaiella"
    ],
    "related_topics": [
        "Hyperlink",
        "Annotation",
        "Task (project management)"
    ],
    "citation_count": "745",
    "reference_count": "22",
    "references": [
        "2022166150",
        "2100341149",
        "86887328",
        "2131357087",
        "1960027552",
        "2161443453",
        "1506845741",
        "2115352105",
        "2146304342",
        "2088314245"
    ]
},{
    "id": "2147010501",
    "title": "Learning Multilevel Distributed Representations for High-Dimensional Sequences",
    "abstract": "We describe a new family of non-linear sequence models that are substantially more powerful than hidden Markov models or linear dynamical systems. Our models have simple approximate inference and learning procedures that work well in practice. Multilevel representations of sequential data can be learned one hidden layer at a time, and adding extra hidden layers improves the resulting generative models. The models can be trained with very high-dimensional, very non-linear data such as raw pixel sequences. Their performance is demonstrated using synthetic video sequences of two balls bouncing in a box.",
    "date": "2007",
    "authors": [
        "Ilya Sutskever",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Approximate inference",
        "Hidden Markov model",
        "Markov model"
    ],
    "citation_count": "266",
    "reference_count": "14",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "1516111018",
        "1481420047",
        "66838807",
        "1528056001",
        "1575388622",
        "116210019",
        "1813659000"
    ]
},{
    "id": "145476170",
    "title": "Learning distributed representations of concepts.",
    "abstract": "",
    "date": "1988",
    "authors": [
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Concept learning",
        "Cognition",
        "Cognitive science"
    ],
    "citation_count": "1,020",
    "reference_count": "4",
    "references": [
        "1652505363",
        "2073257493",
        "1539686131",
        "2013239224"
    ]
},{
    "id": "2123084125",
    "title": "NOUN CLASSIFICATION FROM PREDICATE-ARGUMENT STRUCTURES",
    "abstract": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification.",
    "date": "1990",
    "authors": [
        "Donald Hindle"
    ],
    "related_topics": [
        "Object (grammar)",
        "Predicate (grammar)",
        "Noun"
    ],
    "citation_count": "797",
    "reference_count": "8",
    "references": [
        "2099247782",
        "1593045043",
        "1981724541",
        "2034274945",
        "2111108424",
        "1496719572",
        "1528321674",
        "2052690453"
    ]
},{
    "id": "2025887562",
    "title": "Statistical mechanics and phase transitions in clustering.",
    "abstract": "A new approach to clustering based on statistical physics is presented. The problem is formulated as fuzzy clustering and the association probability distribution is obtained by maximizing the entropy at a given average variance. The corresponding Lagrange multiplier is related to the ``temperature'' and motivates a deterministic annealing process where the free energy is minimized at each temperature. Critical temperatures are derived for phase transitions when existing clusters split. It is a hierarchical clustering estimating the most probable cluster parameters at various average variances.",
    "date": "1990",
    "authors": [
        "Kenneth Rose",
        "Eitan Gurewitz",
        "Geoffrey C. Fox"
    ],
    "related_topics": [
        "Fuzzy clustering",
        "Correlation clustering",
        "Cluster analysis"
    ],
    "citation_count": "624",
    "reference_count": "0",
    "references": []
},{
    "id": "2059800182",
    "title": "A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams",
    "abstract": "Abstract In principle, n -gram probabilities can be estimated from a large sample of text by counting the number of occurrences of each n -gram of interest and dividing by the size of the training sample. This method, which is known as maximum likelihood estimator (MLE), is very simple. However, it is unsuitable because n -grams which do not occur in the training sample are assigned zero probability. This is qualitatively wrong for use as a prior model, because it would never allow the n -gram, while clearly some of the unseen n -grams will occur in other texts. For non-zero frequencies, the MLE is quantitatively wrong. Moreover, at all frequencies, the MLE does not separate bigrams with the same frequency. We study two alternative methods. The first method is an enhanced version of the method due to Good and Turing (I. J. Good [1953]. Biometrika , 40 , 237\u2013264). Under the modest assumption that the distribution of each bigram is binomial, Good provided a theoretical result that increases estimation accuracy. The second method is an enhanced version of the deleted estimation method (F. Jelinek & R. Mercer [1985]. IBM Technical Disclosure Bulletin , 28 , 2591\u20132594). It assumes even less, merely that the training and test corpora are generated by the same process. We emphasize three points about these methods. First, by using a second predictor of the probability in addition to the observed frequency, it is possible to estimate different probabilities for bigrams with the same frequency. We refer to this use of a second predictor as \u201cenhancement.\u201d With enhancement, we find 1200 significantly different probabilities (with a range of five orders of magnitude) for the group of bigrams not observed in the training text; the MLE method would not be able to distinguish any one of these bigrams from any other. The probabilities found by the enhanced methods agree quite closely in qualitative comparisons with the standard calculated from the test corpus. Second, the enhanced Good-Turing method provides accurate predictions of the variances of the standard probabilities estimated from the test corpus. Third, we introduce a refined testing method that enables us to measure the prediction errors directly and accurately and thus to study small differences between methods. We find that while the errors of both methods are small due to the large amount of data that we use, the enhanced Good-Turing method is three to four times as efficient in its use of data as the enhanced deleted estimate method. Good-Turing method is preferable to the enhanced deleted estimate method. Both methods are much better than MLE.",
    "date": "1990",
    "authors": [
        "Kenneth W. Church",
        "William A. Gale"
    ],
    "related_topics": [
        "Bigram",
        "Range (statistics)",
        "Measure (mathematics)"
    ],
    "citation_count": "350",
    "reference_count": "7",
    "references": [
        "2099247782",
        "2134237567",
        "2996160789",
        "1990438144",
        "2159782014",
        "2168938909",
        "2082092506"
    ]
},{
    "id": "2016001305",
    "title": "Contextual word similarity and estimation from sparse data",
    "abstract": "Abstract In recent years there is much interest in word co-occurrence relations, such as n-grams, verb\u2013object combinations, or co-occurrence within a limited context. This paper discusses how to estimate the likelihood of co-occurrences that do not occur in the training data. We present a method that makes local analogies between each specific unobserved co-occurrence and other co-occurrences that contain similar words. These analogies are based on the assumption that similar word co-occurrences have similar values of mutual information. Accordingly, the word similarity metric captures similarities between vectors of mutual information values. Our evaluation suggests that this method performs better than existing, frequency-based, smoothing methods, and may provide an alternative to class-based models. A background survey is included, covering issues of lexical co-occurrence, data sparseness and smoothing, word similarity and clustering, and mutual information.",
    "date": "1995",
    "authors": [
        "Ido Dagan",
        "Shaul Marcus",
        "Shaul Markovitch"
    ],
    "related_topics": [
        "Mutual information",
        "Word (computer architecture)",
        "Smoothing"
    ],
    "citation_count": "410",
    "reference_count": "6",
    "references": [
        "2134237567",
        "2441154163",
        "2123084125",
        "2137638032",
        "2034274945",
        "1715319291"
    ]
},{
    "id": "1982944197",
    "title": "Stochastic lexicalized tree-adjoining grammars",
    "abstract": "The notion of stochastic lexicalized tree-adjoining grammar (SLTAG) is formally defined. The parameters of a SLTAG correspond to the probability of combining two structures each one associated with a word. The characteristics of SLTAG are unique and novel since it is lexieally sensitive (as N-gram models or Hidden Markov Models) and yet hierarchical (as stochastic context-free grammars).Then, two basic algorithms for SLTAG arc introduced: an algorithm for computing the probability of a sentence generated by a SLTAG and an inside-outside-like iterative algorithm for estimating the parameters of a SLTAG given a training corpus.Finally, we should how SLTAG enables to define a lexicalized version of stochastic context-free grammars and we report preliminary experiments showing some of the advantages of SLTAG over stochastic context-free grammars.",
    "date": "1992",
    "authors": [
        "Yves Schabes"
    ],
    "related_topics": [
        "Stochastic context-free grammar",
        "Tree-adjoining grammar",
        "L-attributed grammar"
    ],
    "citation_count": "204",
    "reference_count": "16",
    "references": [
        "2439178139",
        "1995875735",
        "2077302143",
        "1978470410",
        "1541301615",
        "2131986285",
        "2047706513",
        "2153198088",
        "1526927911",
        "1504046386"
    ]
},{
    "id": "2016243284",
    "title": "The LIMSI Broadcast News transcription system",
    "abstract": "Abstract This paper reports on activites at LIMSI over the last few years directed at the transcription of broadcast news data. We describe our development work in moving from laboratory read speech data to real-world or `found' speech data in preparation for the DARPA evaluations on this task from 1996 to 1999. Two main problems needed to be addressed to deal with the continuous flow of inhomogenous data. These concern the varied acoustic nature of the signal (signal quality, environmental and transmission noise, music) and different linguistic styles (prepared and spontaneous speech on a wide range of topics, spoken by a large variety of speakers). The problem of partitioning the continuous stream of data is addressed using an iterative segmentation and clustering algorithm with Gaussian mixtures. The speech recognizer makes use of continuous density HMMs with Gaussian mixture for acoustic modeling and 4-gram statistics estimated on large text corpora. Word recognition is performed in multiple passes, where current hypotheses are used for cluster-based acoustic model adaptation prior to the next decoding pass. The overall word transcription error of the LIMSI evaluation systems were 27.1% (Nov96, partitioned test data), 18.3% (Nov97, unpartitioned data), 13.6% (Nov98, unpartitioned data) and 17.1% (Fall99, unpartitioned data with computation time under 10\u00d7 real-time).",
    "date": "2002",
    "authors": [
        "Jean-Luc Gauvain",
        "Lori Lamel",
        "Gilles Adda"
    ],
    "related_topics": [
        "Acoustic model",
        "Transcription (software)",
        "Language model"
    ],
    "citation_count": "539",
    "reference_count": "24",
    "references": [
        "2146871184",
        "2100969003",
        "1482605500",
        "2090861223",
        "1549285799",
        "2024490156",
        "1484181928",
        "1547083988",
        "2081323593",
        "3765491"
    ]
},{
    "id": "2140679639",
    "title": "A Neural Probabilistic Language Model",
    "abstract": "A goal of statistical language modeling is to learn the joint probability function of sequences of words. This is intrinsically difficult because of the curse of dimensionality: we propose to fight it with its own weapons. In the proposed approach one learns simultaneously (1) a distributed representation for each word (i.e. a similarity between words) along with (2) the probability function for word sequences, expressed with these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar to words forming an already seen sentence. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach very significantly improves on a state-of-the-art trigram model.",
    "date": "1999",
    "authors": [
        "Yoshua Bengio",
        "R\u00e9jean Ducharme",
        "Pascal Vincent"
    ],
    "related_topics": [
        "Language model",
        "Cache language model",
        "Trigram"
    ],
    "citation_count": "396",
    "reference_count": "29",
    "references": [
        "2038721957",
        "2116064496",
        "2147152072",
        "2096175520",
        "2110485445",
        "2158195707",
        "2121227244",
        "2914484425",
        "2127314673",
        "2064580901"
    ]
},{
    "id": "82490022",
    "title": "Fast decoding for indexation of broadcast data.",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Jean-Luc Gauvain",
        "Lori Lamel"
    ],
    "related_topics": [
        "Decoding methods",
        "Indexation",
        "Speech recognition"
    ],
    "citation_count": "22",
    "reference_count": "10",
    "references": [
        "2098162425",
        "2146871184",
        "2081323593",
        "3765491",
        "1977434607",
        "1579752022",
        "2042759801",
        "11920722",
        "2917519822",
        "1482958488"
    ]
},{
    "id": "17500809",
    "title": "Language Model Adaptation",
    "abstract": "This paper reviews methods for language model adaptation. Paradigms and basic methods are first introduced. Basic theory is presented for maximum a-posteriori estimation, mixture based adaptation, and minimum discrimination information. Models to cope with long distance dependencies are also introduced. Applications and results from the recent literature are finally surveyed.",
    "date": "1998",
    "authors": [
        "Renato DeMori",
        "Marcello Federico"
    ],
    "related_topics": [
        "Language model",
        "Adaptation (computer science)",
        "Natural language"
    ],
    "citation_count": "54",
    "reference_count": "43",
    "references": [
        "2099111195",
        "2125838338",
        "2049633694",
        "3017143921",
        "2160842254",
        "2116780029",
        "2134237567",
        "2108321481",
        "1996903695",
        "2441154163"
    ]
},{
    "id": "1996764654",
    "title": "Scatter/Gather: a cluster-based approach to browsing large document collections",
    "abstract": "Document clustering has not been well received as an information retrieval tool. Objections to its use fall into two main categories: first, that clustering is too slow for large corpora (with running time often quadratic in the number of documents); and second, that clustering does not appreciably improve retrieval.We argue that these problems arise only when clustering is used in an attempt to improve conventional search techniques. However, looking at clustering as an information access tool in its own right obviates these objections, and provides a powerful new access paradigm. We present a document browsing technique that employs document clustering as its primary operation. We also present fast (linear time) clustering algorithms which support this interactive browsing paradigm.",
    "date": "1992",
    "authors": [
        "Douglass R. Cutting",
        "David R. Karger",
        "Jan O. Pedersen",
        "John W. Tukey"
    ],
    "related_topics": [
        "Cluster analysis",
        "Document clustering",
        "Fuzzy clustering"
    ],
    "citation_count": "2,558",
    "reference_count": "12",
    "references": [
        "1971784203",
        "1956559956",
        "2145036943",
        "2066667100",
        "2120636855",
        "2084048649",
        "2041565863",
        "2045370125",
        "2093377061",
        "1965080174"
    ]
},{
    "id": "2595741664",
    "title": "IEEE International Conference on Acoustics Speech and Signal Processing",
    "abstract": "",
    "date": "2000",
    "authors": [
        "S. Chen",
        "A. K. Samingan",
        "Bernie Mulgrew",
        "L. Hanzo"
    ],
    "related_topics": [
        "Signal processing",
        "Computer science",
        "Speech recognition"
    ],
    "citation_count": "2,265",
    "reference_count": "0",
    "references": []
},{
    "id": "47415966",
    "title": "Improved Clustering Techniques for Class-Based Statistical Language Modelling",
    "abstract": "",
    "date": "1992",
    "authors": [
        "Reinhard Kneser",
        "Hermann Ney"
    ],
    "related_topics": [
        "Conceptual clustering",
        "Cluster analysis",
        "Class (computer programming)"
    ],
    "citation_count": "270",
    "reference_count": "0",
    "references": []
},{
    "id": "1989705153",
    "title": "Structured language modeling",
    "abstract": "This paper presents an attempt at using the syntactic structure in natural language for improved language models for speech recognition. The structured language model merges techniques in automatic parsing and language modeling using an original probabilistic parameterization of a shift-reduce parser. A maximum likelihood re-estimation procedure belonging to the class of expectation-maximization algorithms is employed for training the model. Experiments on the Wall Street Journal and Switchboard corpora show improvement in both perplexity and word error rate?word lattice rescoring?over the standard 3-gram language model.",
    "date": "2000",
    "authors": [
        "Ciprian Chelba",
        "Frederick Jelinek"
    ],
    "related_topics": [
        "Language model",
        "Language identification",
        "Cache language model"
    ],
    "citation_count": "398",
    "reference_count": "32",
    "references": [
        "2049633694",
        "1632114991",
        "2096175520",
        "1508165687",
        "2121227244",
        "2110882317",
        "1567570606",
        "2166637769",
        "2108321481",
        "2949237929"
    ]
},{
    "id": "2130306094",
    "title": "Deep Neural Networks for Object Detection",
    "abstract": "Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We define a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications. State-of-the-art performance of the approach is shown on Pascal VOC.",
    "date": "2013",
    "authors": [
        "Christian Szegedy",
        "Alexander Toshev",
        "Dumitru Erhan"
    ],
    "related_topics": [
        "Object detection",
        "Viola\u2013Jones object detection framework",
        "Minimum bounding box"
    ],
    "citation_count": "1,310",
    "reference_count": "20",
    "references": [
        "2618530766",
        "2108598243",
        "2161969291",
        "2168356304",
        "2146502635",
        "2100495367",
        "2031489346",
        "2072128103",
        "2022508996",
        "2167510172"
    ]
},{
    "id": "2129305389",
    "title": "Segmentation as selective search for object recognition",
    "abstract": "For object recognition, the current state-of-the-art is based on exhaustive search. However, to enable the use of more expensive features and classifiers and thereby progress beyond the state-of-the-art, a selective search strategy is needed. Therefore, we adapt segmentation as a selective search by reconsidering segmentation: We propose to generate many approximate locations over few and precise object delineations because (1) an object whose location is never generated can not be recognised and (2) appearance and immediate nearby context are most effective for object recognition. Our method is class-independent and is shown to cover 96.7% of all objects in the Pascal VOC 2007 test set using only 1,536 locations per image. Our selective search enables the use of the more expensive bag-of-words method which we use to substantially improve the state-of-the-art by up to 8.5% for 8 out of 20 classes on the Pascal VOC 2010 detection challenge.",
    "date": "2011",
    "authors": [
        "Koen E. A. van de Sande",
        "Jasper R. R. Uijlings",
        "Theo Gevers",
        "Arnold W. M. Smeulders"
    ],
    "related_topics": [
        "Segmentation-based object categorization",
        "Scale-space segmentation",
        "Image segmentation"
    ],
    "citation_count": "793",
    "reference_count": "30",
    "references": [
        "2151103935",
        "2161969291",
        "2168356304",
        "2031489346",
        "3097096317",
        "2162915993",
        "2110158442",
        "2131846894",
        "1999478155",
        "1625255723"
    ]
},{
    "id": "2017691720",
    "title": "Constrained parametric min-cuts for automatic object segmentation",
    "abstract": "We present a novel framework for generating and ranking plausible objects hypotheses in an image using bottom-up processes and mid-level cues. The object hypotheses are represented as figure-ground segmentations, and are extracted automatically, without prior knowledge about properties of individual object classes, by solving a sequence of constrained parametric min-cut problems (CPMC) on a regular image grid. We then learn to rank the object hypotheses by training a continuous model to predict how plausible the segments are, given their mid-level region properties. We show that this algorithm significantly outperforms the state of the art for low-level segmentation in the VOC09 segmentation dataset. It achieves the same average best segmentation covering as the best performing technique to date [2], 0.61 when using just the top 7 ranked segments, instead of the full hierarchy in [2]. Our method achieves 0.78 average best covering using 154 segments. In a companion paper [18], we also show that the algorithm achieves state-of-the art results when used in a segmentation-based recognition pipeline.",
    "date": "2010",
    "authors": [
        "Joao Carreira",
        "Cristian Sminchisescu"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Segmentation-based object categorization",
        "Image segmentation"
    ],
    "citation_count": "585",
    "reference_count": "34",
    "references": [
        "2151103935",
        "2911964244",
        "2121947440",
        "2067191022",
        "2124351162",
        "1999478155",
        "1528789833",
        "2154683974",
        "2119300483",
        "2083305840"
    ]
},{
    "id": "2128715914",
    "title": "What is an object",
    "abstract": "We present a generic objectness measure, quantifying how likely it is for an image window to contain an object of any class. We explicitly train it to distinguish objects with a well-defined boundary in space, such as cows and telephones, from amorphous background elements, such as grass and road. The measure combines in a Bayesian framework several image cues measuring characteristics of objects, such as appearing different from their surroundings and having a closed boundary. This includes an innovative cue measuring the closed boundary characteristic. In experiments on the challenging PASCAL VOC 07 dataset, we show this new cue to outperform a state-of-the-art saliency measure [17], and the combined measure to perform better than any cue alone. Finally, we show how to sample windows from an image according to their objectness distribution and give an algorithm to employ them as location priors for modern class-specific object detectors. In experiments on PASCAL VOC 07 we show this greatly reduces the number of windows evaluated by class-specific object detectors.",
    "date": "2010",
    "authors": [
        "Bogdan Alexe",
        "Thomas Deselaers",
        "Vittorio Ferrari"
    ],
    "related_topics": [
        "Object detection",
        "Image segmentation",
        "Pascal (programming language)"
    ],
    "citation_count": "1,220",
    "reference_count": "32",
    "references": [
        "2161969291",
        "2168356304",
        "2124386111",
        "2128272608",
        "2154422044",
        "1999478155",
        "2166049352",
        "2146103513",
        "2172188317",
        "2161406034"
    ]
},{
    "id": "2122146326",
    "title": "Fast, Accurate Detection of 100,000 Object Classes on a Single Machine",
    "abstract": "Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes.",
    "date": "2013",
    "authors": [
        "Thomas Dean",
        "Mark A. Ruzon",
        "Mark Segal",
        "Jonathon Shlens",
        "Sudheendra Vijayanarasimhan",
        "Jay Yagnik"
    ],
    "related_topics": [
        "Viola\u2013Jones object detection framework",
        "Object detection",
        "Object-class detection"
    ],
    "citation_count": "395",
    "reference_count": "22",
    "references": [
        "2618530766",
        "2161969291",
        "2168356304",
        "3097096317",
        "2037227137",
        "2120419212",
        "2094728533",
        "2147717514",
        "1736726159",
        "2129305389"
    ]
},{
    "id": "2104974755",
    "title": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms",
    "abstract": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.",
    "date": "2001",
    "authors": [
        "D. Scharstein",
        "R. Szeliski",
        "R. Zabih"
    ],
    "related_topics": [
        "Stereo cameras",
        "Computer stereo vision",
        "Graph cuts in computer vision"
    ],
    "citation_count": "6,632",
    "reference_count": "134",
    "references": [
        "2033819227",
        "2167667767",
        "2143516773",
        "2145023731",
        "1997063559",
        "2113137767",
        "3003662786",
        "1963623641",
        "2103504761",
        "2121781154"
    ]
},{
    "id": "2163352848",
    "title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns",
    "abstract": "Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.",
    "date": "2002",
    "authors": [
        "T. Ojala",
        "M. Pietikainen",
        "T. Maenpaa"
    ],
    "related_topics": [
        "Local binary patterns",
        "Binary pattern",
        "Image texture"
    ],
    "citation_count": "16,166",
    "reference_count": "46",
    "references": [
        "2039051707",
        "3017143921",
        "2098347925",
        "2106798282",
        "2132047332",
        "2159988601",
        "2021751319",
        "1993655741",
        "2124353687",
        "2136343973"
    ]
},{
    "id": "1677409904",
    "title": "SURF: speeded up robust features",
    "abstract": "In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance.",
    "date": "2006",
    "authors": [
        "Herbert Bay",
        "Tinne Tuytelaars",
        "Luc Van Gool"
    ],
    "related_topics": [
        "Scale-invariant feature transform",
        "GLOH",
        "Interest point detection"
    ],
    "citation_count": "19,494",
    "reference_count": "36",
    "references": [
        "2151103935",
        "2164598857",
        "2124386111",
        "2177274842",
        "2128017662",
        "2012778485",
        "1980911747",
        "2145072179",
        "2172188317",
        "2124404372"
    ]
},{
    "id": "1496357020",
    "title": "All of Statistics: A Concise Course in Statistical Inference",
    "abstract": "WINNER OF THE 2005 DEGROOT PRIZE! This book is for people who want to learn probability and statistics quickly. It brings together many of the main ideas in modern statistics in one place. The book is suitable for students and researchers in statistics, computer science, data mining and machine learning. This book covers a much wider range of topics than a typical introductory text on mathematical statistics. It includes modern topics like nonparametric curve estimation, bootstrapping and classification, topics that are usually relegated to follow-up courses. The reader is assumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. The text can be used at the advanced undergraduate and graduate level.",
    "date": "2014",
    "authors": [
        "Larry Wasserman"
    ],
    "related_topics": [
        "Statistics education",
        "Probability and statistics",
        "Mathematical statistics"
    ],
    "citation_count": "1,785",
    "reference_count": "0",
    "references": []
},{
    "id": "2606594511",
    "title": "Sn: A simulator for connectionist models",
    "abstract": "",
    "date": "1987",
    "authors": [
        "Leon Bottou",
        "Yann Lecun"
    ],
    "related_topics": [
        "Computer science",
        "Connectionism",
        "Simulation"
    ],
    "citation_count": "12",
    "reference_count": "0",
    "references": []
},{
    "id": "2141362318",
    "title": "Object retrieval with large vocabularies and fast spatial matching",
    "abstract": "In this paper, we present a large-scale object retrieval system. The user supplies a query object by selecting a region of a query image, and the system returns a ranked list of images that contain the same object, retrieved from a large corpus. We demonstrate the scalability and performance of our system on a dataset of over 1 million images crawled from the photo-sharing site, Flickr [3], using Oxford landmarks as queries. Building an image-feature vocabulary is a major time and performance bottleneck, due to the size of our dataset. To address this problem we compare different scalable methods for building a vocabulary and introduce a novel quantization method based on randomized trees which we show outperforms the current state-of-the-art on an extensive ground-truth. Our experiments show that the quantization has a major effect on retrieval quality. To further improve query performance, we add an efficient spatial verification stage to re-rank the results returned from our bag-of-words model and show that this consistently improves search quality, though by less of a margin when the visual vocabulary is large. We view this work as a promising step towards much larger, \"web-scale \" image corpora.",
    "date": "2007",
    "authors": [
        "J. Philbin",
        "O. Chum",
        "M. Isard",
        "J. Sivic",
        "A. Zisserman"
    ],
    "related_topics": [
        "Image retrieval",
        "Vocabulary",
        "Quantization (image processing)"
    ],
    "citation_count": "3,303",
    "reference_count": "17",
    "references": [
        "2151103935",
        "2033819227",
        "2131846894",
        "1660390307",
        "2128017662",
        "2172188317",
        "2073965851",
        "1634005169",
        "2085261163",
        "2427881153"
    ]
},{
    "id": "2094728533",
    "title": "Freebase: a collaboratively created graph database for structuring human knowledge",
    "abstract": "Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.",
    "date": "2008",
    "authors": [
        "Kurt Bollacker",
        "Colin Evans",
        "Praveen Paritosh",
        "Tim Sturge",
        "Jamie Taylor"
    ],
    "related_topics": [
        "Query language",
        "Graph database",
        "Tuple"
    ],
    "citation_count": "3,927",
    "reference_count": "1",
    "references": [
        "23685451"
    ]
},{
    "id": "1618905105",
    "title": "Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods",
    "abstract": "",
    "date": "1998",
    "authors": [
        "John C. Platt"
    ],
    "related_topics": [
        "Relevance vector machine",
        "Margin classifier",
        "Structured support vector machine"
    ],
    "citation_count": "6,425",
    "reference_count": "0",
    "references": []
},{
    "id": "21006490",
    "title": "WSABIE: scaling up to large vocabulary image annotation",
    "abstract": "Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method, called WSABIE, both outperforms several baseline methods and is faster and consumes less memory.",
    "date": "2011",
    "authors": [
        "Jason Weston",
        "Samy Bengio",
        "Nicolas Usunier"
    ],
    "related_topics": [
        "Automatic image annotation",
        "Vocabulary",
        "Ranking"
    ],
    "citation_count": "774",
    "reference_count": "26",
    "references": [
        "2108598243",
        "2135046866",
        "2038721957",
        "1576445103",
        "2145607950",
        "1604938182",
        "2160218441",
        "2154956324",
        "28412257",
        "2102765684"
    ]
},{
    "id": "1897761818",
    "title": "Every picture tells a story: generating sentences from images",
    "abstract": "Humans can prepare concise descriptions of pictures, focusing on what they find important. We demonstrate that automatic methods can do so too. We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning obtained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned us-ingdata. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is sufficient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche.",
    "date": "2010",
    "authors": [
        "Ali Farhadi",
        "Mohsen Hejrati",
        "Mohammad Amin Sadeghi",
        "Peter Young",
        "Cyrus Rashtchian",
        "Julia Hockenmaier",
        "David Forsyth"
    ],
    "related_topics": [
        "Sentence",
        "Meaning (existential)",
        "Discriminative model"
    ],
    "citation_count": "1,089",
    "reference_count": "27",
    "references": [
        "2142194269",
        "2120419212",
        "1666447063",
        "1647729745",
        "2119775030",
        "1532257412",
        "2502277634",
        "2106624428",
        "2147625498",
        "2046589395"
    ]
},{
    "id": "2066134726",
    "title": "Baby talk: Understanding and generating simple image descriptions",
    "abstract": "We posit that visually descriptive language offers computer vision researchers both information about the world, and information about how people describe the world. The potential benefit from this source is made more significant due to the enormous amount of language data easily available today. We present a system to automatically generate natural language descriptions from images that exploits both statistics gleaned from parsing large quantities of text data and recognition algorithms from computer vision. The system is very effective at producing relevant sentences for images. It also generates descriptions that are notably more true to the specific image content than previous work.",
    "date": "2011",
    "authors": [
        "Girish Kulkarni",
        "Visruth Premraj",
        "Sagnik Dhar",
        "Siming Li",
        "Yejin Choi",
        "Alexander C Berg",
        "Tamara L Berg"
    ],
    "related_topics": [
        "Natural language",
        "Parsing",
        "Baby talk"
    ],
    "citation_count": "628",
    "reference_count": "50",
    "references": [
        "2108598243",
        "2101105183",
        "2145607950",
        "2536626143",
        "2098411764",
        "2134270519",
        "2054279472",
        "2137471889",
        "1897761818",
        "2109586012"
    ]
},{
    "id": "2253807446",
    "title": "Building high-level features using large scale unsupervised learning",
    "abstract": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images using unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200\u00d7200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.",
    "date": "2012",
    "authors": [
        "Marc'aurelio Ranzato",
        "Rajat Monga",
        "Matthieu Devin",
        "Kai Chen",
        "Greg Corrado",
        "Jeff Dean",
        "Quoc V. Le",
        "Andrew Y. Ng"
    ],
    "related_topics": [
        "Autoencoder",
        "Unsupervised learning",
        "Normalization (image processing)"
    ],
    "citation_count": "2,588",
    "reference_count": "36",
    "references": [
        "2108598243",
        "2136922672",
        "3118608800",
        "2310919327",
        "2100495367",
        "2546302380",
        "2110798204",
        "1782590233",
        "2130325614",
        "2053229256"
    ]
},{
    "id": "2098411764",
    "title": "Describing objects by their attributes",
    "abstract": "We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (\u201cspotty dog\u201d, not just \u201cdog\u201d); to say something about unfamiliar objects (\u201chairy and four-legged\u201d, not just \u201cunknown\u201d); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (\u201cspotty\u201d) or discriminative (\u201cdogs have it but sheep do not\u201d). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework.",
    "date": "2009",
    "authors": [
        "Ali Farhadi",
        "Ian Endres",
        "Derek Hoiem",
        "David Forsyth"
    ],
    "related_topics": [
        "Identity (object-oriented programming)",
        "3D single-object recognition",
        "Object (philosophy)"
    ],
    "citation_count": "2,010",
    "reference_count": "22",
    "references": [
        "2161969291",
        "2131846894",
        "2154422044",
        "2120419212",
        "2134270519",
        "2108082645",
        "2149489787",
        "2914746235",
        "2171188998",
        "2004915807"
    ]
},{
    "id": "2101234009",
    "title": "Scikit-learn: Machine Learning in Python",
    "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",
    "date": "2011",
    "authors": [
        "Fabian Pedregosa",
        "Ga\u00ebl Varoquaux",
        "Alexandre Gramfort",
        "Vincent Michel",
        "Bertrand Thirion",
        "Olivier Grisel",
        "Mathieu Blondel",
        "Peter Prettenhofer",
        "Ron Weiss",
        "Vincent Dubourg",
        "Jake Vanderplas",
        "Alexandre Passos",
        "David Cournapeau",
        "Matthieu Brucher",
        "Matthieu Perrot",
        "\u00c9douard Duchesnay"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Python (programming language)",
        "Instance-based learning"
    ],
    "citation_count": "40,587",
    "reference_count": "13",
    "references": [
        "2153635508",
        "2097360283",
        "2118585731",
        "2063978378",
        "2146292423",
        "2047804403",
        "2035776949",
        "2097850441",
        "2040387238",
        "1571024744"
    ]
},{
    "id": "2135957164",
    "title": "Graph-Based Visual Saliency",
    "abstract": "A new bottom-up visual saliency model, Graph-Based Visual Saliency (GBVS), is proposed. It consists of two steps: first forming activation maps on certain feature channels, and then normalizing them in a way which highlights conspicuity and admits combination with other maps. The model is simple, and biologically plausible insofar as it is naturally parallelized. This model powerfully predicts human fixations on 749 variations of 108 natural images, achieving 98% of the ROC area of a human-based control, whereas the classical algorithms of Itti & Koch ([2], [3], [4]) achieve only 84%.",
    "date": "2006",
    "authors": [
        "Jonathan Harel",
        "Christof Koch",
        "Pietro Perona"
    ],
    "related_topics": [
        "Kadir\u2013Brady saliency detector",
        "Graph (abstract data type)",
        "Computer vision"
    ],
    "citation_count": "3,920",
    "reference_count": "13",
    "references": [
        "2128272608",
        "2139047169",
        "2054802006",
        "2156595177",
        "1969258103",
        "2119228922",
        "2115738369",
        "2117301471",
        "2014558261",
        "1533198222"
    ]
},{
    "id": "1511924373",
    "title": "Studying aesthetics in photographic images using a computational approach",
    "abstract": "Aesthetics, in the world of art and photography, refers to the principles of the nature and appreciation of beauty. Judging beauty and other aesthetic qualities of photographs is a highly subjective task. Hence, there is no unanimously agreed standard for measuring aesthetic value. In spite of the lack of firm rules, certain features in photographic images are believed, by many, to please humans more than certain others. In this paper, we treat the challenge of automatically inferring aesthetic quality of pictures using their visual content as a machine learning problem, with a peer-rated online photo sharing Website as data source. We extract certain visual features based on the intuition that they can discriminate between aesthetically pleasing and displeasing images. Automated classifiers are built using support vector machines and classification trees. Linear regression on polynomial terms of the features is also applied to infer numerical aesthetics ratings. The work attempts to explore the relationship between emotions which pictures arouse in people, and their low-level content. Potential applications include content-based image retrieval and digital photography.",
    "date": "2006",
    "authors": [
        "Ritendra Datta",
        "Dhiraj Joshi",
        "Jia Li",
        "James Z. Wang"
    ],
    "related_topics": [
        "Photography",
        "Beauty",
        "Rule of thirds"
    ],
    "citation_count": "1,223",
    "reference_count": "25",
    "references": [
        "2156909104",
        "2062024414",
        "1594031697",
        "2130660124",
        "740415",
        "2125148312",
        "2143668817",
        "2137471889",
        "2109868644",
        "2135705692"
    ]
},{
    "id": "2075456404",
    "title": "Large-scale visual sentiment ontology and detectors using adjective noun pairs",
    "abstract": "We address the challenge of sentiment analysis from visual content. In contrast to existing methods which infer sentiment or emotion directly from visual low-level features, we propose a novel approach based on understanding of the visual concepts that are strongly related to sentiments. Our key contribution is two-fold: first, we present a method built upon psychological theories and web mining to automatically construct a large-scale Visual Sentiment Ontology (VSO) consisting of more than 3,000 Adjective Noun Pairs (ANP). Second, we propose SentiBank, a novel visual concept detector library that can be used to detect the presence of 1,200 ANPs in an image. The VSO and SentiBank are distinct from existing work and will open a gate towards various applications enabled by automatic sentiment analysis. Experiments on detecting sentiment of image tweets demonstrate significant improvement in detection accuracy when comparing the proposed SentiBank based predictors with the text-based approaches. The effort also leads to a large publicly available resource consisting of a visual sentiment ontology, a large detector library, and the training/testing benchmark for visual sentiment analysis.",
    "date": "2013",
    "authors": [
        "Damian Borth",
        "Rongrong Ji",
        "Tao Chen",
        "Thomas Breuel",
        "Shih-Fu Chang"
    ],
    "related_topics": [
        "Sentiment analysis",
        "Ontology (information science)",
        "Web mining"
    ],
    "citation_count": "602",
    "reference_count": "47",
    "references": [
        "2108598243",
        "2031489346",
        "2097726431",
        "2171468534",
        "1566135517",
        "1590495275",
        "2022204871",
        "2122369144",
        "38739846",
        "2139043937"
    ]
},{
    "id": "2078807908",
    "title": "AVA: A large-scale database for aesthetic visual analysis",
    "abstract": "With the ever-expanding volume of visual content available, the ability to organize and navigate such content by aesthetic preference is becoming increasingly important. While still in its nascent stage, research into computational models of aesthetic preference already shows great potential. However, to advance research, realistic, diverse and challenging databases are needed. To this end, we introduce a new large-scale database for conducting Aesthetic Visual Analysis: AVA. It contains over 250,000 images along with a rich variety of meta-data including a large number of aesthetic scores for each image, semantic labels for over 60 categories as well as labels related to photographic style. We show the advantages of AVA with respect to existing databases in terms of scale, diversity, and heterogeneity of annotations. We then describe several key insights into aesthetic preference afforded by AVA. Finally, we demonstrate, through three applications, how the large scale of AVA can be leveraged to improve performance on existing preference tasks.",
    "date": "2012",
    "authors": [
        "Naila Murray",
        "Luca Marchesotti",
        "Florent Perronnin"
    ],
    "related_topics": [
        "Preference",
        "Visualization",
        "Data science"
    ],
    "citation_count": "583",
    "reference_count": "19",
    "references": [
        "2151103935",
        "2108598243",
        "2031489346",
        "1576445103",
        "1606858007",
        "2166049352",
        "2147238549",
        "1511924373",
        "2170658603",
        "2104915826"
    ]
},{
    "id": "3124955340",
    "title": "A Decision Theoretic Generalization of On-Line Learning and an Application to Boosting",
    "abstract": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.",
    "date": "2010",
    "authors": [
        "Y. Freund",
        "R. Schapire"
    ],
    "related_topics": [
        "Boosting (machine learning)",
        "Generalization",
        "Bounded function"
    ],
    "citation_count": "28,701",
    "reference_count": "0",
    "references": []
},{
    "id": "2128272608",
    "title": "A model of saliency-based visual attention for rapid scene analysis",
    "abstract": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.",
    "date": "1998",
    "authors": [
        "L. Itti",
        "C. Koch",
        "E. Niebur"
    ],
    "related_topics": [
        "Kadir\u2013Brady saliency detector",
        "Salience (neuroscience)",
        "Visual search"
    ],
    "citation_count": "12,635",
    "reference_count": "16",
    "references": [
        "2093353037",
        "2149095485",
        "1486735428",
        "2160903697",
        "2089597841",
        "1497599070",
        "2152752164",
        "2115441154",
        "1502980253",
        "2142768220"
    ]
},{
    "id": "2159686933",
    "title": "Example-based learning for view-based human face detection",
    "abstract": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.",
    "date": "1997",
    "authors": [
        "K.-K. Sung",
        "T. Poggio"
    ],
    "related_topics": [
        "Feature vector",
        "Face detection",
        "Object detection"
    ],
    "citation_count": "2,873",
    "reference_count": "17",
    "references": [
        "2138451337",
        "3017143921",
        "2098947662",
        "2113341759",
        "2135463994",
        "2125848778",
        "2104671481",
        "1554705102",
        "1532977286",
        "1571461735"
    ]
},{
    "id": "2101522199",
    "title": "Joint induction of shape features and tree classifiers",
    "abstract": "We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically and weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classified handwritten digits from the NIST database; the error rate was 0.7 percent.",
    "date": "1997",
    "authors": [
        "Y. Amit",
        "D. Geman",
        "K. Wilder"
    ],
    "related_topics": [
        "Affine transformation",
        "Feature extraction",
        "Invariant (mathematics)"
    ],
    "citation_count": "265",
    "reference_count": "26",
    "references": [
        "2912934387",
        "1594031697",
        "2087347434",
        "2120240539",
        "1676820704",
        "2154579312",
        "2102734279",
        "2168228682",
        "2100659887",
        "1530454533"
    ]
},{
    "id": "3146003712",
    "title": "Statistical Pattern Recognition",
    "abstract": "Introduction to statistical pattern recognition * Estimation * Density estimation * Linear discriminant analysis * Nonlinear discriminant analysis - neural networks * Nonlinear discriminant analysis - statistical methods * Classification trees * Feature selection and extraction * Clustering * Additional topics * Measures of dissimilarity * Parameter estimation * Linear algebra * Data * Probability theory.",
    "date": "1999",
    "authors": [
        "Andrew R. Webb"
    ],
    "related_topics": [
        "Linear discriminant analysis",
        "Density estimation",
        "Cluster analysis"
    ],
    "citation_count": "2,839",
    "reference_count": "0",
    "references": []
},{
    "id": "1594031697",
    "title": "Classification and regression trees",
    "abstract": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index.",
    "date": "1982",
    "authors": [
        "Leo Breiman",
        "Jerome H Friedman",
        "Richard A Olshen",
        "Charles J Stone"
    ],
    "related_topics": [
        "Classification Tree Method",
        "Pruning (decision trees)",
        "Decision tree learning"
    ],
    "citation_count": "51,566",
    "reference_count": "24",
    "references": [
        "2011039300",
        "3017143921",
        "2022554507",
        "2127218421",
        "2583466288",
        "2164240509",
        "2123838014",
        "1976123439",
        "2150418026",
        "1970074386"
    ]
},{
    "id": "2158940042",
    "title": "Ideal spatial adaptation by wavelet shrinkage",
    "abstract": "SUMMARY With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, piecewise polynomial, variable knot spline, or variable bandwidth kernel, to the unknown function. Estimation with the aid of an oracle offers dramatic advantages over traditional linear estimation by nonadaptive kernels; however, it is a priori unclear whether such performance can be obtained by a procedure relying on the data alone. We describe a new principle for spatially-adaptive estimation: selective wavelet reconstruction. We show that variable-knot spline fits and piecewise-polynomial fits, when equipped with an oracle to select the knots, are not dramatically more powerful than selective wavelet reconstruction with an oracle. We develop a practical spatially adaptive method, RiskShrink, which works by shrinkage of empirical wavelet coefficients. RiskShrink mimics the performance of an oracle for selective wavelet reconstruction as well as it is possible to do so. A new inequality in multivariate normal decision theory which we call the oracle inequality shows that attained performance differs from ideal performance by at most a factor of approximately 2 log n, where n is the sample size. Moreover no estimator can give a better guarantee than this. Within the class of spatially adaptive procedures, RiskShrink is essentially optimal. Relying only on the data, it comes within a factor log 2 n of the performance of piecewise polynomial and variableknot spline methods equipped with an oracle. In contrast, it is unknown how or if piecewise polynomial methods could be made to function this well when denied access to an oracle and forced to rely on data alone.",
    "date": "1994",
    "authors": [
        "David L Donoho",
        "Iain M Johnstone"
    ],
    "related_topics": [
        "Piecewise",
        "Oracle",
        "Spline (mathematics)"
    ],
    "citation_count": "14,549",
    "reference_count": "15",
    "references": [
        "2062024414",
        "2098914003",
        "1489213177",
        "2102201073",
        "1969423031",
        "3132971798",
        "654435104",
        "2797502950",
        "2024599390",
        "2140832824"
    ]
},{
    "id": "2797583072",
    "title": "Generalized Additive Models.",
    "abstract": "",
    "date": "1991",
    "authors": [
        "R. A. Brown",
        "T. J. Hastie",
        "R. J. Tibshirani"
    ],
    "related_topics": [
        "Generalized additive model for location, scale and shape",
        "Generalized additive model",
        "Backfitting algorithm"
    ],
    "citation_count": "12,808",
    "reference_count": "0",
    "references": []
},{
    "id": "2106706098",
    "title": "Reversible jump Markov chain Monte Carlo computation and Bayesian model determination",
    "abstract": "Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.",
    "date": "1995",
    "authors": [
        "Peter J. Green"
    ],
    "related_topics": [
        "Reversible-jump Markov chain Monte Carlo",
        "Markov chain Monte Carlo",
        "Variable-order Bayesian network"
    ],
    "citation_count": "7,169",
    "reference_count": "22",
    "references": [
        "1997063559",
        "2116044718",
        "2136796925",
        "1988684120",
        "2111051773",
        "1582801283",
        "1555683961",
        "2138309709",
        "1989457171",
        "2171166366"
    ]
},{
    "id": "2102201073",
    "title": "Multivariate Adaptive Regression Splines",
    "abstract": "A new method is presented for flexible regression modeling of high dimensional data. The model takes the form of an expansion in product spline basis functions, where the number of basis functions as well as the parameters associated with each one (product degree and knot locations) are automatically determined by the data. This procedure is motivated by the recursive partitioning approach to regression and shares its attractive properties. Unlike recursive partitioning, however, this method produces continuous models with continuous derivatives. It has more power and flexibility to model relationships that are nearly additive or involve interactions in at most a few variables. In addition, the model can be represented in a form that separately identifies the additive contributions and those associated with the different multivariable interactions.",
    "date": "1991",
    "authors": [
        "Jerome H. Friedman"
    ],
    "related_topics": [
        "Multivariate adaptive regression splines",
        "Nonparametric regression",
        "Recursive partitioning"
    ],
    "citation_count": "9,077",
    "reference_count": "31",
    "references": [
        "2798909945",
        "1594031697",
        "2146766088",
        "2162870748",
        "2017977879",
        "133977063",
        "2091886411",
        "2040615655",
        "3000332379",
        "2082102453"
    ]
},{
    "id": "2117897510",
    "title": "Bootstrap Methods: Another Look at the Jackknife",
    "abstract": "We discuss the following problem given a random sample X = (X 1, X 2,\u2026, X n) from an unknown probability distribution F, estimate the sampling distribution of some prespecified random variable R(X, F), on the basis of the observed data x. (Standard jackknife theory gives an approximate mean and variance in the case R(X, F) = \\(\\theta \\left( {\\hat F} \\right) - \\theta \\left( F \\right)\\), \u03b8 some parameter of interest.) A general method, called the \u201cbootstrap\u201d, is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.",
    "date": "1978",
    "authors": [
        "Bradley Efron"
    ],
    "related_topics": [
        "Jackknife resampling",
        "Random variable",
        "Sampling distribution"
    ],
    "citation_count": "27,546",
    "reference_count": "14",
    "references": [
        "2063698478",
        "1981492171",
        "2324309783",
        "2079100340",
        "1989584148",
        "2061905897",
        "2033260623",
        "1971382239",
        "1528761061",
        "2069645522"
    ]
},{
    "id": "191129667",
    "title": "Wavelet Shrinkage: Asymptopia?",
    "abstract": "Much recent effort has sought asymptotically minimax methods for recovering infinite dimensional objects-curves, densities, spectral densities, images-from noisy data. A now rich and complex body of work develops nearly or exactly minimax estimators for an array of interesting problems. Unfortunately, the results have rarely moved into practice, for a variety of reasons-among them being similarity to known methods, computational intractability and lack of spatial adaptivity. We discuss a method for curve estimation based on n noisy data: translate the empirical wavelet coefficients towards the origin by an amount \u221a(2 log n) /\u221an. The proposal differs from those in current use, is computationally practical and is spatially adaptive; it thus avoids several of the previous objections. Further, the method is nearly minimax both for a wide variety of loss functions-pointwise error, global error measured in L p -norms, pointwise and global error in estimation of derivatives-and for a wide range of smoothness classes, including standard Holder and Sobolev classes, and bounded variation. This is a much broader near optimality than anything previously proposed: we draw loose parallels with near optimality in robustness and also with the broad near eigenfunction properties of wavelets themselves. Finally, the theory underlying the method is interesting, as it exploits a correspondence between statistical questions and questions of optimal recovery and information-based complexity",
    "date": "1995",
    "authors": [
        "David L. Donoho",
        "Iain M. Johnstone",
        "G\u00e9rard Kerkyacharian",
        "Dominique Picard"
    ],
    "related_topics": [
        "Minimax",
        "Pointwise",
        "Wavelet"
    ],
    "citation_count": "2,736",
    "reference_count": "41",
    "references": [
        "2132984323",
        "2146842127",
        "2158940042",
        "2151693816",
        "2079724595",
        "2102201073",
        "2033484654",
        "654435104",
        "2092543127",
        "2013987111"
    ]
},{
    "id": "2954064014",
    "title": "Practical Optimization",
    "abstract": "",
    "date": "1981",
    "authors": [
        "Philip E. Gill"
    ],
    "related_topics": [
        "Computer science"
    ],
    "citation_count": "12,592",
    "reference_count": "0",
    "references": []
},{
    "id": "2007069447",
    "title": "Variable selection via Gibbs sampling",
    "abstract": "Abstract A crucial problem in building a multiple regression model is the selection of predictors to include. The main thrust of this article is to propose and develop a procedure that uses probabilistic considerations for selecting promising subsets. This procedure entails embedding the regression setup in a hierarchical normal mixture model where latent variables are used to identify subset choices. In this framework the promising subsets of predictors can be identified as those with higher posterior probability. The computational burden is then alleviated by using the Gibbs sampler to indirectly sample from this multinomial posterior distribution on the set of possible subset choices. Those subsets with higher probability\u2014the promising ones\u2014can then be identified by their more frequent appearance in the Gibbs sample.",
    "date": "1993",
    "authors": [
        "Edward I. George",
        "Robert E. McCulloch"
    ],
    "related_topics": [
        "Gibbs sampling",
        "Mixture model",
        "Posterior probability"
    ],
    "citation_count": "3,046",
    "reference_count": "22",
    "references": [
        "2083875149",
        "2163738067",
        "1969423031",
        "2319794630",
        "2034562813",
        "2152977846",
        "2022480405",
        "2111051773",
        "2797502950",
        "2046811824"
    ]
},{
    "id": "1746819321",
    "title": "Gaussian Processes for Machine Learning",
    "abstract": "A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.",
    "date": "2005",
    "authors": [
        "Carl Edward Rasmussen",
        "Christopher K I Williams"
    ],
    "related_topics": [
        "Active learning (machine learning)",
        "Semi-supervised learning",
        "Instance-based learning"
    ],
    "citation_count": "23,612",
    "reference_count": "179",
    "references": [
        "2296319761",
        "2156909104",
        "2148603752",
        "2170120409",
        "1554663460",
        "2117812871",
        "3140968660",
        "3023786531",
        "2798909945",
        "2078206416"
    ]
},{
    "id": "2097998348",
    "title": "Random search for hyper-parameter optimization",
    "abstract": "Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent \"High Throughput\" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.",
    "date": "2012",
    "authors": [
        "James Bergstra",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Beam search",
        "Best-first search",
        "Random search"
    ],
    "citation_count": "5,826",
    "reference_count": "35",
    "references": [
        "2153635508",
        "2136922672",
        "2310919327",
        "1746819321",
        "1554663460",
        "1533861849",
        "2072128103",
        "2025768430",
        "2581275558",
        "44815768"
    ]
},{
    "id": "2106411961",
    "title": "Algorithms for Hyper-Parameter Optimization",
    "abstract": "Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.",
    "date": "2011",
    "authors": [
        "James S. Bergstra",
        "R\u00e9mi Bardenet",
        "Yoshua Bengio",
        "Bal\u00e1zs K\u00e9gl"
    ],
    "related_topics": [
        "Bayesian optimization",
        "Random search",
        "Feature learning"
    ],
    "citation_count": "2,580",
    "reference_count": "20",
    "references": [
        "2136922672",
        "2310919327",
        "1746819321",
        "1554663460",
        "2145094598",
        "2097998348",
        "2118858186",
        "2123649031",
        "1994197834",
        "2144161366"
    ]
},{
    "id": "2951665052",
    "title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design",
    "abstract": "Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.",
    "date": "2010",
    "authors": [
        "Niranjan Srinivas",
        "Andreas Krause",
        "Matthias Seeger",
        "Sham M. Kakade"
    ],
    "related_topics": [
        "Regret",
        "Multi-armed bandit",
        "Bayesian optimization"
    ],
    "citation_count": "1,387",
    "reference_count": "32",
    "references": [
        "1746819321",
        "2099111195",
        "2168405694",
        "1625390266",
        "1510052597",
        "2168464387",
        "2146766088",
        "2099201756",
        "50486269",
        "2108114251"
    ]
},{
    "id": "60686164",
    "title": "Sequential model-based optimization for general algorithm configuration",
    "abstract": "State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.",
    "date": "2011",
    "authors": [
        "Frank Hutter",
        "Holger H. Hoos",
        "Kevin Leyton-Brown"
    ],
    "related_topics": [
        "Local search (optimization)",
        "Solver",
        "Integer programming"
    ],
    "citation_count": "1,824",
    "reference_count": "25",
    "references": [
        "2911964244",
        "1480376833",
        "1510052597",
        "2147148915",
        "2005059149",
        "1533856049",
        "3016663334",
        "2435432491",
        "1499307573",
        "2141363466"
    ]
},{
    "id": "2165599843",
    "title": "Online Learning for Latent Dirichlet Allocation",
    "abstract": "We develop an online variational Bayes (VB) algorithm for Latent Dirichlet Allocation (LDA). Online LDA is based on online stochastic optimization with a natural gradient step, which we show converges to a local optimum of the VB objective function. It can handily analyze massive document collections, including those arriving in a stream. We study the performance of online LDA in several ways, including by fitting a 100-topic topic model to 3.3M articles from Wikipedia in a single pass. We demonstrate that online LDA finds topic models as good or better than those found with batch VB, and in a fraction of the time.",
    "date": "2010",
    "authors": [
        "Matthew Hoffman",
        "Francis R. Bach",
        "David M. Blei"
    ],
    "related_topics": [
        "Latent Dirichlet allocation",
        "Topic model",
        "Stochastic optimization"
    ],
    "citation_count": "1,723",
    "reference_count": "26",
    "references": [
        "1880262756",
        "2001082470",
        "2049633694",
        "2112447569",
        "1516111018",
        "1536929369",
        "2159426623",
        "2113651538",
        "2567948266",
        "2172085063"
    ]
},{
    "id": "2099201756",
    "title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning",
    "abstract": "We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.",
    "date": "2010",
    "authors": [
        "Eric Brochu",
        "Vlad M. Cora",
        "Nando de Freitas"
    ],
    "related_topics": [
        "Bayesian optimization",
        "Reinforcement learning",
        "Bayesian probability"
    ],
    "citation_count": "1,909",
    "reference_count": "75",
    "references": [
        "2100495367",
        "2121863487",
        "2903158431",
        "2018044188",
        "1510052597",
        "1576452626",
        "2951665052",
        "2041946752",
        "2131824593",
        "2109910161"
    ]
},{
    "id": "1973333099",
    "title": "Bayesian Calibration of computer models",
    "abstract": "We consider prediction and uncertainty analysis for systems which are approximated using complex mathematical models. Such models, implemented as computer codes, are often generic in the sense that by a suitable choice of some of the model's input parameters the code can be used to predict the behaviour of the system in a variety of specific applications. However, in any specific application the values of necessary parameters may be unknown. In this case, physical observations of the system in the specific context are used to learn about the unknown parameters. The process of fitting the model to the observed data by adjusting the parameters is known as calibration. Calibration is typically effected by ad hoc fitting, and after calibration the model is used, with the fitted input values, to predict the future behaviour of the system. We present a Bayesian calibration technique which improves on this traditional approach in two respects. First, the predictions allow for all sources of uncertainty, including the remaining uncertainty over the fitted parameters. Second, they attempt to correct for any inadequacy of the model which is revealed by a discrepancy between the observed data and the model predictions from even the best-fitting parameter values. The method is illustrated by using data from a nuclear radiation release at Tomsk, and from a more complex simulated nuclear accident exercise.",
    "date": "2000",
    "authors": [
        "Marc C. Kennedy",
        "Anthony O'Hagan"
    ],
    "related_topics": [
        "Calibration (statistics)",
        "Uncertainty analysis",
        "Gaussian process emulator"
    ],
    "citation_count": "3,480",
    "reference_count": "63",
    "references": [
        "2018044188",
        "2038669746",
        "2143022286",
        "1567512734",
        "2027792629",
        "2033900415",
        "999207820",
        "1585773866",
        "1977046327",
        "2026645785"
    ]
},{
    "id": "1998042868",
    "title": "End-to-end scene text recognition",
    "abstract": "This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition.",
    "date": "2011",
    "authors": [
        "Kai Wang",
        "Boris Babenko",
        "Serge Belongie"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Intelligent character recognition",
        "Optical character recognition"
    ],
    "citation_count": "958",
    "reference_count": "21",
    "references": [
        "2161969291",
        "1663973292",
        "2168356304",
        "2164598857",
        "2031489346",
        "2030536784",
        "2142159465",
        "2100588357",
        "2148596671",
        "1488125194"
    ]
},{
    "id": "2132424367",
    "title": "Deep, big, simple neural nets for handwritten digit recognition",
    "abstract": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.",
    "date": "2010",
    "authors": [
        "Dan Claudiu Cire\u015fan",
        "Ueli Meier",
        "Luca Maria Gambardella",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "MNIST database",
        "Artificial neural network",
        "Overfitting"
    ],
    "citation_count": "1,212",
    "reference_count": "24",
    "references": [
        "2310919327",
        "2100495367",
        "2064675550",
        "2122410182",
        "2110798204",
        "1652505363",
        "2156163116",
        "2029949252",
        "2139427956",
        "2172174689"
    ]
},{
    "id": "2030723843",
    "title": "The interior-point revolution in optimization: History, recent developments, and lasting consequences",
    "abstract": "Interior methods are a pervasive feature of the optimization landscape today, but it was not always so. Although interior-point techniques, primarily in the form of barrier methods, were widely used during the 1960s for problems with nonlinear constraints, their use for the fundamental problem of linear programming was unthinkable because of the total dominance of the simplex method. During the 1970s, barrier methods were superseded, nearly to the point of oblivion, by newly emerging and seemingly more efficient alternatives such as augmented Lagrangian and sequential quadratic programming methods. By the early 1980s, barrier methods were almost universally regarded as a closed chapter in the history of optimization. This picture changed dramatically in 1984, when Narendra Karmarkar announced a fast polynomial-time interior method for linear programming; in 1985, a formal connection was established between his method and classical barrier methods. Since then, interior methods have continued to transform both the theory and practice of constrained optimization. We present a condensed, unavoidably incomplete look at classical material and recent research about interior methods.",
    "date": "2004",
    "authors": [
        "Margaret H. Wright"
    ],
    "related_topics": [
        "Interior point method",
        "Second-order cone programming",
        "Linear programming"
    ],
    "citation_count": "333",
    "reference_count": "49",
    "references": [
        "2798766386",
        "2077658674",
        "2099839128",
        "2912522929",
        "2611147814",
        "1985123706",
        "2954064014",
        "1963547452",
        "2041684917",
        "1632601927"
    ]
},{
    "id": "2000296233",
    "title": "Primal-dual algorithms and infinite-dimensional Jordan algebras of finite rank",
    "abstract": "We consider primal-dual algorithms for certain types of infinite-dimensional optimization problems. Our approach is based on the generalization of the technique of finite-dimensional Euclidean Jordan algebras to the case of infinite-dimensional JB-algebras of finite rank. This generalization enables us to develop polynomial-time primal-dual algorithms for ``infinite-dimensional second-order cone programs.'' We consider as an example a long-step primal-dual algorithm based on the Nesterov-Todd direction. It is shown that this algorithm can be generalized along with complexity estimates to the infinite-dimensional situation under consideration. An application is given to an important problem of control theory: multi-criteria analytic design of the linear regulator. The calculation of the Nesterov-Todd direction requires in this case solving one matrix differential Riccati equation plus solving a finite-dimensional system of linear algebraic equations on each iteration. The number of equations and unknown variables of this algebraic system is m+1, where m is a number of quadratic performance criteria.",
    "date": "2003",
    "authors": [
        "Leonid Faybusovich",
        "Takashi Tsuchiya"
    ],
    "related_topics": [
        "Rank (linear algebra)",
        "Linear-quadratic regulator",
        "Riccati equation"
    ],
    "citation_count": "30",
    "reference_count": "16",
    "references": [
        "2020830442",
        "2006980285",
        "82689443",
        "10800830",
        "2117065890",
        "1981027849",
        "2016700492",
        "2042592476",
        "1543242366",
        "2004747456"
    ]
},{
    "id": "2006980285",
    "title": "Linear systems in Jordan algebras and primal-dual interior-point algorithms",
    "abstract": "We discuss a possibility of the extension of a primal-dual interior-point algorithm suggested recently by Alizadeh et al. (1994). We consider optimization problems defined on the intersection of a symmetric cone and an affine subspace. The question of solvability of a linear system arising in the implementation of the primal-dual algorithm is analyzed. A nondegeneracy theory for the considered class of problems is developed. The Jordan algebra technique suggested by Faybusovich (1995) plays major role in the present paper.",
    "date": "1997",
    "authors": [
        "Leonid Faybusovich"
    ],
    "related_topics": [
        "Jordan algebra",
        "Interior point method",
        "Affine space"
    ],
    "citation_count": "282",
    "reference_count": "7",
    "references": [
        "10800830",
        "2012110988",
        "1980610004",
        "1484725137",
        "576051538",
        "2040773875",
        "1506692979"
    ]
},{
    "id": "82689443",
    "title": "Euclidean Jordan Algebras and Interior-point Algorithms",
    "abstract": "We provide an introduction to the theory of interior-point algorithms of optimization based on the theory of Euclidean Jordan algebras. A short-step path-following algorithm for the convex quadratic problem on the domain, obtained as the intersection of a symmetric cone with an affine subspace, is considered. Connections with the Linear monotone complementarity problem are discussed. Complexity estimates in terms of the rank of the corresponding Jordan algebra are obtained. Necessary results from the theory of Euclidean Jordan algebras are presented.",
    "date": "1997",
    "authors": [
        "Leonid Faybusovich"
    ],
    "related_topics": [
        "Jordan algebra",
        "Jordan matrix",
        "Affine space"
    ],
    "citation_count": "266",
    "reference_count": "11",
    "references": [
        "2006980285",
        "10800830",
        "1518039036",
        "2075379600",
        "1484725137",
        "576051538",
        "1538534850",
        "2021530792",
        "1971195964",
        "1524254951"
    ]
},{
    "id": "2611147814",
    "title": "A new polynomial-time algorithm for linear programming",
    "abstract": "We present a new polynomial-time algorithm for linear programming. In the worst case, the algorithm requiresO(n 3.5 L) arithmetic operations onO(L) bit numbers, wheren is the number of variables andL is the number of bits in the input. The running-time of this algorithm is better than the ellipsoid algorithm by a factor ofO(n 2.5). We prove that given a polytopeP and a strictly interior point a eP, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property. The ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to the radius of the largest sphere with center a\u2032 contained inP\u2032 isO(n). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial time.",
    "date": "1984",
    "authors": [
        "N. Karmarkar"
    ],
    "related_topics": [
        "Criss-cross algorithm",
        "Simplex algorithm",
        "Karmarkar's algorithm"
    ],
    "citation_count": "7,061",
    "reference_count": "6",
    "references": [
        "2012329067",
        "2033040247",
        "2127470768",
        "2026745357",
        "1571051474",
        "3026407818"
    ]
},{
    "id": "2118202495",
    "title": "Practical statistics for medical research",
    "abstract": "Most medical researchers, whether clinical or non-clinical, receive some background in statistics as undergraduates. However, it is most often brief, a long time ago, and largely forgotten by the time it is needed. Furthermore, many introductory texts fall short of adequately explaining the underlying concepts of statistics, and often are divorced from the reality of conducting and assessing medical research. Practical Statistics for Medical Research is a problem-based text for medical researchers, medical students, and others in the medical arena who need to use statistics but have no specialized mathematics background. The author draws on twenty years of experience as a consulting medical statistician to provide clear explanations to key statistical concepts, with a firm emphasis on practical aspects of designing and analyzing medical research. The text gives special attention to the presentation and interpretation of results and the many real problems that arise in medical research",
    "date": "2006",
    "authors": [
        "Douglas G. Altman"
    ],
    "related_topics": [
        "Medical statistics",
        "Statistician",
        "Medical research"
    ],
    "citation_count": "23,091",
    "reference_count": "0",
    "references": []
},{
    "id": "2098162425",
    "title": "An algorithm for suffix stripping",
    "abstract": "The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL. Although simple, it performs slightly better than a much more elaborate system with which it has been compared. It effectively works by treating complex suffixes as compounds made up of simple suffixes, and removing the simple suffixes in a number of steps. In each step the removal of the suffix is made to depend upon the form of the remaining stem, which usually involves a measure of its syllable length.",
    "date": "1997",
    "authors": [
        "M. F. Porter"
    ],
    "related_topics": [
        "Suffix",
        "Stemming",
        "Stripping (linguistics)"
    ],
    "citation_count": "13,910",
    "reference_count": "4",
    "references": [
        "26591655",
        "1495821370",
        "1988344511",
        "2005095359"
    ]
},{
    "id": "2435251607",
    "title": "A Comparative Study on Feature Selection in Text Categorization",
    "abstract": "",
    "date": "1997",
    "authors": [
        "Yiming Yang",
        "Jan O. Pedersen"
    ],
    "related_topics": [
        "Feature selection",
        "k-nearest neighbors algorithm",
        "Machine learning"
    ],
    "citation_count": "7,627",
    "reference_count": "0",
    "references": []
},{
    "id": "2114535528",
    "title": "An Evaluation of Statistical Approaches to Text Categorization",
    "abstract": "This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performances except for a Naive Bayes approach, the other learning algorithms also performed relatively well.",
    "date": "1999",
    "authors": [
        "Yiming Yang"
    ],
    "related_topics": [
        "Naive Bayes classifier",
        "Text processing",
        "Natural language processing"
    ],
    "citation_count": "3,124",
    "reference_count": "21",
    "references": [
        "2149706766",
        "2435251607",
        "1956559956",
        "1833785989",
        "1969572066",
        "2060216474",
        "2063198646",
        "1983078185",
        "1986913017",
        "2071664212"
    ]
},{
    "id": "2005422315",
    "title": "A re-examination of text categorization methods",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Yiming Yang",
        "Xin Liu"
    ],
    "related_topics": [
        "Natural language processing",
        "Machine learning",
        "Computer science"
    ],
    "citation_count": "4,131",
    "reference_count": "27",
    "references": [
        "2156909104",
        "2119821739",
        "2149684865",
        "2435251607",
        "2114535528",
        "1550206324",
        "2164641162",
        "2137346077",
        "1620204465",
        "1969572066"
    ]
},{
    "id": "2000672666",
    "title": "Improving Retrieval Performance by Relevance Feedback",
    "abstract": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback.",
    "date": "1997",
    "authors": [
        "Gerard Salton",
        "Chris Buckley"
    ],
    "related_topics": [
        "Relevance feedback",
        "Relevance (information retrieval)",
        "Document retrieval"
    ],
    "citation_count": "2,055",
    "reference_count": "17",
    "references": [
        "1978394996",
        "2043909051",
        "2019087979",
        "2164547069",
        "2026937586",
        "120261275",
        "2053039612",
        "2030350774",
        "2174678383",
        "1555286071"
    ]
},{
    "id": "1620204465",
    "title": "Hierarchically Classifying Documents Using Very Few Words",
    "abstract": "The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies. One can use existing classifiers by ignoring the hierarchical structure, treating the topics as separate classes. Unfortunately, in the context of text categorization, we are faced with a large number of classes and a huge number of relevant features needed to distinguish between them. Consequently, we are restricted to using only very simple classifiers, both because of computational cost and the tendency of complex models to overfit. We propose an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree. As we show, each of these smaller problems can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand. This set of relevant features varies widely throughout the hierarchy, so that, while the overall relevant feature set may be large, each classifier only examines a small subset. The use of reduced feature sets allows us to utilize more complex (probabilistic) models, without encountering the computational and robustness difficulties described above.",
    "date": "1997",
    "authors": [
        "Daphne Koller",
        "Mehran Sahami"
    ],
    "related_topics": [
        "Decision tree learning",
        "Overfitting",
        "Probabilistic logic"
    ],
    "citation_count": "1,394",
    "reference_count": "0",
    "references": []
},{
    "id": "1669104078",
    "title": "Constrained Optimization and Lagrange Multiplier Methods",
    "abstract": "",
    "date": "2014",
    "authors": [
        "Dimitri P. Bertsekas"
    ],
    "related_topics": [
        "Lagrangian relaxation",
        "Augmented Lagrangian method",
        "Continuous optimization"
    ],
    "citation_count": "5,382",
    "reference_count": "0",
    "references": []
},{
    "id": "1568307856",
    "title": "Lectures on modern convex optimization: analysis, algorithms, and engineering applications",
    "abstract": "This is a book devoted to well-structured and thus efficiently solvable convex optimization problems, with emphasis on conic quadratic and semidefinite programming. The authors present the basic theory underlying these problems as well as their numerous applications in engineering, including synthesis of filters, Lyapunov stability analysis, and structural design. The authors also discuss the complexity issues and provide an overview of the basic theory of state-of-the-art polynomial time interior point methods for linear, conic quadratic, and semidefinite programming. The book's focus on well-structured convex problems in conic form allows for unified theoretical and algorithmical treatment of a wide spectrum of important optimization problems arising in applications.",
    "date": "2001",
    "authors": [
        "Aharon Ben-Tal",
        "Arkadiaei Semenovich Nemirovskiaei"
    ],
    "related_topics": [
        "Conic optimization",
        "Semidefinite programming",
        "Quadratically constrained quadratic program"
    ],
    "citation_count": "3,072",
    "reference_count": "0",
    "references": []
},{
    "id": "2124541940",
    "title": "Introductory Lectures on Convex Optimization",
    "abstract": "It was in the middle of the 1980s, when the seminal paper by Kar markar opened a new epoch in nonlinear optimization. The importance of this paper, containing a new polynomial-time algorithm for linear op timization problems, was not only in its complexity bound. At that time, the most surprising feature of this algorithm was that the theoretical pre diction of its high efficiency was supported by excellent computational results. This unusual fact dramatically changed the style and direc tions of the research in nonlinear optimization. Thereafter it became more and more common that the new methods were provided with a complexity analysis, which was considered a better justification of their efficiency than computational experiments. In a new rapidly develop ing field, which got the name \"polynomial-time interior-point methods\", such a justification was obligatory. Afteralmost fifteen years of intensive research, the main results of this development started to appear in monographs [12, 14, 16, 17, 18, 19]. Approximately at that time the author was asked to prepare a new course on nonlinear optimization for graduate students. The idea was to create a course which would reflect the new developments in the field. Actually, this was a major challenge. At the time only the theory of interior-point methods for linear optimization was polished enough to be explained to students. The general theory of self-concordant functions had appeared in print only once in the form of research monograph [12].",
    "date": "2002",
    "authors": [
        "Yurii Nesterov"
    ],
    "related_topics": [
        "Nonlinear programming",
        "Theory of computation",
        "Convex optimization"
    ],
    "citation_count": "3,234",
    "reference_count": "0",
    "references": []
},{
    "id": "1553702074",
    "title": "Convex analysis and minimization algorithms",
    "abstract": "IX. Inner Construction of the Subdifferential.- X. Conjugacy in Convex Analysis.- XI. Approximate Subdifferentials of Convex Functions.- XII. Abstract Duality for Practitioners.- XIII. Methods of ?-Descent.- XIV. Dynamic Construction of Approximate Subdifferentials: Dual Form of Bundle Methods.- XV. Acceleration of the Cutting-Plane Algorithm: Primal Forms of Bundle Methods.- Bibliographical Comments.- References.",
    "date": "1993",
    "authors": [
        "Jean-Baptiste Hiriart-Urruty",
        "Claude Lemar\u00e9chal"
    ],
    "related_topics": [
        "Convex analysis",
        "Subderivative",
        "Convex set"
    ],
    "citation_count": "4,223",
    "reference_count": "0",
    "references": []
},{
    "id": "1568288633",
    "title": "Introduction to optimization",
    "abstract": "",
    "date": "1986",
    "authors": [
        "B. T. Poli\ufe20a\ufe21k"
    ],
    "related_topics": [
        "Computer science"
    ],
    "citation_count": "3,036",
    "reference_count": "0",
    "references": []
},{
    "id": "2015263936",
    "title": "Minimization methods for non-differentiable functions",
    "abstract": "",
    "date": "1984",
    "authors": [
        "N. Z. Shor",
        "Krzysztof C. Kiwiel",
        "Andrzej Ruszcay\u01f9ski"
    ],
    "related_topics": [
        "Dilation (metric space)",
        "Subgradient method",
        "Differentiable function"
    ],
    "citation_count": "1,529",
    "reference_count": "0",
    "references": []
},{
    "id": "2150126561",
    "title": "Nonlinear rescaling vs. smoothing technique in convex optimization",
    "abstract": "We introduce an alternative to the smoothing technique approach for constrained optimization. As it turns out for any given smoothing function there exists a modification with particular properties. We use the modification for Nonlinear Rescaling (NR) the constraints of a given constrained optimization problem into an equivalent set of constraints. The constraints transformation is scaled by a vector of positive parameters. The Lagrangian for the equivalent problems is to the correspondent Smoothing Penalty functions as Augmented Lagrangian to the Classical Penalty function or MBFs to the Barrier Functions. Moreover the Lagrangians for the equivalent problems combine the best properties of Quadratic and Nonquadratic Augmented Lagrangians and at the same time are free from their main drawbacks. Sequential unconstrained minimization of the Lagrangian for the equivalent problem in primal space followed by both Lagrange multipliers and scaling parameters update leads to a new class of NR multipliers methods, which are equivalent to the Interior Quadratic Prox methods for the dual problem. We proved convergence and estimate the rate of convergence of the NR multipliers method under very mild assumptions on the input data. We also estimate the rate of convergence under various assumptions on the input data. In particular, under the standard second order optimality conditions the NR method converges with Q- linear rate without unbounded increase of the scaling parameters, which correspond to the active constraints. We also established global quadratic convergence of the NR methods for Linear Programming with unique dual solution. We provide numerical results, which strongly support the theory.",
    "date": "2002",
    "authors": [
        "Roman A. Polyak"
    ],
    "related_topics": [
        "Augmented Lagrangian method",
        "Quadratic programming",
        "Constrained optimization"
    ],
    "citation_count": "71",
    "reference_count": "27",
    "references": [
        "2798766386",
        "1568288633",
        "2038497950",
        "2099679613",
        "2014746566",
        "2036368324",
        "2016939833",
        "2042360648",
        "2135779729",
        "2032690622"
    ]
},{
    "id": "2969945254",
    "title": "A method for unconstrained convex minimization problem with the rate of convergence o(1/k^2)",
    "abstract": "",
    "date": "1982",
    "authors": [
        "Y. Nesterov"
    ],
    "related_topics": [
        "Convex optimization",
        "Rate of convergence",
        "Applied mathematics"
    ],
    "citation_count": "954",
    "reference_count": "0",
    "references": []
},{
    "id": "2008164266",
    "title": "On convergence rates of subgradient optimization methods",
    "abstract": "Rates of convergence of subgradient optimization are studied. If the step size is chosen to be a geometric progression with ratio\u03c1 the convergence, if it occurs, is geometric with rate\u03c1. For convergence to occur, it is necessary that the initial step size be large enough, and that the ratio\u03c1 be greater than a sustainable ratez(\u03bc), which depends upon a condition number\u03bc, defined for both differentiable and nondifferentiable functions. The sustainable ratez(\u03bc) is closely related to the rate of convergence of the steepest ascent method for differentiable functions: in fact it is identical if the function is not too well conditioned.",
    "date": "1977",
    "authors": [
        "Jean-Louis Goffin"
    ],
    "related_topics": [
        "Convergence tests",
        "Subgradient method",
        "Normal convergence"
    ],
    "citation_count": "280",
    "reference_count": "20",
    "references": [
        "3142300713",
        "2017697298",
        "2058748455",
        "1948965050",
        "2008571296",
        "2013243898",
        "2130469840",
        "2329579984",
        "44132750",
        "11112849"
    ]
},{
    "id": "2038669746",
    "title": "A comparison of three methods for selecting values of input variables in the analysis of output from a computer code",
    "abstract": "Two types of sampling plans are examined as alternatives to simple random sampling in Monte Carlo studies. These plans are shown to be improvements over simple random sampling with respect to variance for a class of estimators which includes the sample mean and the empirical distribution function.",
    "date": "2000",
    "authors": [
        "M. D. McKay",
        "R. J. Beckman",
        "W. J. Conover"
    ],
    "related_topics": [
        "Simple random sample",
        "Slice sampling",
        "Sampling (statistics)"
    ],
    "citation_count": "11,949",
    "reference_count": "16",
    "references": [
        "3041461815",
        "2096992152",
        "2116414161",
        "1638594382",
        "2059347608",
        "2330498442",
        "2022498557",
        "2090895976",
        "2010374567",
        "1977573324"
    ]
},{
    "id": "2169713291",
    "title": "Primal-dual subgradient methods for convex problems",
    "abstract": "In this paper we present a new approach for constructing subgradient schemes for different types of nonsmooth problems with convex structure. Our methods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexibility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform boundedness of subgradients). We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequalities, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds.",
    "date": "2009",
    "authors": [
        "Yurii Nesterov"
    ],
    "related_topics": [
        "Subgradient method",
        "Convex optimization",
        "Feasible region"
    ],
    "citation_count": "1,272",
    "reference_count": "20",
    "references": [
        "3141595720",
        "2167732364",
        "2124541940",
        "1553702074",
        "2089559088",
        "2016384870",
        "3128245365",
        "2090963365",
        "2000955051",
        "2018493294"
    ]
},{
    "id": "203276351",
    "title": "Introduction to Stochastic Search and Optimization",
    "abstract": "From the Publisher: * Unique in its survey of the range of topics. * Contains a strong, interdisciplinary format that will appeal to both students and researchers. * Features exercises and web links to software and data sets.",
    "date": "2003",
    "authors": [
        "James C. Spall"
    ],
    "related_topics": [
        "Range (computer programming)",
        "Software",
        "Data science"
    ],
    "citation_count": "1,692",
    "reference_count": "0",
    "references": []
},{
    "id": "2064076655",
    "title": "INTRODUCTION TO STOCHASTIC SEARCH AND OPTIMIZATION: ESTIMATION, SIMULATION, AND CONTROL",
    "abstract": "This comprehensive book offers 504 main pages divided into 17 chapters. In addition, five very useful and clearly written appendices are provided, covering multivariate analysis, basic tests in statistics, probability theory and convergence, random number generators and Markov processes. Some of the topics covered in the book include: stochastic approximation in nonlinear search and optimization; evolutionary computations; reinforcement learning via temporal differences; mathematical model selection; and computer-simulation-based optimizations. Over 250 exercises are provided in the book, though only a small number of them have solutions included in the volume. A separate solution manual is available, as is a very informative webpage. The book may serve as either a reference for researchers and practitioners in many fields or as an excellent graduate level textbook.",
    "date": "2011",
    "authors": [
        "W. Nowak"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Reinforcement learning",
        "Markov decision process"
    ],
    "citation_count": "1,648",
    "reference_count": "0",
    "references": []
},{
    "id": "1983916623",
    "title": "The Sample Average Approximation Method for Stochastic Discrete Optimization",
    "abstract": "In this paper we study a Monte Carlo simulation--based approach to stochastic discrete optimization problems. The basic idea of such methods is that a random sample is generated and the expected value function is approximated by the corresponding sample average function. The obtained sample average optimization problem is solved, and the procedure is repeated several times until a stopping criterion is satisfied. We discuss convergence rates, stopping rules, and computational complexity of this procedure and present a numerical example for the stochastic knapsack problem.",
    "date": "2002",
    "authors": [
        "Anton J. Kleywegt",
        "Alexander Shapiro",
        "Tito Homem-de-Mello"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Stopping time",
        "Discrete optimization"
    ],
    "citation_count": "1,699",
    "reference_count": "23",
    "references": [
        "1569990960",
        "2059120410",
        "1997917263",
        "2000953623",
        "2085300404",
        "1965288387",
        "2017411673",
        "1967331190",
        "1480364293",
        "2115535801"
    ]
},{
    "id": "2090359754",
    "title": "A new approach to the maximum-flow problem",
    "abstract": "All previously known efficient maximum-flow algorithms work by finding augmenting paths, either one path at a time (as in the original Ford and Fulkerson algorithm) or all shortest-length augmenting paths at once (using the layered network approach of Dinic). An alternative method based on the preflow concept of Karzanov is introduced. A preflow is like a flow, except that the total amount flowing into a vertex is allowed to exceed the total amount flowing out. The method maintains a preflow in the original network and pushes local flow excess toward the sink along what are estimated to be shortest paths. The algorithm and its analysis are simple and intuitive, yet the algorithm runs as fast as any other known method on dense graphs, achieving an O(n3) time bound on an n-vertex graph. By incorporating the dynamic tree data structure of Sleator and Tarjan, we obtain a version of the algorithm running in O(nm log(n2/m)) time on an n-vertex, m-edge graph. This is as fast as any known method for any graph density and faster on graphs of moderate density. The algorithm also admits efficient distributed and parallel implementations. A parallel implementation running in O(n2log n) time using n processors and O(m) space is obtained. This time bound matches that of the Shiloach-Vishkin algorithm, which also uses n processors but requires O(n2) space.",
    "date": "1988",
    "authors": [
        "Andrew V. Goldberg",
        "Robert E. Tarjan"
    ],
    "related_topics": [
        "Dinic's algorithm",
        "Push\u2013relabel maximum flow algorithm",
        "Maximum flow problem"
    ],
    "citation_count": "3,429",
    "reference_count": "30",
    "references": [
        "2053913299",
        "1513400187",
        "2090359754",
        "2125690626",
        "2130055503",
        "2077371116",
        "2340365916",
        "1964119857",
        "2092534058",
        "2018804864"
    ]
},{
    "id": "2000257769",
    "title": "The empirical behavior of sampling methods for stochastic programming",
    "abstract": "We investigate the quality of solutions obtained from sample-average approximations to two-stage stochastic linear programs with recourse. We use a recently developed software tool executing on a computational grid to solve many large instances of these problems, allowing us to obtain high-quality solutions and to verify optimality and near-optimality of the computed solutions in various ways.",
    "date": "2006",
    "authors": [
        "Jeff T. Linderoth",
        "Alexander Shapiro",
        "Stephen J. Wright"
    ],
    "related_topics": [
        "Stochastic programming",
        "Grid",
        "Theory of computation"
    ],
    "citation_count": "367",
    "reference_count": "41",
    "references": [
        "2091257550",
        "2038669746",
        "2786741601",
        "1983916623",
        "2000953623",
        "2161292693",
        "1518930036",
        "2127470768",
        "2015616421",
        "2063790063"
    ]
},{
    "id": "2086161653",
    "title": "Acceleration of stochastic approximation by averaging",
    "abstract": "A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence.",
    "date": "1992",
    "authors": [
        "B. T. Polyak",
        "A. B. Juditsky"
    ],
    "related_topics": [
        "Stochastic approximation",
        "Stochastic optimization",
        "Rate of convergence"
    ],
    "citation_count": "1,529",
    "reference_count": "16",
    "references": [
        "1569320505",
        "1540723801",
        "1498711961",
        "3139633029",
        "1994616650",
        "1485035304",
        "2070709745",
        "2060471940",
        "2056698052",
        "2336878578"
    ]
},{
    "id": "1490324987",
    "title": "Monte Carlo Sampling Methods",
    "abstract": "Abstract In this chapter we discuss Monte Carlo sampling methods for solving large scale stochastic programming problems. We concentrate on the \u201cexterior\u201d approach where a random sample is generated outside of an optimization procedure, and then the constructed, so-called sample average approximation (SAA), problem is solved by an appropriate deterministic algorithm. We study statistical properties of the obtained SAA estimators. The developed statistical inference is incorporated into validation analysis and error estimation. We describe some variance reduction techniques which may enhance convergence of sampling based estimates. We also discuss difficulties in extending this methodology to multistage stochastic programming. Finally, we briefly discuss the SAA method applied to stochastic generalized equations and variational inequalities.",
    "date": "2002",
    "authors": [
        "Alexander Shapiro"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Variance reduction",
        "Monte Carlo method"
    ],
    "citation_count": "719",
    "reference_count": "48",
    "references": [
        "2059120410",
        "2010353172",
        "1601741115",
        "1969481231",
        "1983916623",
        "2000257769",
        "2000953623",
        "1752958389",
        "107938046",
        "1531253382"
    ]
},{
    "id": "2000953623",
    "title": "Monte Carlo bounding techniques for determining solution quality in stochastic programs",
    "abstract": "A stochastic program SP with solution value z^* can be approximately solved by sampling n realizations of the program's stochastic parameters, and by solving the resulting ''approximating problem'' for (x^*\"n,z^*\"n). We show that, in expectation, z^*\"n is a lower bound on z^* and that this bound monotonically improves as n increases. The first result is used to construct confidence intervals on the optimality gap for any candidate solution x@^ to SP, e.g., x@^=x^*\"n. A sampling procedure based on common random numbers ensures nonnegative gap estimates and provides significant variance reduction over naive sampling on four test problems.",
    "date": "1999",
    "authors": [
        "Wai-Kei Mak",
        "David P. Morton",
        "R.Kevin Wood"
    ],
    "related_topics": [
        "Variance reduction",
        "Sampling (statistics)",
        "Upper and lower bounds"
    ],
    "citation_count": "736",
    "reference_count": "35",
    "references": [
        "1495951130",
        "2140481308",
        "1983916623",
        "2143863355",
        "1963748947",
        "2053877403",
        "2055635846",
        "2017411673",
        "2311126677",
        "2095962350"
    ]
},{
    "id": "1563088657",
    "title": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods",
    "abstract": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.",
    "date": "1999",
    "authors": [
        "Nello Cristianini",
        "John Shawe-Taylor"
    ],
    "related_topics": [
        "Statistical learning theory",
        "Support vector machine",
        "Software"
    ],
    "citation_count": "21,732",
    "reference_count": "0",
    "references": []
},{
    "id": "1560724230",
    "title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
    "abstract": "From the Publisher: In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs\u0097-kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.",
    "date": "2001",
    "authors": [
        "Bernhard Scholkopf",
        "Alexander J. Smola"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Online machine learning",
        "Kernel method"
    ],
    "citation_count": "15,002",
    "reference_count": "0",
    "references": []
},{
    "id": "1601740268",
    "title": "An introduction to Support Vector Machines",
    "abstract": "This book is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. The book also introduces Bayesian analysis of learning and relates SVMs to Gaussian Processes and other kernel based learning methods. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc. Their first introduction in the early 1990s lead to a recent explosion of applications and deepening theoretical analysis, that has now established Support Vector Machines along with neural networks as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and application of these techniques. The concepts are introduced gradually in accessible and self-contained stages, though in each stage the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally the book will equip the practitioner to apply the techniques and an associated web site will provide pointers to updated literature, new applications, and on-line software.",
    "date": "2000",
    "authors": [
        "Nello Cristianini",
        "J Shawe-Taylor"
    ],
    "related_topics": [
        "Active learning (machine learning)",
        "Online machine learning",
        "Relevance vector machine"
    ],
    "citation_count": "6,483",
    "reference_count": "0",
    "references": []
},{
    "id": "2101276256",
    "title": "Reducing multiclass to binary: a unifying approach for margin classifiers",
    "abstract": "We present a unifying framework for studying the solution of multiclass categorization problems by reducing them to multiple binary problems that are then solved using a margin-based binary learning algorithm. The proposed framework unifies some of the most popular approaches in which each class is compared against all others, or in which all pairs of classes are compared to each other, or in which output codes with error-correcting properties are used. We propose a general method for combining the classifiers generated on the binary problems, and we prove a general empirical multiclass loss bound given the empirical loss of the individual binary learning algorithms. The scheme and the corresponding bounds apply to many popular classification learning algorithms including support-vector machines, AdaBoost, regression, logistic regression and decision-tree algorithms. We also give a multiclass generalization error analysis for general output codes with AdaBoost as the binary learner. Experimental results with SVM and AdaBoost show that our scheme provides a viable alternative to the most commonly used multiclass algorithms.",
    "date": "2001",
    "authors": [
        "Erin L. Allwein",
        "Robert E. Schapire",
        "Yoram Singer"
    ],
    "related_topics": [
        "Multiclass classification",
        "AdaBoost",
        "Structured support vector machine"
    ],
    "citation_count": "2,571",
    "reference_count": "25",
    "references": [
        "2156909104",
        "2119821739",
        "3124955340",
        "2125055259",
        "2154642048",
        "1594031697",
        "2024046085",
        "1975846642",
        "2161920802",
        "2032210760"
    ]
},{
    "id": "2043909051",
    "title": "Relevance weighting of search terms",
    "abstract": "This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections.",
    "date": "1976",
    "authors": [
        "Stephen Robertson",
        "K. Sparck Jones"
    ],
    "related_topics": [
        "Weighting",
        "Relevance (information retrieval)",
        "Okapi BM25"
    ],
    "citation_count": "2,972",
    "reference_count": "14",
    "references": [
        "2082102453",
        "3090556797",
        "1966365186",
        "1908696901",
        "2119529697",
        "2022516005",
        "2049870103",
        "2002852304",
        "2170946109",
        "2049174056"
    ]
},{
    "id": "2083605078",
    "title": "An evaluation of retrieval effectiveness for a full-text document-retrieval system",
    "abstract": "An evaluation of a large, operational full-text document-retrieval system (containing roughly 350,000 pages of text) shows the system to be retrieving less than 20 percent of the documents relevant to a particular search. The findings are discussed in terms of the theory and practice of full-text document retrieval.",
    "date": "1985",
    "authors": [
        "David C. Blair",
        "M. E. Maron"
    ],
    "related_topics": [
        "Document retrieval",
        "Information retrieval",
        "Computer science"
    ],
    "citation_count": "1,204",
    "reference_count": "7",
    "references": [
        "2092488901",
        "2044601358",
        "2158419171",
        "2034701578",
        "2148551702",
        "2084675619",
        "2005156715"
    ]
},{
    "id": "2068632118",
    "title": "Extended Boolean information retrieval",
    "abstract": "In conventional information retrieval Boolean combinations of index terms are used to formulate the users'' information requests. While any document is in principle retrievable by a Boolean query, the amount of output obtainable by Boolean processing is difficult to control, and the retrieved items are not ranked in any presumed order of importance to the user population. In the vector processing model of retrieval, the retrieved items are easily ranked in decreasing order of the query-record similarity, but the queries themselves are unstructured and expressed as simple sets of weighted index terms. A new, extended Boolean information retrieval system is introduced which is intermediate between the Boolean system of query processing and the vector processing model. The query structure inherent in the Boolean system is preserved, while at the same time weighted terms may be incorporated into both queries and stored documents; the retrieved output can also be ranked in strict similarity order with the user queries. A conventional retrieval system can be modified to make use of the extended system. Laboratory tests indicate that the extended system produces better retrieval output than either the Boolean or the vector processing systems.",
    "date": "1983",
    "authors": [
        "Gerard Salton",
        "Edward A. Fox",
        "Harry Wu"
    ],
    "related_topics": [
        "Extended Boolean model",
        "Standard Boolean model",
        "Vector space model"
    ],
    "citation_count": "1,538",
    "reference_count": "26",
    "references": [
        "2043909051",
        "3090556797",
        "2164547069",
        "1557757161",
        "1602667807",
        "1966365186",
        "1908696901",
        "2004436106",
        "2151433603",
        "2129094996"
    ]
},{
    "id": "3090556797",
    "title": "A statistical interpretation of term specificity and its application in retrieval",
    "abstract": "The exhaustivity of document descriptions and the specificity of index terms are usually regarded as independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test collections showing, in particular, that frequently-occurring terms are required for good overall performance. It is argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms. Results for the test collections show that considerable improvements in performance are obtained with this very simple procedure.",
    "date": "1988",
    "authors": [
        "Karen Sparck Jones"
    ],
    "related_topics": [
        "Term (time)",
        "Value (mathematics)",
        "Interpretation (logic)"
    ],
    "citation_count": "4,801",
    "reference_count": "41",
    "references": [
        "1978394996",
        "2043909051",
        "2075006521",
        "1602667807",
        "1979346010",
        "2058089741",
        "2107668593",
        "1988344511",
        "1980880163",
        "2045787043"
    ]
},{
    "id": "2095396650",
    "title": "Another look at automatic text-retrieval systems",
    "abstract": "Evidence from available studies comparing manual and automatic text-retrieval systems does not support the conclusion that intellectual content analysis produces better results than comparable automatic systems.",
    "date": "1986",
    "authors": [
        "Gerard Salton"
    ],
    "related_topics": [
        "Document retrieval",
        "Automatic indexing",
        "Information retrieval"
    ],
    "citation_count": "481",
    "reference_count": "16",
    "references": [
        "1956559956",
        "2043909051",
        "2083605078",
        "2068632118",
        "3090556797",
        "3091372544",
        "26591655",
        "1979346010",
        "2058089741",
        "1989738209"
    ]
},{
    "id": "2075006521",
    "title": "On the Specification of Term Values in Automatic Indexing",
    "abstract": "The existing practice in automatic indexing is reviewed, and it is shown that the standard theories for the specification of term values (or weights) are not adequate. New techniques are introduced for the assignment of weights to index terms, based on the characteristics of individual document collections. The effectiveness of some of the proposed methods is evaluated.",
    "date": "1973",
    "authors": [
        "Gerard Salton",
        "C.S. Yang"
    ],
    "related_topics": [
        "Index term",
        "Automatic indexing",
        "Term (time)"
    ],
    "citation_count": "980",
    "reference_count": "3",
    "references": [
        "3090556797",
        "1979346010",
        "1572870503"
    ]
},{
    "id": "11171803",
    "title": "Experiments in Automatic Phrase Indexing For Document Retrieval: A Comparison of Syntactic and Non-Syntactic Methods",
    "abstract": "In order for an automatic information retrieval system to effectively retrieve documents related to a given subject area, the content of each document in the system''s database must be represented accurately. This study examines the hypothesis that better representations of document content can be constructed if the content analysis method takes into consideration the syntactic structure of document and query texts. Two methods of automatically generating phrases for use as content indicators have been implemented and tested experimentally. The non-syntactic (or statistical) method is based on simple text characteristics such as word frequency and the proximity of words in text. The syntactic method uses augmented phrase structure rules (production rules) to selectively extract phrases from parse trees generated by an automatic syntactic analyzer. Experimental results show that the effect of non-syntactic phrase indexing is inconsistent. For the five collections tested, increases in average precision ranged from 22.7% to 2.2% over simple, single term indexing. The syntactic phrase indexing method was tested on two collections. Precision figures averaged over all test queries indicate that non-syntactic phrase indexing performs significantly better than syntactic phrase indexing for one collection, but that the difference is insignificant for the other collection. More detailed analysis of individual queries, however, indicates that the performance of both methods is highly variable, and that there is evidence that syntax-based indexing has certain benefits not available with the non-syntactic approach. Possible improvements of both methods of phrase indexing are considered. It is concluded that the prospects for improving the syntax-based approach to document indexing are better than for the non-syntactic approach. The PLNLP system was used for syntactic analysis of document and query texts, and for implementing the syntax-based phrase construction rules. The SMART information retrieval system was used for retrieval experimentation.",
    "date": "1987",
    "authors": [
        "Joel L Fagan"
    ],
    "related_topics": [
        "Phrase",
        "Phrase search",
        "Syntactic methods"
    ],
    "citation_count": "298",
    "reference_count": "0",
    "references": []
},{
    "id": "3091372544",
    "title": "Using probabilistic models of document retrieval without relevance information",
    "abstract": "Most probabilistic retrieval models incorporate information about the occurrence of index terms in relevant and non\u2010relevant documents. In this paper we consider the situation where no relevance information is available, that is, at the start of the search. Based on a probabilistic model, strategies are proposed for the initial search and an intermediate search. Retrieval experiments with the Cranfield collection of 1,400 documents show that this initial search strategy is better than conventional search strategies both in terms of retrieval effectiveness and in terms of the number of queries that retrieve relevant documents. The intermediate search is shown to be a useful substitute for a relevance feedback search. Experiments with queries that do not retrieve relevant documents at high rank positions indicate that a cluster search would be an effective alternative strategy.",
    "date": "1988",
    "authors": [
        "W. B. Croft",
        "D. J. Harper"
    ],
    "related_topics": [
        "Relevance (information retrieval)",
        "Document retrieval",
        "Relevance feedback"
    ],
    "citation_count": "678",
    "reference_count": "0",
    "references": []
},{
    "id": "1557757161",
    "title": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing",
    "abstract": "",
    "date": "1970",
    "authors": [
        "G. Salton"
    ],
    "related_topics": [
        "Document clustering",
        "Document management system",
        "Document retrieval"
    ],
    "citation_count": "2,762",
    "reference_count": "0",
    "references": []
},{
    "id": "2138857742",
    "title": "Why Does Unsupervised Pre-training Help Deep Learning?",
    "abstract": "Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.",
    "date": "2010",
    "authors": [
        "Dumitru Erhan",
        "Yoshua Bengio",
        "Aaron Courville",
        "Pierre-Antoine Manzagol",
        "Pascal Vincent",
        "Samy Bengio"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Semi-supervised learning",
        "Competitive learning"
    ],
    "citation_count": "1,811",
    "reference_count": "55",
    "references": [
        "2136922672",
        "2310919327",
        "2100495367",
        "2187089797",
        "2072128103",
        "2116064496",
        "2117130368",
        "2001141328",
        "2025768430",
        "2110798204"
    ]
},{
    "id": "2148461049",
    "title": "Flexible, high performance convolutional neural networks for image classification",
    "abstract": "We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively.",
    "date": "2011",
    "authors": [
        "Dan C. Cire\u015fan",
        "Ueli Meier",
        "Jonathan Masci",
        "Luca M. Gambardella",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Convolutional neural network",
        "MNIST database",
        "Artificial neural network"
    ],
    "citation_count": "1,473",
    "reference_count": "29",
    "references": [
        "3118608800",
        "2310919327",
        "2546302380",
        "2134557905",
        "2118858186",
        "2156163116",
        "2144161366",
        "1624854622",
        "2132424367",
        "2105464873"
    ]
},{
    "id": "2144982973",
    "title": "Robust Object Recognition with Cortex-Like Mechanisms",
    "abstract": "We introduce a new general framework for the recognition of complex visual scenes, which is motivated by biology: We describe a hierarchical system that closely follows the organization of visual cortex and builds an increasingly complex and invariant feature representation by alternating between a template matching and a maximum pooling operation. We demonstrate the strength of the approach on a range of recognition tasks: From invariant single object recognition in clutter to multiclass categorization problems and complex scene understanding tasks that rely on the recognition of both shape-based as well as texture-based objects. Given the biological constraints that the system had to satisfy, the approach performs surprisingly well: It has the capability of learning from only a few training examples and competes with state-of-the-art systems. We also discuss the existence of a universal, redundant dictionary of features that could handle the recognition of most object categories. In addition to its relevance for computer vision, the success of this approach suggests a plausibility proof for a class of feedforward models of object recognition in cortex",
    "date": "2007",
    "authors": [
        "T. Serre",
        "L. Wolf",
        "S. Bileschi",
        "M. Riesenhuber",
        "T. Poggio"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Cognitive neuroscience of visual object recognition",
        "Feature (machine learning)"
    ],
    "citation_count": "1,987",
    "reference_count": "71",
    "references": [
        "2161969291",
        "2310919327",
        "2124386111",
        "2177274842",
        "2057175746",
        "2154422044",
        "2166049352",
        "2134557905",
        "2152473410",
        "1624854622"
    ]
},{
    "id": "1625255723",
    "title": "Visual categorization with bags of keypoints",
    "abstract": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information.",
    "date": "2003",
    "authors": [
        "G. Csurka"
    ],
    "related_topics": [
        "Bag-of-words model in computer vision",
        "Naive Bayes classifier",
        "Categorization"
    ],
    "citation_count": "6,540",
    "reference_count": "25",
    "references": [
        "2148603752",
        "2164598857",
        "2124386111",
        "2177274842",
        "2154422044",
        "2149684865",
        "1676552347",
        "2124351082",
        "2155511848",
        "1484228140"
    ]
},{
    "id": "2113651538",
    "title": "The Tradeoffs of Large Scale Learning",
    "abstract": "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.",
    "date": "2007",
    "authors": [
        "Olivier Bousquet",
        "L\u00e9on Bottou"
    ],
    "related_topics": [
        "Computational learning theory",
        "Stability (learning theory)",
        "Algorithmic learning theory"
    ],
    "citation_count": "1,614",
    "reference_count": "29",
    "references": [
        "2147880316",
        "2035720976",
        "2150102617",
        "2142623206",
        "2156515921",
        "3017143921",
        "2068484625",
        "1530699444",
        "2019363670",
        "2129191766"
    ]
},{
    "id": "2156779765",
    "title": "Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning",
    "abstract": "We consider the minimization of a convex objective function defined on a Hilbert space, which is only available through unbiased estimates of its gradients. This problem includes standard machine learning algorithms such as kernel logistic regression and least-squares regression, and is commonly referred to as a stochastic approximation problem in the operations research community. We provide a non-asymptotic analysis of the convergence of two well-known algorithms, stochastic gradient descent (a.k.a. Robbins-Monro algorithm) as well as a simple modification where iterates are averaged (a.k.a. Polyak-Ruppert averaging). Our analysis suggests that a learning rate proportional to the inverse of the number of iterations, while leading to the optimal convergence rate in the strongly convex case, is not robust to the lack of strong convexity or the setting of the proportionality constant. This situation is remedied when using slower decays together with averaging, robustly leading to the optimal rate of convergence. We illustrate our theoretical results with simulations on synthetic and standard datasets.",
    "date": "2011",
    "authors": [
        "Eric Moulines",
        "Francis R. Bach"
    ],
    "related_topics": [
        "Stochastic gradient descent",
        "Stochastic approximation",
        "Online machine learning"
    ],
    "citation_count": "582",
    "reference_count": "31",
    "references": [
        "3023786531",
        "3141595720",
        "1510073064",
        "1992208280",
        "2142623206",
        "2125993116",
        "1499021337",
        "2799002609",
        "2113651538",
        "2205628031"
    ]
},{
    "id": "2137515395",
    "title": "SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent",
    "abstract": "The SGD-QN algorithm is a stochastic gradient descent algorithm that makes careful use of second-order information and splits the parameter update into independently scheduled components. Thanks to this design, SGD-QN iterates nearly as fast as a first-order stochastic gradient descent but requires less iterations to achieve the same accuracy. This algorithm won the \"Wild Track\" of the first PASCAL Large Scale Learning Challenge (Sonnenburg et al., 2008).",
    "date": "2009",
    "authors": [
        "Antoine Bordes",
        "L\u00e9on Bottou",
        "Patrick Gallinari"
    ],
    "related_topics": [
        "Stochastic gradient descent",
        "Gradient descent",
        "Gradient method"
    ],
    "citation_count": "372",
    "reference_count": "14",
    "references": [
        "2150102617",
        "2165966284",
        "2142623206",
        "2113651538",
        "2914484425",
        "2135106139",
        "1568229137",
        "1491622225",
        "2166347285",
        "2051669046"
    ]
},{
    "id": "1568229137",
    "title": "Adaptive Algorithms and Stochastic Approximations",
    "abstract": "Adaptive systems are widely encountered in many applications ranging through adaptive filtering and more generally adaptive signal processing, systems identification and adaptive control, to pattern recognition and machine intelligence: adaptation is now recognised as keystone of \"intelligence\" within computerised systems. These diverse areas echo the classes of models which conveniently describe each corresponding system. Thus although there can hardly be a \"general theory of adaptive systems\" encompassing both the modelling task and the design of the adaptation procedure, nevertheless, these diverse issues have a major common component: namely the use of adaptive algorithms, also known as stochastic approximations in the mathematical statistics literature, that is to say the adaptation procedure (once all modelling problems have been resolved). The juxtaposition of these two expressions in the title reflects the ambition of the authors to produce a reference work, both for engineers who use these adaptive algorithms and for probabilists or statisticians who would like to study stochastic approximations in terms of problems arising from real applications. Hence the book is organised in two parts, the first one user-oriented, and the second providing the mathematical foundations to support the practice described in the first part. The book covers the topcis of convergence, convergence rate, permanent adaptation and tracking, change detection, and is illustrated by various realistic applications originating from these areas of applications.",
    "date": "1990",
    "authors": [
        "Albert Benveniste",
        "Pierre Priouret",
        "Michel M\u00e9tivier"
    ],
    "related_topics": [
        "Adaptive system",
        "Adaptive control",
        "Adaptive filter"
    ],
    "citation_count": "2,700",
    "reference_count": "0",
    "references": []
},{
    "id": "1598497354",
    "title": "A fast natural Newton method",
    "abstract": "Nowadays, for many tasks such as object recognition or language modeling, data is plentiful. As such, an important challenge has become to find learning algorithms which can make use of all the available data. In this setting, called \"large-scale learning\" by Bottou & Bousquet (2008), learning and optimization become different and powerful optimization algorithms are suboptimal learning algorithms. While most efforts are focused on adapting optimization algorithms for learning by efficiently using the information contained in the Hessian, Le Roux et al. (2008) exploited the special structure of the learning problem to achieve faster convergence. In this paper, we investigate a natural way of combining these two directions to yield fast and robust learning algorithms.",
    "date": "2010",
    "authors": [
        "Nicolas L. Roux",
        "Andrew W. Fitzgibbon"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Instance-based learning",
        "Active learning (machine learning)"
    ],
    "citation_count": "61",
    "reference_count": "6",
    "references": [
        "3029645440",
        "1970789124",
        "2113651538",
        "2137515395",
        "1491622225",
        "2164273299"
    ]
},{
    "id": "2130984546",
    "title": "Fast curvature matrix-vector products for second-order gradient descent",
    "abstract": "We propose a generic method for iteratively approximating various second-order gradient steps--Newton, Gauss-Newton, Levenberg-Marquardt, and natural gradient--in linear time per iteration, using special curvature matrix-vector products that can be computed in O(n). Two recent acceleration techniques for on-line learning, matrix momentum and stochastic meta-descent (SMD), implement this approach. Since both were originally derived by very different routes, this offers fresh insight into their operation, resulting in further improvements to SMD.",
    "date": "2002",
    "authors": [
        "Nicol N. Schraudolph"
    ],
    "related_topics": [
        "Gradient method",
        "Gradient descent",
        "Curvature"
    ],
    "citation_count": "313",
    "reference_count": "26",
    "references": [
        "1554663460",
        "1970789124",
        "1708197474",
        "2986444355",
        "2006903949",
        "1520168181",
        "2011395874",
        "2112462566",
        "2137269967",
        "2129142203"
    ]
},{
    "id": "2160699933",
    "title": "Learning Algorithms for Connectionist Networks: Applied Gradient Methods of Nonlinear Optimization",
    "abstract": "The problem of learning using connectionist networks, in which network connection strengths are modified systematically so that the response of the network increasingly approximates the desired response can be structured as an optimization problem. The widely used back propagation method of connectionist learning [19, 21, 18] is set in the context of nonlinear optimization. In this framework, the issues of stability, convergence and parallelism are considered. As a form of gradient descent with fixed step size, back propagation is known to be unstable, which is illustrated using Rosenbrock's function. This is contrasted with stable methods which involve a line search in the gradient direction. The convergence criterion for connectionist problems involving binary functions is discussed relative to the behavior of gradient descent in the vicinity of local minima. A minimax criterion is compared with the least squares criterion. The contribution of the momentum term [19, 18] to more rapid convergence is interpreted relative to the geometry of the weight space. It is shown that in plateau regions of relatively constant gradient, the momentum term acts to increase the step size by a factor of 1/1-\u03bc, where \u03bc is the momentum term. In valley regions with steep sides, the momentum constant acts to focus the search direction toward the local minimum by averaging oscillations in the gradient. Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-88-62. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/597 LEARNING ALGORITHMS FOR CONNECTIONIST NETWORKS: APPLIED GRADIENT METHODS OF NONLINEAR OPTIMIZATION",
    "date": "1987",
    "authors": [
        "Raymond L. Watrous"
    ],
    "related_topics": [
        "Gradient descent",
        "Backpropagation",
        "Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno algorithm"
    ],
    "citation_count": "350",
    "reference_count": "18",
    "references": [
        "2154642048",
        "2293063825",
        "2077658674",
        "2266946488",
        "2171074980",
        "2046432185",
        "2022772618",
        "1526055535",
        "1686514609",
        "2078409719"
    ]
},{
    "id": "1526055535",
    "title": "Experiments on Learning by Back Propagation.",
    "abstract": "Abstract : Rumelhart, Hinton and Williams (Rumelhart 86) describe a learning procedure for layered networks of deterministic, neuron-like units. This paper describes further research on the learning procedure. We start by describing the units, the way they are connected, the learning procedure, and the extension to iterative nets. We then give an example in which a network learns a set of filters that enable it to discriminate formant-like patterns in the presence of noise. The speed of learning is strongly dependent on the shape of the surface formed by the error measure in weight space . We give examples of the shape of the error surface for a typical task and illustrate how an acceleration method speeds up descent in weight space. The main drawback of the learning procedure is the way it scales as the size of the task and the network increases. We give some preliminary results on scaling and show how the magnitude of the optimal weight changes depends on the fan-in of the units. Additional results illustrate the effects on learning speed of the amount of interaction between the weights. A variation of the learning procedure that back-propagates desired state information rather than error gradients is developed and compared with the standard procedure. Finally, we discuss the relationship between our iterative networks and the analog networks described by Hopefield and Tank (Hopfield 85). The learning procedure can discover appropriate weights in their kind of network, as well as determine an optimal schedule for varying the nonlinearity of the units during a search.",
    "date": "1986",
    "authors": [
        "David C Plaut",
        "Steven J Nowlan",
        "Geoffrey E Hinton"
    ],
    "related_topics": [
        "Active learning (machine learning)",
        "Artificial neural network",
        "Backpropagation"
    ],
    "citation_count": "543",
    "reference_count": "9",
    "references": [
        "2581275558",
        "2154642048",
        "2293063825",
        "1597286183",
        "1507849272",
        "2155487652",
        "2157629899",
        "2414854470",
        "413857758"
    ]
},{
    "id": "2156985047",
    "title": "A systematic comparison of various statistical alignment models",
    "abstract": "We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented.",
    "date": "2003",
    "authors": [
        "Franz Josef Och",
        "Hermann Ney"
    ],
    "related_topics": [
        "Tree alignment",
        "Statistical model",
        "Hidden Markov model"
    ],
    "citation_count": "4,790",
    "reference_count": "37",
    "references": [
        "2049633694",
        "2006969979",
        "1916559533",
        "2119168550",
        "2116316001",
        "1517947178",
        "47415966",
        "2038698865",
        "1538023239",
        "2139403546"
    ]
},{
    "id": "2146574666",
    "title": "Minimum Error Rate Training in Statistical Machine Translation",
    "abstract": "Often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. In this paper, we analyze various training criteria which directly optimize translation quality. These training criteria make use of recently proposed automatic evaluation metrics. We describe a new algorithm for efficient training an unsmoothed error count. We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure.",
    "date": "2003",
    "authors": [
        "Franz Josef Och"
    ],
    "related_topics": [
        "Interactive machine translation",
        "Hybrid machine translation",
        "Example-based machine translation"
    ],
    "citation_count": "3,517",
    "reference_count": "18",
    "references": [
        "2170120409",
        "2101105183",
        "3017143921",
        "2078861931",
        "2154124206",
        "1517947178",
        "1529616844",
        "1979102019",
        "2018482254",
        "1603508585"
    ]
},{
    "id": "2109664771",
    "title": "Large Language Models in Machine Translation",
    "abstract": "Systems, methods, and computer program products for machine translation are provided. In some implementations a system is provided. The system includes a language model including a collection of n-grams from a corpus, each n-gram having a corresponding relative frequency in the corpus and an order n corresponding to a number of tokens in the n-gram, each n-gram corresponding to a backoff n-gram having an order of n-1 and a collection of backoff scores, each backoff score associated with an n-gram, the backoff score determined as a function of a backoff factor and a relative frequency of a corresponding backoff n-gram in the corpus.",
    "date": "2007",
    "authors": [
        "Thorsten Brants",
        "Ashok C. Popat",
        "Peng Xu",
        "Franz J. Och",
        "Jeffrey Dean"
    ],
    "related_topics": [
        "Machine translation",
        "Language model",
        "Factor (programming language)"
    ],
    "citation_count": "670",
    "reference_count": "44",
    "references": [
        "2173213060",
        "2101105183",
        "2006969979",
        "2158195707",
        "2119168550",
        "222053410",
        "2134237567",
        "1934041838",
        "2111305191",
        "2838046082"
    ]
},{
    "id": "2251098065",
    "title": "Continuous Space Translation Models with Neural Networks",
    "abstract": "The use of conventional maximum likelihood estimates hinders the performance of existing phrase-based translation models. For lack of sufficient training data, most models only consider a small amount of context. As a partial remedy, we explore here several continuous space translation models, where translation probabilities are estimated using a continuous representation of translation units in lieu of standard discrete representations. In order to handle a large set of translation units, these representations and the associated estimates are jointly computed using a multi-layer neural network with a SOUL architecture. In small scale and large scale English to French experiments, we show that the resulting models can effectively be trained and used on top of a n-gram translation system, delivering significant improvements in performance.",
    "date": "2012",
    "authors": [
        "Hai-Son Le",
        "Alexandre Allauzen",
        "Fran\u00e7ois Yvon"
    ],
    "related_topics": [
        "Translation (geometry)",
        "Context (language use)",
        "Artificial neural network"
    ],
    "citation_count": "143",
    "reference_count": "33",
    "references": [
        "2158899491",
        "2132339004",
        "2124807415",
        "2131462252",
        "2171928131",
        "2006969979",
        "2146574666",
        "1970689298",
        "2158195707",
        "2121227244"
    ]
},{
    "id": "2143719855",
    "title": "Structured Output Layer neural network language model",
    "abstract": "This paper introduces a new neural network language model (NNLM) based on word clustering to structure the output vocabulary: Structured Output Layer NNLM. This model is able to handle vocabularies of arbitrary size, hence dispensing with the design of short-lists that are commonly used in NNLMs. Several softmax layers replace the standard output layer in this model. The output structure depends on the word clustering which uses the continuous word representation induced by a NNLM. The GALE Mandarin data was used to carry out the speech-to-text experiments and evaluate the NNLMs. On this data the well tuned baseline system has a character error rate under 10%. Our model achieves consistent improvements over the combination of an n-gram model and classical short-list NNLMs both in terms of perplexity and recognition accuracy.",
    "date": "2011",
    "authors": [
        "Hai-Son Le",
        "Ilya Oparin",
        "Alexandre Allauzen",
        "Jean-Luc Gauvain",
        "Francois Yvon"
    ],
    "related_topics": [
        "Word error rate",
        "Language model",
        "Cluster analysis"
    ],
    "citation_count": "175",
    "reference_count": "13",
    "references": [
        "179875071",
        "2132339004",
        "1632114991",
        "2131462252",
        "1970689298",
        "2121227244",
        "2140679639",
        "2056590938",
        "2130917146",
        "83522546"
    ]
},{
    "id": "2250379827",
    "title": "Large, Pruned or Continuous Space Language Models on a GPU for Statistical Machine Translation",
    "abstract": "Language models play an important role in large vocabulary speech recognition and statistical machine translation systems. The dominant approach since several decades are back-off language models. Some years ago, there was a clear tendency to build huge language models trained on hundreds of billions of words. Lately, this tendency has changed and recent works concentrate on data selection. Continuous space methods are a very competitive approach, but they have a high computational complexity and are not yet in widespread use. This paper presents an experimental comparison of all these approaches on a large statistical machine translation task. We also describe an open-source implementation to train and use continuous space language models (CSLM) for such large tasks. We describe an efficient implementation of the CSLM using graphical processing units from Nvidia. By these means, we are able to train an CSLM on more than 500 million words in 20 hours. This CSLM provides an improvement of up to 1.8 BLEU points with respect to the best back-off language model that we were able to build.",
    "date": "2012",
    "authors": [
        "Holger Schwenk",
        "Anthony Rousseau",
        "Mohammed Attik"
    ],
    "related_topics": [
        "Machine translation",
        "Language model",
        "Machine learning"
    ],
    "citation_count": "126",
    "reference_count": "27",
    "references": [
        "2072128103",
        "179875071",
        "2132339004",
        "2124807415",
        "2131462252",
        "2171928131",
        "1970689298",
        "36903255",
        "2158195707",
        "2134800885"
    ]
},{
    "id": "1489181569",
    "title": "A program for aligning sentences in bilingual corpora",
    "abstract": "Researchers in both machine translation (e.g., Brown et al. 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann 1990) have recently become interested in studying bilingual corpora, bodies of text such as the Canadian Hansards (parliamentary proceedings), which are available in multiple languages (such as French and English). One useful step is to align the sentences, that is, to identify correspondences between sentences in one language and sentences in the other language.This paper will describe a method and a program (align) for aligning sentences based on a simple statistical model of character lengths. The program uses the fact that longer sentences in one language tend to be translated into longer sentences in the other language, and that shorter sentences tend to be translated into shorter sentences. A probabilistic score is assigned to each proposed correspondence of sentences, based on the scaled difference of lengths of the two sentences (in characters) and the variance of this difference. This probabilistic score is used in a dynamic programming framework to find the maximum likelihood alignment of sentences.It is remarkable that such a simple approach works as well as it does. An evaluation was performed based on a trilingual corpus of economic reports issued by the Union Bank of Switzerland (UBS) in English, French, and German. The method correctly aligned all but 4% of the sentences. Moreover, it is possible to extract a large subcorpus that has a much smaller error rate. By selecting the best-scoring 80% of the alignments, the error rate is reduced from 4% to 0.7%. There were more errors on the English-French subcorpus than on the English-German subcorpus, showing that error rates will depend on the corpus considered; however, both were small enough to hope that the method will be useful for many language pairs.To further research on bilingual corpora, a much larger sample of Canadian Hansards (approximately 90 million words, half in English and and half in French) has been aligned with the align program and will be available through the Data Collection Initiative of the Association for Computational Linguistics (ACL/DCI). In addition, in order to facilitate replication of the align program, an appendix is provided with detailed c-code of the more difficult core of the align program.",
    "date": "1993",
    "authors": [
        "William A. Gale",
        "Kenneth W. Church"
    ],
    "related_topics": [
        "Sentence",
        "Machine translation",
        "Computational linguistics"
    ],
    "citation_count": "1,955",
    "reference_count": "11",
    "references": [
        "1973948212",
        "2120062331",
        "2099247782",
        "2097333193",
        "1501400124",
        "2801179766",
        "2117652747",
        "2048390999",
        "2028770325",
        "78534123"
    ]
},{
    "id": "2117652747",
    "title": "ALIGNING SENTENCES IN PARALLEL CORPORA",
    "abstract": "In this paper we describe a statistical technique for aligning sentences with their translations in two parallel corpora. In addition to certain anchor points that are available in our data, the only information about the sentences that we use for calculating alignments is the number of tokens that they contain. Because we make no use of the lexical details of the sentence, the alignment computation is fast and therefore practical for application to very large collections of text. We have used this technique to align several million sentences in the English-French Hansard corpora and have achieved an accuracy in excess of 99% in a random selected set of 1000 sentence pairs that we checked by hand. We show that even without the benefit of anchor points the correlation between the lengths of aligned sentences is strong enough that we should expect to achieve an accuracy of between 96% and 97%. Thus, the technique may be applicable to a wider variety of texts than we have yet tried.",
    "date": "1991",
    "authors": [
        "Peter F. Brown",
        "Jennifer C. Lai",
        "Robert L. Mercer"
    ],
    "related_topics": [
        "Sentence",
        "Set (abstract data type)",
        "Natural language processing"
    ],
    "citation_count": "841",
    "reference_count": "8",
    "references": [
        "2049633694",
        "2097333193",
        "1489181569",
        "1575431606",
        "2341171179",
        "2048390999",
        "2028770325",
        "1880089301"
    ]
},{
    "id": "2129139611",
    "title": "WORD-SENSE DISAMBIGUATION USING STATISTICAL METHODS",
    "abstract": "We describe a statistical technique for assigning senses to words. An instance of a word is assigned a sense by asking a question about the context in which the word appears. The question is constructed to have high mutual information with the translation of that instance in another language. When we incorporated this method of assigning senses into our statistical machine translation system, the error rate of the system decreased by thirteen percent.",
    "date": "1991",
    "authors": [
        "Peter F. Brown",
        "Stephen A. Della Pietra",
        "Vincent J. Della Pietra",
        "Robert L. Mercer"
    ],
    "related_topics": [
        "SemEval",
        "Word error rate",
        "Statistical semantics"
    ],
    "citation_count": "611",
    "reference_count": "9",
    "references": [
        "1594031697",
        "2097333193",
        "1971220772",
        "2099345940",
        "2048390999",
        "1976241232",
        "2120234416",
        "2169528353",
        "195809013"
    ]
},{
    "id": "2154384676",
    "title": "Identifying word correspondence in parallel texts",
    "abstract": "Researchers in both machine translation (e.g., Brown et al, 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann, 1990) have recently become interested in studying parallel texts (also known as bilingual corpora), bodies of text such as the Canadian Hansards (parliamentary debates) which are available in multiple languages (such as French and English). Much of the current excitement surrounding parallel texts was initiated by Brown et al. (1990), who outline a self-organizing method for using these parallel texts to build a machine translation system.",
    "date": "1991",
    "authors": [
        "William A. Gale",
        "Kenneth W. Church"
    ],
    "related_topics": [
        "Machine translation",
        "Linguistics",
        "Natural language processing"
    ],
    "citation_count": "473",
    "reference_count": "4",
    "references": [
        "2099247782",
        "2097333193",
        "2117652747",
        "2028770325"
    ]
},{
    "id": "2138584836",
    "title": "Text-translation alignment",
    "abstract": "We present an algorithm for aligning texts with their translations that is based only on internal evidence. The relaxation process rests on a notion of which word in one text corresponds to which word in the other text that is essentially based on the similarity of their distributions. It exploits a partial alignment of the word level to induce a maximum likelihood alignment of the sentence level, which is in turn used, in the next iteration, to refine the word level estimate. The algorithm appears to converge to the correct sentence alignment in only a few iterations.",
    "date": "1993",
    "authors": [
        "Martin Kay",
        "Martin R\u00f6scheisen"
    ],
    "related_topics": [
        "Word (computer architecture)",
        "Sentence",
        "Similarity (geometry)"
    ],
    "citation_count": "653",
    "reference_count": "12",
    "references": [
        "2752853835",
        "2097333193",
        "1593045043",
        "1489181569",
        "2117652747",
        "1600795850",
        "2799137445",
        "2011008859",
        "2111173177",
        "2066873261"
    ]
},{
    "id": "2048390999",
    "title": "A statistical approach to language translation",
    "abstract": "An approach to automatic translation is outlined that utilizes techniques of statistical information extraction from large data bases. The method is based on the availability of pairs of large corresponding texts that are translations of each other. In our case, the texts are in English and French.Fundamental to the technique is a complex glossary of correspondence of fixed locutions. The steps of the proposed translation process are: (1) Partition the source text into a set of fixed locutions. (2) Use the glossary plus contextual information to select the corresponding set of fixed locutions into a sequence forming the target sentence. (3) Arrange the words of the target fixed locutions into a sequence forming the target sentence.We have developed statistical techniques facilitating both the automatic creation of the glossary, and the performance of the three translation steps, all on the basis of an alignment of corresponding sentences in the two texts.While we are not yet able to provide examples of French / English translation, we present some encouraging intermediate results concerning glossary creation and the arrangement of target word sequences.",
    "date": "1988",
    "authors": [
        "P. Brown",
        "J. Cocke",
        "S. Della Pietra",
        "V. Della Pietra",
        "F. Jelinek",
        "R. Mercer",
        "P. Roossin"
    ],
    "related_topics": [
        "Language translation",
        "Glossary",
        "Source text"
    ],
    "citation_count": "369",
    "reference_count": "9",
    "references": [
        "1594031697",
        "2049633694",
        "1966812932",
        "2142901448",
        "1991133427",
        "2334801970",
        "1575431606",
        "2035227369",
        "2021021293"
    ]
},{
    "id": "196761320",
    "title": "Deep learning via Hessian-free optimization",
    "abstract": "We develop a 2nd-order optimization method based on the \"Hessian-free\" approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn't limited in applicability to auto-encoders, or any specific model class. We also discuss the issue of \"pathological curvature\" as a possible explanation for the difficulty of deep-learning and how 2nd-order optimization, and our method in particular, effectively deals with it.",
    "date": "2010",
    "authors": [
        "James Martens"
    ],
    "related_topics": [
        "Hessian matrix",
        "Deep learning",
        "Class (philosophy)"
    ],
    "citation_count": "911",
    "reference_count": "10",
    "references": [
        "2100495367",
        "3029645440",
        "2110798204",
        "2138857742",
        "2914484425",
        "2606321545",
        "2006903949",
        "2130984546",
        "2166347285",
        "3023533631"
    ]
},{
    "id": "2110575115",
    "title": "Dynamic bayesian networks: representation, inference and learning",
    "abstract": "",
    "date": "2001",
    "authors": [
        "Kevin Patrick Murphy",
        "Stuart Russell"
    ],
    "related_topics": [
        "Frequentist inference",
        "Bayesian statistics",
        "Inference"
    ],
    "citation_count": "3,514",
    "reference_count": "384",
    "references": [
        "1554663460",
        "1480376833",
        "2147880316",
        "2160337655",
        "2122410182",
        "2125838338",
        "2581275558",
        "2137813581",
        "1483307070",
        "2159080219"
    ]
},{
    "id": "1408639475",
    "title": "Learning Recurrent Neural Networks with Hessian-Free Optimization",
    "abstract": "In this work we resolve the long-outstanding problem of how to effectively train recurrent neural networks (RNNs) on complex and difficult sequence modeling problems which may contain long-term data dependencies. Utilizing recent advances in the Hessian-free optimization approach (Martens, 2010), together with a novel damping scheme, we successfully train RNNs on two sets of challenging problems. First, a collection of pathological synthetic datasets which are known to be impossible for standard optimization approaches (due to their extremely long-term dependencies), and second, on three natural and highly complex real-world sequence datasets where we find that our method significantly outperforms the previous state-of-the-art method for training neural sequence models: the Long Short-term Memory approach of Hochreiter and Schmidhuber (1997). Additionally, we offer a new interpretation of the generalized Gauss-Newton matrix of Schraudolph (2002) which is used within the HF approach of Martens.",
    "date": "2011",
    "authors": [
        "James Martens",
        "Ilya Sutskever"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Hessian matrix",
        "Sequence"
    ],
    "citation_count": "663",
    "reference_count": "16",
    "references": [
        "2100495367",
        "3029645440",
        "2064675550",
        "1498436455",
        "196761320",
        "3023071679",
        "2118706537",
        "2107878631",
        "2110575115",
        "2136848157"
    ]
},{
    "id": "2170942820",
    "title": "Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks",
    "abstract": "Offline handwriting recognition\u2014the automatic transcription of images of handwritten text\u2014is a challenging task that combines computer vision with sequence learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks\u2014multidimensional recurrent neural networks and connectionist temporal classification\u2014this paper introduces a globally trained offline handwriting recogniser that takes raw pixel data as input. Unlike competing systems, it does not require any alphabet specific preprocessing, and can therefore be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it outperformed all entries (91.4% accuracy compared to 87.2% for the competition winner) despite the fact that neither author understands a word of Arabic.",
    "date": "2008",
    "authors": [
        "Alex Graves",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Intelligent character recognition",
        "Recurrent neural network",
        "Handwriting recognition"
    ],
    "citation_count": "1,020",
    "reference_count": "20",
    "references": [
        "2310919327",
        "2064675550",
        "2127141656",
        "2144499799",
        "2142069714",
        "2149194912",
        "2131774270",
        "2147568880",
        "2163614729",
        "2167898728"
    ]
},{
    "id": "2116825644",
    "title": "Training restricted Boltzmann machines using approximations to the likelihood gradient",
    "abstract": "A new algorithm for training Restricted Boltzmann Machines is introduced. The algorithm, named Persistent Contrastive Divergence, is different from the standard Contrastive Divergence algorithms in that it aims to draw samples from almost exactly the model distribution. It is compared to some standard Contrastive Divergence and Pseudo-Likelihood algorithms on the tasks of modeling and classifying various types of data. The Persistent Contrastive Divergence algorithm outperforms the other algorithms, and is equally fast and simple.",
    "date": "2008",
    "authors": [
        "Tijmen Tieleman"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Restricted Boltzmann machine",
        "Algorithm"
    ],
    "citation_count": "1,000",
    "reference_count": "20",
    "references": [
        "2136922672",
        "2100495367",
        "2116064496",
        "2110798204",
        "2099866409",
        "1994197834",
        "2096192494",
        "2120340025",
        "2124914669",
        "66838807"
    ]
},{
    "id": "2127141656",
    "title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
    "abstract": "Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.",
    "date": "2006",
    "authors": [
        "Alex Graves",
        "Santiago Fern\u00e1ndez",
        "Faustino Gomez",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Recurrent neural network",
        "TIMIT",
        "Speech corpus"
    ],
    "citation_count": "3,108",
    "reference_count": "16",
    "references": [
        "2064675550",
        "1554663460",
        "2147880316",
        "2125838338",
        "3023071679",
        "2131774270",
        "2079735306",
        "2147568880",
        "2150355110",
        "1553004968"
    ]
},{
    "id": "2144499799",
    "title": "Supervised Sequence Labelling with Recurrent Neural Networks",
    "abstract": "Recurrent neural networks are powerful sequence learners. They are able to incorporate context information in a flexible way, and are robust to localised distortions of the input data. These properties make them well suited to sequence labelling, where input sequences are transcribed with streams of labels. The aim of this thesis is to advance the state-of-the-art in supervised sequence labelling with recurrent networks. Its two main contributions are (1) a new type of output layer that allows recurrent networks to be trained directly for sequence labelling tasks where the alignment between the inputs and the labels is unknown, and (2) an extension of the long short-term memory network architecture to multidimensional data, such as images and video sequences.",
    "date": "2012",
    "authors": [
        "Alexander Graves"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Context (language use)",
        "Sequence"
    ],
    "citation_count": "1,779",
    "reference_count": "137",
    "references": [
        "2156909104",
        "1663973292",
        "2136922672",
        "2310919327",
        "2064675550",
        "1554663460",
        "2147880316",
        "2125838338",
        "2110798204",
        "1993882792"
    ]
},{
    "id": "2029949252",
    "title": "Parallel & distributed processing",
    "abstract": "",
    "date": "2005",
    "authors": [
        "Philipp Slusallek",
        "Peter Shirley",
        "William Mark",
        "Gordon Stoll",
        "Ingo Wald"
    ],
    "related_topics": [
        "Computational science",
        "Theoretical computer science",
        "Connectionism"
    ],
    "citation_count": "4,394",
    "reference_count": "0",
    "references": []
},{
    "id": "2129652681",
    "title": "Arithmetic coding for data compression",
    "abstract": "The state of the art in data compression is arithmetic coding, not the better-known Huffman method. Arithmetic coding gives greater compression, is faster for adaptive models, and clearly separates the model from the channel encoding.",
    "date": "1987",
    "authors": [
        "Ian H. Witten",
        "Radford M. Neal",
        "John G. Cleary"
    ],
    "related_topics": [
        "Context-adaptive binary arithmetic coding",
        "Arithmetic coding",
        "Huffman coding"
    ],
    "citation_count": "4,082",
    "reference_count": "23",
    "references": [
        "2122962290",
        "1990653637",
        "1995875735",
        "2161628678",
        "1975965284",
        "2119047110",
        "2107927941",
        "2165564574",
        "2079729471",
        "2911940095"
    ]
},{
    "id": "2114766824",
    "title": "Optimal Brain Damage",
    "abstract": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application.",
    "date": "1988",
    "authors": [
        "Yann LeCun",
        "John S. Denker",
        "Sara A. Solla"
    ],
    "related_topics": [
        "Network complexity",
        "Artificial neural network",
        "Generalization"
    ],
    "citation_count": "3,941",
    "reference_count": "17",
    "references": [
        "2147800946",
        "2165758113",
        "2154579312",
        "1533169541",
        "169539560",
        "19621276",
        "56903235",
        "2134273960",
        "2169163929",
        "2029538739"
    ]
},{
    "id": "2150218618",
    "title": "Graphical Models for Machine Learning and Digital Communication",
    "abstract": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions.",
    "date": "1998",
    "authors": [
        "Brendan J. Frey"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Active learning (machine learning)",
        "Computational learning theory"
    ],
    "citation_count": "778",
    "reference_count": "6",
    "references": [
        "2159080219",
        "2126185296",
        "2090761873",
        "1965552673",
        "1496450597",
        "1538192045"
    ]
},{
    "id": "2054658115",
    "title": "Paper: Modeling by shortest data description",
    "abstract": "The number of digits it takes to write down an observed sequence x\"1, ..., x\"N of a time series depends on the model with its parameters that one assumes to have generated the observed data. Accordingly, by finding the model which minimizes the description length one obtains estimates of both the integer-valued structure parameters and the real-valued system parameters.",
    "date": "1978",
    "authors": [
        "J. Rissanen"
    ],
    "related_topics": [
        "Minimum description length",
        "Minimum message length",
        "Series (mathematics)"
    ],
    "citation_count": "9,010",
    "reference_count": "11",
    "references": [
        "2168175751",
        "2058815839",
        "2123838014",
        "2158208985",
        "2549568718",
        "2046419776",
        "171686316",
        "2005097301",
        "2110381504",
        "2798453649"
    ]
},{
    "id": "1521626219",
    "title": "Natural Language Processing with Python",
    "abstract": "This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you: Extract information from unstructured text, either to guess the topic or identify \"named entities\" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful.",
    "date": "2009",
    "authors": [
        "Steven Bird",
        "Ewan Klein",
        "Edward Loper"
    ],
    "related_topics": [
        "Language identification",
        "Natural language programming",
        "Language technology"
    ],
    "citation_count": "3,128",
    "reference_count": "57",
    "references": [
        "1532325895",
        "1592805114",
        "2751318774",
        "2013833248",
        "1496357020",
        "2024228866",
        "2148212498",
        "2129765547",
        "1967461618",
        "1711163617"
    ]
},{
    "id": "2138204974",
    "title": "Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics",
    "abstract": "We consider the task of estimating, from observed data, a probabilistic model that is parameterized by a finite number of parameters. In particular, we are considering the situation where the model probability density function is unnormalized. That is, the model is only specified up to the partition function. The partition function normalizes a model so that it integrates to one for any choice of the parameters. However, it is often impossible to obtain it in closed form. Gibbs distributions, Markov and multi-layer networks are examples of models where analytical normalization is often impossible. Maximum likelihood estimation can then not be used without resorting to numerical approximations which are often computationally expensive. We propose here a new objective function for the estimation of both normalized and unnormalized models. The basic idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise. With this approach, the normalizing partition function can be estimated like any other parameter. We prove that the new estimation method leads to a consistent (convergent) estimator of the parameters. For large noise sample sizes, the new estimator is furthermore shown to behave like the maximum likelihood estimator. In the estimation of unnormalized models, there is a trade-off between statistical and computational performance. We show that the new method strikes a competitive trade-off in comparison to other estimation methods for unnormalized models. As an application to real data, we estimate novel two-layer models of natural image statistics with spline nonlinearities.",
    "date": "2011",
    "authors": [
        "Michael U. Gutmann",
        "Aapo Hyv\u00e4rinen"
    ],
    "related_topics": [
        "Estimator",
        "Statistical model",
        "Probability density function"
    ],
    "citation_count": "590",
    "reference_count": "29",
    "references": [
        "2133665775",
        "1554663460",
        "1480376833",
        "2116064496",
        "1548802052",
        "1985093013",
        "2145889472",
        "2152790380",
        "2116825644",
        "130710483"
    ]
},{
    "id": "2962968839",
    "title": "Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription",
    "abstract": "We investigate the problem of modeling symbolic sequences of polyphonic music in a completely general piano-roll representation. We introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high-dimensional sequences. Our approach outperforms many traditional models of polyphonic music on a variety of realistic datasets. We show how our musical language model can serve as a symbolic prior to improve the accuracy of polyphonic transcription.",
    "date": "2012",
    "authors": [
        "Nicolas Boulanger-lewandowski",
        "Yoshua Bengio",
        "Pascal Vincent"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Transcription (software)",
        "Polyphony"
    ],
    "citation_count": "468",
    "reference_count": "25",
    "references": [
        "2072128103",
        "2116064496",
        "2154642048",
        "2096192494",
        "2107878631",
        "1408639475",
        "2158164339",
        "2124914669",
        "2135181320",
        "2135341757"
    ]
},{
    "id": "2108563286",
    "title": "Advances in optimizing recurrent networks",
    "abstract": "After a more than decade-long period of relatively little research activity in the area of recurrent neural networks, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks. These advances have been motivated by and related to the optimization issues surrounding deep learning. Although recurrent networks are extremely powerful in what they can in principle represent in terms of modeling sequences, their training is plagued by two aspects of the same issue regarding the learning of long-term dependencies. Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment. The experiments are performed on text and music data and show off the combined effects of these techniques in generally improving both training and test error.",
    "date": "2013",
    "authors": [
        "Yoshua Bengio",
        "Nicolas Boulanger-Lewandowski",
        "Razvan Pascanu"
    ],
    "related_topics": [
        "Deep learning",
        "Recurrent neural network",
        "Artificial neural network"
    ],
    "citation_count": "513",
    "reference_count": "31",
    "references": [
        "2618530766",
        "2136922672",
        "2064675550",
        "1665214252",
        "2072128103",
        "2110798204",
        "2156387975",
        "2097998348",
        "1498436455",
        "196761320"
    ]
},{
    "id": "2162911105",
    "title": "High-dimensional sequence transduction",
    "abstract": "We investigate the problem of transforming an input sequence into a high-dimensional output sequence in order to transcribe polyphonic audio music into symbolic notation. We introduce a probabilistic model based on a recurrent neural network that is able to learn realistic output distributions given the input and we devise an efficient algorithm to search for the global mode of that distribution. The resulting method produces musically plausible transcriptions even under high levels of noise and drastically outperforms previous state-of- the-art approaches on five datasets of synthesized sounds and real recordings, approximately halving the test error rate.",
    "date": "2013",
    "authors": [
        "Nicolas Boulanger-Lewandowski",
        "Yoshua Bengio",
        "Pascal Vincent"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Audio signal processing",
        "Statistical model"
    ],
    "citation_count": "51",
    "reference_count": "24",
    "references": [
        "2064675550",
        "2072128103",
        "2116064496",
        "2025768430",
        "2097998348",
        "2154642048",
        "1408639475",
        "2962968839",
        "1828163288",
        "2135181320"
    ]
},{
    "id": "2131774270",
    "title": "Bidirectional recurrent neural networks",
    "abstract": "In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported.",
    "date": "1997",
    "authors": [
        "M. Schuster",
        "K.K. Paliwal"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Posterior probability",
        "Frame (networking)"
    ],
    "citation_count": "5,139",
    "reference_count": "15",
    "references": [
        "1554663460",
        "1988520084",
        "3161062409",
        "2173629880",
        "2974222084",
        "1980501707",
        "2143503258",
        "183625566",
        "2110871230",
        "2095539364"
    ]
},{
    "id": "2079735306",
    "title": "2005 Special Issue: Framewise phoneme classification with bidirectional LSTM and other neural network architectures",
    "abstract": "In this paper, we present bidirectional Long Short Term Memory (LSTM) networks, and a modified, full gradient version of the LSTM learning algorithm. We evaluate Bidirectional LSTM (BLSTM) and several other network architectures on the benchmark task of framewise phoneme classification, using the TIMIT database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory (LSTM) is much faster and also more accurate than both standard Recurrent Neural Nets (RNNs) and time-windowed Multilayer Perceptrons (MLPs). Our results support the view that contextual information is crucial to speech processing, and suggest that BLSTM is an effective architecture with which to exploit it.",
    "date": "2005",
    "authors": [
        "Alex Graves",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Artificial neural network",
        "Perceptron",
        "Speech processing"
    ],
    "citation_count": "1,807",
    "reference_count": "22",
    "references": [
        "2064675550",
        "1554663460",
        "2131774270",
        "2147568880",
        "1553004968",
        "1485231155",
        "1525783482",
        "2110871230",
        "1566256432",
        "1674799117"
    ]
},{
    "id": "2124807415",
    "title": "Moses: Open Source Toolkit for Statistical Machine Translation",
    "abstract": "We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks.",
    "date": "2007",
    "authors": [
        "Philipp Koehn",
        "Hieu Hoang",
        "Alexandra Birch",
        "Chris Callison-Burch",
        "Marcello Federico",
        "Nicola Bertoldi",
        "Brooke Cowan",
        "Wade Shen",
        "Christine Moran",
        "Richard Zens",
        "Chris Dyer",
        "Ondrej Bojar",
        "Alexandra Constantin",
        "Evan Herbst"
    ],
    "related_topics": [
        "Hybrid machine translation",
        "Computer-assisted translation",
        "Interactive machine translation"
    ],
    "citation_count": "6,097",
    "reference_count": "13",
    "references": [
        "2101105183",
        "2153653739",
        "2156985047",
        "1631260214",
        "2146574666",
        "1498238796",
        "2113788796",
        "2105891181",
        "2056250865",
        "2130450156"
    ]
},{
    "id": "2117278770",
    "title": "Intelligent Selection of Language Model Training Data",
    "abstract": "We address the problem of selecting non-domain-specific language model training data to build auxiliary language models for use in tasks such as machine translation. Our approach is based on comparing the cross-entropy, according to domain-specific and non-domain-specifc language models, for each sentence of the text source used to produce the latter language model. We show that this produces better language models, trained on less data, than both random data selection and two other previously proposed methods.",
    "date": "2010",
    "authors": [
        "Robert C. Moore",
        "William Lewis"
    ],
    "related_topics": [
        "Language identification",
        "Cache language model",
        "Data control language"
    ],
    "citation_count": "515",
    "reference_count": "8",
    "references": [
        "22168010",
        "2109664771",
        "2123958887",
        "2075201173",
        "1974967573",
        "1926502259",
        "9155011",
        "265531733"
    ]
},{
    "id": "2137387514",
    "title": "Experiments in Domain Adaptation for Statistical Machine Translation",
    "abstract": "The special challenge of the WMT 2007 shared task was domain adaptation. We took this opportunity to experiment with various ways of adapting a statistical machine translation systems to a special domain (here: news commentary), when most of the training data is from a different domain (here: European Parliament speeches). This paper also gives a description of the submission of the University of Edinburgh to the shared task.",
    "date": "2007",
    "authors": [
        "Philipp Koehn",
        "Josh Schroeder"
    ],
    "related_topics": [
        "Example-based machine translation",
        "Machine translation",
        "Machine translation software usability"
    ],
    "citation_count": "300",
    "reference_count": "8",
    "references": [
        "2124807415",
        "2153653739",
        "1631260214",
        "2146574666",
        "2162245945",
        "2401082558",
        "2280403519",
        "2597684388"
    ]
},{
    "id": "2132001515",
    "title": "Mixture-Model Adaptation for SMT",
    "abstract": "We describe a mixture-model approach to adapting a Statistical Machine Translation System for new domains, using weights that depend on text distances to mixture components. We investigate a number of variants on this approach, including cross-domain versus dynamic adaptation; linear versus loglinear mixtures; language and translation model adaptation; different methods of assigning weights; and granularity of the source unit being adapted to. The best methods achieve gains of approximately one BLEU percentage point over a state-of-the art non-adapted baseline system.",
    "date": "2007",
    "authors": [
        "George Foster",
        "Roland Kuhn"
    ],
    "related_topics": [
        "Machine translation",
        "Mixture model",
        "Log-linear model"
    ],
    "citation_count": "299",
    "reference_count": "21",
    "references": [
        "2170120409",
        "1480376833",
        "2101105183",
        "2147152072",
        "2153653739",
        "2006969979",
        "1508165687",
        "2105891181",
        "2143564602",
        "24102868"
    ]
},{
    "id": "2130450156",
    "title": "Factored Language Models for Statistical Machine Translation",
    "abstract": "Machine translation systems, as a whole, are currently not able to use the output of linguistic tools, such as part-of-speech taggers, to effectively improve translation performance. However, a new language modeling technique, Factored Language Models can incorporate the additional linguistic information that is produced by these tools. In the field of automatic speech recognition, Factored Language Models smoothed with Generalized Parallel Backoff have been shown to significantly reduce language model perplexity. However, Factored Language Models have previously only been applied to statistical machine translation as part of a second-pass rescoring system. In this thesis, we show that a state-of-the-art phrase-based system using factored language models with generalized parallel backoff can improve performance over an identical system using trigram language models. These improvements can be seen both with the use of additional word features and without. The relative gain from the Factored Language Models increases with smaller training corpora, making this approach especially useful for domains with limited data.",
    "date": "2005",
    "authors": [
        "Amittai E. Axelrod"
    ],
    "related_topics": [
        "Cache language model",
        "Machine translation",
        "Language model"
    ],
    "citation_count": "52",
    "reference_count": "30",
    "references": [
        "2101105183",
        "1574901103",
        "2153653739",
        "2098162425",
        "2049633694",
        "1631260214",
        "2006969979",
        "2146574666",
        "2152263452",
        "1773803948"
    ]
},{
    "id": "2148861208",
    "title": "Using Word-Dependent Transition Models in HMM-Based Word Alignment for Statistical Machine Translation",
    "abstract": "In this paper, we present a Bayesian Learning based method to train word dependent transition models for HMM based word alignment. We present word alignment results on the Canadian Hansards corpus as compared to the conventional HMM and IBM model 4. We show that this method gives consistent and significant alignment error rate (AER) reduction. We also conducted machine translation (MT) experiments on the Europarl corpus. MT results show that word alignment based on this method can be used in a phrase-based machine translation system to yield up to 1% absolute improvement in BLEU score, compared to a conventional HMM, and 0.8% compared to a IBM model 4 based word alignment.",
    "date": "2007",
    "authors": [
        "Xiaodong He"
    ],
    "related_topics": [
        "Word error rate",
        "Word (computer architecture)",
        "Machine translation"
    ],
    "citation_count": "93",
    "reference_count": "47",
    "references": [
        "1663973292",
        "2101105183",
        "2125838338",
        "1506806321",
        "2153653739",
        "2006969979",
        "2146574666",
        "2109664771",
        "1973923101",
        "2100969003"
    ]
},{
    "id": "2123301721",
    "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments",
    "abstract": "We describe METEOR, an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings; furthermore, METEOR can be easily extended to include more advanced matching strategies. Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference. We evaluate METEOR by measuring the correlation between the metric scores and human judgments of translation quality. We compute the Pearson R correlation value between its scores and human quality assessments of the LDC TIDES 2003 Arabic-to-English and Chinese-to-English datasets. We perform segment-bysegment correlation, and show that METEOR gets an R correlation value of 0.347 on the Arabic data and 0.331 on the Chinese data. This is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic F1 combination. We also perform experiments to show the relative contributions of the various mapping modules.",
    "date": "2005",
    "authors": [
        "Satanjeev Banerjee",
        "Alon Lavie"
    ],
    "related_topics": [
        "Hybrid machine translation",
        "Evaluation of machine translation",
        "Machine translation"
    ],
    "citation_count": "2,668",
    "reference_count": "5",
    "references": [
        "2101105183",
        "2078861931",
        "1489409710",
        "2118021410",
        "1588719663"
    ]
},{
    "id": "2078861931",
    "title": "Automatic evaluation of machine translation quality using n-gram co-occurrence statistics",
    "abstract": "Evaluation is recognized as an extremely helpful forcing function in Human Language Technology R&D. Unfortunately, evaluation has not been a very powerful tool in machine translation (MT) research because it requires human judgments and is thus expensive and time-consuming and not easily factored into the MT research agenda. However, at the July 2001 TIDES PI meeting in Philadelphia, IBM described an automatic MT evaluation technique that can provide immediate feedback and guidance in MT research. Their idea, which they call an \"evaluation understudy\", compares MT output with expert reference translations in terms of the statistics of short sequences of words (word N-grams). The more of these N-grams that a translation shares with the reference translations, the better the translation is judged to be. The idea is elegant in its simplicity. But far more important, IBM showed a strong correlation between these automatically generated scores and human judgments of translation quality. As a result, DARPA commissioned NIST to develop an MT evaluation facility based on the IBM work. This utility is now available from NIST and serves as the primary evaluation measure for TIDES MT research.",
    "date": "2002",
    "authors": [
        "George Doddington"
    ],
    "related_topics": [
        "Machine translation",
        "Evaluation of machine translation",
        "Hybrid machine translation"
    ],
    "citation_count": "2,095",
    "reference_count": "0",
    "references": []
},{
    "id": "2087735403",
    "title": "Findings of the 2012 Workshop on Statistical Machine Translation",
    "abstract": "This paper presents the results of the WMT12 shared tasks, which included a translation task, a task for machine translation evaluation metrics, and a task for run-time estimation of machine translation quality. We conducted a large-scale manual evaluation of 103 machine translation systems submitted by 34 teams. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 12 evaluation metrics. We introduced a new quality estimation task this year, and evaluated submissions from 11 teams.",
    "date": "2012",
    "authors": [
        "Chris Callison-Burch",
        "Philipp Koehn",
        "Christof Monz",
        "Matt Post",
        "Radu Soricut",
        "Lucia Specia"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "Machine translation",
        "Task (project management)"
    ],
    "citation_count": "775",
    "reference_count": "63",
    "references": [
        "2153635508",
        "2164777277",
        "2143539737",
        "222053410",
        "2147192413",
        "2116492146",
        "2115081467",
        "2895810819",
        "2169279899",
        "2159107349"
    ]
},{
    "id": "222053410",
    "title": "Statistical Significance Tests for Machine Translation Evaluation.",
    "abstract": "If two translation systems differ differ in performance on a test set, can we trust that this indicates a difference in true system quality? To answer this question, we describe bootstrap resampling methods to compute statistical significance of test results, and validate them on the concrete example of the BLEU score. Even for small test sizes of only 300 sentences, our methods may give us assurances that test result differences are real.",
    "date": "2004",
    "authors": [
        "Philipp Koehn"
    ],
    "related_topics": [
        "Machine translation",
        "Test set",
        "Test (assessment)"
    ],
    "citation_count": "1,459",
    "reference_count": "15",
    "references": [
        "1995945562",
        "2170120409",
        "2101105183",
        "2153653739",
        "2097333193",
        "1498238796",
        "2797563284",
        "2088781183",
        "2136657878",
        "2111798208"
    ]
},{
    "id": "1489525520",
    "title": "Re-evaluating the Role of Bleu in Machine Translation Research",
    "abstract": "We argue that the machine translation community is overly reliant on the Bleu machine translation evaluation metric. We show that an improved Bleu score is neither necessary nor sufficient for achieving an actual improvement in translation quality, and give two significant counterexamples to Bleu\u2019s correlation with human judgments of quality. This offers new potential for research which was previously deemed unpromising by an inability to improve upon Bleu scores.",
    "date": "2006",
    "authors": [
        "Chris Callison-Burch",
        "Miles Osborne",
        "Philipp Koehn"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "Machine translation software usability",
        "Machine translation"
    ],
    "citation_count": "751",
    "reference_count": "14",
    "references": [
        "2101105183",
        "22168010",
        "1916559533",
        "2123301721",
        "2078861931",
        "2150824314",
        "2154124206",
        "1498238796",
        "2088781183",
        "23077562"
    ]
},{
    "id": "2115081467",
    "title": "Findings of the 2009 Workshop on Statistical Machine Translation",
    "abstract": "This paper presents the results of the WMT09 shared tasks, which included a translation task, a system combination task, and an evaluation task. We conducted a large-scale manual evaluation of 87 machine translation systems and 22 system combination entries. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics. We present a new evaluation technique whereby system output is edited and judged for correctness.",
    "date": "2009",
    "authors": [
        "Chris Callison-Burch",
        "Philipp Koehn",
        "Christof Monz",
        "Josh Schroeder"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "Machine translation",
        "Task (project management)"
    ],
    "citation_count": "775",
    "reference_count": "48",
    "references": [
        "2101105183",
        "2164777277",
        "2149327368",
        "2147192413",
        "2169279899",
        "2108325777",
        "2018869373",
        "2152311128",
        "2061910127",
        "1819903106"
    ]
},{
    "id": "2895810819",
    "title": "Findings of the 2011 Workshop on Statistical Machine Translation",
    "abstract": "This paper presents the results of the WMT11 shared tasks, which included a translation task, a system combination task, and a task for machine translation evaluation metrics. We conducted a large-scale manual evaluation of 148 machine translation systems and 41 system combination entries. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 21 evaluation metrics. This year featured a Haitian Creole to English task translating SMS messages sent to an emergency response service in the aftermath of the Haitian earthquake. We also conducted a pilot 'tunable metrics' task to test whether optimizing a fixed system to different metrics would result in perceptibly different translation quality.",
    "date": "2011",
    "authors": [
        "Chris Callison-Burch",
        "Philipp Koehn",
        "Christof Monz",
        "Omar Zaidan"
    ],
    "related_topics": [
        "Machine translation",
        "Task (project management)",
        "Ranking"
    ],
    "citation_count": "1,064",
    "reference_count": "0",
    "references": []
},{
    "id": "2011301426",
    "title": "Matplotlib: A 2D Graphics Environment",
    "abstract": "Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems",
    "date": "2007",
    "authors": [
        "J.D. Hunter"
    ],
    "related_topics": [
        "2D computer graphics",
        "Computer graphics",
        "Python (programming language)"
    ],
    "citation_count": "19,411",
    "reference_count": "0",
    "references": []
},{
    "id": "2061939373",
    "title": "IPython: A System for Interactive Scientific Computing",
    "abstract": "Python offers basic facilities for interactive work and a comprehensive library on top of which more sophisticated systems can be built. The IPython project provides on enhanced interactive environment that includes, among other features, support for data visualization and facilities for distributed and parallel computation",
    "date": "2007",
    "authors": [
        "F. Perez",
        "B.E. Granger"
    ],
    "related_topics": [
        "Python (programming language)",
        "Data visualization",
        "Object-oriented programming"
    ],
    "citation_count": "3,341",
    "reference_count": "7",
    "references": [
        "3005347330",
        "2030572719",
        "1630264553",
        "2076977756",
        "1550301432",
        "2141013982",
        "1540903397"
    ]
},{
    "id": "3005347330",
    "title": "SciPy: Open Source Scientific Tools for Python",
    "abstract": "",
    "date": "2000",
    "authors": [
        "E Jones",
        "T Oliphant",
        "P Peterson"
    ],
    "related_topics": [
        "Python (programming language)",
        "Scientific instrument",
        "Computer science"
    ],
    "citation_count": "6,116",
    "reference_count": "0",
    "references": []
},{
    "id": "2110114082",
    "title": "Python for Scientific Computing",
    "abstract": "Python is an excellent \"steering\" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.",
    "date": "2006",
    "authors": [
        "Travis E. Oliphant"
    ],
    "related_topics": [
        "Scripting language",
        "High-level programming language",
        "Python (programming language)"
    ],
    "citation_count": "3,265",
    "reference_count": "1",
    "references": [
        "2912827267"
    ]
},{
    "id": "2185726469",
    "title": "Empirical Evaluation and Combination of Advanced Language Modeling Techniques.",
    "abstract": "We present results obtained with several advanced language modeling techniques, including class based model, cache model, maximum entropy model, structured language model, random forest language model and several types of neural network based language models. We show results obtained after combining all these models by using linear interpolation. We conclude that for both small and moderately sized tasks, we obtain new state of the art results with combination of models, that is significantly better than performance of any individual model. Obtained perplexity reductions against Good-Turing trigram baseline are over 50% and against modified Kneser-Ney smoothed 5-gram over 40%.",
    "date": "2011",
    "authors": [
        "Tomas Mikolov",
        "Anoop Deoras",
        "Stefan Kombrink",
        "Luk\u00e1s Burget",
        "Jan Cernock\u00fd"
    ],
    "related_topics": [
        "Language model",
        "Perplexity",
        "Trigram"
    ],
    "citation_count": "349",
    "reference_count": "18",
    "references": [
        "179875071",
        "2132339004",
        "2171928131",
        "1970689298",
        "2091812280",
        "2158195707",
        "2096072088",
        "2143719855",
        "2171645483",
        "10704533"
    ]
},{
    "id": "2254715784",
    "title": "Theano: Deep Learning on GPUs with Python",
    "abstract": "In this paper, we present Theano 1 , a framework in the Python programming language for defining, optimizing and evaluating expressions involving high-level operations on tensors. Theano offers most of NumPy\u2019s functionality, but adds automatic symbolic differentiation, GPU support, and faster expression evaluation. Theano is a general mathematical tool, but it was developed with the goal of facilitating research in deep learning. The Deep Learning Tutorials 2 introduce recent advances in deep learning, and showcase how Theano",
    "date": "2011",
    "authors": [
        "James Bergstra",
        "Frederic Bastien",
        "Olivier Breuleux",
        "Pascal Lamblin",
        "Razvan Pascanu",
        "Olivier Delalleau",
        "Guillaume Desjardins",
        "David Warde-Farley",
        "Ian Goodfellow",
        "Arnaud Bergeron",
        "Yoshua Bengio"
    ],
    "related_topics": [
        "Theano",
        "NumPy",
        "Python (programming language)"
    ],
    "citation_count": "300",
    "reference_count": "5",
    "references": [
        "2136922672",
        "2310919327",
        "2072128103",
        "2025768430",
        "1498436455"
    ]
},{
    "id": "2112090702",
    "title": "Collective dynamics of small-world networks",
    "abstract": "Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon (popularly known as six degrees of separation. The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.",
    "date": "1998",
    "authors": [
        "Duncan J. Watts",
        "Steven H. Strogatz"
    ],
    "related_topics": [
        "Complex network",
        "Evolving networks",
        "Network motif"
    ],
    "citation_count": "46,999",
    "reference_count": "28",
    "references": [
        "2061901927",
        "2905110430",
        "2062663664",
        "111157985",
        "2025490132",
        "2079948225",
        "3049667020",
        "2088678566",
        "2026552514",
        "2017444605"
    ]
},{
    "id": "2008620264",
    "title": "Emergence of Scaling in Random Networks",
    "abstract": "Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.",
    "date": "1999",
    "authors": [
        "Albert L\u00e1szl\u00f3 Barab\u00e1si",
        "R\u00e9ka Albert"
    ],
    "related_topics": [
        "Evolving networks",
        "Complex network",
        "Network motif"
    ],
    "citation_count": "39,951",
    "reference_count": "16",
    "references": [
        "2112090702",
        "2769133055",
        "2905110430",
        "2107252390",
        "3125161049",
        "1971788485",
        "1643412971",
        "2121821841",
        "2062021443",
        "2147164982"
    ]
},{
    "id": "1659842140",
    "title": "Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control and Artificial Intelligence",
    "abstract": "From the Publisher: Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. John H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and isDirector of the University of Michigan/Santa Fe Institute Advanced Research Program.",
    "date": "1992",
    "authors": [
        "John H. Holland"
    ],
    "related_topics": [
        "Complex adaptive system",
        "Adaptation (computer science)",
        "Game theory"
    ],
    "citation_count": "16,288",
    "reference_count": "0",
    "references": []
},{
    "id": "2142069714",
    "title": "Online and off-line handwriting recognition: a comprehensive survey",
    "abstract": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered.",
    "date": "1999",
    "authors": [
        "R. Plamondon",
        "S.N. Srihari"
    ],
    "related_topics": [
        "Intelligent character recognition",
        "Handwriting",
        "Handwriting recognition"
    ],
    "citation_count": "3,470",
    "reference_count": "215",
    "references": [
        "1554663460",
        "2125838338",
        "2046079134",
        "2133059825",
        "2102734279",
        "1970800786",
        "1549285799",
        "2010595692",
        "1885639605",
        "2178432768"
    ]
},{
    "id": "1578856370",
    "title": "Spoken Language Processing: A Guide to Theory, Algorithm, and System Development",
    "abstract": "From the Publisher: New advances in spoken language processing: theory and practice In-depth coverage of speech processing, speech recognition, speech synthesis, spoken language understanding, and speech interface design Many case studies from state-of-the-art systems, including examples from Microsoft's advanced research labs Spoken Language Processing draws on the latest advances and techniques from multiple fields: computer science, electrical engineering, acoustics, linguistics, mathematics, psychology, and beyond. Starting with the fundamentals, it presents all this and more: Essential background on speech production and perception, probability and information theory, and pattern recognition Extracting information from the speech signal: useful representations and practical compression solutions Modern speech recognition techniques: hidden Markov models, acoustic and language modeling, improving resistance to environmental noises, search algorithms, and large vocabulary speech recognition Text-to-speech: analyzing documents, pitch and duration controls; trainable synthesis, and more Spoken language understanding: dialog management, spoken language applications, and multimodal interfaces To illustrate the book's methods, the authors present detailed case studies based on state-of-the-art systems, including Microsoft's Whisper speech recognizer, Whistler text-to-speech system, Dr. Who dialog system, and the MiPad handheld device. Whether you're planning, designing, building, or purchasing spoken language technology, this is the state of the art\u0097fromalgorithms through business productivity.",
    "date": "2001",
    "authors": [
        "Xuedong Huang",
        "Alex Acero",
        "Hsiao-Wuen Hon",
        "Raj Reddy"
    ],
    "related_topics": [
        "Speech processing",
        "Speech corpus",
        "Spoken language"
    ],
    "citation_count": "4,268",
    "reference_count": "0",
    "references": []
},{
    "id": "2147568880",
    "title": "Learning precise timing with lstm recurrent networks",
    "abstract": "The temporal distance between events conveys information essential for numerous sequential tasks such as motor control and rhythm detection. While Hidden Markov Models tend to ignore this information, recurrent neural networks (RNNs) can in principle learn to make use of it. We focus on Long Short-Term Memory (LSTM) because it has been shown to outperform other RNNs on tasks involving long time lags. We find that LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes spaced either 50 or 49 time steps apart without the help of any short training exemplars. Without external resets or teacher forcing, our LSTM variant also learns to generate stable streams of precisely timed spikes and other highly nonlinear periodic patterns. This makes LSTM a promising approach for tasks that require the accurate measurement or generation of time intervals.",
    "date": "2003",
    "authors": [
        "Felix A. Gers",
        "Nicol N. Schraudolph",
        "J\u00fcrgen Schmidhuber"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Hidden Markov model",
        "Machine learning"
    ],
    "citation_count": "1,385",
    "reference_count": "23",
    "references": [
        "2064675550",
        "2107878631",
        "2136848157",
        "2914484425",
        "2016589492",
        "1525783482",
        "194249466",
        "2154890045",
        "1674799117",
        "2121029939"
    ]
},{
    "id": "1543237449",
    "title": "Real-time prediction of hand trajectory by ensembles of cortical neurons in primates",
    "abstract": "Signals derived from the rat motor cortex can be used for controlling one-dimensional movements of a robot arm1. It remains unknown, however, whether real-time processing of cortical signals can be employed to reproduce, in a robotic device, the kind of complex arm movements used by primates to reach objects in space. Here we recorded the simultaneous activity of large populations of neurons, distributed in the premotor, primary motor and posterior parietal cortical areas, as non-human primates performed two distinct motor tasks. Accurate real-time predictions of one- and three-dimensional arm movement trajectories were obtained by applying both linear and nonlinear algorithms to cortical neuronal ensemble activity recorded from each animal. In addition, cortically derived signals were successfully used for real-time control of robotic devices, both locally and through the Internet. These results suggest that long-term control of complex prosthetic robot arm movements can be achieved by simple real-time transformations of neuronal population signals derived from multiple cortical areas in primates.",
    "date": "2000",
    "authors": [
        "Johan Wessberg",
        "Christopher R. Stambaugh",
        "Jerald D. Kralik",
        "Pamela D. Beck",
        "Mark Laubach",
        "John K. Chapin",
        "Jung Kim",
        "S. James Biggs",
        "Mandayam A. Srinivasan",
        "Miguel A. L. Nicolelis"
    ],
    "related_topics": [
        "Premotor cortex",
        "Robotic arm",
        "Body movement"
    ],
    "citation_count": "1,764",
    "reference_count": "30",
    "references": [
        "1483156930",
        "2098301339",
        "2018742520",
        "2043721804",
        "2040739363",
        "2003209004",
        "2039619955",
        "2080119716",
        "2090257483",
        "2168120373"
    ]
},{
    "id": "2166322089",
    "title": "'Neural-gas' network for vector quantization and its application to time-series prediction",
    "abstract": "A neural network algorithm based on a soft-max adaptation rule is presented. This algorithm exhibits good performance in reaching the optimum minimization of a cost function for vector quantization data compression. The soft-max rule employed is an extension of the standard K-means clustering procedure and takes into account a neighborhood ranking of the reference (weight) vectors. It is shown that the dynamics of the reference (weight) vectors during the input-driven adaptation procedure are determined by the gradient of an energy function whose shape can be modulated through a neighborhood determining parameter and resemble the dynamics of Brownian particles moving in a potential determined by the data point density. The network is used to represent the attractor of the Mackey-Glass equation and to predict the Mackey-Glass time series, with additional local linear mappings for generating output values. The results obtained for the time-series prediction compare favorably with the results achieved by backpropagation and radial basis function networks. >",
    "date": "1993",
    "authors": [
        "T.M. Martinetz",
        "S.G. Berkovich",
        "K.J. Schulten"
    ],
    "related_topics": [
        "Neural gas",
        "Vector quantization",
        "Backpropagation"
    ],
    "citation_count": "1,849",
    "reference_count": "28",
    "references": [
        "1997063559",
        "2171277043",
        "65738273",
        "2150593711",
        "2913399920",
        "2002182716",
        "2127218421",
        "2098929365",
        "1998367480",
        "2094631910"
    ]
},{
    "id": "2134514463",
    "title": "A new evolutionary system for evolving artificial neural networks",
    "abstract": "This paper presents a new evolutionary system, i.e., EPNet, for evolving artificial neural networks (ANNs). The evolutionary algorithm used in EPNet is based on Fogel's evolutionary programming (EP). Unlike most previous studies on evolving ANN's, this paper puts its emphasis on evolving ANN's behaviors. Five mutation operators proposed in EPNet reflect such an emphasis on evolving behaviors. Close behavioral links between parents and their offspring are maintained by various mutations, such as partial training and node splitting. EPNet evolves ANN's architectures and connection weights (including biases) simultaneously in order to reduce the noise in fitness evaluation. The parsimony of evolved ANN's is encouraged by preferring node/connection deletion to addition. EPNet has been tested on a number of benchmark problems in machine learning and ANNs, such as the parity problem, the medical diagnosis problems, the Australian credit card assessment problem, and the Mackey-Glass time series prediction problem. The experimental results show that EPNet can produce very compact ANNs with good generalization ability in comparison with other algorithms.",
    "date": "1997",
    "authors": [
        "X. Yao",
        "Y. Liu"
    ],
    "related_topics": [
        "Evolutionary programming",
        "Evolutionary algorithm",
        "Evolutionary computation"
    ],
    "citation_count": "1,210",
    "reference_count": "48",
    "references": [
        "2154642048",
        "2171277043",
        "1978970913",
        "2142334564",
        "2109779438",
        "177635913",
        "2166322089",
        "2145085734",
        "2034099719",
        "2138784882"
    ]
},{
    "id": "2094631910",
    "title": "Oscillation and chaos in physiological control systems",
    "abstract": "First-order nonlinear differential-delay equations describing physiological control systems are studied. The equations display a broad diversity of dynamical behavior including limit cycle oscillations, with a variety of wave forms, and apparently aperiodic or \"chaotic\" solutions. These results are discussed in relation to dynamical respiratory and hematopoietic diseases.",
    "date": "1977",
    "authors": [
        "Michael C. Mackey",
        "Leon Glass"
    ],
    "related_topics": [
        "Dynamical systems theory",
        "Nonlinear system",
        "Oscillation (cell signaling)"
    ],
    "citation_count": "4,887",
    "reference_count": "26",
    "references": [
        "2102892532",
        "2008536883",
        "2056942998",
        "2014096963",
        "2320365816",
        "2047857069",
        "2325337867",
        "117960354",
        "2470860349",
        "2286035120"
    ]
},{
    "id": "2058580716",
    "title": "Original Contribution: Approximation of dynamical systems by continuous time recurrent neural networks",
    "abstract": "In this paper, we prove that any finite time trajectory of a given n-dimensional dynamical system can be approximately realized by the internal state of the output units of a continuous time recurrent neural network with n output units, some hidden units, and an appropriate initial condition. The essential idea of the proof is to embed the n-dimensional dynamical system into a higher dimensional one which defines a recurrent neural network. As a corollary, we also show that any continuous curve can be approximated by the output of a recurrent neural network.",
    "date": "1993",
    "authors": [
        "Ken-ichi Funahashi",
        "Yuichi Nakamura"
    ],
    "related_topics": [
        "Recurrent neural network",
        "Feedforward neural network",
        "Dynamical systems theory"
    ],
    "citation_count": "1,034",
    "reference_count": "13",
    "references": [
        "2154642048",
        "2137983211",
        "2103496339",
        "3146803896",
        "1971735090",
        "2016589492",
        "2007431958",
        "2143503258",
        "1977106683",
        "2065134213"
    ]
},{
    "id": "2143879519",
    "title": "Reconstruction of Natural Scenes from Ensemble Responses in the Lateral Geniculate Nucleus",
    "abstract": "A major challenge in studying sensory processing is to understand the meaning of the neural messages encoded in the spiking activity of neurons. From the recorded responses in a sensory circuit, what information can we extract about the outside world? Here we used a linear decoding technique to reconstruct spatiotemporal visual inputs from ensemble responses in the lateral geniculate nucleus (LGN) of the cat. From the activity of 177 cells, we have reconstructed natural scenes with recognizable moving objects. The quality of reconstruction depends on the number of cells. For each point in space, the quality of reconstruction begins to saturate at six to eight pairs of on and off cells, approaching the estimated coverage factor in the LGN of the cat. Thus, complex visual inputs can be reconstructed with a simple decoding algorithm, and these analyses provide a basis for understanding ensemble coding in the early visual pathway.",
    "date": "1999",
    "authors": [
        "Garrett B. Stanley",
        "Fei F. Li",
        "Yang Dan"
    ],
    "related_topics": [
        "Neural decoding",
        "Lateral geniculate nucleus",
        "Sensory system"
    ],
    "citation_count": "302",
    "reference_count": "41",
    "references": [
        "2145889472",
        "2137234026",
        "2097560155",
        "2167034998",
        "1589549454",
        "1993197592",
        "2116360511",
        "1570751785",
        "1984931175",
        "2162489171"
    ]
},{
    "id": "2045182040",
    "title": "WINNING ENTRY OF THE K. U. LEUVEN TIME-SERIES PREDICTION COMPETITION",
    "abstract": "In this paper we describe the winning entry of the time-series prediction competition which was part of the International Workshop on Advanced Black-Box Techniques for Nonlinear Modeling, held at K. U. Leuven, Belgium on July 8\u201310, 1998. We also describe the source of the data set, a nonlinear transform of a 5-scroll generalized Chua's circuit. Participants were given 2000 data points and were asked to predict the next 200 points in the series. The winning entry exploited symmetry that was discovered during exploratory data analysis and a method of local modeling designed specifically for the prediction of chaotic time-series. This method includes an exponentially weighted metric, a nearest trajectory algorithm, integrated local averaging, and a novel multistep ahead cross-validation estimation of model error for the purpose of parameter optimization.",
    "date": "1999",
    "authors": [
        "J McNames",
        "Johan Suykens",
        "Joos Vandewalle"
    ],
    "related_topics": [
        "Time series",
        "Metric (mathematics)",
        "Exploratory data analysis"
    ],
    "citation_count": "60",
    "reference_count": "42",
    "references": [
        "1689445748",
        "1549386224",
        "2034099719",
        "2024668293",
        "1599681710",
        "2129287653",
        "2171987742",
        "3036383388",
        "2136038769",
        "2496842803"
    ]
},{
    "id": "1943433854",
    "title": "Model of Cortical-Basal Ganglionic Processing: Encoding the Serial Order of Sensory Events",
    "abstract": "Beiser, David G. and James C. Houk. Model of cortical-basal ganglionic processing: encoding the serial order of sensory events. J. Neurophysiol. 79: 3168\u20133188, 1998. Several lines of evidence sugge...",
    "date": "1998",
    "authors": [
        "David G. Beiser",
        "James C. Houk"
    ],
    "related_topics": [
        "Sensory system",
        "Neuroscience",
        "Basal (phylogenetics)"
    ],
    "citation_count": "329",
    "reference_count": "111",
    "references": [
        "2099652807",
        "182048401",
        "2031170958",
        "2044474088",
        "1939596644",
        "1513126258",
        "2887242076",
        "1959983357",
        "1828538530",
        "3081834340"
    ]
},{
    "id": "2128499899",
    "title": "Induction of Multiscale Temporal Structure",
    "abstract": "Learning structure in temporally-extended sequences is a difficult computational problem because only a fraction of the relevant information is available at any instant. Although variants of back propagation can in principle be used to find structure in sequences, in practice they are not sufficiently powerful to discover arbitrary contingencies, especially those spanning long temporal intervals or involving high order statistics. For example, in designing a connectionist network for music composition, we have encountered the problem that the net is able to learn musical structure that occurs locally in time--e.g., relations among notes within a musical phrase--but not structure that occurs over longer time periods--e.g., relations among phrases. To address this problem, we require a means of constructing a reduced description of the sequence that makes global aspects more explicit or more readily detectable. I propose to achieve this using hidden units that operate with different time constants. Simulation experiments indicate that slower time-scale hidden units are able to pick up global structure, structure that simply can not be learned by standard back propagation.",
    "date": "1991",
    "authors": [
        "Michael C Mozer"
    ],
    "related_topics": [
        "Computational problem",
        "Sequence",
        "Structure (mathematical logic)"
    ],
    "citation_count": "157",
    "reference_count": "8",
    "references": [
        "2154642048",
        "2016589492",
        "2007431958",
        "2143503258",
        "1959983357",
        "2028629011",
        "2053127376",
        "2167607759"
    ]
},{
    "id": "2088978850",
    "title": "Minimizing multimodal functions of continuous variables with the \u201csimulated annealing\u201d algorithm\u2014Corrigenda for this article is available here",
    "abstract": "A new global optimization algorithm for functions of continuous variables is presented, derived from the \u201cSimulated Annealing\u201d algorithm recently introduced in combinatorial optimization.The algorithm is essentially an iterative random search procedure with adaptive moves along the coordinate directions. It permits uphill moves under the control of a probabilistic criterion, thus tending to avoid the first local minima encountered.The algorithm has been tested against the Nelder and Mead simplex method and against a version of Adaptive Random Search. The test functions were Rosenbrock valleys and multiminima functions in 2,4, and 10 dimensions.The new method proved to be more reliable than the others, being always able to find the optimum, or at least a point very close to it. It is quite costly in term of function evaluations, but its cost can be predicted in advance, depending only slightly on the starting point.",
    "date": "1987",
    "authors": [
        "A. Corana",
        "M. Marchesi",
        "C. Martini",
        "S. Ridella"
    ],
    "related_topics": [
        "Adaptive simulated annealing",
        "Simulated annealing",
        "Hill climbing"
    ],
    "citation_count": "2,063",
    "reference_count": "15",
    "references": [
        "2581275558",
        "2171074980",
        "2022772618",
        "2056760934",
        "2026258334",
        "2012231377",
        "2152710595",
        "2029673686",
        "1652464192",
        "2065606540"
    ]
},{
    "id": "2148099973",
    "title": "Global optimization of a neural network-hidden Markov model hybrid",
    "abstract": "The integration of multilayered and recurrent artificial neural networks (ANNs) with hidden Markov models (HMMs) is addressed. ANNs are suitable for approximating functions that compute new acoustic parameters, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported. >",
    "date": "1992",
    "authors": [
        "Y. Bengio",
        "R. De Mori",
        "G. Flammia",
        "R. Kompe"
    ],
    "related_topics": [
        "Hidden Markov model",
        "Markov model",
        "Artificial neural network"
    ],
    "citation_count": "349",
    "reference_count": "30",
    "references": [
        "2125838338",
        "2154642048",
        "169539560",
        "2077804127",
        "2135622428",
        "2086699924",
        "2140539590",
        "2169415433",
        "2140766383",
        "2125610452"
    ]
},{
    "id": "1996741810",
    "title": "Local feedback multilayered networks",
    "abstract": "In this paper, we investigate the capabilities of local feedback multilayered networks, a particular class of recurrent networks, in which feedback connections are only allowed from neurons to themselves. In this class, learning can be accomplished by an algorithm that is local in both space and time. We describe the limits and properties of these networks and give some insights on their use for solving practical problems.",
    "date": "1992",
    "authors": [
        "Paolo Frasconi",
        "Marco Gori",
        "Giovanni Soda"
    ],
    "related_topics": [
        "Class (computer programming)",
        "Artificial intelligence",
        "Computer science"
    ],
    "citation_count": "273",
    "reference_count": "14",
    "references": [
        "2110485445",
        "2016589492",
        "2007431958",
        "2143503258",
        "2121553911",
        "2140539590",
        "2133656308",
        "2047515372",
        "2032164462",
        "2094096029"
    ]
},{
    "id": "2125329357",
    "title": "Using random weights to train multilayer networks of hard-limiting units",
    "abstract": "A gradient descent algorithm suitable for training multilayer feedforward networks of processing units with hard-limiting output functions is presented. The conventional backpropagation algorithm cannot be applied in this case because the required derivatives are not available. However, if the network weights are random variables with smooth distribution functions, the probability of a hard-limiting unit taking one of its two possible values is a continuously differentiable function. In the paper, this is used to develop an algorithm similar to backpropagation, but for the hard-limiting case. It is shown that the computational framework of this algorithm is similar to standard backpropagation, but there is an additional computational expense involved in the estimation of gradients. Upper bounds on this estimation penalty are given. Two examples which indicate that, when this algorithm is used to train networks of hard-limiting units, its performance is similar to that of conventional backpropagation applied to networks of units with sigmoidal characteristics are presented. >",
    "date": "1992",
    "authors": [
        "P.L. Barlett",
        "T. Downs"
    ],
    "related_topics": [
        "Backpropagation",
        "Gradient descent",
        "Artificial neural network"
    ],
    "citation_count": "55",
    "reference_count": "15",
    "references": [
        "2154642048",
        "2165758113",
        "2016589492",
        "1507849272",
        "2176028050",
        "2010029425",
        "2084544490",
        "2181111061",
        "1529808766",
        "2003357516"
    ]
},{
    "id": "1527772862",
    "title": "A focused backpropagation algorithm for temporal pattern recognition",
    "abstract": "",
    "date": "1994",
    "authors": [
        "Michael C. Mozer"
    ],
    "related_topics": [
        "Pattern recognition (psychology)",
        "Backpropagation",
        "Pattern recognition"
    ],
    "citation_count": "339",
    "reference_count": "0",
    "references": []
},{
    "id": "2001810881",
    "title": "Corpus-based comprehensive and diagnostic MT evaluation: initial Arabic, Chinese, French, and Spanish results",
    "abstract": "We describe two metrics for automatic evaluation of machine translation quality. These metrics, BLEU and NEE, are compared to human judgment of quality of translation of Arabic, Chinese, French, and Spanish documents into English.",
    "date": "2002",
    "authors": [
        "Kishore Papineni",
        "Salim Roukos",
        "Todd Ward",
        "John Henderson",
        "Florence Reeder"
    ],
    "related_topics": [
        "Evaluation of machine translation",
        "BLEU",
        "Natural language processing"
    ],
    "citation_count": "58",
    "reference_count": "4",
    "references": [
        "2101105183",
        "2913739034",
        "2046319108",
        "638025976"
    ]
},{
    "id": "3037252522",
    "title": "The ARPA MT Evaluation Methodologies: Evolution, Lessons, and Future Approaches",
    "abstract": "",
    "date": "1994",
    "authors": [
        "John S. White",
        "Theresa A. O\u2019Connell",
        "Francis E. O\u2019Mara"
    ],
    "related_topics": [
        "Machine translation",
        "Computer science",
        "Software engineering"
    ],
    "citation_count": "202",
    "reference_count": "5",
    "references": [
        "2006969979",
        "1969655989",
        "2016336271",
        "2155802047",
        "2103330339"
    ]
},{
    "id": "2732923061",
    "title": "Proficiency and Performance in Language Testing.",
    "abstract": "",
    "date": "1992",
    "authors": [
        "James Child"
    ],
    "related_topics": [
        "Language assessment",
        "Language proficiency",
        "Linguistics"
    ],
    "citation_count": "29",
    "reference_count": "0",
    "references": []
},{
    "id": "1980862600",
    "title": "Statistical Learning by 8-Month-Old Infants",
    "abstract": "Learners rely on a combination of experience-independent and experience-dependent mechanisms to extract information from the environment. Language acquisition involves both types of mechanisms, but most theorists emphasize the relative importance of experience-independent mechanisms. The present study shows that a fundamental task of language acquisition, segmentation of words from fluent speech, can be accomplished by 8-month-old infants based solely on the statistical relationships between neighboring speech sounds. Moreover, this word segmentation was based on statistical learning from only 2 minutes of exposure, suggesting that infants have access to a powerful mechanism for the computation of statistical properties of the language input.",
    "date": "1996",
    "authors": [
        "Jenny R. Saffran",
        "Richard N. Aslin",
        "Elissa L. Newport"
    ],
    "related_topics": [
        "Language acquisition",
        "Speech segmentation",
        "Artificial grammar learning"
    ],
    "citation_count": "5,866",
    "reference_count": "7",
    "references": [
        "2140661818",
        "2038056950",
        "2029948425",
        "2135547275",
        "1979285432",
        "2015982521",
        "2039686608"
    ]
},{
    "id": "2038698865",
    "title": "HMM-based word alignment in statistical translation",
    "abstract": "In this paper, we describe a new model for word alignment in statistical translation and present experimental results. The idea of the model is to make the alignment probabilities dependent on the differences in the alignment positions rather than on the absolute positions. To achieve this goal, the approach uses a first-order Hidden Markov model (HMM) for the word alignment problem as they are used successfully in speech recognition for the time alignment problem. The difference to the time alignment HMM is that there is no monotony constraint for the possible word orderings. We describe the details of the model and test the model on several bilingual corpora.",
    "date": "1996",
    "authors": [
        "Stephan Vogel",
        "Hermann Ney",
        "Christoph Tillmann"
    ],
    "related_topics": [
        "Word error rate",
        "Hidden Markov model",
        "Word (computer architecture)"
    ],
    "citation_count": "1,104",
    "reference_count": "6",
    "references": [
        "2006969979",
        "1575431606",
        "1562694524",
        "2065627366",
        "2134627713",
        "2160721289"
    ]
},{
    "id": "1979102019",
    "title": "A comparison of alignment models for statistical machine translation",
    "abstract": "In this paper, we present and compare various alignment models for statistical machine translation. We propose to measure the quality of an alignment model using the quality of the Viterbi alignment compared to a manually-produced alignment and describe a refined annotation scheme to produce suitable reference alignments. We also compare the impact of different alignment models on the translation quality of a statistical machine translation system.",
    "date": "2000",
    "authors": [
        "Franz Josef Och",
        "Hermann Ney"
    ],
    "related_topics": [
        "Machine translation",
        "Viterbi algorithm",
        "Translation (geometry)"
    ],
    "citation_count": "280",
    "reference_count": "9",
    "references": [
        "2006969979",
        "1517947178",
        "2038698865",
        "1529616844",
        "1575431606",
        "3104029765",
        "1562694524",
        "1811404221",
        "136130055"
    ]
},{
    "id": "1811404221",
    "title": "Manual Annotation of Translational Equivalence: The Blinker Project",
    "abstract": "Bilingual annotators were paid to link roughly sixteen thousand corresponding words between on-line versions of the Bible in modern French and modern English. These annotations are freely available to the research community from this http URL . The annotations can be used for several purposes. First, they can be used as a standard data set for developing and testing translation lexicons and statistical translation models. Second, researchers in lexical semantics will be able to mine the annotations for insights about cross-linguistic lexicalization patterns. Third, the annotations can be used in research into certain recently proposed methods for monolingual word-sense disambiguation. This paper describes the annotated texts, the specially-designed annotation tool, and the strategies employed to increase the consistency of the annotations. The annotation process was repeated five times by different annotators. Inter-annotator agreement rates indicate that the annotations are reasonably reliable and that the method is easy to replicate.",
    "date": "1998",
    "authors": [
        "I. Dan Melamed"
    ],
    "related_topics": [
        "Annotation",
        "Lexicalization",
        "Natural language processing"
    ],
    "citation_count": "122",
    "reference_count": "11",
    "references": [
        "1632114991",
        "2006969979",
        "2343954916",
        "2016336271",
        "91190427",
        "2138787466",
        "1540222736",
        "3037393508",
        "1672171594",
        "2159343191"
    ]
},{
    "id": "2030750105",
    "title": "But dictionaries are data too",
    "abstract": "Although empiricist approaches to machine translation depend vitally on data in the form of large bilingual corpora, bilingual dictionaries are also a source of information. We show how to model at least a part of the information contained in a bilingual dictionary so that we can treat a bilingual dictionary and a bilingual corpus as two facets of a unified collection of data from which to extract values for the parameters of a probabilistic machine translation system. We give an algorithm for obtaining maximum likelihood estimates of the parameters of a probabilistic model from this combined data and we show how these parameters are affected by inclusion of the dictionary for some sample words.",
    "date": "1993",
    "authors": [
        "Peter F. Brown",
        "Stephen A. Della Pietra",
        "Vincent J. Della Pietra",
        "Meredith J. Goldsmith",
        "Jan Hajic",
        "Robert L. Mercer",
        "Surya Mohanty"
    ],
    "related_topics": [
        "Bilingual dictionary",
        "Example-based machine translation",
        "Machine translation"
    ],
    "citation_count": "85",
    "reference_count": "3",
    "references": [
        "2049633694",
        "2006969979",
        "1575431606"
    ]
},{
    "id": "1525706028",
    "title": "Evaluation of word alignment systems",
    "abstract": "This project evaluates two different systems that generate wordalignments on English-Swedish data. The systems to be used are the Giza++ system, that may generate a variety of statistical translati ...",
    "date": "2000",
    "authors": [
        "Lars Ahrenberg",
        "Magnus Merkel",
        "Anna S\u00e5gvall Hein",
        "J\u00f6rg Tiedemann"
    ],
    "related_topics": [
        "Language technology",
        "Quantitative linguistics",
        "Variety (linguistics)"
    ],
    "citation_count": "72",
    "reference_count": "17",
    "references": [
        "2006969979",
        "1973923101",
        "2097333193",
        "1489181569",
        "2117652747",
        "1979102019",
        "3140453591",
        "2963010813",
        "1811404221",
        "1672171594"
    ]
},{
    "id": "136130055",
    "title": "Forming Word Classes by Statistical Clustering for Statistical Language Modelling",
    "abstract": "In statistical language modelling there is always a problem of sparse data. A way to reduce this problem is to form groups of words in order to get equivalence classes. In this paper we present a clustering algorithm that builds abstract word equivalence classes. The algorithm finds a local optimum according to a maximum-likelihood criterion. Experiments were made on an English 1.1-million word corpus and a German 100,000-word corpus. Compared to a word bigram model, the use of clustered equivalence classes in a bigram class model leads to a significant improvement, as measured by the perplexity. Depending on the size of the training material, the automatically clustered word classes are even better than manually determined categories.",
    "date": "1992",
    "authors": [
        "Reinhard Kneser",
        "Hermann Ney"
    ],
    "related_topics": [
        "Bigram",
        "Cluster analysis",
        "Perplexity"
    ],
    "citation_count": "57",
    "reference_count": "6",
    "references": [
        "3017143921",
        "1966812932",
        "2127836646",
        "2055528812",
        "2020749563",
        "2153295945"
    ]
},{
    "id": "2052449326",
    "title": "Three new probabilistic models for dependency parsing: an exploration",
    "abstract": "After presenting a novel O(n3) parsing algorithm for dependency grammar, we develop three contrasting ways to stochasticize it. We propose (a) a lexical affinity model where words struggle to modify each other, (b) a sense tagging model where words fluctuate randomly in their selectional preferences, and (c) a generative model where the speaker fleshes out each word's syntactic and conceptual structure without regard to the implications for the hearer. We also give preliminary empirical results from evaluating the three models' parsing performance on annotated Wall Street Journal training text (derived from the Penn Treebank). In these results, the generative model performs significantly better than the others, and does about equally well at assigning part-of-speech tags.",
    "date": "1996",
    "authors": [
        "Jason M. Eisner"
    ],
    "related_topics": [
        "Data-oriented parsing",
        "S-attributed grammar",
        "Top-down parsing"
    ],
    "citation_count": "919",
    "reference_count": "14",
    "references": [
        "2099247782",
        "2110882317",
        "2153439141",
        "3089319657",
        "2100796029",
        "2142708806",
        "2167434254",
        "1541301615",
        "1976241232",
        "1982944197"
    ]
},{
    "id": "1972573551",
    "title": "Generalized Phrase Structure Grammar",
    "abstract": "\"Generalized Phrase Structure Grammar\" provides the definitive exposition of the theory of grammar originally proposed by Gerald Gazdar and developed during half a dozen years' work with his colleagues Ewan Klein, Geoffrey Pullum, and Ivan Sag. This long-awaited book contains both detailed specifications of the theory and extensive illustrations of its power to describe large parts of English grammar. Experts who wish to evaluate the theory and students learning GPSP for the first time will find this book an invaluable guide.The initial chapters lay out the theoretical machinery of GPSP in a readily intelligible way. Combining informal discussion with precise formalization, the authors describe all major aspects of their grammatical system, including a complete theory of syntactic features, phrase structure rules, meta rules, and feature instantiation principles. The book then shows just what a GPSP analysis of English syntax can accomplish. Topics include the internal structure of phrases, unbounded dependency constructions of many varieties, and coordinate conjunction a construction long considered the sticking point for phrase structure approaches to syntax.The book concludes with a well developed proposal for a model theoretic semantic system to go along with GPSP syntax. Throughout, the authors maintain the highest standards of explicitness and rigor in developing and assessing their grammatical system. Their aim is to provide the best possible test of the hypothesis that syntactic description can be accomplished in a single-level system. And more generally, it is their intention to formulate a grammatical framework in which linguistic universals follow directly from the form of the system and therefore require no explicit statement. Their book sets new methodological standards for work in generative grammar while presenting a grammatical system of extraordinary scope.\"",
    "date": "1984",
    "authors": [
        "Gerald Gazdar",
        "Ewan Klein",
        "Geoffrey Pullum",
        "Ivan Sag"
    ],
    "related_topics": [
        "Generalized phrase structure grammar",
        "Generative grammar",
        "Phrase structure rules"
    ],
    "citation_count": "4,136",
    "reference_count": "0",
    "references": []
},{
    "id": "2087165009",
    "title": "Procedure for quantitatively comparing the syntactic coverage of English grammars",
    "abstract": "The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution. Prima facie, known English grammars appear to disagree strongly with each other as to the elements of even the simplest sentences. For instance, the grammars of Steve Abney (Bellcore), Ezra Black (IBM), Dan Flickinger (Hewlett Packard), Claudia Gdaniec (Logos), Ralph Grishman and Tomek Strzalkowski (NYU), Phil Harrison (Boeing), Don Hindle (AT&T), Bob Ingria (BBN), and Mitch Marcus (U. of Pennsylvania) recognize in common only the following constituents, when each grammarian provides the single parse which he/she would ideally want his/her grammar to specify for three sample Brown Corpus sentences:The famed Yankee Clipper, now retired, has been assisting (as (a batting coach)).One of those capital-gains ventures, in fact, has saddled him (with Gore Court).He said this constituted a (very serious) misuse (of the (Criminal court) processes).",
    "date": "1991",
    "authors": [
        "S. Abney",
        "S. Flickenger",
        "C. Gdaniec",
        "C. Grishman",
        "P. Harrison",
        "D. Hindle",
        "R. Ingria",
        "F. Jelinek",
        "J. Klavans",
        "M. Liberman",
        "M. Marcus",
        "S. Roukos",
        "B. Santorini",
        "T. Strzalkowski",
        "E. Black"
    ],
    "related_topics": [
        "Parsing",
        "Brown Corpus",
        "Grammarian"
    ],
    "citation_count": "639",
    "reference_count": "0",
    "references": []
},{
    "id": "2069912724",
    "title": "Decision tree parsing using a hidden derivation model",
    "abstract": "Parser development is generally viewed as a primarily linguistic enterprise. A grammarian examines sentences, skillfully extracts the linguistic generalizations evident in the data, and writes grammar rules which cover the language. The grammarian then evaluates the performance of the grammar, and upon analysis of the errors made by the grammar-based parser, carefully refines the rules, repeating this process, typically over a period of several years.",
    "date": "1994",
    "authors": [
        "F. Jelinek",
        "J. Lafferty",
        "D. Magerman",
        "R. Mercer",
        "A. Ratnaparkhi",
        "S. Roukos"
    ],
    "related_topics": [
        "Parsing",
        "Attribute grammar",
        "Top-down parsing"
    ],
    "citation_count": "123",
    "reference_count": "12",
    "references": [
        "1594031697",
        "2121227244",
        "2167434254",
        "1542847127",
        "1924403233",
        "2039240651",
        "2021758792",
        "2029825515",
        "2008506796",
        "2128430409"
    ]
},{
    "id": "2162455891",
    "title": "A Fully Statistical Approach to Natural Language Interfaces",
    "abstract": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames.",
    "date": "1996",
    "authors": [
        "Scott Miller",
        "David Stallard",
        "Robert Bobrow",
        "Richard Schwartz"
    ],
    "related_topics": [
        "Language identification",
        "Natural language user interface",
        "Semantic interpretation"
    ],
    "citation_count": "191",
    "reference_count": "15",
    "references": [
        "2099247782",
        "2153439141",
        "1936920915",
        "1955233831",
        "2091671846",
        "2138425667",
        "1975040318",
        "2134495021",
        "2096435848",
        "1529084404"
    ]
},{
    "id": "1916559533",
    "title": "Statistical Machine Translation",
    "abstract": "This introductory text to statistical machine translation (SMT) provides all of the theories and methods needed to build a statistical machine translator, such as Google Language Tools and Babelfish. In general, statistical techniques allow automatic translation systems to be built quickly for any language-pair using only translated texts and generic software. With increasing globalization, statistical machine translation will be central to communication and commerce. Based on courses and tutorials, and classroom-tested globally, it is ideal for instruction or self-study, for advanced undergraduates and graduate students in computer science and/or computational linguistics, and researchers in natural language processing. The companion website provides open-source corpora and tool-kits.",
    "date": "2010",
    "authors": [
        "Philipp Koehn"
    ],
    "related_topics": [
        "Hybrid machine translation",
        "Machine translation",
        "Example-based machine translation"
    ],
    "citation_count": "2,000",
    "reference_count": "68",
    "references": [
        "2101105183",
        "1574901103",
        "2049633694",
        "2006969979",
        "2135843243",
        "2117400858",
        "2101210369",
        "1973923101",
        "2097333193",
        "2122922578"
    ]
},{
    "id": "2135843243",
    "title": "TnT -- A Statistical Part-of-Speech Tagger",
    "abstract": "Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger. Contrary to claims found elsewhere in the literature, we argue that a tagger based on Markov models performs at least as well as other current approaches, including the Maximum Entropy framework. A recent comparison has even shown that TnT performs significantly better for the tested corpora. We describe the basic model of TnT, the techniques used for smoothing and for handling unknown words. Furthermore, we present evaluations on two corpora.",
    "date": "2000",
    "authors": [
        "Thorsten Brants"
    ],
    "related_topics": [
        "Trigram tagger",
        "Markov model",
        "Principle of maximum entropy"
    ],
    "citation_count": "2,030",
    "reference_count": "12",
    "references": [
        "2125838338",
        "1632114991",
        "1773803948",
        "2046224275",
        "1522263329",
        "1554031433",
        "1551773846",
        "1965364888",
        "2166394306",
        "2130636661"
    ]
},{
    "id": "2107551411",
    "title": "A DP based Search Algorithm for Statistical Machine Translation",
    "abstract": "We introduce a novel search algorithm for statistical machine translation based on dynamic programming (DP). During the search process two statistical knowledge sources are combined: a translation model and a bigram language model. This search algorithm expands hypotheses along the positions of the target string while guaranteeing progressive coverage of the words in the source string. We present experimental results on the Verbmobil task.",
    "date": "1998",
    "authors": [
        "S. NieBen",
        "S. Vogel",
        "H. Ney",
        "C. Tillmann"
    ],
    "related_topics": [
        "Example-based machine translation",
        "Beam search",
        "Rule-based machine translation"
    ],
    "citation_count": "85",
    "reference_count": "12",
    "references": [
        "2006969979",
        "2038698865",
        "2138584836",
        "1562694524",
        "2065627366",
        "2146418175",
        "2422872931",
        "1603508585",
        "2134627713",
        "2012511220"
    ]
},{
    "id": "2113106066",
    "title": "Speech translation: coupling of recognition and translation",
    "abstract": "In speech translation, we are faced with the problem of how to couple the speech recognition process and the translation process. Starting from the Bayes decision rule for speech translation, we analyze how the interaction between the recognition process and the translation process can be modelled. In the light of this decision rule, we discuss the already existing approaches to speech translation. None of the existing approaches seems to have addressed this direct interaction. We suggest two new methods, the local averaging approximation and the monotone alignments.",
    "date": "1999",
    "authors": [
        "H. Ney"
    ],
    "related_topics": [
        "Speech translation",
        "Rule-based machine translation",
        "Example-based machine translation"
    ],
    "citation_count": "213",
    "reference_count": "11",
    "references": [
        "2006969979",
        "2146418175",
        "2422872931",
        "1603508585",
        "2139647714",
        "2012511220",
        "2158164089",
        "2166810516",
        "2096312440",
        "3088213079"
    ]
},{
    "id": "2196555355",
    "title": "Automatic Acquisition of Hierarchical Transduction Models for Machine Translation",
    "abstract": "We describe a method for the fully automatic learning of hierarchical finite state translation models. The input to the method is transcribed speech utterances and their corresponding human translations, and the output is a set of head transducers, i.e. statistical lexical head-outward transducers. A word-alignment function and a head-ranking function are first obtained, and then counts are generated for hypothesized state transitions of head transducers whose lexical translations and word order changes are consistent with the alignment. The method has been applied to create an English-Spanish translation model for a Speech translation application, with word accuracy of over 75% as measured by a string-distance comparison to three reference translations.",
    "date": "1998",
    "authors": [
        "Hiyan Alshawi",
        "Srinivas Bangalore",
        "Shona Douglas"
    ],
    "related_topics": [
        "Speech translation",
        "Example-based machine translation",
        "Rule-based machine translation"
    ],
    "citation_count": "65",
    "reference_count": "10",
    "references": [
        "2006969979",
        "2110882317",
        "2097333193",
        "2158388102",
        "2154384676",
        "2952654140",
        "2139895384",
        "2162346592",
        "1942952754",
        "2016747603"
    ]
},{
    "id": "2294072136",
    "title": "Improving Statistical Natural Language Translation with Categories and Rules",
    "abstract": "This paper describes an all level approach on statistical natural language translation (SNLT). Without any predefined knowledge the system learns a statistical translation lexicon (STL), word classes (WCs) and translation rules (TRs) from a parallel corpus thereby producing a generalized form of a word alignment (WA). The translation process itself is realized as a beam search. In our method example-based techniques enter an overall statistical approach leading to about 50 percent correctly translated sentences applied to the very difficult English-German VERBMOBIL spontaneous speech corpus.",
    "date": "1998",
    "authors": [
        "Franz Josef Och",
        "Hans Weber"
    ],
    "related_topics": [
        "Example-based machine translation",
        "Machine translation",
        "Lexicon"
    ],
    "citation_count": "56",
    "reference_count": "6",
    "references": [
        "2006969979",
        "47415966",
        "2038698865",
        "1575431606",
        "1520943203",
        "2154361524"
    ]
},{
    "id": "2158164089",
    "title": "A DP-based Search Using Monotone Alignments in Statistical Translation",
    "abstract": "In this paper, we describe a Dynamic Programming (DP) based search algorithm for statistical translation and present experimental results. The statistical translation uses two sources of information: a translation model and a language model. The language model used is a standard bigram model. For the translation model, the alignment probabilities are made dependent on the differences in the alignment positions rather than on the absolute positions. Thus, the approach amounts to a first-order Hidden Markov model (HMM) as they are used successfully in speech recognition for the time alignment problem. Under the assumption that the alignment is monotone with respect to the word order in both languages, an efficient search strategy for translation can be formulated. The details of the search algorithm are described. Experiments on the EuTrans corpus produced a word error rate of 5.1%.",
    "date": "1997",
    "authors": [
        "Christoph Tillmann",
        "Stephan Vogel",
        "Hermann Ney",
        "Alex Zubiaga"
    ],
    "related_topics": [
        "Word error rate",
        "Cache language model",
        "Language model"
    ],
    "citation_count": "134",
    "reference_count": "10",
    "references": [
        "2006969979",
        "2038698865",
        "2065627366",
        "2115755647",
        "2146418175",
        "2422872931",
        "2134627713",
        "2139647714",
        "2144789800",
        "2160721289"
    ]
},{
    "id": "2129765547",
    "title": "Empirical Methods for Exploiting Parallel Texts",
    "abstract": "The translation of a text can be viewed as a detailed annotation of the text's meaning. From this point of view, texts that exist in two languages (bitexts) are the richest accessible source of linguistic knowledge. Such knowledge can be exploited in many ways, if it can be automatically acquired. The acquisition process is invariably based on automatic methods for inducing translational equivalence relations between the two halves of a bitext. At the word token level, these relations are called bitext maps; at the word type level, they are called translation models. This dissertation advances the state of the art in methods for determining both kinds of translational equivalence. It also shows how to integrate these methods to exploit a much wider variety of bitexts than was previously possible. The dissertation begins by showing that the language-specific aspects of the bitext mapping problem can be encapsulated and modularized away, leaving only a problem of geometric pattern recognition. The best solution is then the one that maximizes the signal-to-noise ratio in the search space and employs the fastest and most accurate search algorithm. The dissertation presents new methods for maximizing the signal strength, for filtering noise, and for searching the resulting scatterplot in linear expected space and time. The unprecedented accuracy of this solution enables a new application of bitext maps--automatic detection of omissions in translations. The second half of the dissertation makes a number of advances in statistical translation modeling. First, it proves the feasibility of modeling translational equivalence independently of word order. Second, the dissertation shows why and how translation models can benefit from an explicit noise model. Third, it shows how the noise model can be conditioned on almost any kind of pre-existing language-specific knowledge, and that even simple linguistic clues can significantly improve translation model accuracy. Fourth, the dissertation shows how to automatically determine the sense inventories of words in bitext and how to automatically discover word sequences that are translated as a unit. This information enables translation models that account for polysemy and for phrasal translations.",
    "date": "2000",
    "authors": [
        "Ilya Dan Melamed",
        "Mitchell Marcus"
    ],
    "related_topics": [
        "Word order",
        "Equivalence (formal languages)",
        "Polysemy"
    ],
    "citation_count": "228",
    "reference_count": "5",
    "references": [
        "2006969979",
        "3017143921",
        "1489181569",
        "2117652747",
        "2134031652"
    ]
},{
    "id": "2139403546",
    "title": "Fast Decoding and Optimal Decoding for Machine Translation",
    "abstract": "A good decoding algorithm is critical to the success of any statistical machine translation system. The decoder's job is to find the translation that is most likely according to set of previously learned parameters (and a formula for combining them). Since the space of possible translations is extremely large, typical decoding algorithms are only able to examine a portion of it, thus risking to miss good solutions. In this paper, we compare the speed and output quality of a traditional stack-based decoding algorithm with two new decoders: a fast greedy decoder and a slow but optimal decoder that treats decoding as an integer-programming optimization problem.",
    "date": "2001",
    "authors": [
        "Ulrich Germann",
        "Michael Jahr",
        "Kevin Knight",
        "Daniel Marcu",
        "Kenji Yamada"
    ],
    "related_topics": [
        "Soft-decision decoder",
        "Sequential decoding",
        "List decoding"
    ],
    "citation_count": "326",
    "reference_count": "11",
    "references": [
        "2011039300",
        "2006969979",
        "1667614912",
        "1650993530",
        "1559942044",
        "1555286493",
        "2146418175",
        "2012511220",
        "2158164089",
        "2035227369"
    ]
},{
    "id": "133045130",
    "title": "The CMU Statistical Machine Translation System",
    "abstract": "In this paper we describe the components of our statistical machine translation system. This system combines phrase-tophrase translations extracted from a bilingual corpus using different alignment approaches. Special methods to extract and align named entities are used. We show how a manual lexicon can be incorporated into the statistical system in an optimized way. Experiments on Chinese-toEnglish and Arabic-to-English translation tasks are presented.",
    "date": "2002",
    "authors": [
        "Stephan Vogel",
        "Ying Zhang",
        "Fei Huang",
        "Alicia Tribble",
        "Ashish Venugopal",
        "Bing Zhao",
        "Alex Waibel"
    ],
    "related_topics": [
        "Lexicon",
        "Natural language processing",
        "Translation (geometry)"
    ],
    "citation_count": "182",
    "reference_count": "13",
    "references": [
        "2101105183",
        "2006969979",
        "1973923101",
        "2116316001",
        "2161792612",
        "2158388102",
        "2038698865",
        "1991635536",
        "2114434620",
        "2396590899"
    ]
},{
    "id": "1513168562",
    "title": "Regular models of phonological rule systems",
    "abstract": "This paper presents a set of mathematical and computational tools for manipulating and reasoning about regular languages and regular relations and argues that they provide a solid basis for computational phonology. It shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism. This analysis provides a common representation of phonological constraints that supports efficient generation and recognition by a single simple interpreter.",
    "date": "1994",
    "authors": [
        "Ronald M. Kaplan",
        "Martin Kay"
    ],
    "related_topics": [
        "Regular language",
        "Phonological rule",
        "Rule-based machine translation"
    ],
    "citation_count": "972",
    "reference_count": "14",
    "references": [
        "2002089154",
        "201288405",
        "1598851216",
        "1535681052",
        "2167954650",
        "2065700902",
        "13674071",
        "2569714427",
        "1983606164",
        "1823507963"
    ]
},{
    "id": "1991133427",
    "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm",
    "abstract": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms.",
    "date": "1967",
    "authors": [
        "A. Viterbi"
    ],
    "related_topics": [
        "Sequential decoding",
        "Serial concatenated convolutional codes",
        "List decoding"
    ],
    "citation_count": "9,436",
    "reference_count": "7",
    "references": [
        "2034274945",
        "1993944611",
        "2087362480",
        "2005530146",
        "1976797517",
        "1527268325",
        "1527096151"
    ]
},{
    "id": "201288405",
    "title": "Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production",
    "abstract": "",
    "date": "1982",
    "authors": [
        "Kimmo Koskenniemi"
    ],
    "related_topics": [
        "Computational linguistics",
        "Computational model",
        "Word (computer architecture)"
    ],
    "citation_count": "1,125",
    "reference_count": "0",
    "references": []
},{
    "id": "2145287260",
    "title": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification",
    "abstract": "In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance.",
    "date": "2014",
    "authors": [
        "Yaniv Taigman",
        "Ming Yang",
        "Marc'Aurelio Ranzato",
        "Lior Wolf"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face hallucination",
        "Facial recognition system"
    ],
    "citation_count": "5,593",
    "reference_count": "34",
    "references": [
        "2618530766",
        "2310919327",
        "2168231600",
        "2072128103",
        "1782590233",
        "2163808566",
        "2047508432",
        "1498436455",
        "2536626143",
        "1976948919"
    ]
},{
    "id": "2062118960",
    "title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition",
    "abstract": "Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the OverFeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the OverFeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the OverFeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or L2 distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.",
    "date": "2014",
    "authors": [
        "Ali Sharif Razavian",
        "Hossein Azizpour",
        "Josephine Sullivan",
        "Stefan Carlsson"
    ],
    "related_topics": [
        "Feature (machine learning)",
        "Visual Word",
        "Convolutional neural network"
    ],
    "citation_count": "3,937",
    "reference_count": "49",
    "references": [
        "2618530766",
        "2102605133",
        "1849277567",
        "2963542991",
        "2155541015",
        "2145287260",
        "2128017662",
        "2161381512",
        "2141362318",
        "2113325037"
    ]
},{
    "id": "2138621811",
    "title": "Authoritative sources in a hyperlinked environment",
    "abstract": "The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of \u201cauthorative\u201d information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of \u201chub pages\u201d that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.",
    "date": "1999",
    "authors": [
        "Jon M. Kleinberg"
    ],
    "related_topics": [
        "HITS algorithm",
        "Link farm",
        "Link analysis"
    ],
    "citation_count": "16,206",
    "reference_count": "52",
    "references": [
        "3013264884",
        "2798909945",
        "2147152072",
        "1578099820",
        "2148694408",
        "2006119904",
        "2089192108",
        "1568713441",
        "2079672501",
        "1996764654"
    ]
},{
    "id": "2160660844",
    "title": "Mining and summarizing customer reviews",
    "abstract": "Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.",
    "date": "2004",
    "authors": [
        "Minqing Hu",
        "Bing Liu"
    ],
    "related_topics": [
        "Automatic summarization",
        "Product (category theory)",
        "Sentiment analysis"
    ],
    "citation_count": "8,422",
    "reference_count": "40",
    "references": [
        "2038721957",
        "2166706824",
        "1574901103",
        "3146306708",
        "1506285740",
        "2115023510",
        "2102381086",
        "1581485226",
        "2155328222",
        "2199803028"
    ]
},{
    "id": "2038952578",
    "title": "Active shape models\u2014their training and application",
    "abstract": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN.",
    "date": "1995",
    "authors": [
        "T. F. Cootes",
        "C. J. Taylor",
        "D. H. Cooper",
        "J. Graham"
    ],
    "related_topics": [
        "Active shape model",
        "Active appearance model",
        "Active contour model"
    ],
    "citation_count": "9,921",
    "reference_count": "13",
    "references": [
        "2096600681",
        "2160225702",
        "2132396702",
        "1512148629",
        "1696786548",
        "2042695730",
        "2151105625",
        "1863232835",
        "2128294289",
        "2007895855"
    ]
},{
    "id": "2146766088",
    "title": "Spline models for observational data",
    "abstract": "This book serves well as an introduction into the more theoretical aspects of the use of spline models. It develops a theory and practice for the estimation of functions from noisy data on functionals. The simplest example is the estimation of a smooth curve, given noisy observations on a finite number of its values. Convergence properties, data based smoothing parameter selection, confidence intervals, and numerical methods are established which are appropriate to a number of problems within this framework. Methods for including side conditions and other prior information in solving ill posed inverse problems are provided. Data which involves samples of random variables with Gaussian, Poisson, binomial, and other distributions are treated in a unified optimization context. Experimental design questions, i.e., which functionals should be observed, are studied in a general context. Extensions to distributed parameter system identification problems are made by considering implicitly defined functionals.",
    "date": "1990",
    "authors": [
        "Grace Wahba"
    ],
    "related_topics": [
        "Smoothing spline",
        "Thin plate spline",
        "Smoothing"
    ],
    "citation_count": "9,287",
    "reference_count": "1",
    "references": [
        "2019357902"
    ]
},{
    "id": "1593793857",
    "title": "Local computations with probabilities on graphical structures and their application to expert systems",
    "abstract": "",
    "date": "1990",
    "authors": [
        "S. L. Lauritzen",
        "D. J. Spiegelhalter"
    ],
    "related_topics": [
        "Expert system",
        "Variable elimination",
        "Probabilistic logic"
    ],
    "citation_count": "5,387",
    "reference_count": "130",
    "references": [
        "1498436455",
        "1997063559",
        "2797148637",
        "2155322595",
        "2138162238",
        "2143075689",
        "2143474538",
        "2166325326",
        "1516964807",
        "1549872659"
    ]
},{
    "id": "2797148637",
    "title": "A mathematical theory of evidence",
    "abstract": "Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his \"lower probabilities\" as epistemic probabilities and taking his rule for combining \"upper and lower probabilities\" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster's rule for combining such set functions. This rule, together with the idea of \"weights of evidence,\" leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem.",
    "date": "1975",
    "authors": [
        "Glenn Shafer"
    ],
    "related_topics": [
        "Dempster\u2013Shafer theory",
        "Upper and lower probabilities",
        "Mathematical theory"
    ],
    "citation_count": "20,577",
    "reference_count": "0",
    "references": []
},{
    "id": "2155322595",
    "title": "A logic for default reasoning",
    "abstract": "The need to make default assumptions is frequently encountered in reasoning about incompletely specified worlds. Inferences sanctioned by default are best viewed as beliefs which may well be modified or rejected by subsequent observations. It is this property which leads to the non-monotonicity of any logic of defaults. In this paper we propose a logic for default reasoning. We then specialize our treatment to a very large class of commonly occuring defaults. For this class we develop a complete proof theory and show how to interface it with a top down resolution theorem prover. Finally, we provide criteria under which the revision of derived beliefs must be effected.",
    "date": "1987",
    "authors": [
        "Raymond Reiter"
    ],
    "related_topics": [
        "Default logic",
        "Non-monotonic logic",
        "Default rule"
    ],
    "citation_count": "6,927",
    "reference_count": "26",
    "references": [
        "2138162238",
        "1766332311",
        "2121773050",
        "1996347293",
        "2105486835",
        "2212036697",
        "2100738443",
        "2530006810",
        "2157368609",
        "1541540802"
    ]
},{
    "id": "158727920",
    "title": "Judgment Under Uncertainty: Heuristics and Biases",
    "abstract": "This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.",
    "date": "1973",
    "authors": [
        "A. Tversky",
        "D. Kahneman"
    ],
    "related_topics": [
        "Heuristics",
        "Social heuristics",
        "Representativeness heuristic"
    ],
    "citation_count": "45,835",
    "reference_count": "13",
    "references": [
        "2035782089",
        "1980054641",
        "2016377072",
        "2079199322",
        "1976624377",
        "1965761421",
        "2018507693",
        "1972320590",
        "1965740984",
        "2013224592"
    ]
},{
    "id": "2138162238",
    "title": "Some philosophical problems from the standpoint of artificial intelligence",
    "abstract": "Abstract A computer program capable of acting intelligently in the world must have a general representation of the world in terms of which its inputs are interpreted. Designing such a program requires commitments about what knowledge is and how it is obtained. Thus, some of the major traditional problems of philosophy arise in artificial intelligence. More specifically, we want a computer program that decides what to do by inferring in a formal language that a certain strategy will achieve its assigned goal. This requires formalizing concepts of causality, ability, and knowledge. Such formalisms are also considered in philosophical logic. The first part of the paper begins with a philosophical point of view that seems to arise naturally once we take seriously the idea of actually making an intelligent machine. We go on to the notions of metaphysically and epistemo-logically adequate representations of the world and then to an explanation of can, causes, and knows in terms of a representation of the world by a system of interacting automata. A proposed resolution of the problem of freewill in a deterministic universe and of counterfactual conditional sentences is presented. The second part is mainly concerned with formalisms within which it can be proved that a strategy will achieve a goal. Concepts of situation, fluent, future operator, action, strategy, result of a strategy and knowledge are formalized. A method is given of constructing a sentence of first-order logic which will be true in all models of certain axioms if and only if a certain strategy will achieve a certain goal. The formalism of this paper represents an advance over McCarthy (1963) and Green (1969) in that it permits proof of the correctness of strategies that contain loops and strategies that involve the acquisition of knowledge; and it is also somewhat more concise. The third part discusses open problems in extending the formalism of part 2. The fourth part is a review of work in philosophical logic in relation to problems of artificial intelligence and a discussion of previous efforts to program \u2018general intelligence\u2019 from the point of view of this paper.",
    "date": "1987",
    "authors": [
        "J. McCarthy",
        "P. J. Hayes"
    ],
    "related_topics": [
        "Frame problem",
        "Action description language",
        "Situation calculus"
    ],
    "citation_count": "5,461",
    "reference_count": "46",
    "references": [
        "2041833446",
        "2124141583",
        "1684304711",
        "3149025087",
        "205043379",
        "2119409989",
        "2075277371",
        "2145482038",
        "1964011508",
        "3144889436"
    ]
},{
    "id": "2108309071",
    "title": "A theory of diagnosis from first principles",
    "abstract": "Suppose one is given a description of a system, together with an observation of the system's behaviour which conflicts with the way the system is meant to behave. The diagnostic problem is to determine those components of the system which, when assumed to be functioning abnormally, will explain the discrepancy between the observed and correct system behaviour. We propose a general theory for this problem. The theory requires only that the system be described in a suitable logic. Moreover, there are many such suitable logics, e.g. first-order, temporal, dynamic, etc. As a result, the theory accommodates diagnostic reasoning in a wide variety of practical settings, including digital and analogue circuits, medicine, and database updates. The theory leads to an algorithm for computing all diagnoses, and to various results concerning principles of measurement for discriminating among competing diagnoses. Finally, the theory reveals close connections between diagnostic reasoning and nonmonotonic reasoning.",
    "date": "1987",
    "authors": [
        "Raymond Reiter"
    ],
    "related_topics": [
        "Non-monotonic logic",
        "Automated theorem proving",
        "Variety (cybernetics)"
    ],
    "citation_count": "4,510",
    "reference_count": "15",
    "references": [
        "2155322595",
        "2144386448",
        "1549872659",
        "1983382292",
        "2140627345",
        "1998363560",
        "1562964770",
        "2032511848",
        "2038569232",
        "1520443109"
    ]
},{
    "id": "1986808060",
    "title": "Decisions with Multiple Objectives: Preferences and Value Trade-Offs",
    "abstract": "Many of the complex problems faced by decision makers involve multiple conflicting objectives. This book describes how a confused decision maker, who wishes to make a reasonable and responsible choice among alternatives, can systematically probe his true feelings in order to make those critically important, vexing trade-offs between incommensurable objectives. The theory is illustrated by many real concrete examples taken from a host of disciplinary settings. The standard approach in decision theory or decision analysis specifies a simplified single objective like monetary return to maximise. By generalising from the single objective case to the multiple objective case, this book considerably widens the range of applicability of decision analysis.",
    "date": "1975",
    "authors": [
        "R. L. Keeney",
        "H. Raiffa",
        "David W. Rajala"
    ],
    "related_topics": [
        "Decision analysis",
        "Decision engineering",
        "Decision theory"
    ],
    "citation_count": "19,564",
    "reference_count": "0",
    "references": []
},{
    "id": "2027197837",
    "title": "Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks",
    "abstract": "Abstract We give conditions ensuring that multilayer feedforward networks with as few as a single hidden layer and an appropriately smooth hidden layer activation function are capable of arbitrarily accurate approximation to an arbitrary function and its derivatives. In fact, these networks can approximate functions that are not differentiable in the classical sense, but possess only a generalized derivative, as is the case for certain piecewise differentiable functions. The conditions imposed on the hidden layer activation function are relatively mild; the conditions imposed on the domain of the function to be approximated have practical implications. Our approximation results provide a previously missing theoretical justification for the use of multilayer feedforward networks in applications requiring simultaneous approximation of a function and its derivatives.",
    "date": "1990",
    "authors": [
        "Kurt Hornik",
        "Maxwell Stinchcombe",
        "Halbert White"
    ],
    "related_topics": [
        "Piecewise",
        "Differentiable function",
        "Activation function"
    ],
    "citation_count": "2,330",
    "reference_count": "17",
    "references": [
        "2137983211",
        "3146803896",
        "1971735090",
        "2056099894",
        "2416739038",
        "2090270852",
        "1613359937",
        "1490039160",
        "2090248140",
        "1537887709"
    ]
},{
    "id": "2068017609",
    "title": "Mitigating the paucity-of-data problem: exploring the effect of training corpus size on classifier performance for natural language processing",
    "abstract": "In this paper, we discuss experiments applying machine learning techniques to the task of confusion set disambiguation, using three orders of magnitude more training data than has previously been used for any disambiguation-in-string-context problem. In an attempt to determine when current learning methods will cease to benefit from additional training data, we analyze residual errors made by learners when issues of sparse data have been significantly mitigated. Finally, in the context of our results, we discuss possible directions for the empirical natural language research community.",
    "date": "2001",
    "authors": [
        "Michele Banko",
        "Eric Brill"
    ],
    "related_topics": [
        "Online machine learning",
        "Language identification",
        "Semi-supervised learning"
    ],
    "citation_count": "132",
    "reference_count": "12",
    "references": [
        "2097089247",
        "1977182536",
        "2156202195",
        "2118996379",
        "1953828586",
        "2130851608",
        "1648417313",
        "1519443010",
        "2119966617",
        "1988842251"
    ]
},{
    "id": "2147345686",
    "title": "An offline cursive handwritten word recognition system",
    "abstract": "This paper describes an offline cursive handwritten word recognition system that combines hidden Markov models (HMM) and neural networks (NN). Using a fast left-right slicing method, we generate a segmentation graph that describes all possible ways to segment a word into letters. The NN computes the observation probabilities for each letter hypothesis in the segmentation graph. Then, the HMM compute the likelihood for each word in the lexicon by summing the probabilities over all possible paths through the graph. We present the preprocessing and the recognition process as well as the training procedure for the NN-HMM hybrid system. Another recognition system based on discrete HMM is also presented for performance comparison. The latter is also used for bootstrapping the NN-HMM hybrid system. Recognition performances of the two recognition systems using two image databases of French isolated words are presented. This paper is one of the first publications using the IRONOFF database, and thus can be used as a reference for future work on this database.",
    "date": "2001",
    "authors": [
        "Yong Haur Tay",
        "P.M. Lallican",
        "M. Khalid",
        "C. Viard-Gaudin",
        "S. Kneer"
    ],
    "related_topics": [
        "Intelligent word recognition",
        "Handwriting recognition",
        "Word recognition"
    ],
    "citation_count": "32",
    "reference_count": "11",
    "references": [
        "2310919327",
        "2125838338",
        "2142069714",
        "183625566",
        "2149597185",
        "2077863651",
        "2148295954",
        "101240229",
        "2113292028",
        "2064838583"
    ]
},{
    "id": "51975515",
    "title": "An improved recognition module for the identification of handwritten digits",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Anshu Sinha"
    ],
    "related_topics": [
        "Intelligent character recognition",
        "Intelligent word recognition",
        "Document processing"
    ],
    "citation_count": "12",
    "reference_count": "16",
    "references": [
        "2124776405",
        "2227933188",
        "2126727781",
        "2256679588",
        "2122827492",
        "49742075",
        "2072181047",
        "2107600630",
        "1519534430",
        "2151513848"
    ]
},{
    "id": "2166469100",
    "title": "Effective Training of a Neural Network Character Classifier for Word Recognition",
    "abstract": "We have combined an artificial neural network (ANN) character classifier with context-driven search over character segmentation, word segmentation, and word recognition hypotheses to provide robust recognition of hand-printed English text in new models of Apple Computer's Newton Message Pad. We present some innovations in the training and use of ANNs as character classifiers for word recognition, including normalized output error, frequency balancing, error emphasis, negative training, and stroke warping. A recurring theme of reducing a priori biases emerges and is discussed.",
    "date": "1996",
    "authors": [
        "Larry S. Yaeger",
        "Richard F. Lyon",
        "Brandyn J. Webb"
    ],
    "related_topics": [
        "Intelligent character recognition",
        "Intelligent word recognition",
        "Word error rate"
    ],
    "citation_count": "106",
    "reference_count": "13",
    "references": [
        "2150884987",
        "2137291015",
        "2055075080",
        "1980501707",
        "2099070536",
        "2111494971",
        "2140539590",
        "2124229187",
        "2170541567",
        "2607313294"
    ]
},{
    "id": "2121927366",
    "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics",
    "abstract": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties.",
    "date": "2001",
    "authors": [
        "D. Martin",
        "C. Fowlkes",
        "D. Tal",
        "J. Malik"
    ],
    "related_topics": [
        "Image segmentation",
        "Segmentation",
        "Ground truth"
    ],
    "citation_count": "6,556",
    "reference_count": "15",
    "references": [
        "2121947440",
        "2126326837",
        "2124731682",
        "1524408959",
        "2101933716",
        "2120838001",
        "2150117517",
        "2139643804",
        "2124592837",
        "1537519384"
    ]
},{
    "id": "2113945798",
    "title": "Image denoising using scale mixtures of Gaussians in the wavelet domain",
    "abstract": "We describe a method for removing noise from digital images, based on a statistical model of the coefficients of an overcomplete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood, and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model, the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods, both visually and in terms of mean squared error.",
    "date": "2003",
    "authors": [
        "J. Portilla",
        "V. Strela",
        "M.J. Wainwright",
        "E.P. Simoncelli"
    ],
    "related_topics": [
        "Mean squared error",
        "Additive white Gaussian noise",
        "Estimation theory"
    ],
    "citation_count": "2,949",
    "reference_count": "60",
    "references": [
        "2132984323",
        "2158940042",
        "2053691921",
        "2132680427",
        "2145889472",
        "2129276048",
        "2134929491",
        "2127006916",
        "1991605728",
        "2137234026"
    ]
},{
    "id": "2295936755",
    "title": "Image inpainting",
    "abstract": "Inpainting, the technique of modifying an image in an undetectable form, is as ancient as art itself. The goals and applications of inpainting are numerous, from the restoration of damaged paintings and photographs to the removal/replacement of selected objects. In this paper, we introduce a novel algorithm for digital inpainting of still images that attempts to replicate the basic techniques used by professional restorators. After the user selects the regions to be restored, the algorithm automatically fills-in these regions with information surrounding them. The fill-in is done in such a way that isophote lines arriving at the regions' boundaries are completed inside. In contrast with previous approaches, the technique here introduced does not require the user to specify where the novel information comes from. This is automatically done (and in a fast way), thereby allowing to simultaneously fill-in numerous regions containing completely different structures and surrounding backgrounds. In addition, no limitations are imposed on the topology of the region to be inpainted. Applications of this technique include the restoration of old photographs and damaged film; removal of superimposed text like dates, subtitles, or publicity; and the removal of entire objects from the image like microphones or wires in special effects.",
    "date": "2000",
    "authors": [
        "Marcelo Bertalmio",
        "Guillermo Sapiro",
        "Vincent Caselles",
        "Coloma Ballester"
    ],
    "related_topics": [
        "Inpainting",
        "Image restoration",
        "Texture synthesis"
    ],
    "citation_count": "4,727",
    "reference_count": "16",
    "references": [
        "2103559027",
        "2150134853",
        "2116013899",
        "1991113069",
        "2146052399",
        "1490632837",
        "2132363464",
        "2100415658",
        "2023292900",
        "2140865211"
    ]
},{
    "id": "2116013899",
    "title": "Texture synthesis by non-parametric sampling",
    "abstract": "A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures.",
    "date": "1999",
    "authors": [
        "A.A. Efros",
        "T.K. Leung"
    ],
    "related_topics": [
        "Texture atlas",
        "Image texture",
        "Texture synthesis"
    ],
    "citation_count": "4,203",
    "reference_count": "10",
    "references": [
        "1971719398",
        "2042371054",
        "1490632837",
        "2150920547",
        "2134849909",
        "1995875735",
        "2162413715",
        "2096355125",
        "132940180",
        "2141080522"
    ]
},{
    "id": "2149760002",
    "title": "Learning Low-Level Vision",
    "abstract": "We describe a learning-based method for low-level vision problems\u2014estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA\u2014Vision by Image/Scene TrAining. We apply VISTA to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a \u201cblobs world\u201d, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery.",
    "date": "2000",
    "authors": [
        "William T. Freeman",
        "Egon C. Pasztor",
        "Owen T. Carmichael"
    ],
    "related_topics": [
        "Motion estimation",
        "Probabilistic logic",
        "Belief propagation"
    ],
    "citation_count": "2,152",
    "reference_count": "47",
    "references": [
        "1554663460",
        "2159080219",
        "1997063559",
        "2145889472",
        "1988520084",
        "1746680969",
        "2911709767",
        "2103504761",
        "2137234026",
        "1481420047"
    ]
},{
    "id": "1647075334",
    "title": "Potent and specific genetic interference by double-stranded RNA in Caenorhabditis elegans",
    "abstract": "Experimental introduction of RNA into cells can be used in certain biological systems to interfere with the function of an endogenous gene. Such effects have been proposed to result from a simple antisense mechanism that depends on hybridization between the injected RNA and endogenous messenger RNA transcripts. RNA interference has been used in the nematode Caenorhabditis elegans to manipulate gene expression. Here we investigate the requirements for structure and delivery of the interfering RNA. To our surprise, we found that double-stranded RNA was substantially more effective at producing interference than was either strand individually. After injection into adult animals, purified single strands had at most a modest effect, whereas double-stranded mixtures caused potent and specific interference. The effects of this interference were evident in both the injected animals and their progeny. Only a few molecules of injected double-stranded RNA were required per affected cell, arguing against stochiometric interference with endogenous mRNA and suggesting that there could be a catalytic or amplification component in the interference process.",
    "date": "1998",
    "authors": [
        "Andrew Fire",
        "SiQun Xu",
        "Mary K. Montgomery",
        "Steven A. Kostas",
        "Samuel E. Driver",
        "Craig C. Mello"
    ],
    "related_topics": [
        "RNA silencing",
        "RNA",
        "Antisense RNA"
    ],
    "citation_count": "25,627",
    "reference_count": "26",
    "references": [
        "2032579724",
        "2034831897",
        "1944127002",
        "2149871164",
        "1992194142",
        "1989952069",
        "1581412826",
        "1594381468",
        "2022846624",
        "2151068726"
    ]
},{
    "id": "2119823327",
    "title": "Learning to detect natural image boundaries using local brightness, color, and texture cues",
    "abstract": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images.",
    "date": "2004",
    "authors": [
        "D.R. Martin",
        "C.C. Fowlkes",
        "J. Malik"
    ],
    "related_topics": [
        "Image texture",
        "Edge detection",
        "Brightness"
    ],
    "citation_count": "2,768",
    "reference_count": "37",
    "references": [
        "2153635508",
        "2145023731",
        "2121927366",
        "2111308925",
        "2032210760",
        "2135705692",
        "2093191240",
        "2141376824",
        "2025653905",
        "1490632837"
    ]
},{
    "id": "2117853077",
    "title": "The EM algorithm and extensions",
    "abstract": "The first unified account of the theory, methodology, and applications of the EM algorithm and its extensionsSince its inception in 1977, the Expectation-Maximization (EM) algorithm has been the subject of intense scrutiny, dozens of applications, numerous extensions, and thousands of publications. The algorithm and its extensions are now standard tools applied to incomplete data problems in virtually every field in which statistical methods are used. Until now, however, no single source offered a complete and unified treatment of the subject.The EM Algorithm and Extensions describes the formulation of the EM algorithm, details its methodology, discusses its implementation, and illustrates applications in many statistical contexts. Employing numerous examples, Geoffrey McLachlan and Thriyambakam Krishnan examine applications both in evidently incomplete data situations-where data are missing, distributions are truncated, or observations are censored or grouped-and in a broad variety of situations in which incompleteness is neither natural nor evident. They point out the algorithm's shortcomings and explain how these are addressed in the various extensions.Areas of application discussed include: Regression Medical imaging Categorical data analysis Finite mixture analysis Factor analysis Robust statistical modeling Variance-components estimation Survival analysis Repeated-measures designs For theoreticians, practitioners, and graduate students in statistics as well as researchers in the social and physical sciences, The EM Algorithm and Extensions opens the door to the tremendous potential of this remarkably versatile statistical tool.",
    "date": "1996",
    "authors": [
        "Geoffrey J. McLachlan",
        "Thriyambakam Krishnan"
    ],
    "related_topics": [
        "MM algorithm",
        "Statistical model",
        "Expectation\u2013maximization algorithm"
    ],
    "citation_count": "8,995",
    "reference_count": "2",
    "references": [
        "2049633694",
        "3129711340"
    ]
},{
    "id": "2024476015",
    "title": "The EM Algorithm\u2014an Old Folk\u2010song Sung to a Fast New Tune",
    "abstract": "Celebrating the 20th anniversary of the presentation of the paper by Dempster, Laird and Rubin which popularized the EM algorithm, we investigate, after a brief historical account, strategies that aim to make the EM algorithm converge faster while maintaining its simplicity and stability (e.g. automatic monotone convergence in likelihood). First we introduce the idea of a \u2018working parameter\u2019 to facilitate the search for efficient data augmentation schemes and thus fast EM implementations. Second, summarizing various recent extensions of the EM algorithm, we formulate a general alternating expectation\u2013conditional maximization algorithm AECM that couples flexible data augmentation schemes with model reduction schemes to achieve efficient computations. We illustrate these methods using multivariate t-models with known or unknown degrees of freedom and Poisson models for image reconstruction. We show, through both empirical and theoretical evidence, the potential for a dramatic reduction in computational time with little increase in human effort. We also discuss the intrinsic connection between EM-type algorithms and the Gibbs sampler, and the possibility of using the techniques presented here to speed up the latter. The main conclusion of the paper is that, with the help of statistical considerations, it is possible to construct algorithms that are simple, stable and fast.",
    "date": "1996",
    "authors": [
        "Xiao-Li Meng",
        "David Van Dyk"
    ],
    "related_topics": [
        "Stability (learning theory)",
        "Expectation\u2013maximization algorithm",
        "Gibbs sampling"
    ],
    "citation_count": "905",
    "reference_count": "110",
    "references": [
        "2045656233",
        "2610857016",
        "2049633694",
        "2117853077",
        "2106706098",
        "2148534890",
        "2154744699",
        "2082246284",
        "2017899835",
        "2033482494"
    ]
},{
    "id": "1580495158",
    "title": "Soft competitive adaptation: neural network learning algorithms based on fitting statistical mixtures",
    "abstract": "In this thesis, we consider learning algorithms for neural networks which are based on fitting a mixture probability density to a set of data. We begin with an unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms. Rather than updating only the parameters of the \"winner\" on each case, the parameters of all competitors are updated in proportion to their relative responsibility for the case. Use of such a \"soft\" competitive algorithm is shown to give better performance than the more traditional algorithms, with little additional cost. We then consider a supervised modular architecture in which a number of simple \"expert\" networks compete to solve distinct pieces of a large task. A soft competitive mechanism is used to determine how much an expert learns on a case, based on how well the expert performs relative to the other expert networks. At the same time, a separate gating network learns to weight the output of each expert according to a prediction of its relative performance based on the input to the system. Experiments on a number of tasks illustrate that this architecture is capable of uncovering interesting task decompositions and of generalizing better than a single network with small training sets. Finally, we consider learning algorithms in which we assume that the actual output of the network should fall into one of a small number of classes or clusters. The objective of learning is to make the variance of these classes as small as possible. In the classical decision-directed algorithm, we decide that an output belongs to the class it is closest to and minimize the squared distance between the output and the center (mean) of this closest class. In the \"soft\" version of this algorithm, we minimize the squared distance between the actual output and a weighted average of the means of all of the classes. The weighting factors are the relative probability that the output belongs to each class. This idea may also be used to model the weights of a network, to produce networks which generalize better from small training sets.",
    "date": "1991",
    "authors": [
        "Steven J. Nowlan"
    ],
    "related_topics": [
        "Competitive analysis",
        "Competitive learning",
        "Artificial neural network"
    ],
    "citation_count": "178",
    "reference_count": "0",
    "references": []
},{
    "id": "1991278573",
    "title": "Another interpretation of the EM algorithm for mixture distributions",
    "abstract": "Abstract The EM algorithm for mixture problems can be interpreted as a method of coordinate descent on a particular objective function. This view of the iteration partially illuminates the relationship of EM to certain clustering techniques and explains global convergence properties of the algorithm without direct reference to an incomplete data framework.",
    "date": "1986",
    "authors": [
        "Richard J. Hathaway"
    ],
    "related_topics": [
        "Coordinate descent",
        "Expectation\u2013maximization algorithm",
        "Cluster analysis"
    ],
    "citation_count": "308",
    "reference_count": "8",
    "references": [
        "2049633694",
        "2113076747",
        "1981367467",
        "2038614136",
        "2118570622",
        "2010140249",
        "2043803464",
        "2131034055"
    ]
},{
    "id": "581152777",
    "title": "Recent results in estimation theory and related topics",
    "abstract": "",
    "date": "1983",
    "authors": [
        "Edward J. Dudewicz",
        "Detlef Plachky",
        "Pranab Kumar Sen"
    ],
    "related_topics": [
        "Estimation theory",
        "Mathematics",
        "Econometrics"
    ],
    "citation_count": "3",
    "reference_count": "0",
    "references": []
},{
    "id": "1512098439",
    "title": "Fast training of support vector machines using sequential minimal optimization",
    "abstract": "This chapter describes a new algorithm for training Support Vector Machines: Sequential Minimal Optimization, or SMO. Training a Support Vector Machine (SVM) requires the solution of a very large quadratic programming (QP) optimization problem. SMO breaks this large QP problem into a series of smallest possible QP problems. These small QP problems are solved analytically, which avoids using a time-consuming numerical QP optimization as an inner loop. The amount of memory required for SMO is linear in the training set size, which allows SMO to handle very large training sets. Because large matrix computation is avoided, SMO scales somewhere between linear and quadratic in the training set size for various test problems, while a standard projected conjugate gradient (PCG) chunking algorithm scales somewhere between linear and cubic in the training set size. SMO's computation time is dominated by SVM evaluation, hence SMO is fastest for linear SVMs and sparse data sets. For the MNIST database, SMO is as fast as PCG chunking; while for the UCI Adult database and linear SVMs, SMO can be more than 1000 times faster than the PCG chunking algorithm.",
    "date": "1999",
    "authors": [
        "John C. Platt"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Support vector machine",
        "Relevance vector machine"
    ],
    "citation_count": "7,400",
    "reference_count": "0",
    "references": []
},{
    "id": "1604938182",
    "title": "Advances in kernel methods: support vector learning",
    "abstract": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al.",
    "date": "1999",
    "authors": [
        "Bernhard Sch\u00f6lkopf",
        "Christopher J. C. Burges",
        "Alexander J. Smola"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Relevance vector machine",
        "Least squares support vector machine"
    ],
    "citation_count": "6,285",
    "reference_count": "0",
    "references": []
},{
    "id": "2151040995",
    "title": "Improvements to Platt's SMO Algorithm for SVM Classifier Design",
    "abstract": "This article points out an important source of inefficiency in Platt's sequential minimal optimization (SMO) algorithm that is caused by the use of a single threshold value. Using clues from the KKT conditions for the dual problem, two threshold parameters are employed to derive modifications of SMO. These modified algorithms perform significantly faster than the original SMO on all benchmark data sets tried.",
    "date": "2001",
    "authors": [
        "S. S. Keerthi",
        "S. K. Shevade",
        "C. Bhattacharyya",
        "K. R. K. Murthy"
    ],
    "related_topics": [
        "Sequential minimal optimization",
        "Support vector machine",
        "Karush\u2013Kuhn\u2013Tucker conditions"
    ],
    "citation_count": "2,192",
    "reference_count": "16",
    "references": [
        "2156909104",
        "2139212933",
        "1512098439",
        "2108995755",
        "1574862351",
        "2047542122",
        "2100038678",
        "2133458583",
        "2166282318",
        "2138907228"
    ]
},{
    "id": "2160547390",
    "title": "$rm K$ -SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation",
    "abstract": "In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data",
    "date": "2006",
    "authors": [
        "M. Aharon",
        "M. Elad",
        "A. Bruckstein"
    ],
    "related_topics": [
        "K-SVD",
        "Sparse approximation",
        "Matching pursuit"
    ],
    "citation_count": "10,172",
    "reference_count": "44",
    "references": [
        "2078204800",
        "2116148865",
        "2099641086",
        "2108384452",
        "2151693816",
        "2097323375",
        "2049633694",
        "2050834445",
        "1634005169",
        "2154332973"
    ]
},{
    "id": "2146842127",
    "title": "De-noising by soft-thresholding",
    "abstract": "Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model. >",
    "date": "1995",
    "authors": [
        "D.L. Donoho"
    ],
    "related_topics": [
        "Independent and identically distributed random variables",
        "Estimator",
        "Smoothness (probability theory)"
    ],
    "citation_count": "13,518",
    "reference_count": "32",
    "references": [
        "2098914003",
        "2079724595",
        "2152328854",
        "191129667",
        "3005363104",
        "2107790757",
        "2109246257",
        "2050880896",
        "2033484654",
        "654435104"
    ]
},{
    "id": "2151693816",
    "title": "Matching pursuits with time-frequency dictionaries",
    "abstract": "The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992). >",
    "date": "1993",
    "authors": [
        "S.G. Mallat",
        "Zhifeng Zhang"
    ],
    "related_topics": [
        "Matching pursuit",
        "Basis pursuit",
        "K-SVD"
    ],
    "citation_count": "11,923",
    "reference_count": "13",
    "references": [
        "2062024414",
        "2798909945",
        "1996021349",
        "2156447271",
        "1970352604",
        "2165878107",
        "2913399920",
        "3132971798",
        "2091886411",
        "2080563952"
    ]
},{
    "id": "2132680427",
    "title": "The curvelet transform for image denoising",
    "abstract": "We describe approximate digital implementations of two new mathematical transforms, namely, the ridgelet transform and the curvelet transform. Our implementations offer exact reconstruction, stability against perturbations, ease of implementation, and low computational complexity. A central tool is Fourier-domain computation of an approximate digital Radon transform. We introduce a very simple interpolation in the Fourier space which takes Cartesian samples and yields samples on a rectopolar grid, which is a pseudo-polar sampling set based on a concentric squares geometry. Despite the crudeness of our interpolation, the visual performance is surprisingly good. Our ridgelet transform applies to the Radon transform a special overcomplete wavelet pyramid whose wavelets have compact support in the frequency domain. Our curvelet transform uses our ridgelet transform as a component step, and implements curvelet subbands using a filter bank of a/spl grave/ trous wavelet filters. Our philosophy throughout is that transforms should be overcomplete, rather than critically sampled. We apply these digital transforms to the denoising of some standard images embedded in white noise. In the tests reported here, simple thresholding of the curvelet coefficients is very competitive with \"state of the art\" techniques based on wavelets, including thresholding of decimated or undecimated wavelet transforms and also including tree-based Bayesian posterior mean methods. Moreover, the curvelet reconstructions exhibit higher perceptual quality than wavelet-based reconstructions, offering visually sharper images and, in particular, higher quality recovery of edges and of faint linear and curvilinear features. Existing theory for curvelet and ridgelet transforms suggests that these new approaches can outperform wavelet methods in certain image reconstruction problems. The empirical results reported here are in encouraging agreement.",
    "date": "2002",
    "authors": [
        "Jean-Luc Starck",
        "E.J. Candes",
        "D.L. Donoho"
    ],
    "related_topics": [
        "Curvelet",
        "Discrete wavelet transform",
        "Wavelet"
    ],
    "citation_count": "3,200",
    "reference_count": "26",
    "references": [
        "2134929491",
        "1485280399",
        "59771946",
        "2107790757",
        "2109504624",
        "2066462711",
        "2035737465",
        "2033367330",
        "2031299600",
        "2158576618"
    ]
},{
    "id": "2079724595",
    "title": "Adapting to Unknown Smoothness via Wavelet Shrinkage",
    "abstract": "Abstract We attempt to recover a function of unknown smoothness from noisy sampled data. We introduce a procedure, SureShrink, that suppresses noise by thresholding the empirical wavelet coefficients. The thresholding is adaptive: A threshold level is assigned to each dyadic resolution level by the principle of minimizing the Stein unbiased estimate of risk (Sure) for threshold estimates. The computational effort of the overall procedure is order N \u00b7 log(N) as a function of the sample size N. SureShrink is smoothness adaptive: If the unknown function contains jumps, then the reconstruction (essentially) does also; if the unknown function has a smooth piece, then the reconstruction is (essentially) as smooth as the mother wavelet will allow. The procedure is in a sense optimally smoothness adaptive: It is near minimax simultaneously over a whole interval of the Besov scale; the size of this interval depends on the choice of mother wavelet. We know from a previous paper by the authors that traditional smoot...",
    "date": "1995",
    "authors": [
        "David L. Donoho",
        "Iain M. Johnstone"
    ],
    "related_topics": [
        "Wavelet",
        "Thresholding",
        "Smoothness"
    ],
    "citation_count": "6,727",
    "reference_count": "29",
    "references": [
        "2062024414",
        "2132984323",
        "2158940042",
        "2098914003",
        "2102201073",
        "191129667",
        "2166982406",
        "162854683",
        "2024081693",
        "2054640142"
    ]
},{
    "id": "2740373864",
    "title": "Computer vision",
    "abstract": "",
    "date": "1981",
    "authors": [
        "Dana Harry Ballard",
        "Christopher M. Brown"
    ],
    "related_topics": [
        "Computer science",
        "Computer vision",
        "Artificial intelligence"
    ],
    "citation_count": "5,554",
    "reference_count": "0",
    "references": []
},{
    "id": "2177040213",
    "title": "A massively parallel architecture for a self-organizing neural pattern recognition machine",
    "abstract": "A neural network architecture for the learning of recognition categories is derived. Real-time network dynamics are completely characterized through mathematical analysis and computer simulations. The architecture self-organizes and self-stabilizes its recognition codes in response to arbitrary orderings of arbitrarily many and arbitrarily complex binary input patterns. Top-down attentional and matching mechanisms are critical in self-stabilizing the code learning process. The architecture embodies a parallel search scheme which updates itself adaptively as the learning process unfolds. After learning self-stabilizes, the search process is automatically disengaged. Thereafter input patterns directly access their recognition codes without any search. Thus recognition time does not grow as a function of code complexity. A novel input pattern can directly access a category if it shares invariant properties with the set of familiar exemplars of that category. These invariant properties emerge in the form of learned critical feature patterns, or prototypes. The architecture possesses a context-sensitive self-scaling property which enables its emergent critical feature patterns to form. They detect and remember statistically predictive configurations of featural elements which are derived from the set of all input patterns that are ever experienced. Four types of attentional process\u2014priming, gain control, vigilance, and intermodal competition\u2014are mechanistically characterized. Top\u2014down priming and gain control are needed for code matching and self-stabilization. Attentional vigilance determines how fine the learned categories will be. If vigilance increases due to an environmental disconfirmation, then the system automatically searches for and learns finer recognition categories. A new nonlinear matching law (the \u2154 Rule) and new nonlinear associative laws (the Weber Law Rule, the Associative Decay Rule, and the Template Learning Rule) are needed to achieve these properties. All the rules describe emergent properties of parallel network interactions. The architecture circumvents the noise, saturation, capacity, orthogonality, and linear predictability constraints that limit the codes which can be stably learned by alternative recognition models.",
    "date": "1988",
    "authors": [
        "G. A. Carpenter",
        "S. Grossberg"
    ],
    "related_topics": [
        "Learning rule",
        "Feature (machine learning)",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "4,045",
    "reference_count": "0",
    "references": []
},{
    "id": "1533169541",
    "title": "Stochastic Complexity In Statistical Inquiry",
    "abstract": "",
    "date": "1989",
    "authors": [
        "Jorma Rissanen"
    ],
    "related_topics": [
        "Stochastic optimization",
        "Minimum description length",
        "Theoretical computer science"
    ],
    "citation_count": "2,309",
    "reference_count": "0",
    "references": []
},{
    "id": "2044875682",
    "title": "Acetylcholine and memory",
    "abstract": "Acetylcholine may set the dynamics of cortical networks to those appropriate for learning of new information, while decreased cholinergic modulation may set the appropriate dynamics for recall. In slice preparations of the olfactory cortex, acetylcholine selectively suppresses intrinsic but not afferent fiber synaptic transmission, while decreasing the adaptation of pyramidal cells. In biologically realistic models of this region, the selective suppression of synaptic transmission prevents recall of previously learned memories from interfering with the learning of new memories, while the decrease in adaptation enhances the response to afferent input and the modification of synapses. This theoretical framework may serve to guide future studies linking neuromodulators to cortical memory function.",
    "date": "1993",
    "authors": [
        "Michael E. Hasselmo",
        "James M. Bower"
    ],
    "related_topics": [
        "Acetylcholine",
        "Neurotransmission",
        "Recall"
    ],
    "citation_count": "458",
    "reference_count": "40",
    "references": [
        "1991848143",
        "2126974689",
        "2073055671",
        "2027066860",
        "2037944537",
        "2115121624",
        "1969884751",
        "2160356704",
        "2129090497",
        "155080488"
    ]
},{
    "id": "94647076",
    "title": "Lectures in pattern theory",
    "abstract": "",
    "date": "1977",
    "authors": [
        "Ulf Grenander"
    ],
    "related_topics": [
        "Pattern theory",
        "Computer science",
        "Calculus"
    ],
    "citation_count": "87",
    "reference_count": "0",
    "references": []
},{
    "id": "2160208155",
    "title": "Increased Rates of Convergence Through Learning Rate Adaptation",
    "abstract": "WHILE THERE EXIST MANY TECHNIQUES FOR FINDING THE PARAMETERS THAT MINI- MIZE AN ERROR FUNCTION, ONLY THOSE METHODS THAT SOLELY PERFORM LOCAL COMPU- TATIONS ARE USED IN CONNECTIONIST NETWORKS. THE MOST POPULAR LEARNING ALGO RITHM FOR CONNECTIONIST NETWORKS IS THE BACK-PROPOGATION PROCEDURE [13], WHICH CAN BE USED TO UPDATE THE WEIGHTS BY THE METHOD OF STEEPEST DESCENT. IN THIS PAPER, WE EXAMINE STEEPEST DESCENT AND ANALYZE WHY IT CAN BE SLOW TO CONVERGE. WE THEN PROPOSE FOUR HEURISTICS FOR ACHIEVING FASTER RATES OF CONVERGENCE WHILE ADHERING TO THE LOCALITY CONSTRAINT. THESE HEURISTICS SUGGEST THAT EVERY WEIGHT OF A NETWORK SHOULD BE GIVEN ITS OWN LEARNING RATE AND THAT THESE RATES SHOULD BE ALLOWED TO VARY OVER TIME. ADDITIONALLY THE HEURISTICS SUGGEST HOW THE LEARNING RATES SHOULD BE ADJUSTED. TWO IMPLEMENTATIONS OF THESE HEURISTICS, NAMELY MOMENTUM AND AN ALGORITHM CALLED THE DELTA-BAR-DELTA RULE, ARE STUDIED AND SIMULATION RESULTS ARE PRESENTED.",
    "date": "1987",
    "authors": [
        "Robert A. Jacobs"
    ],
    "related_topics": [
        "Heuristics",
        "Method of steepest descent",
        "Gradient descent"
    ],
    "citation_count": "2,739",
    "reference_count": "14",
    "references": [
        "2154642048",
        "1492221128",
        "2895674046",
        "1535810436",
        "2129113961",
        "1686514609",
        "1573427320",
        "423115584",
        "2078057316",
        "3147765605"
    ]
},{
    "id": "3121126077",
    "title": "Fast-learning variations on back propagation: an empirical study.",
    "abstract": "",
    "date": "1988",
    "authors": [
        "S. E. Fahlman"
    ],
    "related_topics": [
        "Computer science",
        "Empirical research",
        "Algorithm"
    ],
    "citation_count": "1,131",
    "reference_count": "0",
    "references": []
},{
    "id": "50076749",
    "title": "Learning to tell two spirals apart",
    "abstract": "",
    "date": "1988",
    "authors": [
        "K. Lang"
    ],
    "related_topics": [
        "Computer science"
    ],
    "citation_count": "1,034",
    "reference_count": "0",
    "references": []
},{
    "id": "2127385318",
    "title": "Fast Learning in Multi-Resolution Hierarchies",
    "abstract": "A class of fast, supervised learning algorithms is presented. They use local representations, hashing, and multiple scales of resolution to approximate functions which are piece-wise continuous. Inspired by Albus's CMAC model, the algorithms learn orders of magnitude more rapidly than typical implementations of back propagation, while often achieving comparable qualities of generalization. Furthermore, unlike most traditional function approximation methods, the algorithms are well suited for use in real time adaptive signal processing. Unlike simpler adaptive systems, such as linear predictive coding, the adaptive linear combiner, and the Kalman filter, the new algorithms are capable of efficiently capturing the structure of complicated non-linear systems. As an illustration, the algorithm is applied to the prediction of a chaotic timeseries.",
    "date": "1987",
    "authors": [
        "John Moody"
    ],
    "related_topics": [
        "Adaptive filter",
        "Function approximation",
        "Kalman filter"
    ],
    "citation_count": "194",
    "reference_count": "18",
    "references": [
        "1594031697",
        "2171277043",
        "2103504761",
        "3036751298",
        "2066366061",
        "2034099719",
        "2052207834",
        "2153709524",
        "2094631910",
        "1993740947"
    ]
},{
    "id": "2169163929",
    "title": "Consonant recognition by modular construction of large phonemic time-delay neural networks",
    "abstract": "It is shown that neural networks for speech recognition can be constructed in a modular fashion by exploiting the hidden structure of previously trained phonetic subcategory networks. The performance of resulting larger phonetic nets was found to be as good as the performance of the subcomponent nets by themselves. This approach avoids the excessive learning times that would be necessary to train larger networks and allows for incremental learning. Large time-delay neural networks constructed incrementally by applying these modular training techniques achieved a recognition performance of 96.0% for all consonants and 94.7% for all phonemes. >",
    "date": "1989",
    "authors": [
        "A. Waibel",
        "H. Sawai",
        "K. Shikano"
    ],
    "related_topics": [
        "Artificial neural network",
        "Speech recognition",
        "Consonant"
    ],
    "citation_count": "181",
    "reference_count": "9",
    "references": [
        "2154642048",
        "2173629880",
        "1541007220",
        "2167462730",
        "3108739439",
        "1997547570",
        "2189011649",
        "2120383790",
        "2306005020"
    ]
},{
    "id": "2167277568",
    "title": "Consonant Recognition by Modular Construction of Large Phonemic Time-Delay Neural Networks",
    "abstract": "In this paper we show that neural networks for speech recognition can be constructed in a modular fashion by exploiting the hidden structure of previously trained phonetic subcategory networks. The performance of resulting larger phonetic nets was found to be as good as the performance of the subcomponent nets by themselves. This approach avoids the excessive learning times that would be necessary to train larger networks and allows for incremental learning. Large time-delay neural networks constructed incrementally by applying these modular training techniques achieved a recognition performance of 96.0% for all consonants.",
    "date": "1987",
    "authors": [
        "Alex Waibel"
    ],
    "related_topics": [
        "Time delay neural network",
        "Artificial neural network",
        "Speech recognition"
    ],
    "citation_count": "92",
    "reference_count": "6",
    "references": [
        "2173629880",
        "1541007220",
        "2167462730",
        "3108739439",
        "1997547570",
        "2306005020"
    ]
},{
    "id": "2154952480",
    "title": "Learnability and the Vapnik-Chervonenkis dimension",
    "abstract": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability.",
    "date": "1989",
    "authors": [
        "Anselm Blumer",
        "A. Ehrenfeucht",
        "David Haussler",
        "Manfred K. Warmuth"
    ],
    "related_topics": [
        "Learnability",
        "Probably approximately correct learning",
        "VC dimension"
    ],
    "citation_count": "2,268",
    "reference_count": "64",
    "references": [
        "2011039300",
        "3017143921",
        "1655990431",
        "2752853835",
        "2611147814",
        "2165758113",
        "1530699444",
        "2019363670",
        "2117362057",
        "2129113961"
    ]
},{
    "id": "2159047538",
    "title": "Learning Efficient Classification Procedures and Their Application to Chess End Games",
    "abstract": "A series of experiments dealing with the discovery of efficient classification procedures from large numbers of examples is described, with a case study from the chess end game king-rook versus king-knight. After an outline of the inductive inference machinery used, the paper reports on trials leading to correct and very fast attribute-based rules for the relations lost 2-ply and lost 3-ply. On another tack, a model of the performance of an idealized induction system is developed and its somewhat surprising predictions compared with observed results. The paper ends with a description of preliminary work on the automatic specification of relevant attributes.",
    "date": "1982",
    "authors": [
        "J. Ross Quinlan"
    ],
    "related_topics": [
        "Game tree",
        "Classification rule",
        "Inductive reasoning"
    ],
    "citation_count": "1,639",
    "reference_count": "8",
    "references": [
        "2067642555",
        "19427811",
        "2074584355",
        "2021332478",
        "1543584403",
        "1605775535",
        "2134148799",
        "15464195"
    ]
},{
    "id": "2160167256",
    "title": "Segmentation using eigenvectors: a unifying view",
    "abstract": "Automatic grouping and segmentation of images remains a challenging problem in computer vision. Recently, a number of authors have demonstrated good performance on this task using methods that are based on eigenvectors of the affinity matrix. These approaches are extremely attractive in that they are based on simple eigendecomposition algorithms whose stability is well understood. Nevertheless, the use of eigendecompositions in the context of segmentation is far from well understood. In this paper we give a unified treatment of these algorithms, and show the close connections between them while highlighting their distinguishing features. We then prove results on eigenvectors of block matrices that allow us to analyze the performance of these algorithms in simple grouping settings. Finally, we use our analysis to motivate a variation on the existing methods that combines aspects from different eigenvector segmentation algorithms. We illustrate our analysis with results on real and synthetic images.",
    "date": "1999",
    "authors": [
        "Y. Weiss"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Image segmentation",
        "Segmentation"
    ],
    "citation_count": "1,066",
    "reference_count": "10",
    "references": [
        "2121947440",
        "2049633694",
        "1640070940",
        "2136120429",
        "2143920871",
        "2083761303",
        "1576344349",
        "1731063510",
        "2151869980",
        "2127123593"
    ]
},{
    "id": "1678356000",
    "title": "Greedy function approximation: A gradient boosting machine.",
    "abstract": "Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent \u201cboosting\u201d paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such \u201cTreeBoost\u201d models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.",
    "date": "2001",
    "authors": [
        "Jerome H. Friedman"
    ],
    "related_topics": [
        "Gradient boosting",
        "BrownBoost",
        "LogitBoost"
    ],
    "citation_count": "13,565",
    "reference_count": "20",
    "references": [
        "2156909104",
        "2117812871",
        "1594031697",
        "2112076978",
        "1498436455",
        "2151693816",
        "2024046085",
        "740415",
        "2797583072",
        "2102201073"
    ]
},{
    "id": "2091886411",
    "title": "Projection Pursuit Regression",
    "abstract": "Abstract A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation.",
    "date": "1981",
    "authors": [
        "Jerome H. Friedman",
        "Werner Stuetzle"
    ],
    "related_topics": [
        "Nonparametric regression",
        "Proper linear model",
        "Linear predictor function"
    ],
    "citation_count": "2,938",
    "reference_count": "12",
    "references": [
        "2319794630",
        "2024081693",
        "2059507684",
        "2026258334",
        "2082612735",
        "1979519992",
        "2478937241",
        "168150807",
        "2146434287",
        "1994753884"
    ]
},{
    "id": "2108263314",
    "title": "Boosting Algorithms as Gradient Descent",
    "abstract": "We provide an abstract characterization of boosting algorithms as gradient decsent on cost-functionals in an inner-product function space. We prove convergence of these functional-gradient-descent algorithms under quite weak conditions. Following previous theoretical results bounding the generalization performance of convex combinations of classifiers in terms of general cost functions of the margin, we present a new algorithm (DOOM II) for performing a gradient descent optimization of such cost functions. Experiments on several data sets from the UC Irvine repository demonstrate that DOOM II generally outperforms AdaBoost, especially in high noise situations, and that the overfitting behaviour of AdaBoost is predicted by our cost functions.",
    "date": "1999",
    "authors": [
        "Llew Mason",
        "Jonathan Baxter",
        "Peter L. Bartlett",
        "Marcus R. Frean"
    ],
    "related_topics": [
        "Stochastic gradient descent",
        "Gradient descent",
        "Boosting (machine learning)"
    ],
    "citation_count": "886",
    "reference_count": "17",
    "references": [
        "3124955340",
        "2912934387",
        "2084812512",
        "2112076978",
        "2024046085",
        "1975846642",
        "1605688901",
        "2032210760",
        "1966280301",
        "2099968818"
    ]
},{
    "id": "2109405055",
    "title": "Efficient Non-Parametric Function Induction in Semi-Supervised Learning",
    "abstract": "There has been an increase of interest for semi-supervised learning recently, because of the many datasets with large amounts of unlabeled examples and only a few labeled ones. This paper follows up on proposed non-parametric algorithms which provide an estimated continuous label for the given unlabeled examples. It extends them to function induction algorithms that correspond to the minimization of a regularization criterion applied to an out-of-sample example, and happens to have the form of a Parzen windows regressor. The advantage of the extension is that it allows predicting the label for a new example without having to solve again a linear system of dimension n (the number of unlabeled and labeled training examples), which can cost O(n 3 ). Experiments show that the extension works well, in the sense of predicting a label close to the one that would have been obtained if the test example had been included in the unlabeled set. This relatively efficient function induction procedure can also be used when n is large to approximate the solution by writing it only in terms of a kernel expansion with m n terms, and reducing the linear system to m equations in m unknowns.",
    "date": "2003",
    "authors": [
        "Yoshua Bengio",
        "Olivier Delalleau",
        "Nicolas Le Roux"
    ],
    "related_topics": [
        "Semi-supervised learning",
        "Linear system",
        "Regularization (mathematics)"
    ],
    "citation_count": "228",
    "reference_count": "17",
    "references": [
        "2165874743",
        "2154455818",
        "2139823104",
        "2520931985",
        "2112545207",
        "2122837498",
        "2113592823",
        "1491300635",
        "1574877594",
        "1514707997"
    ]
},{
    "id": "2075887074",
    "title": "Semi-infinite programming: theory, methods, and applications",
    "abstract": "Starting from a number of motivating and abundant applications in \u00a72, including control of robots, eigenvalue computations, mechanical stress of materials, and statistical design, the authors describe a class of optimization problems which are referred to as semi-infinite, because their constraints bound functions of a finite number of variables on a whole region. In \u00a7\u00a73\u20135, first- and second-order optimality conditions are derived for general nonlinear problems as well as a procedure for reducing the problem locally to one with only finitely many constraints. Another main effort for achieving simplification is through duality in \u00a76. There, algebraic properties of finite linear programming are brought to bear on duality theory in semi-infinite programming. Section 7 treats numerical methods based on either discretization or local reduction with the emphasis on the design of superlinearly convergent (SQP-type) methods. Taking this differentiable point of view, this paper can be considered to be complementar...",
    "date": "1993",
    "authors": [
        "R. Hettich",
        "K. O. Kortanek"
    ],
    "related_topics": [
        "Semi-infinite programming",
        "Generalized semi-infinite programming",
        "Nonlinear programming"
    ],
    "citation_count": "1,287",
    "reference_count": "19",
    "references": [
        "1494436834",
        "2152882024",
        "2503147665",
        "624054654",
        "2798065041",
        "1995994736",
        "2171502450",
        "2596682183",
        "2048741758",
        "2087576060"
    ]
},{
    "id": "2109943925",
    "title": "A Practical Guide to Support Vector Classication",
    "abstract": "Support vector machine (SVM) is a popular technique for classication. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but signicant steps. In this guide, we propose a simple procedure, which usually gives reasonable results.",
    "date": "2007",
    "authors": [
        "Chih-Wei Hsu",
        "Chih-Chung Chang",
        "Chih-Jen Lin"
    ],
    "related_topics": [
        "Structured support vector machine",
        "Relevance vector machine",
        "Support vector machine"
    ],
    "citation_count": "7,908",
    "reference_count": "10",
    "references": [
        "2153635508",
        "2156909104",
        "2119821739",
        "2118585731",
        "2087347434",
        "91932901",
        "2142334564",
        "2118286367",
        "2129191766",
        "2160072419"
    ]
},{
    "id": "2172000360",
    "title": "A comparison of methods for multiclass support vector machines",
    "abstract": "Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such \"all-together\" methods. We then compare their performance with three methods based on binary classifications: \"one-against-all,\" \"one-against-one,\" and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the \"one-against-one\" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors.",
    "date": "2002",
    "authors": [
        "Chih-Wei Hsu",
        "Chih-Jen Lin"
    ],
    "related_topics": [
        "Multiclass classification",
        "Structured support vector machine",
        "Support vector machine"
    ],
    "citation_count": "9,523",
    "reference_count": "24",
    "references": [
        "2153635508",
        "2148603752",
        "2119821739",
        "2084812512",
        "1512098439",
        "1576520375",
        "2124351082",
        "2282078507",
        "1602492977",
        "1543810117"
    ]
},{
    "id": "2132870739",
    "title": "Estimating the Support of a High-Dimensional Distribution",
    "abstract": "Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a \"simple\" subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.",
    "date": "2001",
    "authors": [
        "Bernhard Sch\u00f6lkopf",
        "John C. Platt",
        "John C. Shawe-Taylor",
        "Alex J. Smola",
        "Robert C. Williamson"
    ],
    "related_topics": [
        "Probability distribution",
        "Function (mathematics)",
        "Kernel (statistics)"
    ],
    "citation_count": "5,434",
    "reference_count": "56",
    "references": [
        "2156909104",
        "2148603752",
        "2099111195",
        "2798766386",
        "1512098439",
        "1576520375",
        "2087347434",
        "1604938182",
        "2108995755",
        "2161920802"
    ]
},{
    "id": "2165758113",
    "title": "What Size Net Gives Valid Generalization",
    "abstract": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < e \u2264 1/8. We show that if m \u2265 O(W/e log N/e) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 - e/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 - e of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than \u03a9(W/e) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 - e fraction of the future test examples.",
    "date": "1987",
    "authors": [
        "Eric B. Baum",
        "David Haussler"
    ],
    "related_topics": [
        "Probability distribution",
        "Fraction (mathematics)",
        "Generalization"
    ],
    "citation_count": "2,224",
    "reference_count": "32",
    "references": [
        "2147800946",
        "3017143921",
        "1530699444",
        "2019363670",
        "3036751298",
        "2176028050",
        "2154952480",
        "2129113961",
        "2010029425",
        "2020246210"
    ]
},{
    "id": "169539560",
    "title": "Generalization and network design strategies",
    "abstract": "",
    "date": "1988",
    "authors": [
        "Yann Lecun"
    ],
    "related_topics": [
        "Generalization",
        "Network planning and design",
        "Artificial intelligence"
    ],
    "citation_count": "1,107",
    "reference_count": "5",
    "references": [
        "2173629880",
        "19621276",
        "56903235",
        "2606594511",
        "2153988646"
    ]
},{
    "id": "56903235",
    "title": "Large Automatic Learning, Rule Extraction, and Generalization.",
    "abstract": "",
    "date": "1986",
    "authors": [
        "John S. Denker",
        "Daniel B. Schwartz",
        "Ben S. Wittner",
        "Sara A. Solla",
        "Richard E. Howard",
        "Lawrence D. Jackel",
        "John J. Hopfield"
    ],
    "related_topics": [
        "Generalization",
        "Computer science",
        "Machine learning"
    ],
    "citation_count": "504",
    "reference_count": "12",
    "references": [
        "2581275558",
        "2154642048",
        "2011039300",
        "1991848143",
        "2895674046",
        "1666015432",
        "1505652865",
        "2137224975",
        "1964849666",
        "1978909760"
    ]
},{
    "id": "2157475639",
    "title": "Neural Network Recognizer for Hand-Written Zip Code Digits",
    "abstract": "This paper describes the construction of a system that recognizes handprinted digits, using a combination of classical techniques and neural-net methods. The system has been trained and tested on real-world data, derived from zip codes seen on actual U.S. Mail. The system rejects a small percentage of the examples as unclassifiable, and achieves a very low error rate on the remaining examples. The system compares favorably with other state-of-the art recognizers. While some of the methods are specific to this task, it is hoped that many of the techniques will be applicable to a wide range of recognition tasks.",
    "date": "1987",
    "authors": [
        "John S. Denker",
        "W. R. Gardner",
        "Hans Peter Graf",
        "Donnie Henderson",
        "R. E. Howard",
        "W. Hubbard",
        "L. D. Jackel",
        "Henry S. Baird",
        "Isabelle Guyon"
    ],
    "related_topics": [
        "Word error rate",
        "Artificial neural network",
        "Speech recognition"
    ],
    "citation_count": "171",
    "reference_count": "11",
    "references": [
        "3017143921",
        "1655554306",
        "2155818555",
        "2116360511",
        "2058841211",
        "1501657095",
        "131259011",
        "2062361515",
        "2044630651",
        "2002448074"
    ]
},{
    "id": "1965770722",
    "title": "Consistent inference of probabilities in layered networks: predictions and generalizations",
    "abstract": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example. >",
    "date": "1988",
    "authors": [
        "Tishby",
        "Levin",
        "Solla"
    ],
    "related_topics": [
        "Supervised learning",
        "Generalization",
        "Artificial neural network"
    ],
    "citation_count": "202",
    "reference_count": "12",
    "references": [
        "2581275558",
        "2293063825",
        "1593125407",
        "56903235",
        "1968908999",
        "2012903341",
        "2123838014",
        "2043014754",
        "2476694670",
        "2161278885"
    ]
},{
    "id": "2116360511",
    "title": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex",
    "abstract": "",
    "date": "1961",
    "authors": [
        "D. H. Hubel",
        "T. N. Wiesel"
    ],
    "related_topics": [
        "Binocular neurons",
        "Visual cortex",
        "Receptive field"
    ],
    "citation_count": "24,694",
    "reference_count": "19",
    "references": [
        "2103212315",
        "2253776861",
        "2037316494",
        "2212384750",
        "2166025442",
        "2110121211",
        "2010554296",
        "2136325353",
        "2111624873",
        "2418763445"
    ]
},{
    "id": "1996355918",
    "title": "Blind separation of sources, Part 1: an adaptive algorithm based on neuromimetic architecture",
    "abstract": "Abstract The separation of independent sources from an array of sensors is a classical but difficult problem in signal processing. Based on some biological observations, an adaptive algorithm is proposed to separate simultaneously all the unknown independent sources. The adaptive rule, which constitutes an independence test using non-linear functions, is the main original point of this blind identification procedure. Moreover, a new concept, that of INdependent Components Analysis (INCA), more powerful than the classical Principal Components Analysis (in decision tasks) emerges from this work.",
    "date": "1991",
    "authors": [
        "Christian Jutten",
        "Jeanny Herault"
    ],
    "related_topics": [
        "Blind signal separation",
        "Adaptive algorithm",
        "Independent component analysis"
    ],
    "citation_count": "3,737",
    "reference_count": "8",
    "references": [
        "2051385641",
        "1996773027",
        "1481696337",
        "46701496",
        "2248478808",
        "2215995846",
        "2090736342",
        "2068447332"
    ]
},{
    "id": "2132984323",
    "title": "A theory for multiresolution signal decomposition: the wavelet representation",
    "abstract": "Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed. >",
    "date": "1989",
    "authors": [
        "S.G. Mallat"
    ],
    "related_topics": [
        "Wavelet",
        "Wavelet transform",
        "Orthogonal wavelet"
    ],
    "citation_count": "29,431",
    "reference_count": "43",
    "references": [
        "2078206416",
        "2098914003",
        "2103504761",
        "2109863423",
        "1980149518",
        "2096684483",
        "2022735534",
        "1995756857",
        "2139797453",
        "2978983090"
    ]
},{
    "id": "1536929369",
    "title": "The Handbook of Brain Theory and Neural Networks",
    "abstract": "From the Publisher: Dramatically updating and extending the first edition, published in 1995, the second edition of The Handbook of Brain Theory and Neural Networks presents the enormous progress made in recent years in the many subfields related to the two great questions: How does the brain work? and, How can we build intelligent machines? Once again, the heart of the book is a set of almost 300 articles covering the whole spectrum of topics in brain theory and neural networks. The first two parts of the book, prepared by Michael Arbib, are designed to help readers orient themselves in this wealth of material. Part I provides general background on brain modeling and on both biological and artificial neural networks. Part II consists of \"Road Maps\" to help readers steer through articles in part III on specific topics of interest. The articles in part III are written so as to be accessible to readers of diverse backgrounds. They are cross-referenced and provide lists of pointers to Road Maps, background material, and related reading. The second edition greatly increases the coverage of models of fundamental neurobiology, cognitive neuroscience, and neural network approaches to language. It contains 287 articles, compared to the 266 in the first edition. Articles on topics from the first edition have been updated by the original authors or written anew by new authors, and there are 106 articles on new topics.",
    "date": "2006",
    "authors": [
        "Michael A. Arbib"
    ],
    "related_topics": [
        "Reading (process)",
        "Cognitive neuroscience",
        "Cognitive science"
    ],
    "citation_count": "5,489",
    "reference_count": "0",
    "references": []
},{
    "id": "2133069808",
    "title": "A New Learning Algorithm for Blind Signal Separation",
    "abstract": "A new on-line learning algorithm which minimizes a statistical dependency among outputs is derived for blind separation of mixed signals. The dependency is measured by the average mutual information (MI) of the outputs. The source signals and the mixing matrix are unknown except for the number of the sources. The Gram-Charlier expansion instead of the Edgeworth expansion is used in evaluating the MI. The natural gradient approach is used to minimize the MI. A novel activation function is proposed for the on-line learning algorithm which has an equivariant property and is easily implemented on a neural network like model. The validity of the new learning algorithm are verified by computer simulations.",
    "date": "1995",
    "authors": [
        "Shun-ichi Amari",
        "Andrzej Cichocki",
        "Howard Hua Yang"
    ],
    "related_topics": [
        "Blind signal separation",
        "Wake-sleep algorithm",
        "Artificial neural network"
    ],
    "citation_count": "3,036",
    "reference_count": "6",
    "references": [
        "2099741732",
        "2108384452",
        "1996355918",
        "1977067929",
        "2022261649",
        "1520168181"
    ]
},{
    "id": "3022628558",
    "title": "The helmholtz machine",
    "abstract": "Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.",
    "date": "1999",
    "authors": [
        "Peter Dayan",
        "Geoffrey E. Hinton",
        "Radford M. Neal",
        "Richard S. Zemel"
    ],
    "related_topics": [
        "Generative model",
        "Helmholtz machine",
        "Combinatorial explosion"
    ],
    "citation_count": "1,417",
    "reference_count": "0",
    "references": []
},{
    "id": "2145012779",
    "title": "Natural image statistics and efficient coding.",
    "abstract": "Natural images contain characteristic statistical regularities that set them apart from purely random images. Understanding what these regularities are can enable natural images to be coded more efficiently. In this paper, we describe some of the forms of structure that are contained in natural images, and we show how these are related to the response properties of neurons at early stages of the visual system. Many of the important forms of structure require higher-order (i.e. more than linear, pairwise) statistics to characterize, which makes models based on linear Hebbian learning, or principal components analysis, inappropriate for finding efficient codes for natural images. We suggest that a good objective for an efficient coding of natural scenes is to maximize the sparseness of the representation, and we show that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive fields similar to those in the mammalian striate cortex.",
    "date": "1996",
    "authors": [
        "B A Olshausen",
        "D J Field"
    ],
    "related_topics": [
        "Hebbian theory",
        "Coding (social sciences)",
        "Pairwise comparison"
    ],
    "citation_count": "756",
    "reference_count": "15",
    "references": [
        "2108384452",
        "2180838288",
        "2167034998",
        "2120838001",
        "2122925692",
        "1914401667",
        "1993197592",
        "1971027050",
        "2117731089",
        "2135587681"
    ]
},{
    "id": "2146474141",
    "title": "Face recognition by independent component analysis",
    "abstract": "A number of current face recognition algorithms use face representations found by unsupervised statistical methods. Typically these methods find a set of basis images and represent faces as a linear combination of those images. Principal component analysis (PCA) is a popular example of such methods. The basis images found by PCA depend only on pairwise relationships between pixels in the image database. In a task such as face recognition, in which important information may be contained in the high-order relationships among pixels, it seems reasonable to expect that better basis images may be found by methods sensitive to these high-order statistics. Independent component analysis (ICA), a generalization of PCA, is one such method. We used a version of ICA derived from the principle of optimal information transfer through sigmoidal neurons. ICA was performed on face images in the FERET database under two different architectures, one which treated the images as random variables and the pixels as outcomes, and a second which treated the pixels as random variables and the images as outcomes. The first architecture found spatially local basis images for the faces. The second architecture produced a factorial face code. Both ICA representations were superior to representations based on PCA for recognizing faces across days and changes in expression. A classifier that combined the two ICA representations gave the best performance.",
    "date": "2002",
    "authors": [
        "M.S. Bartlett",
        "J.R. Movellan",
        "T.J. Sejnowski"
    ],
    "related_topics": [
        "FERET database",
        "Facial recognition system",
        "Independent component analysis"
    ],
    "citation_count": "2,820",
    "reference_count": "56",
    "references": [
        "2138451337",
        "1902027874",
        "2099741732",
        "2108384452",
        "2145889472",
        "2124101779",
        "2098947662",
        "1997011019",
        "1996355918",
        "2133069808"
    ]
},{
    "id": "2110208125",
    "title": "Measuring the thickness of the human cerebral cortex from magnetic resonance images",
    "abstract": "Accurate and automated methods for measuring the thickness of human cerebral cortex could provide powerful tools for diagnosing and studying a variety of neurodegenerative and psychiatric disorders. Manual methods for estimating cortical thickness from neuroimaging data are labor intensive, requiring several days of effort by a trained anatomist. Furthermore, the highly folded nature of the cortex is problematic for manual techniques, frequently resulting in measurement errors in regions in which the cortical surface is not perpendicular to any of the cardinal axes. As a consequence, it has been impractical to obtain accurate thickness estimates for the entire cortex in individual subjects, or group statistics for patient or control populations. Here, we present an automated method for accurately measuring the thickness of the cerebral cortex across the entire brain and for generating cross-subject statistics in a coordinate system based on cortical anatomy. The intersubject standard deviation of the thickness measures is shown to be less than 0.5 mm, implying the ability to detect focal atrophy in small populations or even individual subjects. The reliability and accuracy of this new method are assessed by within-subject test-retest studies, as well as by comparison of cross-subject regional thickness measures with published values.",
    "date": "2000",
    "authors": [
        "Bruce Fischl",
        "Anders M. Dale"
    ],
    "related_topics": [
        "Cortex (anatomy)",
        "Gyrification",
        "Cerebral cortex"
    ],
    "citation_count": "4,957",
    "reference_count": "41",
    "references": [
        "2170120409",
        "2104095591",
        "3127623214",
        "2151721316",
        "1238092070",
        "2103504761",
        "1994875376",
        "2113319997",
        "2099290282",
        "2110437310"
    ]
},{
    "id": "2042422091",
    "title": "An Energy Budget for Signaling in the Grey Matter of the Brain",
    "abstract": "Anatomic and physiologic data are used to analyze the energy expenditure on different components of excitatory signaling in the grey matter of rodent brain. Action potentials and postsynaptic effects of glutamate are predicted to consume much of the energy (47% and 34%, respectively), with the resting potential consuming a smaller amount (13%), and glutamate recycling using only 3%. Energy usage depends strongly on action potential rate\u2014an increase in activity of 1 action potential/cortical neuron/s will raise oxygen consumption by 145 mL/100 g grey matter/h. The energy expended on signaling is a large fraction of the total energy used by the brain; this favors the use of energy efficient neural codes and wiring patterns. Our estimates of energy usage predict the use of distributed codes, with \u226415% of neurons simultaneously active, to reduce energy consumption and allow greater computing power from a fixed number of neurons. Functional magnetic resonance imaging signals are likely to be dominated by chang...",
    "date": "2001",
    "authors": [
        "David Attwell",
        "Simon B. Laughlin"
    ],
    "related_topics": [
        "Energy consumption",
        "Energy budget",
        "Efficient energy use"
    ],
    "citation_count": "3,004",
    "reference_count": "71",
    "references": [
        "2145889472",
        "2090306035",
        "1956327946",
        "266383608",
        "1976738367",
        "1603661052",
        "2038584209",
        "2053268711",
        "2163886718",
        "2131803903"
    ]
},{
    "id": "1907121963",
    "title": "Neural Mechanisms of Visual Working Memory in Prefrontal Cortex of the Macaque",
    "abstract": "Prefrontal (PF) cells were studied in monkeys performing a delayed matching to sample task, which requires working memory. The stimuli were complex visual patterns and to solve the task, the monkeys had to discriminate among the stimuli, maintain a memory of the sample stimulus during the delay periods, and evaluate whether a test stimulus matched the sample presented earlier in the trial. PF cells have properties consistent with a role in all three of these operations. Approximately 25% of the cells responded selectively to different visual stimuli. Half of the cells showed heightened activity during the delay after the sample and, for many of these cells, the magnitude of delay activity was selective for different samples. Finally, more than half of the cells responded differently to the test stimuli depending on whether they matched the sample. Because inferior temporal (IT) cortex also is important for working memory, we compared PF cells with IT cells studied in the same task. Compared with IT cortex, PF responses were less often stimulus-selective but conveyed more information about whether a given test stimulus was a match to the sample. Furthermore, sample-selective delay activity in PF cortex was maintained throughout the trial even when other test stimuli intervened during the delay, whereas delay activity in IT cortex was disrupted by intervening stimuli. The results suggest that PF cortex plays a primary role in working memory tasks and may be a source of feedback inputs to IT cortex, biasing activity in favor of behaviorally relevant stimuli.",
    "date": "1996",
    "authors": [
        "Earl K. Miller",
        "Cynthia A. Erickson",
        "Robert Desimone"
    ],
    "related_topics": [
        "Working memory",
        "Interference theory",
        "Echoic memory"
    ],
    "citation_count": "1,664",
    "reference_count": "58",
    "references": [
        "2118615399",
        "2013755742",
        "1939596644",
        "2012521891",
        "2033118251",
        "1565561704",
        "2053315601",
        "1569395231",
        "2080530802",
        "2028310026"
    ]
},{
    "id": "1976738367",
    "title": "Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex.",
    "abstract": "1. Dual voltage recordings were made from pairs of adjacent, synaptically connected thick tufted layer 5 pyramidal neurones in brain slices of young rat (14-16 days) somatosensory cortex to examine the physiological properties of unitary EPSPs. Pre- and postsynaptic neurones were filled with biocytin and examined in the light and electron microscope to quantify the morphology of axonal and dendritic arbors and the number and location of synaptic contacts on the target neurone. 2. In 138 synaptic connections between pairs of pyramidal neurones 96 (70%) were unidirectional and 42 (30%) were bidirectional. The probability of finding a synaptic connection in dual recordings was 0.1. Unitary EPSPs evoked by a single presynaptic action potential (AP) had a mean peak amplitude ranging from 0.15 to 5.5 mV in different connections with a mean of 1.3 +/- 1.1 mV, a latency of 1.7 +/- 0.9 ms, a 20-80% rise time of 2.9 +/- 2.3 ms and a decay time constant of 40 +/- 18 ms at 32-24 degrees C and -60 +/- 2 mV membrane potential. 3. Peak amplitudes of unitary EPSPs fluctuated randomly from trial to trial. The coefficient of variation (c.v.) of the unitary EPSP amplitudes ranged from 0.13 to 2.8 in different synaptic connections (mean, 0.52; median, 0.41). The percentage of failures of single APs to evoke a unitary EPSP ranged from 0 to 73% (mean, 14%; median, 7%). Both c.v. and percentage of failures decreased with increasing mean EPSP amplitude. 4. Postsynaptic glutamate receptors which mediate unitary EPSPs at -60 mV were predominantly of the L-alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionate (AMPA) receptor type. Receptors of the N-methyl-D-aspartate (NMDA) type contributed only a small fraction (< 20%) to the voltage-time integral of the unitary EPSP at -60 mV, but their contribution increased at more positive membrane potentials. 5. Branching patterns of dendrites and axon collaterals of forty-five synaptically connected neurones, when examined in the light microscope, indicated that the axonal and dendritic anatomy of both projecting and target neurones and of uni- and bidirectionally connected neurones was uniform. 6. The number of potential synaptic contacts formed by a presynaptic neurone on a target neurone varied between four and eight (mean, 5.5 +/- 1.1 contacts; n = 19 connections). Synaptic contacts were preferentially located on basal dendrites (63%, 82 +/- 35 microns from the soma, n = 67) and apical oblique dendrites (27%, 145 +/- 59 microns, n = 29), and 35% of all contacts were located on tertiary basal dendritic branches. The mean geometric distances (from the soma) of the contacts of a connection varied between 80 and 585 microns (mean, 147 microns; median, 105 microns). The correlation between EPSP amplitude and the number of morphologically determined synaptic contacts or the mean geometric distances from the soma was only weak (correlation coefficients were 0.2 and 0.26, respectively). 7. Compartmental models constructed from camera lucida drawings of eight target neurones showed that synaptic contacts were located at mean electrotonic distances between 0.07 and 0.33 from the soma (mean, 0.13). Simulations of unitary EPSPs, assuming quantal conductance changes with fast rise time and short duration, indicated that amplitudes of quantal EPSPs at the soma were attenuated, on average, to < 10% of dendritic EPSPs and varied in amplitude up to 10-fold depending on the dendritic location of synaptic contacts. The inferred quantal peak conductance increase varied between 1.5 and 5.5 nS (mean, 3 nS). 8. The combined physiological and morphological measurements in conjunction with EPSP simulations indicated that the 20-fold range in efficacy of the synaptic connections between thick tufted pyramidal neurones, which have their synaptic contacts preferentially located on basal and apical oblique dendrites, was due to differences in transmitter release probability of the projecting neurones and, to a lesser extent, to differenc",
    "date": "1997",
    "authors": [
        "Henry Markram",
        "Joachim H. R. L\u00fcbke",
        "Michael Frotscher",
        "Arnd Roth",
        "Bert Sakmann"
    ],
    "related_topics": [
        "Excitatory postsynaptic potential",
        "Postsynaptic potential",
        "Biocytin"
    ],
    "citation_count": "959",
    "reference_count": "47",
    "references": [
        "2053980736",
        "2056661320",
        "1971405760",
        "1974804836",
        "2087758815",
        "2013070880",
        "2090584164",
        "1997862361",
        "2053794249",
        "2063542323"
    ]
},{
    "id": "2003739479",
    "title": "What does fMRI tell us about neuronal activity",
    "abstract": "In recent years, cognitive neuroscientists have taken great advantage of functional magnetic resonance imaging (fMRI) as a non-invasive method of measuring neuronal activity in the human brain. But what exactly does fMRI tell us? We know that its signals arise from changes in local haemodynamics that, in turn, result from alterations in neuronal activity, but exactly how neuronal activity, haemodynamics and fMRI signals are related is unclear. It has been assumed that the fMRI signal is proportional to the local average neuronal activity, but many factors can influence the relationship between the two. A clearer understanding of how neuronal activity influences the fMRI signal is needed if we are correctly to interpret functional imaging data.",
    "date": "2002",
    "authors": [
        "David J. Heeger",
        "David Ress"
    ],
    "related_topics": [
        "Resting state fMRI",
        "Functional magnetic resonance imaging",
        "Functional imaging"
    ],
    "citation_count": "1,132",
    "reference_count": "116",
    "references": [
        "2114104729",
        "2002660165",
        "2050717100",
        "2170814877",
        "2111609296",
        "2025283285",
        "2071714163",
        "2042422091",
        "2170117095",
        "2123586737"
    ]
},{
    "id": "1603661052",
    "title": "Cortex: Statistics and Geometry of Neuronal Connectivity",
    "abstract": "",
    "date": "1997",
    "authors": [
        "Braitenberg",
        "A Sch\u00fcz"
    ],
    "related_topics": [
        "Cortex (anatomy)",
        "Neuroscience",
        "Computer science"
    ],
    "citation_count": "1,106",
    "reference_count": "0",
    "references": []
},{
    "id": "1993303421",
    "title": "Nonoxidative glucose consumption during focal physiologic neural activity",
    "abstract": "Brain glucose uptake, oxygen metabolism, and blood flow in humans were measured with positron emission tomography, and a resting-state molar ratio of oxygen to glucose consumption of 4.1:1 was obtained. Physiological neural activity, however, increased glucose uptake and blood flow much more (51 and 50 percent, respectively) than oxygen consumption (5 percent) and produced a molar ratio for the increases of 0.4:1. Transient increases in neural activity cause a tissue uptake of glucose in excess of that consumed by oxidative metabolism, acutely consume much less energy than previously believed, and regulate local blood flow for purposes other than oxidative metabolism.",
    "date": "1988",
    "authors": [
        "Peter T. Fox",
        "Marcus E. Raichle",
        "Mark A. Mintun",
        "Carmen Dence"
    ],
    "related_topics": [
        "Glucose uptake",
        "Carbohydrate metabolism",
        "Metabolism"
    ],
    "citation_count": "2,012",
    "reference_count": "15",
    "references": [
        "1967009686",
        "2170652634",
        "1898723177",
        "1574637310",
        "2070972951",
        "1991707478",
        "2080949017",
        "1989650300",
        "1982774084",
        "2013885616"
    ]
},{
    "id": "1991233288",
    "title": "Recurrent excitation in neocortical circuits.",
    "abstract": "The majority of synapses in the mammalian cortex originate from cortical neurons. Indeed, the largest input to cortical cells comes from neighboring excitatory cells. However, most models of cortical development and processing do not reflect the anatomy and physiology of feedback excitation and are restricted to serial feedforward excitation. This report describes how populations of neurons in cat visual cortex can use excitatory feedback, characterized as an effective \"network conductance\", to amplify their feedforward input signals and demonstrates how neuronal discharge can be kept proportional to stimulus strength despite strong, recurrent connections that threaten to cause runaway excitation. These principles are incorporated into models of cortical direction and orientation selectivity that emphasize the basic design principles of cortical architectures.",
    "date": "1995",
    "authors": [
        "Rodney J. Douglas",
        "Christof Koch",
        "Misha Mahowald",
        "Kevan A. C. Martin",
        "Humbert H. Suarez"
    ],
    "related_topics": [
        "Visual cortex",
        "Cortex (anatomy)",
        "Neural Inhibition"
    ],
    "citation_count": "1,046",
    "reference_count": "50",
    "references": [
        "2177721432",
        "1996773027",
        "2163630896",
        "2008240154",
        "2116360511",
        "2096519870",
        "2082622165",
        "1672439543",
        "2038718814",
        "2107098820"
    ]
},{
    "id": "2096519870",
    "title": "Comparative electrophysiology of pyramidal and sparsely spiny stellate neurons of the neocortex.",
    "abstract": "Slices of sensorimotor and anterior cingulate cortex from guinea pigs were maintained in vitro and bathed in a normal physiological medium. Electrophysiological properties of neurons were assessed with intracellular recording techniques. Some neurons were identified morphologically by intracellular injection of the fluorescent dye Lucifer yellow CH. Three distinct neuronal classes of electrophysiological behavior were observed; these were termed regular spiking, bursting, and fast spiking. The physiological properties of neurons from sensorimotor and anterior cingulate areas did not differ significantly. Regular-spiking cells were characterized by action potentials with a mean duration of 0.80 ms at one-half amplitude, a ratio of maximum rate of spike rise to maximum rate of fall of 4.12, and a prominent afterhyperpolarization following a train of spikes. The primary slope of initial spike frequency versus injected current intensity was 241 Hz/nA. During prolonged suprathreshold current pulses the frequency of firing adapted strongly. When local synaptic pathways were activated, all cells were transiently excited and then strongly inhibited. Bursting cells were distinguished by their ability to generate endogenous, all-or-none bursts of three to five action potentials. Their properties were otherwise very similar to regular-spiking cells. The ability to generate a burst was eliminated when the membrane was depolarized to near the firing threshold with tonic current. By contrast, hyperpolarization of regular-spiking (i.e., nonbursting) cells did not uncover latent bursting tendencies. The action potentials of fast-spiking cells were much briefer (mean of 0.32 ms) than those of the other cell types.(ABSTRACT TRUNCATED AT 250 WORDS)",
    "date": "1985",
    "authors": [
        "D. A. McCormick",
        "B. W. Connors",
        "J. W. Lighthall",
        "D. A. Prince"
    ],
    "related_topics": [
        "Bursting",
        "Electrophysiology",
        "Afterhyperpolarization"
    ],
    "citation_count": "2,080",
    "reference_count": "59",
    "references": [
        "2096428903",
        "2116360511",
        "1864836097",
        "1939037149",
        "1971866692",
        "1926219845",
        "2082769538",
        "1953088445",
        "2042431572",
        "97067864"
    ]
},{
    "id": "43284170",
    "title": "Circulation and Energy Metabolism of the Brain",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Donald D Clarke",
        "Louis Sokoloff"
    ],
    "related_topics": [
        "Circulation (currency)",
        "Cell biology",
        "Biology"
    ],
    "citation_count": "790",
    "reference_count": "0",
    "references": []
},{
    "id": "2176028050",
    "title": "Connectionist learning procedures",
    "abstract": "A major goal of research on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths in such a way that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting gradient-descent procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, gradient-descent learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks.",
    "date": "1990",
    "authors": [
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Artificial neural network",
        "Connectionism",
        "Task (computing)"
    ],
    "citation_count": "3,901",
    "reference_count": "85",
    "references": [
        "1497256448",
        "2581275558",
        "2154642048",
        "1498436455",
        "1997063559",
        "2049633694",
        "2293063825",
        "2895674046",
        "1597286183",
        "22297218"
    ]
},{
    "id": "2078626246",
    "title": "Neural networks and principal component analysis: learning from examples without local minima",
    "abstract": "Abstract We consider the problem of learning from examples in layered linear feed-forward neural networks using optimization methods, such as back propagation, with respect to the usual quadratic error function E of the connection weights. Our main result is a complete description of the landscape attached to E in terms of principal component analysis. We show that E has a unique minimum corresponding to the projection onto the subspace generated by the first principal vectors of a covariance matrix associated with the training patterns. All the additional critical points of E are saddle points (corresponding to projections onto subspaces generated by higher order vectors). The auto-associative case is examined in detail. Extensions and implications for the learning algorithms are discussed.",
    "date": "1988",
    "authors": [
        "P. Baldi",
        "K. Hornik"
    ],
    "related_topics": [
        "Principal component analysis",
        "Artificial neural network",
        "Projection (linear algebra)"
    ],
    "citation_count": "1,636",
    "reference_count": "14",
    "references": [
        "2154642048",
        "1652505363",
        "2042264548",
        "1507849272",
        "1996773027",
        "2046432185",
        "2432567885",
        "2010069926",
        "2017257315",
        "2165746994"
    ]
},{
    "id": "2063089147",
    "title": "A new view of the EM algorithm that justifies incremental and other variants",
    "abstract": "",
    "date": "1992",
    "authors": [
        "R. M. Neal"
    ],
    "related_topics": [
        "Expectation\u2013maximization algorithm",
        "Algorithm",
        "Pattern recognition"
    ],
    "citation_count": "250",
    "reference_count": "0",
    "references": []
},{
    "id": "1578739277",
    "title": "A minimum description length framework for unsupervised learning",
    "abstract": "A fundamental problem in learning and reasoning about a set of information is finding the right representation. The primary goal of an unsupervised learning procedure is to optimize the quality of a system's internal representation. In this thesis, we present a general framework for describing unsupervised learning procedures based on the Minimum Description Length (MDL) principle. The MDL principle states that the best model is one that minimizes the summed description length of the model and the data with respect to the model. Applying this approach to the unsupervised learning problem makes explicit a key trade off between the accuracy of a representation (i.e., how concise a description of the input may be generated from it) and its succinctness (i.e., how compactly the representation itself can be described). Viewing existing unsupervised learning procedures in terms of the framework exposes their implicit assumptions about the type of structure assumed to underlie the data. While these existing algorithms typically minimize the data description using a fixed length representation, we use the framework to derive a class of objective functions for training self-supervised neural networks, where the goal is to minimize the description length of the representation simultaneously with that of the data. Formulating a description of the representation forces assumptions about the structure of the data to be made explicit, which in turn leads to a particular network configuration as well as an objective function that can be used to optimize the network parameters. We describe three new learning algorithms derived in this manner from the MDL framework. Each algorithm embodies a different scheme for describing the internal representation, and is therefore suited to a range of datasets based on the structure underlying the data. Simulations demonstrate the applicability of these algorithms on some simple computational vision tasks.",
    "date": "1993",
    "authors": [
        "Richard Stanley Zemel"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Minimum description length",
        "Artificial neural network"
    ],
    "citation_count": "134",
    "reference_count": "0",
    "references": []
},{
    "id": "2110553242",
    "title": "The limitations of deterministic Boltzmann machine learning",
    "abstract": "The stochastic Boltzmann machine (SBM) learning procedure allows a system of stochastic binary units at thermal equilibrium to model arbitrary probabilistic distributions of binary vectors, but the inefficiency inherent in stochastic simulations limits its usefulness. By employing mean field theory, the stochastic settling to thermal equilibrium can be replaced by efficient deterministic settling to a steady state. The analogous deterministic Boltzmann machine (DBM) learning rule performs steepest descent in an appropriately defined error measure under certain circumstances and has been empirically shown to solve a variety of non-trivial supervised, input-output problems.However, by applying \u2018naive\u2019 mean field theory to a finite system with non-random interactions, the true stochastic system is not well described, and representational problems result that significantly limit the situations in which the DBM procedure can be successfully applied. It is shown that the independence assumption is unacceptably ...",
    "date": "1992",
    "authors": [
        "Conrad C Galland"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Stochastic neural network",
        "Restricted Boltzmann machine"
    ],
    "citation_count": "29",
    "reference_count": "21",
    "references": [
        "2170120409",
        "1652505363",
        "2177721432",
        "2165225968",
        "2006544565",
        "145476170",
        "2725061391",
        "2165432985",
        "1990755770",
        "2205217816"
    ]
},{
    "id": "2151907713",
    "title": "Developing Population Codes by Minimizing Description Length",
    "abstract": "The Minimum Description Length principle (MDL) can be used to train the hidden units of a neural network to extract a representation that is cheap to describe but nonetheless allows the input to be reconstructed accurately. We show how MDL can be used to develop highly redundant population codes. Each hidden unit has a location in a low-dimensional implicit space. If the hidden unit activities form a bump of a standard shape in this space, they can be cheaply encoded by the center ofthis bump. So the weights from the input units to the hidden units in an autoencoder are trained to make the activities form a standard bump. The coordinates of the hidden units in the implicit space are also learned, thus allowing flexibility, as the network develops a discontinuous topography when presented with different input classes. Population-coding in a space other than the input enables a network to extract nonlinear higher-order properties of the inputs.",
    "date": "1993",
    "authors": [
        "Richard S. Zemel",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Autoencoder",
        "Population",
        "Minimum description length"
    ],
    "citation_count": "65",
    "reference_count": "11",
    "references": [
        "65738273",
        "1533169541",
        "2051719061",
        "2040739363",
        "2102409316",
        "2132747970",
        "1578739277",
        "2107053213",
        "2146465837",
        "2150065638"
    ]
},{
    "id": "2103504761",
    "title": "The Laplacian Pyramid as a Compact Image Code",
    "abstract": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding.",
    "date": "1983",
    "authors": [
        "P. Burt",
        "E. Adelson"
    ],
    "related_topics": [
        "Image compression",
        "Image processing",
        "Image texture"
    ],
    "citation_count": "8,766",
    "reference_count": "11",
    "references": [
        "1622620102",
        "2978983090",
        "2078498116",
        "2074163268",
        "2024397673",
        "2099590965",
        "2089975134",
        "1486071255",
        "2125311604",
        "118993750"
    ]
},{
    "id": "2134929491",
    "title": "Wavelet-based statistical signal processing using hidden Markov models",
    "abstract": "Wavelet-based statistical signal processing techniques such as denoising and detection typically model the wavelet coefficients as independent or jointly Gaussian. These models are unrealistic for many real-world signals. We develop a new framework for statistical signal processing based on wavelet-domain hidden Markov models (HMMs) that concisely models the statistical dependencies and non-Gaussian statistics encountered in real-world signals. Wavelet-domain HMMs are designed with the intrinsic properties of the wavelet transform in mind and provide powerful, yet tractable, probabilistic signal models. Efficient expectation maximization algorithms are developed for fitting the HMMs to observational signal data. The new framework is suitable for a wide range of applications, including signal estimation, detection, classification, prediction, and even synthesis. To demonstrate the utility of wavelet-domain HMMs, we develop novel algorithms for signal denoising, classification, and detection.",
    "date": "1998",
    "authors": [
        "M.S. Crouse",
        "R.D. Nowak",
        "R.G. Baraniuk"
    ],
    "related_topics": [
        "Step detection",
        "Statistical signal processing",
        "Wavelet"
    ],
    "citation_count": "2,401",
    "reference_count": "39",
    "references": [
        "2062024414",
        "2125838338",
        "2159080219",
        "2053691921",
        "2049633694",
        "2079724595",
        "2152328854",
        "2004217976",
        "2101789093",
        "1493163583"
    ]
},{
    "id": "2127006916",
    "title": "A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients",
    "abstract": "We present a universal statistical model for texture images in the context of an overcomplete complex wavelet transform. The model is parameterized by a set of statistics computed on pairs of coefficients corresponding to basis functions at adjacent spatial locations, orientations, and scales. We develop an efficient algorithm for synthesizing random images subject to these constraints, by iteratively projecting onto the set of images satisfying each constraint, and we use this to test the perceptual validity of the model. In particular, we demonstrate the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set. We also demonstrate the power of our model by successfully synthesizing examples drawn from a diverse collection of artificial and natural textures.",
    "date": "2000",
    "authors": [
        "Javier Portilla",
        "Eero P. Simoncelli"
    ],
    "related_topics": [
        "Parametric statistics",
        "Complex wavelet transform",
        "Wavelet"
    ],
    "citation_count": "2,084",
    "reference_count": "64",
    "references": [
        "2132984323",
        "2098914003",
        "1997063559",
        "2116013899",
        "2137234026",
        "1490632837",
        "2107790757",
        "2124731682",
        "2103384342",
        "2167034998"
    ]
},{
    "id": "2137234026",
    "title": "The \"independent components\" of natural scenes are edge filters.",
    "abstract": "It has previously been suggested that neurons with line and edge selectivities found in primary visual cortex of cats and monkeys form a sparse, distributed representation of natural scenes, and it has been reasoned that such responses should emerge from an unsupervised learning algorithm that attempts to find a factorial code of independent visual features. We show here that a new unsupervised learning algorithm based on information maximization, a nonlinear \u201cinfomax\u201d network, when applied to an ensemble of natural scenes produces sets of visual filters that are localized and oriented. Some of these filters are Gabor-like and resemble those produced by the sparseness-maximization network. In addition, the outputs of these filters are as independent as possible, since this infomax network performs Independent Components Analysis or ICA, for sparse (super-gaussian) component distributions. We compare the resulting ICA filters and their associated basis functions, with other decorrelating filters produced by Principal Components Analysis (PCA) and zero-phase whitening filters (ZCA). The ICA filters have more sparsely distributed (kurtotic) outputs on natural scenes. They also resemble the receptive fields of simple cells in visual cortex, which suggests that these neurons form a natural, information-theoretic coordinate system for natural images.",
    "date": "1997",
    "authors": [
        "Anthony J. Bell",
        "Terrence J. Sejnowski"
    ],
    "related_topics": [
        "Independent component analysis",
        "Infomax",
        "Efficient coding hypothesis"
    ],
    "citation_count": "2,765",
    "reference_count": "48",
    "references": [
        "2099111195",
        "2099741732",
        "2108384452",
        "1996355918",
        "2133069808",
        "2003370853",
        "1977067929",
        "2180838288",
        "2006500012",
        "2167034998"
    ]
},{
    "id": "2109863423",
    "title": "Scale-space filtering",
    "abstract": "The extrema in a signal and its first few derivatives provide a useful general-purpose qualitative description for many kinds of signals. A fundamental problem in computing such descriptions is scale: a derivative must be taken over some neighborhood, but there is seldom a principled basis for choosing its size. Scale-space filtering is a method that describes signals qualitatively, managing the ambiguity of scale in an organized and natural way. The signal is first expanded by convolution with gaussian masks over a continuum of sizes. This \"scale-space\" image is then collapsed, using its qualitative structure, into a tree providing a concise but complete qualitative description covering all scales of observation. The description is further refined by applying a stability criterion, to identify events that persist of large changes in scale.",
    "date": "1986",
    "authors": [
        "Andrew P. Witkin"
    ],
    "related_topics": [
        "Scale-space axioms",
        "Scale space",
        "Scale (ratio)"
    ],
    "citation_count": "3,997",
    "reference_count": "16",
    "references": [
        "1995756857",
        "1968245656",
        "1530383550",
        "2824445807",
        "2117900366",
        "1870339432",
        "2059376358",
        "2524793274",
        "1965555058",
        "2044972977"
    ]
},{
    "id": "2116682907",
    "title": "Clinical features and rapid viral diagnosis of human disease associated with avian influenza A H5N1 virus.",
    "abstract": "Summary Background Human infection with an avian influenza A virus (subtype H5N1) was reported recently in Hong Kong. We describe the clinical presentation of the first 12 patients and options for rapid viral diagnosis. Methods Case notes of 12 patients with virus-culture-confirmed influenza A H5N1 infection were analysed. The clinical presentation and risk factors associated with severe disease were defined and the results of methods for rapid virus diagnosis were compared. Findings Patients ranged from 1 to 60 years of age. Clinical presentation was that of an influenza-like illness with evidence of pneumonia in seven patients. All seven patients older than 13 years had severe disease (four deaths), whereas children 5 years or younger had mild symptoms with the exception of one who died with Reye's syndrome associated with intake of aspirin. Gastrointestinal manifestations, raised liver enzymes, renal failure unrelated to rhabdomyolysis, and pancytopenia were unusually prominent. Factors associated with severe disease included older age, delay in hospitalisation, lower-respiratory-tract involvement, and a low total peripheral white blood cell count or lymphopenia at admission. An H5-specific reverse-transcription PCR assay (RT-PCR) was useful for rapid detection of virus directly in respiratory specimens. A commercially available enzyme immunoassay was more sensitive than direct immunofluorescence for rapid viral diagnosis. Direct immunofluorescence with an H5-specific monoclonal antibody pool was useful for rapid exclusion of H5-subtype infection. Interpretation Avian Influenza A H5N1 virus causes human influenza-like illness with a high rate of complications in adults admitted to hospital. Rapid H5-subtype-specific laboratory diagnosis can be made by RT-PCR applied directly to clinical specimens.",
    "date": "1998",
    "authors": [
        "K. Y. Yuen",
        "P. K. S. Chan",
        "M. Peiris",
        "D. N. C. Tsang",
        "T. L. Que",
        "K. F. Shortridge",
        "P. T. Cheung",
        "W. K. To",
        "E. T. F. Ho",
        "R. Sung",
        "A. F. B. Cheng"
    ],
    "related_topics": [
        "Avian Influenza A Virus",
        "Influenza A virus",
        "Influenza A (H5N1) Virus"
    ],
    "citation_count": "1,415",
    "reference_count": "22",
    "references": [
        "2047480444",
        "2126309815",
        "2166785990",
        "2214091827",
        "2120432686",
        "2074766065",
        "2163911337",
        "2149409886",
        "146939554",
        "1566744867"
    ]
},{
    "id": "2122399224",
    "title": "Induction of proinflammatory cytokines in human macrophages by influenza A (H5N1) viruses: a mechanism for the unusual severity of human disease?",
    "abstract": "Summary Background In 1997, the first documented instance of human respiratory disease and death associated with a purely avian H5N1 influenza virus resulted in an overall case-fatality rate of 33%. The biological basis for the severity of human H5N1 disease has remained unclear. We tested the hypothesis that virus-induced cytokine dysregulation has a role. Methods We used cDNA arrays and quantitative RT-PCR to compare the profile of cytokine gene expression induced by viruses A/HK/486/97 and A/HK/483/97 (both H5N1/97) with that of human H3N2 and H1N1 viruses in human primary monocyte-derived macrophages in vitro. Secretion of tumour necrosis factor \u03b1 (TNF \u03b1) from macrophages infected with the viruses was compared by ELISA. By use of naturally occurring viral reassortants and recombinant viruses generated by reverse genetic techniques, we investigated the viral genes associated with the TNF-\u03b1 response. Findings The H5N1/97 viruses induced much higher gene transcription of proinflammatory cytokines than did H3N2 or H1N1 viruses, particularly TNF \u03b1 and interferon beta. The concentration of TNF-\u03b1 protein in culture supernatants of macrophages infected with these viruses was similar to that induced by stimulation with Escherichia coli lipopolysaccharide. The non-structural ( NS ) gene-segment of H5N1/97 viruses contributed to the increase in TNF \u03b1 induced by the virus. Interpretation The H5N1/97 viruses are potent inducers of proinflammatory cytokines in macrophages, the most notable being TNF \u03b1. This characteristic may contribute to the unusual severity of human H5N1 disease.",
    "date": "2002",
    "authors": [
        "C Y Cheung",
        "L L M Poon",
        "A S Lau",
        "W Luk",
        "Y L Lau",
        "K F Shortridge",
        "S Gordon",
        "Y Guan",
        "J S M Peiris"
    ],
    "related_topics": [
        "Proinflammatory cytokine",
        "Influenza A virus",
        "Orthomyxoviridae"
    ],
    "citation_count": "1,080",
    "reference_count": "30",
    "references": [
        "2116682907",
        "2126309815",
        "2024970913",
        "2163960578",
        "2091527885",
        "2148734478",
        "2093983981",
        "2143232661",
        "1988436330",
        "1974668319"
    ]
},{
    "id": "2104730345",
    "title": "Detection of Influenza A Viruses from Different Species by PCR Amplification of Conserved Sequences in the Matrix Gene",
    "abstract": "The recently raised awareness of the threat of a new influenza pandemic has stimulated interest in the detection of influenza A viruses in human as well as animal secretions. Virus isolation alone is unsatisfactory for this purpose because of its inherent limited sensitivity and the lack of host cells that are universally permissive to all influenza A viruses. Previously described PCR methods are more sensitive but are targeted predominantly at virus strains currently circulating in humans, since the sequences of the primer sets display considerable numbers of mismatches to the sequences of animal influenza A viruses. Therefore, a new set of primers, based on highly conserved regions of the matrix gene, was designed for single-tube reverse transcription-PCR for the detection of influenza A viruses from multiple species. This PCR proved to be fully reactive with a panel of 25 genetically diverse virus isolates that were obtained from birds, humans, pigs, horses, and seals and that included all known subtypes of influenza A virus. It was not reactive with the 11 other RNA viruses tested. Comparative tests with throat swab samples from humans and fecal and cloacal swab samples from birds confirmed that the new PCR is faster and up to 100-fold more sensitive than classical virus isolation procedures.",
    "date": "2000",
    "authors": [
        "Ron A. M. Fouchier",
        "Theo M. Bestebroer",
        "Sander Herfst",
        "Liane Van Der Kemp",
        "Guus F. Rimmelzwaan",
        "Albert D. M. E. Osterhaus"
    ],
    "related_topics": [
        "Influenza A virus",
        "Orthomyxoviridae",
        "Virus"
    ],
    "citation_count": "576",
    "reference_count": "24",
    "references": [
        "2126309815",
        "2160881014",
        "2148734478",
        "2041877620",
        "2092097938",
        "2334261876",
        "2153782171",
        "2171369029",
        "2120432686",
        "2164655171"
    ]
},{
    "id": "2141291230",
    "title": "Evaluation of the Directigen FluA+B Test for Rapid Diagnosis of Influenza Virus Type A and B Infections",
    "abstract": "Directigen FluA+B (BD Diagnostic Systems, Sparks, Md.), a new rapid test for the detection of influenza virus types A and B, was evaluated with nasopharyngeal aspirate specimens collected from 250 patients in comparison with culture and direct fluorescent antigen (DFA) detection tests. The patients studied were predominantly children, 80% being \u22646 years old. Specimens negative by culture but positive by the Directigen FluA+B or DFA tests were analyzed by reverse transcription-PCR to resolve the discrepant results. The resolved sensitivity, specificity, and positive and negative predictive values of the Directigen FluA+B test for influenza virus type A were 96%, 99.6%, 96%, and 99.6%, respectively, and for influenza virus type B they were 87.5%, 96.8%, 80%, and 98%, respectively. Storage of nasopharyngeal aspirates in virus transport medium at 2 to 8\u00b0C for 48 h had little adverse effect on the detection of influenza virus type A, but diagnosis of influenza virus type B is best carried out with fresh specimens. The test detected a range of human and animal influenza virus A subtypes, including the H5N1 and H9N2 viruses that recently caused human disease in Hong Kong.",
    "date": "2002",
    "authors": [
        "K. H. Chan",
        "N. Maldeis",
        "W. Pope",
        "A. Yup",
        "A. Ozinskas",
        "J. Gill",
        "W. H. Seto",
        "K. F. Shortridge",
        "J. S. M. Peiris"
    ],
    "related_topics": [
        "Influenza A virus",
        "Orthomyxoviridae",
        "Influenzavirus B"
    ],
    "citation_count": "179",
    "reference_count": "19",
    "references": [
        "2116682907",
        "2148734478",
        "2092097938",
        "2082036062",
        "2169706295",
        "2163911337",
        "2167082727",
        "2142239556",
        "2030408297",
        "1987179697"
    ]
},{
    "id": "2154664055",
    "title": "Spectrum of Clinical Illness in Hospitalized Patients with \u201cCommon Cold\u201d Virus Infections",
    "abstract": "The viruses associated most frequently with the \"common cold\" are rhinoviruses and coronaviruses. The first prospective cohort study to determine the prevalence of rhinovirus and coronavirus infections in patients of all ages hospitalized for acute respiratory illnesses is described. Hospital admissions for acute respiratory illnesses were identified, and cell culture for rhinovirus and serologic assays on paired sera for coronaviruses 229E and OC43 were performed. A total of 61 infections with rhinoviruses and coronaviruses were identified from 1198 respiratory illnesses (5.1%); in addition, 9 additional infections associated with >/=1 other respiratory viruses were identified. Of those infected with only rhinovirus or coronavirus, underlying cardiopulmonary diseases were present in 35% of the patients aged 35 years. The predominant clinical syndromes varied by age: pneumonia and bronchiolitis in children aged <5 years; exacerbations of asthma in older children and young adults; and pneumonia and exacerbations of chronic obstructive pulmonary disease and congestive heart failure in older adults. Therefore, rhinovirus and coronavirus infections in hospitalized patients were associated with lower respiratory tract illnesses in all age groups.",
    "date": "2000",
    "authors": [
        "Hana M. El-Sahly",
        "Robert L. Atmar",
        "William P. Glezen",
        "Stephen B. Greenberg"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Rhinovirus",
        "Coronavirus"
    ],
    "citation_count": "196",
    "reference_count": "49",
    "references": [
        "1964779747",
        "2127062009",
        "2136123493",
        "1980185618",
        "2148710849",
        "1520164477",
        "2016357017",
        "2091249799",
        "2098388207",
        "2019621692"
    ]
},{
    "id": "1970720481",
    "title": "Coronavirus pneumonia following autologous bone marrow transplantation for breast cancer.",
    "abstract": "Infectious bronchitis virus, otherwise known as coronavirus, can cause mild upper respiratory tract illnesses in children and adults. Rarely has coronavirus been linked, either by serology or nasal wash, to pneumonia. We report a case of a young woman who, following treatment for stage IIIA breast cancer using a high-dose chemotherapy regimen followed by autologous bone marrow and stem cell transplantation, developed respiratory failure and was found to have coronavirus pneumonia as diagnosed by electron microscopy from BAL fluid. We propose that coronavirus should be considered in the differential diagnosis of acute respiratory failure in cancer patients who have undergone high-dose chemotherapy and autologous hematopoietic support.",
    "date": "1999",
    "authors": [
        "Rodney J. Folz",
        "Maha A. Elkordy"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Idiopathic pneumonia syndrome"
    ],
    "citation_count": "88",
    "reference_count": "31",
    "references": [
        "2619503610",
        "2155757329",
        "1971062720",
        "2012153513",
        "2001636475",
        "2016060597",
        "2036196845",
        "2036210533",
        "1578235202",
        "2123113466"
    ]
},{
    "id": "576359727",
    "title": "Manual of Clinical Virology",
    "abstract": "Part 1 General laboratory procedures: laboratory design and equipment laboratory safety general methodologies virus testing protocols specimen collection and processing mammalian cell culture procedures quality assurance. Part 2 Specific detection methods: adenoviruses chlamydiae clostridium difficile toxin assay cytomegalovirus enteroviruses Epstein-Barr virus hepatitis A virus herpes simplex virus human herpesvirus 6 influenza virus measles virus mumps virus parainfluenza virus human papillomavirus polyomavirus human parvovirus respiratory syncytial virus human retroviruses rhinovirus rotavirus rubella virus varicella-zoster virus. Part 3 Appendices: glossary of commonly used terms reagent resources reagent formulations.",
    "date": "1992",
    "authors": [
        "Danny L. Wiedbrauk",
        "Sheryl L. G. Johnston"
    ],
    "related_topics": [
        "Viral culture",
        "Virus",
        "Measles virus"
    ],
    "citation_count": "75",
    "reference_count": "0",
    "references": []
},{
    "id": "2239493136",
    "title": "Coronaviruses: a comparative review.",
    "abstract": "The coronaviruses have been recently classified as a separate virus genus on the basis of several fundamental characteristics, which include their nucleic acid type, the presence of a lipid envelope, and, in particular, their distinctive morphology (Tyrrell et al., 1968a). Members of the genus infect a number of different animal species, and until their reclassification were considered to belong to the myxovirus group although they possessed many atypical features. It was through detailed studies of their morphology in negatively stained preparations that they were finally differentiated and set out as a separate genus. When properly prepared, Coronavirus particles appear medium-sized, round, and moderately pleomorphic, and bear characteristic widely-spaced club-shaped surface projections. Coronaviruses naturally infect man, chickens, pigs, mice and rats, causing a wide variety of disorders involving a number of different organ systems. Indeed, new species are being added at frequent intervals as the techniques of electron microscopy and modern virology are applied to diseases which have often been clinically recognized for decades. A tentative scheme of the Coronavirus genus is shown in Table 1, with a listing of serotypes and strains. The list of types is not complete, but those of importance to this review are shown.",
    "date": "1973",
    "authors": [
        "Kenneth McIntosh"
    ],
    "related_topics": [
        "Coronavirus",
        "Genus",
        "Serotype"
    ],
    "citation_count": "247",
    "reference_count": "214",
    "references": [
        "2014020683",
        "2169726092",
        "2037805800",
        "2332629841",
        "1566903320",
        "1990428998",
        "2092162071",
        "1821572714",
        "1555556046",
        "2137857422"
    ]
},{
    "id": "2081510963",
    "title": "Further studies on human enteric coronaviruses.",
    "abstract": "Comparisons were made between human enteric coronaviruses and the enteric coronaviruses of pigs and calves by negative staining. Examination of human intestinal organ culture fluids at various time intervals after inoculation with the human enteric coronavirus showed increasing numbers of particles in the fluids. Thin sections of the columnar epithelial cells of these explants showed a number of features consistent with the replication of known human and animal coronaviruses. Virus particles found in thin sections had a mean diameter of 68 nm. In addition, a structure was found in thin sections which has not been described previously. This structure may represent the viral nucleocapsid.",
    "date": "1976",
    "authors": [
        "E. O. Caul",
        "S. I. Egglestone"
    ],
    "related_topics": [
        "Viral nucleocapsid",
        "Viral replication",
        "Virus"
    ],
    "citation_count": "98",
    "reference_count": "17",
    "references": [
        "2239493136",
        "2037805800",
        "2332629841",
        "2092162071",
        "2137857422",
        "1970210012",
        "2005081670",
        "2170844974",
        "2089025288",
        "2017255364"
    ]
},{
    "id": "2336133541",
    "title": "Coronavirus infections in military recruits. Three-year study with coronavirus strains OC43 and 229E.",
    "abstract": "A seroepidemiologic study of respiratory infections due to coronaviruses OC43 and 229E occurring in U.S. Marine recruits in the winters of 1970, 1971, and 1972 was performed. The per cent of respiratory infections due to these strains was low (0 to 5 per cent) in 2 of the 3 years, but a sharp outbreak of OC43 infection occurred in the winter of 1970 and 1971. f'ifty.two per cent of 75 trainees studied seroconverted to coronavirus OC43, and 37 of the 39 seroconversions occurred while the men were hospitalized for acute respiratory disease. Lower respiratory tract disease was apparent in some of these men although many others had concomitant infection with adenovirus and/or Mycoplasma pneumoniae. In OC43 infection, a serum hemagglutination inhibition anti\u00b7 body titer of:=' 40 was associated with protection (P = OJ)()2) against reinfection. Nevertheless, 43 per cent of men who became infected with OC43 virus had initial serum antibody titers of \"\" 20 and < 80.",
    "date": "1974",
    "authors": [
        "Wenzel Rp",
        "Hendley Jo",
        "Davies Ja",
        "Gwaltney Jm"
    ],
    "related_topics": [
        "Coronavirus",
        "Mycoplasma pneumoniae",
        "Seroconversion"
    ],
    "citation_count": "71",
    "reference_count": "8",
    "references": [
        "2169726092",
        "2037805800",
        "2332629841",
        "2092162071",
        "1984970974",
        "2413945105",
        "2050904323",
        "2064586751"
    ]
},{
    "id": "2107978811",
    "title": "APACHE II: a severity of disease classification system.",
    "abstract": "This paper presents the form and validation results of APACHE II, a severity of disease classification system. APACHE II uses a point score based upon initial values of 12 routine physiologic measurements, age, and previous health status to provide a general measure of severity of disease. An increasing score (range 0 to 71) was closely correlated with the subsequent risk of hospital death for 5815 intensive care admissions from 13 hospitals. This relationship was also found for many common diseases. When APACHE II scores are combined with an accurate description of disease, they can prognostically stratify acutely ill patients and assist investigators comparing the success of new or differing forms of therapy. This scoring index can be used to evaluate the use of hospital resources and compare the efficacy of intensive care in different hospitals or over time.",
    "date": "1985",
    "authors": [
        "William A. Knaus",
        "Elizabeth A. Draper",
        "Douglas P. Wagner",
        "Jack E. Zimmerman"
    ],
    "related_topics": [
        "APACHE II",
        "SAPS II",
        "Simplified Acute Physiology Score"
    ],
    "citation_count": "20,984",
    "reference_count": "0",
    "references": []
},{
    "id": "2161328469",
    "title": "The American-European Consensus Conference on ARDS: Definitions, mechanisms, relevant outcomes, and clinical trial coordination",
    "abstract": "The acute respiratory distress syndrome (ARDS), a process of nonhydrostatic pulmonary edema and hypoxemia associated with a variety of etiologies, carries a high morbidity, mortality (10 to 90%), and financial cost. The reported annual incidence in the United States is 150,000 cases, but this figure has been challenged, and it may be different in Europe. Part of the reason for these uncertainties are the heterogeneity of diseases underlying ARDS and the lack of uniform definitions for ARDS. Thus, those who wish to know the true incidence and outcome of this clinical syndrome are stymied. The American-European Consensus Committee on ARDS was formed to focus on these issues and on the pathophysiologic mechanisms of the process. It was felt that international coordination between North America and Europe in clinical studies of ARDS was becoming increasingly important in order to address the recent plethora of potential therapeutic agents for the prevention and treatment of ARDS.",
    "date": "1994",
    "authors": [
        "G R Bernard",
        "A Artigas",
        "K L Brigham",
        "J Carlet",
        "K Falke",
        "L Hudson",
        "M Lamy",
        "J R Legall",
        "A Morris",
        "R Spragg"
    ],
    "related_topics": [
        "ARDS",
        "Diffuse alveolar damage",
        "Clinical trial"
    ],
    "citation_count": "7,795",
    "reference_count": "21",
    "references": [
        "2107978811",
        "2120156715",
        "2005357317",
        "2086247090",
        "2056554475",
        "2077539093",
        "2062476705",
        "1971696195",
        "2003673873",
        "2024330176"
    ]
},{
    "id": "2155583106",
    "title": "Rapid Diagnosis of a Coronavirus Associated with Severe Acute Respiratory Syndrome (SARS)",
    "abstract": "Severe acute respiratory syndrome (SARS) is a recently emerged disease associated with pneumonia in infected patients (1). The disease is unusual in its severity, and patients suffering from this disease do not respond to empirical antimicrobial treatment for acute community-acquired typical or atypical pneumonia (2). By the end of March 2003, a cumulative total of 1622 cases and 58 deaths had been reported from 13 countries (3). The disease is highly infectious, and attach rates >56% have been reported in healthcare workers caring for SARS patients (2). Recently, we identified a novel virus in the family Coronaviridae in SARS patients (4). Of patients from whom paired acute and convalescent sera were available, all had seroconverted or had a greater than fourfold increase in antibody titer to this novel virus (4), suggesting that it plays an important role in the etiology of SARS. Thus, the establishment of a rapid noninvasive test for this virus is a high priority for monitoring and control of this disease. Here, we report a real-time quantitative PCR assay to detect this virus in clinical specimens. Patients with a clinical diagnosis of SARS and admitted in two hospitals in Hong Kong between February 26, 2003, and March 26, 2003, were considered for this study. Inclusion criteria were a fever of 38 \u00b0C or higher, cough or shortness of breath, new pulmonary infiltrate(s) on chest radiographs, and either a history of exposure to a patient with SARS or absence of response to empirical antimicrobial coverage for typical and atypical pneumonia. Samples were collected with informed consent. In total, 29 SARS patients with paired sera and nasopharyngeal aspirate (NPA) samples were available for the study. The diagnosis of SARS was confirmed in all patients by the presence of antibodies against the novel coronavirus in the serum (4). The \u2026",
    "date": "2003",
    "authors": [
        "Leo L.M. Poon",
        "On Kei Wong",
        "Winsie Luk",
        "Kwok Yung Yuen",
        "Joseph S.M. Peiris",
        "Yi Guan"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Atypical pneumonia",
        "Pneumonia"
    ],
    "citation_count": "206",
    "reference_count": "7",
    "references": [
        "2132260239",
        "2131262274",
        "2463755683",
        "2144617314",
        "2491252321",
        "2239493136",
        "1041988209"
    ]
},{
    "id": "1675164605",
    "title": "Ribavirin Inhibits Viral-Induced Macrophage Production of TNF, IL-1, the Procoagulant fgl2 Prothrombinase and Preserves Th1 Cytokine Production But Inhibits Th2 Cytokine Response",
    "abstract": "Ribavirin, a synthetic guanosine analogue, possesses a broad spectrum of activity against DNA and RNA viruses. It has been previously shown to attenuate the course of fulminant hepatitis in mice produced by murine hepatitis virus strain 3. We therefore studied the effects of ribavirin on murine hepatitis virus strain 3 replication, macrophage production of proinflammatory mediators including TNF, IL-1, and the procoagulant activity (PCA), fgl2 prothrombinase; and Th1/Th2 cytokine production. Although ribavirin had inhibitory effects on viral replication (<1 log), even at high concentrations complete eradication of the virus was not seen. In contrast, at physiologic concentrations (up to 500 \u03bcg/ml), ribavirin markedly reduced viral-induced parameters of macrophage activation. With ribavirin treatment, the concentrations of PCA, TNF-\u03b1 and IL-1\u03b2 all decreased to basal concentrations: PCA from 941 \u00b1 80 to 34 \u00b1 11 mU/106 cells; TNF-\u03b1 from 10.73 \u00b1 2.15 to 2.74 \u00b1 0.93 ng/ml; and IL-1\u03b2 from 155.91 \u00b1 22.62 to 5.74 \u00b1 0.70 pg/ml. The inhibitory effects of ribavirin were at the level of gene transcription as evidenced by Northern analysis. Both in vitro and in vivo, ribavirin inhibited the production of IL-4 by Th2 cells, whereas it did not diminish the production of IFN-\u03b3 in Th1 cells. In contrast, ribavirin had no inhibitory effect on TNF-\u03b1 and IL-1\u03b2 production in LPS-stimulated macrophages. These results suggest that the beneficial effects of ribavirin are mediated by inhibition of induction of macrophage proinflammatory cytokines and Th2 cytokines while preserving Th1 cytokines.",
    "date": "1998",
    "authors": [
        "Qin Ning",
        "Deron Brown",
        "Jean Parodo",
        "Mark Cattral",
        "Reginald Gorczynski",
        "Edward Cole",
        "Laisum Fung",
        "Jin Wen Ding",
        "Ming Feng Liu",
        "Ori Rotstein",
        "M. James Phillips",
        "Gary Levy"
    ],
    "related_topics": [
        "Proinflammatory cytokine",
        "Ribavirin",
        "FGL2"
    ],
    "citation_count": "427",
    "reference_count": "44",
    "references": [
        "2172466148",
        "2175117246",
        "1976415203",
        "2127278205",
        "1634158134",
        "2105054347",
        "1580125578",
        "2016710605",
        "1605898561",
        "2110623508"
    ]
},{
    "id": "2061759246",
    "title": "Guideline on management of severe acute respiratory syndrome (SARS).",
    "abstract": "Severe acute respiratory syndrome (SARS) has recently been recognised as a newly emerging infectious disease that is highly contagious with significant morbidity and mortality. The first index case in Hong Kong was admitted on Feb 22, 2003. As of April 6, 842 cases have been identified in Hong Kong, with fatal complications in 22 patients. The outbreak has prompted the Hospital Authority of Hong Kong and the Department of Health to implement a series of public-health measures and hospital policies for the diagnosis and management of patients with SARS. The figures are summaries of the management flowchart in the accident and emergency department for patients with a history of definite contact with SARS patients within the past 10 days (figure 1) and for patients with no such definite contact (figure 2). The Hong Kong Hospital Authority SARS Command Centre has been established to coordinate clinical activities, including identification and reporting of cases, implementation of infection-control measures, dissemination of information to the public, development of diagnostic tests, and assessment of treatment regimens in a cluster network of hospitals. Each hospital cluster has designated treatment centres. The Hospital Authority Guideline on management of severe acute respiratory syndrome (SARS)",
    "date": "2003",
    "authors": [
        "William Ho"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Guideline",
        "Disease cluster"
    ],
    "citation_count": "84",
    "reference_count": "0",
    "references": []
},{
    "id": "2167080692",
    "title": "The severe acute respiratory syndrome.",
    "abstract": "textabstractThe severe acute respiratory syndrome (SARS) is responsible for the first pandemic of the 21st century. Within months after its emergence in Guangdong Province in mainland China, it had affected more than 8000 patients and caused 774 deaths in 26 countries on five continents. It illustrated dramatically the potential of air travel and globalization for the dissemination of an emerging infectious disease and highlighted the need for a coordinated global response to contain such disease threats. We review the cause, epidemiology, and clinical features of the disease.",
    "date": "2003",
    "authors": [
        "Joseph S M Peiris",
        "Kwok Y Yuen",
        "Albert D M E Osterhaus",
        "Klaus St\u00f6hr"
    ],
    "related_topics": [
        "Disease reservoir",
        "Emerging infectious disease",
        "Pandemic"
    ],
    "citation_count": "1,426",
    "reference_count": "71",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2100820722",
        "2125251240",
        "2147166346",
        "2116586125",
        "2169198329"
    ]
},{
    "id": "1593955729",
    "title": "A pancoronavirus RT-PCR assay for detection of all known coronaviruses",
    "abstract": "The recent discoveries of novel human coronaviruses, including the coronavirus causing SARS, and the previously unrecognized human coronaviruses HCoV-NL63 and HCoV-HKU1, indicate that the family Coronaviridae harbors more members than was previously assumed. All human coronaviruses characterized at present are associated with respiratory illnesses, ranging from mild common colds to more severe lower respiratory tract infections. Since the etiology of a relatively large percentage of respiratory tract diseases remains unidentified, it is possible that for a certain number of these illnesses, a yet unknown viral causative agent may be found. Screening for the presence of novel coronaviruses requires the use of a method that can detect all coronaviruses known at present. In this chapter, we describe a pancoronavirus degenerate primer-based method that allows the detection of all known and possibly unknown coronaviruses by RT-PCR amplification and sequencing of a 251-bp fragment of the coronavirus polymerase gene.",
    "date": "2007",
    "authors": [
        "Leen Vijgen",
        "Elien Mo\u00ebs",
        "Els Keyaerts",
        "Sandra Li",
        "Marc Van Ranst"
    ],
    "related_topics": [
        "Coronavirus",
        "Respiratory tract infections",
        "Multiple displacement amplification"
    ],
    "citation_count": "73",
    "reference_count": "9",
    "references": [
        "2055043387",
        "2097382368",
        "2146396346",
        "163498145",
        "2084994773",
        "2063850263",
        "1905858949",
        "2155523942",
        "1998335482"
    ]
},{
    "id": "2145810580",
    "title": "Evaluation of Advanced Reverse Transcription-PCR Assays and an Alternative PCR Target Region for Detection of Severe Acute Respiratory Syndrome-Associated Coronavirus",
    "abstract": "First-generation reverse transcription-PCR (RT-PCR) assays for severe acute respiratory syndrome-associated coronavirus (SARS-CoV) gave false-negative results in a considerable fraction of patients. In the present study, we evaluated two second-generation, replicase (R) gene-based, real-time RT-PCR test kits\u2014the RealArt HPA coronavirus LC kit (Artus, Hamburg, Germany) and the LightCycler SARS-CoV quantification kit (Roche, Penzberg, Germany)\u2014and a real-time RT-PCR assay for the nucleocapsid (N) gene. Detecting the N-gene RNA might be advantageous due to its high abundance in cells. The kits achieved sensitivities of 70.8% (Artus) and 67.1% (Roche) in 66 specimens from patients with confirmed SARS (samples primarily from the upper and lower respiratory tract and stool). The sensitivity of the N-gene assay was 74.2%. The differences in all of the sensitivities were not statistically significant (P = 0.680 [analysis of variance]). Culture cells initially contained five times more N- than R-gene RNA, but the respective levels converged during 4 days of virus replication. In clinical samples the median concentrations of R- and N-gene RNA, respectively, were 1.2 \u00d7 106 and 2.8 \u00d7 106 copies/ml (sputum and endotracheal aspirates), 4.3 \u00d7 104 and 5.5 \u00d7 104 copies/ml (stool), and 5.5 \u00d7 102 and 5.2 \u00d7 102 copies/sample (throat swabs and saliva). Differences between the samples types were significant but not between the types of target RNA. All (n = 12) samples from the lower respiratory tract tested positive in all tests. In conclusion, the novel assays are more sensitive than the first-generation tests, but they still do not allow a comprehensive ruling out of SARS. Methods for the routine sampling of sputum without infection risk are needed to improve SARS RT-PCR.",
    "date": "2004",
    "authors": [
        "Christian Drosten",
        "Lily-Lily Chiu",
        "Marcus Panning",
        "Hoe Nam Leong",
        "Wolfgang Preiser",
        "John S. Tam",
        "Stephan G\u00fcnther",
        "Stefanie Kramme",
        "Petra Emmerich",
        "Wooi Loon Ng",
        "Herbert Schmitz",
        "Evelyn S. C. Koay"
    ],
    "related_topics": [
        "Coronavirus",
        "Sputum",
        "RNA-dependent RNA polymerase"
    ],
    "citation_count": "113",
    "reference_count": "12",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2129542667",
        "3022331664",
        "2116586125",
        "1990049863",
        "2168446943",
        "1976741900",
        "2107922358"
    ]
},{
    "id": "1975169783",
    "title": "Real-time reverse transcription-polymerase chain reaction assay for SARS-associated coronavirus.",
    "abstract": "A real-time reverse transcription-polymerase chain reaction (RT-PCR) assay was developed to rapidly detect the severe acute respiratory syndrome-associated coronavirus (SARS-CoV). The assay, based on multiple primer and probe sets located in different regions of the SARS-CoV genome, could discriminate SARS-CoV from other human and animal coronaviruses with a potential detection limit of <10 genomic copies per reaction. The real-time RT-PCR assay was more sensitive than a conventional RT-PCR assay or culture isolation and proved suitable to detect SARS-CoV in clinical specimens. Application of this assay will aid in diagnosing SARS-CoV infection.",
    "date": "2004",
    "authors": [
        "Shannon L. Emery",
        "Dean D. Erdman",
        "Michael D. Bowen",
        "Bruce R. Newton",
        "Jonas M. Winchell",
        "Richard F. Meyer",
        "Suxiang Tong",
        "Byron T. Cook",
        "Brian P. Holloway",
        "Karen A. McCaustland",
        "Paul A. Rota",
        "Bettina Bankamp",
        "Luis E. Lowe",
        "Thomas Ksiazek",
        "William J. Bellini",
        "Larry J. Anderson"
    ],
    "related_topics": [
        "Coronavirus",
        "Reverse transcription polymerase chain reaction",
        "Primer (molecular biology)"
    ],
    "citation_count": "247",
    "reference_count": "17",
    "references": [
        "2132260239",
        "2104548316",
        "2131262274",
        "2129542667",
        "2100820722",
        "2125251240",
        "2116586125",
        "2463755683",
        "2100187217",
        "1959254653"
    ]
},{
    "id": "2069961370",
    "title": "Subacute sclerosing panencephalitis.",
    "abstract": "Subacute sclerosing panencephalitis (SSPE) is a subacute encephalopathy of childhood and young adolescence. Infrequently, SSPE can occur in adults and pregnant women. It is caused by an aberrant measles virus, known as the SSPE virus. SSPE virus differs from wild-type measles viruses in the form of several mutations affecting the viral genome. The matrix gene is most commonly affected by these mutations. The characteristic clinical manifestations of SSPE include behavioral changes, cognitive decline, myoclonic jerks, seizures, abnormalities in vision, bilateral pyramidal signs and coma. Ocular changes may occur in up to 50 % of patients. The most characteristic ophthalmological lesion is necrotizing retinitis. Cortical blindness can be the early feature of SSPE. The diagnosis of SSPE is often difficult in the early stages. In a typical case diagnosis is based on clinical, electroencephalographic, and cerebrospinal fluid findings. At present, there is no effective treatment to completely cure SSPE. Oral isoprinosine and intrathecal or intraventricular alpha-interferon may prolong survival to some extent. Immunization against measles is currently the most effective strategy against SSPE.",
    "date": "2008",
    "authors": [
        "Ravindra Kumar Garg"
    ],
    "related_topics": [
        "SSPE Virus",
        "Subacute sclerosing panencephalitis",
        "Cognitive decline"
    ],
    "citation_count": "440",
    "reference_count": "92",
    "references": [
        "2069961370",
        "2143879250",
        "1991093481",
        "2116805677",
        "2119333927",
        "2036030296",
        "2127909121",
        "1600027143",
        "2016219858",
        "2161726052"
    ]
},{
    "id": "2105870155",
    "title": "Generic detection of coronaviruses and differentiation at the prototype strain level by reverse transcription-PCR and nonfluorescent low-density microarray.",
    "abstract": "A nonfluorescent low-cost, low-density oligonucleotide array was designed for detecting the whole coronavirus genus after reverse transcription (RT)-PCR. The limit of detection was 15.7 copies/reaction. The clinical detection limit in patients with severe acute respiratory syndrome was 100 copies/sample. In 39 children suffering from coronavirus 229E, NL63, OC43, or HKU1, the sensitivity was equal to that of individual real-time RT-PCRs.",
    "date": "2007",
    "authors": [
        "Luciano Kleber de Souza Luna",
        "Volker Heiser",
        "Nicolas Regamey",
        "Marcus Panning",
        "Jan Felix Drexler",
        "Sabue Mulangu",
        "Leo Poon",
        "Sigrid Baumgarte",
        "Bert Jan Haijema",
        "Laurent Kaiser",
        "Christian Drosten"
    ],
    "related_topics": [
        "Coronavirus",
        "Reverse transcription polymerase chain reaction",
        "Reverse transcriptase"
    ],
    "citation_count": "118",
    "reference_count": "16",
    "references": [
        "2111412754",
        "2170933940",
        "2159857626",
        "2078917493",
        "2107922358",
        "2084994773",
        "132455992",
        "2145810580",
        "1905858949",
        "2132202407"
    ]
},{
    "id": "2100516702",
    "title": "Pegylated interferon-alpha protects type 1 pneumocytes against SARS coronavirus infection in macaques.",
    "abstract": "The primary cause of severe acute respiratory syndrome (SARS) is a newly discovered coronavirus1,2,3,4,5,6,7. Replication of this SARS coronavirus (SCV) occurs mainly in the lower respiratory tract, and causes diffuse alveolar damage2,7,8. Lack of understanding of the pathogenesis of SARS has prevented the rational development of a therapy against this disease. Here we show extensive SCV antigen expression in type 1 pneumocytes of experimentally infected cynomolgus macaques (Macaca fascicularis) at 4 d postinfection (d.p.i.), indicating that this cell type is the primary target for SCV infection early in the disease, and explaining the subsequent pulmonary damage. We also show that prophylactic treatment of SCV-infected macaques with the antiviral agent pegylated interferon-\u03b1 (IFN-\u03b1) significantly reduces viral replication and excretion, viral antigen expression by type 1 pneumocytes and pulmonary damage, compared with untreated macaques. Postexposure treatment with pegylated IFN-\u03b1 yielded intermediate results. We therefore suggest that pegylated IFN-\u03b1 protects type 1 pneumocytes from SCV infection, and should be considered a candidate drug for SARS therapy",
    "date": "2004",
    "authors": [
        "Bart L. Haagmans",
        "Thijs Kuiken",
        "Byron Ee E Martina",
        "Ron Am M Fouchier",
        "Guus F. Rimmelzwaan",
        "Geert Van Amerongen",
        "Debby A J Van Riel",
        "Ton De Jong",
        "Shigeyuki Itamura",
        "Kwokhung Chan",
        "Masato Tashiro",
        "Albert Dme M E Osterhaus"
    ],
    "related_topics": [
        "Pegylated interferon",
        "Viral replication",
        "Pathogenesis"
    ],
    "citation_count": "410",
    "reference_count": "27",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2127685726",
        "2100820722",
        "2125251240",
        "2116586125",
        "2169198329"
    ]
},{
    "id": "2161315652",
    "title": "Detection of SARS Coronavirus in Patients with Suspected SARS",
    "abstract": "Cases of severe acute respiratory syndrome (SARS) were investigated for SARS coronavirus (SARS-CoV) through RNA tests, serologic response, and viral culture. Of 537 specimens from patients in whom SARS was clinically diagnosed, 332 (60%) had SARS-CoV RNA in one or more clinical specimens, compared with 1 (0.3%) of 332 samples from controls. Of 417 patients with clinical SARS from whom paired serum samples were available, 92% had an antibody response. Rates of viral RNA positivity increased progressively and peaked at day 11 after onset of illness. Although viral RNA remained detectable in respiratory secretions and stool and urine specimens for >30 days in some patients, virus could not be cultured after week 3 of illness. Nasopharyngeal aspirates, throat swabs, or sputum samples were the most useful clinical specimens in the first 5 days of illness, but later in the illness viral RNA could be detected more readily in stool specimens.",
    "date": "2004",
    "authors": [
        "Kwok H. Chan",
        "Leo L.L.M. Poon",
        "V.C.C. Cheng",
        "Yi Guan",
        "I.F.N. Hung",
        "James Kong",
        "Loretta Y.C. Yam",
        "Wing H. Seto",
        "Kwok Y. Yuen",
        "Joseph S. Malik Peiris"
    ],
    "related_topics": [
        "Viral culture",
        "Sputum",
        "Virus"
    ],
    "citation_count": "299",
    "reference_count": "16",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2125251240",
        "2147166346",
        "1990049863",
        "1976741900",
        "2155583106"
    ]
},{
    "id": "2169198329",
    "title": "The Genome Sequence of the SARS-associated Coronavirus",
    "abstract": "We sequenced the 29,751-base genome of the severe acute respiratory syndrome (SARS)-associated coronavirus known as the Tor2 isolate. The genome sequence reveals that this coronavirus is only moderately related to other known coronaviruses, including two human coronaviruses, HCoV-OC43 and HCoV-229E. Phylogenetic analysis of the predicted viral proteins indicates that the virus does not closely resemble any of the three previously known groups of coronaviruses. The genome sequence will aid in the diagnosis of SARS virus infection in humans and potential animal hosts (using polymerase chain reaction and immunological tests), in the development of antivirals (including neutralizing antibodies), and in the identification of putative epitopes for vaccine development.",
    "date": "2003",
    "authors": [
        "Marco A. Marra",
        "Steven J. M. Jones",
        "Caroline R. Astell",
        "Robert A. Holt",
        "Angela Brooks-Wilson",
        "Yaron S. N. Butterfield",
        "Jaswinder Khattra",
        "Jennifer K. Asano",
        "Sarah A. Barber",
        "Susanna Y. Chan",
        "Alison Cloutier",
        "Shaun M. Coughlin",
        "Doug Freeman",
        "Noreen Girn",
        "Obi L. Griffith",
        "Stephen R. Leach",
        "Michael Mayo",
        "Helen McDonald",
        "Stephen B. Montgomery",
        "Pawan K. Pandoh",
        "Anca S. Petrescu",
        "A. Gordon Robertson",
        "Jacqueline E. Schein",
        "Asim Siddiqui",
        "Duane E. Smailus",
        "Jeff M. Stott",
        "George S. Yang",
        "Francis Plummer",
        "Anton Andonov",
        "Harvey Artsob",
        "Nathalie Bastien",
        "Kathy Bernard",
        "Timothy F. Booth",
        "Donnie Bowness",
        "Martin Czub",
        "Michael Drebot",
        "Lisa Fernando",
        "Ramon Flick",
        "Michael Garbutt",
        "Michael Gray",
        "Allen Grolla",
        "Steven Jones",
        "Heinz Feldmann",
        "Adrienne Meyers",
        "Amin Kabani",
        "Yan Li",
        "Susan Normand",
        "Ute Stroher",
        "Graham A. Tipples",
        "Shaun Tyler"
    ],
    "related_topics": [
        "Coronavirus",
        "Severe acute respiratory syndrome",
        "Alphacoronavirus"
    ],
    "citation_count": "2,707",
    "reference_count": "22",
    "references": [
        "2158714788",
        "2106882534",
        "2141885858",
        "2015292449",
        "2116586125",
        "2171091522",
        "2022366078",
        "2166699767",
        "2114083522",
        "205578041"
    ]
},{
    "id": "2134061616",
    "title": "Isolation and characterization of viruses related to the SARS coronavirus from animals in southern China.",
    "abstract": "A novel coronavirus (SCoV) is the etiological agent of severe acute respiratory syndrome (SARS). SCoV-like viruses were isolated from Himalayan palm civets found in a live-animal market in Guangdong, China. Evidence of virus infection was also detected in other animals (including a raccoon dog, Nyctereutes procyonoides) and in humans working at the same market. All the animal isolates retain a 29-nucleotide sequence that is not found in most human isolates. The detection of SCoV-like viruses in small, live wild mammals in a retail market indicates a route of interspecies transmission, although the natural reservoir is not known.",
    "date": "2003",
    "authors": [
        "Y. Guan",
        "B. J. Zheng",
        "Y. Q. He",
        "X. L. Liu",
        "Z. X. Zhuang",
        "C. L. Cheung",
        "S. W. Luo",
        "P. H. Li",
        "L. J. Zhang",
        "Y. J. Guan",
        "K. M. Butt",
        "K. L. Wong",
        "K. W. Chan",
        "W. Lim",
        "K. F. Shortridge",
        "K. Y. Yuen",
        "J. S. M. Peiris",
        "L. L. M. Poon"
    ],
    "related_topics": [
        "Coronavirus",
        "Severe acute respiratory syndrome",
        "Nyctereutes procyonoides"
    ],
    "citation_count": "2,305",
    "reference_count": "6",
    "references": [
        "2104548316",
        "2025170735",
        "2156434383",
        "2169198329",
        "2065461553",
        "1976741900"
    ]
},{
    "id": "2166229810",
    "title": "Rapid and simple method for purification of nucleic acids.",
    "abstract": "We have developed a simple, rapid, and reliable protocol for the small-scale purification of DNA and RNA from, e.g., human serum and urine. The method is based on the lysing and nuclease-inactivating properties of the chaotropic agent guanidinium thiocyanate together with the nucleic acid-binding properties of silica particles or diatoms in the presence of this agent. By using size-fractionated silica particles, nucleic acids (covalently closed circular, relaxed circular, and linear double-stranded DNA; single-stranded DNA; and rRNA) could be purified from 12 different specimens in less than 1 h and were recovered in the initial reaction vessel. Purified DNA (although significantly sheared) was a good substrate for restriction endonucleases and DNA ligase and was recovered with high yields (usually over 50%) from the picogram to the microgram level. Copurified rRNA was recovered almost undegraded. Substituting size-fractionated silica particles for diatoms (the fossilized cell walls of unicellular algae) allowed for the purification of microgram amounts of genomic DNA, plasmid DNA, and rRNA from cell-rich sources, as exemplified for pathogenic gram-negative bacteria. In this paper, we show representative experiments illustrating some characteristics of the procedure which may have wide application in clinical microbiology.",
    "date": "1990",
    "authors": [
        "R. Boom",
        "C. J. A. Sol",
        "M. M. M. Salimans",
        "C. L. Jansen",
        "P. M. E. Wertheim-Van Dillen",
        "J. Van Der Noordaa"
    ],
    "related_topics": [
        "Spin column-based nucleic acid purification",
        "Nucleic acid",
        "DNA ligase"
    ],
    "citation_count": "8,014",
    "reference_count": "25",
    "references": [
        "2134812217",
        "2032118018",
        "2050717506",
        "2060333964",
        "2047480444",
        "2029987769",
        "2049635421",
        "1979197786",
        "2156326901",
        "2009263927"
    ]
},{
    "id": "2163400707",
    "title": "Full-Length Human Immunodeficiency Virus Type 1 Genomes from Subtype C-Infected Seroconverters in India, with Evidence of Intersubtype Recombination",
    "abstract": "According to World Health Organization estimates, India will have the greatest number of human immunodeficiency virus (HIV)-infected individuals of any country by the end of this decade (1, 6). High rates of sexually transmitted diseases, rapidly increasing seroprevalence in female commercial sex workers, and inadequate facilities for HIV testing, counseling, and prevention are the major contributing factors in the recent explosive increases in the numbers of HIV infections (5, 6, 24, 29). While antiretroviral drugs have reduced mortality from AIDS in developed nations, their effect will be negligible elsewhere due to their cost. For most communicable diseases, vaccines offer the most cost-effective control strategy. It is likely that development of a vaccine for HIV will require knowledge of the viral variants being transmitted in the target population. Despite India\u2019s impending predominance in the worldwide pandemic, little is known of the genetic diversity of HIV-1 in India. The HIV-1 sequence database is growing exponentially, but the distribution of submitted sequences is not representative of the worldwide picture. Subtype C has been reported in nearly every region affected by HIV-1 (11, 23, 28) and predominates in India, and it also causes 74% of infections in southern Africa and 96% of infections in northern Africa (11, 18, 32). Given the combined population of India and the other regions affected, subtype C is likely to be the most commonly transmitted HIV-1 subtype worldwide. In contrast, 7% of the available HIV-1 sequence data is from subtype C-infected individuals (37), and of the 46 completely sequenced HIV-1 genomes (excluding multiple derivatives of HIV-1LAI), only two are of subtype C, one from a 1992 Brazilian sample and the other from a 1986 Ethiopian sample (37). In November 1997, an analysis of cross-clade epitope variation (9) excluded the C clade from evaluation of p24gag epitopes because of a lack of sequence data, whereas there was sufficient data to analyze subtypes A, B, D, F, G, and H (no HIV-1 harboring a subtype E gag gene has been found). Further sequence data from subtype C is needed, but the past approach of generating data from small subgenomic amplicons is no longer sufficient. Recent developments have made full-genome characterization of HIV-1 isolates both important and feasible. First, the recognition of intersubtype recombination in a significant proportion of HIV-1 sequences (44, 45) has led to detection of mosaic genomes in many regions of the world affected by multiple subtypes (14, 17, 31). Subtypes A, B, and C in India have been reported (4, 22, 30, 31, 59), but mosaic HIV-1 there has not been reported. The existence of such recombinants makes characterization of variants by analyzing subgenomic segments incomplete. Second, immune responses to vaccines based on single genes such as env have been limited (13), and attention is being shifted toward multivalent vaccines that incorporate other gene products. Third, interactions among discontinuous regions of the genome, such as between the long terminal repeat (LTR) and pol (26), can be detected only when such regions can be analyzed from the same template. In an effort to characterize subtype C virus genomes being transmitted currently in India, viral isolates were obtained from individuals with seroincident infections in India. Three of the isolates (collected in 1994 and 1995) were known to be non-syncytium inducing (NSI) and therefore resembled viruses transmitted through unprotected sexual contact, which account for 75 to 85% of new infections (2, 15, 61). These isolates were cloned, and nearly full-length genomic sequences were determined. Detailed sequence analysis was performed, as was an analysis of variation in characterized cytotoxic T lymphocyte (CTL) epitopes.",
    "date": "1998",
    "authors": [
        "Kavita S. Lole",
        "Robert C. Bollinger",
        "Ramesh S. Paranjape",
        "Deepak Gadkari",
        "Smita S. Kulkarni",
        "Nicole G. Novak",
        "Roxann Ingersoll",
        "Haynes W. Sheppard",
        "Stuart C. Ray"
    ],
    "related_topics": [
        "Population",
        "Sequence analysis",
        "Enterovirus C"
    ],
    "citation_count": "2,447",
    "reference_count": "51",
    "references": [
        "2106882534",
        "2030966943",
        "2150297520",
        "1997844736",
        "2037793240",
        "2025948021",
        "2048999843",
        "2059513540",
        "2091181646",
        "2056487140"
    ]
},{
    "id": "2159857626",
    "title": "Unique and conserved features of genome and proteome of SARS-coronavirus, an early split-off from the coronavirus group 2 lineage.",
    "abstract": "The genome organization and expression strategy of the newly identified severe acute respiratory syndrome coronavirus (SARS-CoV) were predicted using recently published genome sequences. Fourteen putative open reading frames were identified, 12 of which were predicted to be expressed from a nested set of eight subgenomic mRNAs. The synthesis of these mRNAs in SARS-CoV-infected cells was confirmed experimentally. The 4382- and 7073 amino acid residue SARS-CoV replicase polyproteins are predicted to be cleaved into 16 subunits by two viral proteinases (bringing the total number of SARS-CoV proteins to 28). A phylogenetic analysis of the replicase gene, using a distantly related torovirus as an outgroup, demonstrated that, despite a number of unique features, SARS-CoV is most closely related to group 2 coronaviruses. Distant homologs of cellular RNA processing enzymes were identified in group 2 coronaviruses, with four of them being conserved in SARS-CoV. These newly recognized viral enzymes place the mechanism of coronavirus RNA synthesis in a completely new perspective. Furthermore, together with previously described viral enzymes, they will be important targets for the design of antiviral strategies aimed at controlling the further spread of SARS-CoV.",
    "date": "2003",
    "authors": [
        "Eric J. Snijder",
        "Peter J. Bredenbeek",
        "Jessika C. Dobbe",
        "Volker Thiel",
        "John Ziebuhr",
        "Leo L.M. Poon",
        "Yi Guan",
        "Mikhail Rozanov",
        "Willy J.M. Spaan",
        "Alexander E. Gorbalenya"
    ],
    "related_topics": [
        "Coronavirus",
        "Alphacoronavirus",
        "Gene"
    ],
    "citation_count": "1,237",
    "reference_count": "74",
    "references": [
        "2158714788",
        "2097382368",
        "2132260239",
        "2097706568",
        "2104548316",
        "2025170735",
        "2150297520",
        "2116586125",
        "2169198329",
        "2045391589"
    ]
},{
    "id": "2029293367",
    "title": "Virology: SARS virus infection of cats and ferrets.",
    "abstract": "There is now a choice of animal models for testing therapies against the human virus. The reservoir of the coronavirus isolated from patients with severe acute respiratory syndrome (SARS)1,2 is still unknown, but is suspected to have been a wild animal species. Here we show that ferrets (Mustela furo) and domestic cats (Felis domesticus) are susceptible to infection by SARS coronavirus (SCV) and that they can efficiently transmit the virus to previously uninfected animals that are housed with them. The observation that these two distantly related carnivores can so easily be infected with the virus indicates that the reservoir for this pathogen may involve a range of animal species.",
    "date": "2003",
    "authors": [
        "Byron E. E. Martina",
        "Bart L. Haagmans",
        "Thijs Kuiken",
        "Ron A. M. Fouchier",
        "Guus F. Rimmelzwaan",
        "Geert van Amerongen",
        "J. S. Malik Peiris",
        "Wilina Lim",
        "Albert D. M. E. Osterhaus"
    ],
    "related_topics": [
        "Coronavirus",
        "Veterinary virology",
        "Human Virus"
    ],
    "citation_count": "557",
    "reference_count": "5",
    "references": [
        "2104548316",
        "2025170735",
        "2134061616",
        "2168446943",
        "1976741900"
    ]
},{
    "id": "2141885858",
    "title": "The Pfam protein families database",
    "abstract": "Pfam is a large collection of protein multiple sequence alignments and profile hidden Markov models. Pfam is available on the World Wide Web in the UK at http://www.sanger.ac.uk/Software/Pfam/, in Sweden at http://www.cgb.ki.se/Pfam/, in France at http://pfam.jouy.inra.fr/ and in the US at http://pfam.wustl.edu/. The latest version (6.6) of Pfam contains 3071 families, which match 69% of proteins in SWISS-PROT 39 and TrEMBL 14. Structural data, where available, have been utilised to ensure that Pfam families correspond with structural domains, and to improve domain-based annotation. Predictions of non-domain regions are now also included. In addition to secondary structure, Pfam multiple sequence alignments now contain active site residue mark-up. New search tools, including taxonomy search and domain query, greatly add to the functionality and usability of the Pfam resource.",
    "date": "1999",
    "authors": [
        "Marco Punta",
        "Penny C. Coggill",
        "Ruth Y. Eberhardt",
        "Jaina Mistry",
        "John G. Tate",
        "Chris Boursnell",
        "Ningze Pang",
        "Kristoffer Forslund",
        "Goran Ceric",
        "Jody Clements",
        "Andreas Heger",
        "Liisa Holm",
        "Erik L. L. Sonnhammer",
        "Sean R. Eddy",
        "Alex Bateman",
        "Robert D. Finn"
    ],
    "related_topics": [
        "Protein Families Database",
        "Domain of unknown function",
        "Rfam"
    ],
    "citation_count": "13,194",
    "reference_count": "28",
    "references": [
        "2158714788",
        "2130479394",
        "2168909179",
        "2096525273",
        "2028231353",
        "2141652419",
        "2152770371",
        "2003144438",
        "2085277871",
        "2026258231"
    ]
},{
    "id": "2171091522",
    "title": "Identification of prokaryotic and eukaryotic signal peptides and prediction of their cleavage sites.",
    "abstract": "We have developed a new method for the identification of signal peptides and their cleavage sites based on neural networks trained on separate sets of prokaryotic and eukaryotic sequence. The method performs significantly better than previous prediction schemes and can easily be applied on genome-wide data sets. Discrimination between cleaved signal peptides and uncleaved N-terminal signal-anchor sequences is also possible, though with lower precision. Predictions can be made on a publicly available WWW server.",
    "date": "1996",
    "authors": [
        "H Nielsen",
        "J Engelbrecht",
        "S Brunak",
        "G von Heijne"
    ],
    "related_topics": [
        "Signal peptide",
        "PSORT",
        "Peptide sequence"
    ],
    "citation_count": "6,563",
    "reference_count": "1",
    "references": [
        "2144885757"
    ]
},{
    "id": "2170881661",
    "title": "A newly discovered human pneumovirus isolated from young children with respiratory tract disease.",
    "abstract": "From 28 young children in the Netherlands, we isolated a paramyxovirus that was identified as a tentative new member of the Metapneumovirus genus based on virological data, sequence homology and gene constellation. Previously, avian pneumovirus was the sole member of this recently assigned genus, hence the provisional name for the newly discovered virus: human metapneumovirus. The clinical symptoms of the children from whom the virus was isolated were similar to those caused by human respiratory syncytial virus infection, ranging from upper respiratory tract disease to severe bronchiolitis and pneumonia. Serological studies showed that by the age of five years, virtually all children in the Netherlands have been exposed to human metapneumovirus and that the virus has been circulating in humans for at least 50 years.",
    "date": "2001",
    "authors": [
        "Bernadette G. van den Hoogen",
        "Jan C. de Jong",
        "Jan Groen",
        "Thijs Kuiken",
        "Ronald de Groot",
        "Ron A.M. Fouchier",
        "Albert D.M.E. Osterhaus"
    ],
    "related_topics": [
        "Human metapneumovirus",
        "Pneumovirus",
        "Metapneumovirus"
    ],
    "citation_count": "2,531",
    "reference_count": "23",
    "references": [
        "1963953102",
        "177909858",
        "2558766452",
        "1565923748",
        "2083410136",
        "2136540289",
        "2147230281",
        "2159449750",
        "2121967038",
        "2034008402"
    ]
},{
    "id": "2141877163",
    "title": "Epidemiology and cause of severe acute respiratory syndrome (SARS) in Guangdong, People's Republic of China, in February, 2003",
    "abstract": "Summary Background An epidemic of severe acute respiratory syndrome (SARS) has been associated with an outbreak of atypical pneumonia originating in Guangdong Province, People's Republic of China. We aimed to identify the causative agent in the Guangdong outbreak and describe the emergence and spread of the disease within the province. Methods We analysed epidemiological information and collected serum and nasopharyngeal aspirates from patients with SARS in Guangdong in mid-February, 2003. We did virus isolation, serological tests, and molecular assays to identify the causative agent. Findings SARS had been circulating in other cities of Guangdong Province for about 2 months before causing a major outbreak in Guangzhou, the province's capital. A novel coronavirus, SARS coronavirus (CoV), was isolated from specimens from three patients with SARS. Viral antigens were also directly detected in nasopharyngeal aspirates from these patients. 48 of 55 (87%) patients had antibodies to SARS CoV in their convalescent sera. Genetic analysis showed that the SARS CoV isolates from Guangzhou shared the same origin with those in other countries, and had a phylogenetic pathway that matched the spread of SARS to the other parts of the world. Interpretation SARS CoV is the infectious agent responsible for the epidemic outbreak of SARS in Guangdong. The virus isolated from patients in Guangdong is the prototype of the SARS CoV in other regions and countries.",
    "date": "2003",
    "authors": [
        "N. S. Zhong",
        "B. J. Zheng",
        "Y. M. Li",
        "L. L. M. Poon",
        "Z. H. Xie",
        "K. H. Chan",
        "P. H. H. Li",
        "S. Y. Tan",
        "Q. Chang",
        "J. P. Xie",
        "X. Q. Liu",
        "J. Xu",
        "D. X. Li",
        "K. Y. Yuen",
        "J. S. M. Peiris",
        "Y. Guan"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Coronavirus",
        "Outbreak"
    ],
    "citation_count": "1,138",
    "reference_count": "17",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2156434383",
        "2100820722",
        "2125251240",
        "2169198329",
        "2463755683",
        "2163960578",
        "2131155472"
    ]
},{
    "id": "1966238900",
    "title": "Angiotensin-converting enzyme 2 is a functional receptor for the SARS coronavirus.",
    "abstract": "Spike (S) proteins of coronaviruses, including the coronavirus that causes severe acute respiratory syndrome (SARS), associate with cellular receptors to mediate infection of their target cells. Here we identify a metallopeptidase, angiotensin-converting enzyme 2 (ACE2), isolated from SARS coronavirus (SARS-CoV)-permissive Vero E6 cells, that efficiently binds the S1 domain of the SARS-CoV S protein. We found that a soluble form of ACE2, but not of the related enzyme ACE1, blocked association of the S1 domain with Vero E6 cells. 293T cells transfected with ACE2, but not those transfected with human immunodeficiency virus-1 receptors, formed multinucleated syncytia with cells expressing S protein. Furthermore, SARS-CoV replicated efficiently on ACE2-transfected but not mock-transfected 293T cells. Finally, anti-ACE2 but not anti-ACE1 antibody blocked viral replication on Vero E6 cells. Together our data indicate that ACE2 is a functional receptor for SARS-CoV.",
    "date": "2003",
    "authors": [
        "Wenhui Li",
        "Michael J. Moore",
        "Natalya Vasilieva",
        "Jianhua Sui",
        "Swee Kee Wong",
        "Michael A. Berne",
        "Mohan Somasundaran",
        "John L. Sullivan",
        "Katherine Luzuriaga",
        "Thomas C. Greenough",
        "Hyeryun Choe",
        "Michael Farzan"
    ],
    "related_topics": [
        "Coronavirus",
        "Vero cell",
        "Severe acute respiratory syndrome"
    ],
    "citation_count": "4,412",
    "reference_count": "32",
    "references": [
        "2132260239",
        "2104548316",
        "2116586125",
        "2169198329",
        "2168446943",
        "1757215199",
        "1976741900",
        "2025672718",
        "1965019797",
        "2000040025"
    ]
},{
    "id": "2164578725",
    "title": "Real time quantitative PCR.",
    "abstract": "We have developed a novel \"real time\" quantitative PCR method. The method measures PCR product accumulation through a dual-labeled fluorogenic probe (i.e., TaqMan Probe). This method provides very accurate and reproducible quantitation of gene copies. Unlike other quantitative PCR methods, real-time PCR does not require post-PCR sample handling, preventing potential PCR product carry-over contamination and resulting in much faster and higher throughput assays. The real-time PCR method has a very large dynamic range of starting target molecule determination (at least five orders of magnitude). Real-time quantitative PCR is extremely accurate and less labor-intensive than current quantitative PCR methods.",
    "date": "1996",
    "authors": [
        "C A Heid",
        "J Stevens",
        "K J Livak",
        "P M Williams"
    ],
    "related_topics": [
        "TaqMan",
        "Real-time polymerase chain reaction",
        "Orders of magnitude (mass)"
    ],
    "citation_count": "9,213",
    "reference_count": "33",
    "references": [
        "2063450941",
        "2141393790",
        "2145684092",
        "1994091239",
        "2070721758",
        "2077077811",
        "1569947224",
        "2150705960",
        "1988966853",
        "1618865275"
    ]
},{
    "id": "2109970232",
    "title": "The transcriptional program in the response of human fibroblasts to serum.",
    "abstract": "The temporal program of gene expression during a model physiological response of human cells, the response of fibroblasts to serum, was explored with a complementary DNA microarray representing about 8600 different human genes. Genes could be clustered into groups on the basis of their temporal patterns of expression in this program. Many features of the transcriptional program appeared to be related to the physiology of wound repair, suggesting that fibroblasts play a larger and richer role in this complex multicellular response than had previously been appreciated.",
    "date": "1998",
    "authors": [
        "Vishwanath R. Iyer",
        "Michael B. Eisen",
        "Douglas T. Ross",
        "Greg Schuler",
        "Troy Moore",
        "Jeffrey C. F. Lee",
        "Jeffrey M. Trent",
        "Louis M. Staudt",
        "James Hudson",
        "Mark S. Boguski",
        "Deval Lashkari",
        "Dari Shalon",
        "David Botstein",
        "Patrick O. Brown"
    ],
    "related_topics": [
        "DNA microarray",
        "Gene",
        "Gene expression"
    ],
    "citation_count": "2,559",
    "reference_count": "13",
    "references": [
        "2150926065",
        "1970156673",
        "238668910",
        "1994091239",
        "2068719237",
        "1964504843",
        "1986891966",
        "1968164578",
        "1971228457",
        "1607626977"
    ]
},{
    "id": "2128088040",
    "title": "An overview of real-time quantitative PCR: applications to quantify cytokine gene expression.",
    "abstract": "The analysis of cytokine profiles helps to clarify functional properties of immune cells, both for research and for clinical diagnosis. The real-time reverse transcription polymerase chain reaction (RT-PCR) is becoming widely used to quantify cytokines from cells, body fluids, tissues, or tissue biopsies. Being a very powerful and sensitive method it can be used to quantify mRNA expression levels of cytokines, which are often very low in the tissues under investigation. The method allows for the direct detection of PCR product during the exponential phase of the reaction, combining amplification and detection in one single step. In this review we discuss the principle of real-time RT-PCR, the different methodologies and chemistries available, the assets, and some of the pitfalls. With the TaqMan chemistry and the 7700 Sequence Detection System (Applied Biosystems), validation for a large panel of murine and human cytokines and other factors playing a role in the immune system is discussed in detail. In summary, the real-time RT-PCR technique is very accurate and sensitive, allows a high throughput, and can be performed on very small samples; therefore it is the method of choice for quantification of cytokine profiles in immune cells or inflamed tissues.",
    "date": "2001",
    "authors": [
        "Annapaula Giulietti",
        "Lutgart Overbergh",
        "Dirk Valckx",
        "Brigitte Decallonne",
        "Roger Bouillon",
        "Chantal Mathieu"
    ],
    "related_topics": [
        "TaqMan",
        "Reverse transcription polymerase chain reaction",
        "Real-time polymerase chain reaction"
    ],
    "citation_count": "1,794",
    "reference_count": "88",
    "references": [
        "2107277218",
        "2164578725",
        "2143146123",
        "2026710381",
        "2145684092",
        "2070721758",
        "1569947224",
        "2150705960",
        "2131987407",
        "1569955072"
    ]
},{
    "id": "2145879504",
    "title": "Effect of experimental treatment on housekeeping gene expression: validation by real-time, quantitative RT-PCR",
    "abstract": "The effects of serum on the expression of four commonly used housekeeping genes were examined in serum-stimulated fibroblasts in order to validate the internal control genes for a quantitative RT-PCR assay. NIH 3T3 fibroblasts transfected with an inducible chimeric gene were serum-starved for 24 h and then induced with 15% serum for 8 h. Serum did not alter the amount of total RNA that was expressed in the cells, however, the amount of mRNA significantly increased over time with serum-stimulation. Both messenger and total RNA from each of the time points were reverse transcribed under two different conditions; one in which the reactions were normalized to contain equal amounts of RNA and another series of reactions that were not normalized to RNA content. The resulting cDNA was amplified by real-time, quantitative PCR using gene-specific primers for beta-actin, beta-2 microglobulin, glyceraldehyde-3-phosphate dehydrogenase (GAPDH) and 18S ribosomal RNA. The expression of beta-actin and GAPDH increased up to nine- and three-fold, respectively, under all conditions of reverse transcription (P 0.05). The expression of beta-2 microglobulin increased up to two-fold when assayed from cDNA synthesized from non-normalized mRNA, but was unaffected by serum when the reverse transcriptions were normalized to mRNA. beta-2 Microglobulin expression was found to be directly proportional to the amount of mRNA that was present in non-normalized reverse transcription reactions. Thus, beta-2 microglobulin and 18S rRNA are suitable internal control genes in quantitative serum-stimulation studies, while beta-actin and GAPDH are not. The internal control gene needs to be properly validated when designing quantitative gene expression studies.",
    "date": "2000",
    "authors": [
        "Thomas D Schmittgen",
        "Brian A Zakrajsek"
    ],
    "related_topics": [
        "Housekeeping gene",
        "Gene expression",
        "Reference genes"
    ],
    "citation_count": "1,454",
    "reference_count": "7",
    "references": [
        "2109970232",
        "1983241347",
        "1783699960",
        "1970581527",
        "2168965618",
        "1761395234",
        "2117870664"
    ]
},{
    "id": "1983241347",
    "title": "Development and validation of real-time quantitative reverse transcriptase-polymerase chain reaction for monitoring gene expression in cardiac myocytes in vitro.",
    "abstract": "In this article we present validation of a real-time RT-PCR method to quantitate mRNA expression levels of atrial natriuretic peptide and c-fos in an in vitro model of cardiac hypertrophy. This method requires minimal sample and no postreaction manipulation. In real-time RT-PCR a dual-labeled fluorescent probe is degraded concomitant with PCR amplification. Input target mRNA levels are correlated with the time (measured in PCR cycles) at which the reporter fluorescent emission increases beyond a threshold level. The use of an oligo(dt) magnetic bead protocol to harvest poly(A) mRNA from cultured cells in 96-well plates minimized DNA contamination. We show that the GAPDH gene chosen for normalization of the RNA load is truly invariant throughout the biological treatments examined. We discuss two methods of calculating fold increase: a standard curve method and the DeltaDelta Ct method. Real-time quantitative RT-PCR was used to determine the time course of c-fos induction and the effect of varying doses of four known hypertrophy agents on atrial naturitic factor messenger RNA expression in cultured cardiac muscle cells. Our results agree with published data obtained from Northern blot analysis.",
    "date": "1999",
    "authors": [
        "J. Winer",
        "C. K. S. Jung",
        "I. Shackel",
        "P. M. Williams"
    ],
    "related_topics": [
        "Gene expression",
        "Northern blot",
        "Messenger RNA"
    ],
    "citation_count": "1,959",
    "reference_count": "14",
    "references": [
        "2164578725",
        "2145684092",
        "1594653092",
        "2046971992",
        "1972680803",
        "1492344672",
        "1483231863",
        "1599556324",
        "1989355270",
        "1562427827"
    ]
},{
    "id": "2123325948",
    "title": "Quantitative Reverse Transcription\u2013Polymerase Chain Reaction to Study mRNA Decay: Comparison of Endpoint and Real-Time Methods\u2606",
    "abstract": "Abstract Four quantitative reverse transcription\u2013PCR (RT-PCR) methods were compared to evaluate the time course of mRNA formation and decay. Mouse fibroblasts (NIH 3T3) transfected with the human \u03b2-globin open reading frame/c- myc 3\u2032-untranslated region chimeric gene under control of the c- fos promoter (fos-glo-myc) were used for serum-inducible transcription. The amount of fos-glo-myc mRNA, relative to \u03b2-actin, was measured by quantitative, RT-PCR at various times following the addition of serum to serum-starved fibroblasts transfected with the chimeric gene. Both endpoint (band densitometry and probe hybridization) and real-time (SYBR green and TaqMan) PCR methods were used to assay the identical cDNA. The real-time methods produced a 4- to 5-log dynamic range of amplification, while the dynamic range of the endpoint assays was 1-log. The real-time and probe hybridization assays produced a comparable level of sensitivity that was considerably greater than band densitometry. The coefficient of variation from 22 replicate PCR reactions was 14.2 and 24.0% for the SYBR green and TaqMan detection, respectively, and 44.9 and 45.1% for the band densitometry and probe hybridization assays, respectively. The rank order for the values of r 2 obtained from the linear regression of the first-order mRNA decay plots was SYBR green > TaqMan > probe hybridization > band densitometry. Real-time PCR is more precise and displays a greater dynamic range than endpoint PCR. Among the real-time methods, SYBR green and TaqMan assays produced comparable dynamic range and sensitivity while SYBR green detection was more precise and produced a more linear decay plot than TaqMan detection.",
    "date": "2000",
    "authors": [
        "Thomas D. Schmittgen",
        "Brian A. Zakrajsek",
        "Alan G. Mills",
        "Vladimir Gorn",
        "Michael J. Singer",
        "Michael W. Reed"
    ],
    "related_topics": [
        "TaqMan",
        "Reverse transcription polymerase chain reaction",
        "Hybridization probe"
    ],
    "citation_count": "1,179",
    "reference_count": "21",
    "references": [
        "2164578725",
        "2109970232",
        "1983241347",
        "1594653092",
        "2150705960",
        "2131589770",
        "1566892773",
        "2069943574",
        "2014588425",
        "2170081920"
    ]
},{
    "id": "2134343377",
    "title": "Quantitation of viral load using real-time amplification techniques.",
    "abstract": "Real-time PCR amplification techniques are currently used to determine the viral load in clinical samples for an increasing number of targets. Real-time PCR reduces the time necessary to generate results after amplification. In-house developed PCR and nucleic acid sequence-based amplification (NASBA)-based systems combined with several detection strategies are being employed in a clinical diagnostic setting. The importance of these assays in disease management is still in an exploration phase. Although these technologies have the implicit capability of accurately measuring DNA and RNA in clinical samples, issues related to standardization and quality control must be resolved to enable routine implementation of these technologies in molecular diagnostics.",
    "date": "2001",
    "authors": [
        "Hubert G.M. Niesters"
    ],
    "related_topics": [
        "NASBA",
        "Molecular diagnostics",
        "Molecular beacon"
    ],
    "citation_count": "271",
    "reference_count": "74",
    "references": [
        "2026710381",
        "1994091239",
        "1594653092",
        "1569947224",
        "1959254653",
        "2170081920",
        "2169706295",
        "2018466980",
        "2146812842",
        "2140521217"
    ]
},{
    "id": "1756433044",
    "title": "Selective degradation of early-response-gene mRNAs: functional analyses of sequence features of the AU-rich elements.",
    "abstract": "The metabolic lifetime of mRNA can be specified by specific cis-acting elements within mRNA. One type of element is an adenylate- and uridylate-rich element (ARE) found in the 3' untranslated region of many highly unstable mRNAs for mammalian early-response genes (ERGs). Among the better-characterized members of the ERG family are certain genes encoding nuclear transcription factors. Of particular significance was the finding that their mRNAs decay rapidly with kinetics similar to those of c-fos mRNA. Our previous studies of the c-fos ARE-directed mRNA decay have revealed the existence in this ARE of two structurally distinct and functionally interdependent domains, termed domain I and domain II. We proposed that the c-fos ARE-directed decay is a two-step mechanism in which rapid shortening of the poly(A) tail leads to the decay of the mRNA body and further hypothesized that this is a general mechanism by which the ERG AREs mediate rapid mRNA degradation. To test this hypothesis and to further address the generality of the critical structural characteristics within the c-fos ARE, the RNA-destabilizing functions of more than 10 different AU-rich sequences from various nuclear transcription factor mRNAs have been tested. Consistent with the above-mentioned hypothesis is the observation that mRNAs carrying the functional AREs display a biphasic decay, which is characteristic of the proposed two-step mechanism. Our results indicated that the presence of AUUUA pentanucleotides in an AU-rich region does not always guarantee an RNA-destabilizing function for this region. Our results also led to the identification of a novel class of AU-rich destabilizing elements which contains no AUUUA pentanucleotide. The results of sequence comparison and functional tests revealed that a continuous U-rich sequence is a unique feature among the functional AREs. Finally, our experiments further showed that the c-fos ARE domain II has an RNA decay-enhancing ability upon its fusion to heterologous AU-rich regions and defined for the first time an RNA decay-enhancing element, which we termed the RDE element.",
    "date": "1994",
    "authors": [
        "Chyi-Ying A Chen",
        "Ann-Bin Shyu"
    ],
    "related_topics": [
        "AU-rich element",
        "P-bodies",
        "Untranslated region"
    ],
    "citation_count": "358",
    "reference_count": "39",
    "references": [
        "2080532845",
        "2021253208",
        "1976415203",
        "2051819610",
        "2107359522",
        "2057094603",
        "1971421846",
        "1993210315",
        "1760280961",
        "2082658854"
    ]
},{
    "id": "1566892773",
    "title": "Quantitation of Thymidylate Synthase, Dihydrofolate Reductase, and DT-Diaphorase Gene Expression in Human Tumors Using the Polymerase Chain Reaction",
    "abstract": "A polymerase chain reaction (PCR)-based method was used to quantitate the expression levels of low abundance genes relevant to cancer drug activity. RNA from tumor samples as small as 20 mg was isolated and converted to cDNA using random hexamers. The 5' primers for the PCR contained a T7 polymerase promoter sequence, allowing the PCR-amplified DNA to be transcribed to RNA fragments. In each sample, the linear ranges of amplification of each cDNA of interest were established. Relative gene expressions were calculated by extrapolating the amounts of PCR products generated within the linear amplification regions of each gene to equal volumes of the cDNA solution. The method was accurate to less than a 2-fold difference in expression levels. Using beta 2-microglobulin and beta-actin gene expressions as internal reference standards and cDNA from HT-29 cells as an external linearity standard, we measured the relative expressions of thymidylate synthase, dihydrofolate reductase, and DT-diaphorase in a number of clinical tumor samples. The expressions of these genes varied from 50- to 100-fold among different tumors, although most of the values were grouped within about a 10-fold range. The amount of thymidylate synthase gene expression in tumor tissues was directly proportional to the content of thymidylate synthase protein. Those tumors with the lowest thymidylate synthase expression had the best response to both the 5-fluorouracil-leucovorin and 5-fluorouracil-cisplatin combinations.",
    "date": "1991",
    "authors": [
        "T Horikoshi",
        "K D Danenberg",
        "T H Stadlbauer",
        "M Volkenandt",
        "L C Shea",
        "K Aigner",
        "B Gustavsson",
        "L Leichman",
        "R Fr\u00f6sing",
        "M Ray"
    ],
    "related_topics": [
        "Rapid amplification of cDNA ends",
        "Real-time polymerase chain reaction",
        "Inverse polymerase chain reaction"
    ],
    "citation_count": "384",
    "reference_count": "0",
    "references": []
},{
    "id": "2138324310",
    "title": "Middle East respiratory syndrome.",
    "abstract": "Middle East respiratory syndrome (MERS) is a highly lethal respiratory disease caused by a novel single-stranded, positive-sense RNA betacoronavirus (MERS-CoV). Dromedary camels, hosts for MERS-CoV, are implicated in direct or indirect transmission to human beings, although the exact mode of transmission is unknown. The virus was first isolated from a patient who died from a severe respiratory illness in June, 2012, in Jeddah, Saudi Arabia. As of May 31, 2015, 1180 laboratory-confirmed cases (483 deaths; 40% mortality) have been reported to WHO. Both community-acquired and hospital-acquired cases have been reported with little human-to-human transmission reported in the community. Although most cases of MERS have occurred in Saudi Arabia and the United Arab Emirates, cases have been reported in Europe, the USA, and Asia in people who travelled from the Middle East or their contacts. Clinical features of MERS range from asymptomatic or mild disease to acute respiratory distress syndrome and multiorgan failure resulting in death, especially in individuals with underlying comorbidities. No specific drug treatment exists for MERS and infection prevention and control measures are crucial to prevent spread in health-care facilities. MERS-CoV continues to be an endemic, low-level public health threat. However, the virus could mutate to have increased interhuman transmissibility, increasing its pandemic potential.",
    "date": "2015",
    "authors": [
        "Alimuddin Zumla",
        "David S Hui",
        "Stanley Perlman"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Betacoronavirus"
    ],
    "citation_count": "972",
    "reference_count": "176",
    "references": [
        "2166867592",
        "2107053896",
        "2131262274",
        "2006434809",
        "1993577573",
        "2125251240",
        "2565805236",
        "2119111857",
        "2147166346",
        "2112147913"
    ]
},{
    "id": "2119111857",
    "title": "Dipeptidyl peptidase 4 is a functional receptor for the emerging human coronavirus-EMC",
    "abstract": "Most human coronaviruses cause mild upper respiratory tract disease but may be associated with more severe pulmonary disease in immunocompromised individuals. However, SARS coronavirus caused severe lower respiratory disease with nearly 10% mortality and evidence of systemic spread. Recently, another coronavirus (human coronavirus-Erasmus Medical Center (hCoV-EMC)) was identified in patients with severe and sometimes lethal lower respiratory tract infection. Viral genome analysis revealed close relatedness to coronaviruses found in bats. Here we identify dipeptidyl peptidase 4 (DPP4; also known as CD26) as a functional receptor for hCoV-EMC. DPP4 specifically co-purified with the receptor-binding S1 domain of the hCoV-EMC spike protein from lysates of susceptible Huh-7 cells. Antibodies directed against DPP4 inhibited hCoV-EMC infection of primary human bronchial epithelial cells and Huh-7 cells. Expression of human and bat (Pipistrellus pipistrellus) DPP4 in non-susceptible COS-7 cells enabled infection by hCoV-EMC. The use of the evolutionarily conserved DPP4 protein from different species as a functional receptor provides clues about the host range potential of hCoV-EMC. In addition, it will contribute critically to our understanding of the pathogenesis and epidemiology of this emerging human coronavirus, and may facilitate the development of intervention strategies.",
    "date": "2013",
    "authors": [
        "V. Stalin Raj",
        "Huihui Mou",
        "Saskia L. Smits",
        "Dick H. W. Dekkers",
        "Marcel A. M\u00fcller",
        "Ronald Dijkman",
        "Doreen Muth",
        "Jeroen A. A. Demmers",
        "Ali Zaki",
        "Ron A. M. Fouchier",
        "Volker Thiel",
        "Christian Drosten",
        "Peter J. M. Rottier",
        "Albert D. M. E. Osterhaus",
        "Berend Jan Bosch",
        "Bart L. Haagmans"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "1,574",
    "reference_count": "25",
    "references": [
        "2166867592",
        "1966238900",
        "2103503670",
        "2113457186",
        "2091671824",
        "1690366459",
        "1982533785",
        "2126707939",
        "1964982019",
        "2101063972"
    ]
},{
    "id": "2141008678",
    "title": "RDP3: a flexible and fast computer program for analyzing recombination",
    "abstract": "rpd3 is a computer program for statistical identification and characterization of historical recombination events. Given a set of aligned nucleotide sequences, rpd3 will rapidly analyze these with a range of powerful non-parametric recombination detection methods (including bootscan, maxchi, chimaera, 3seq, geneconv, siscan, phylpro and visrd; Boni et al., 2007; Gibbs et al., 2000; Lemey et al., 2009; Padidam et al., 1999, Posada and Crandall, 2001; Weiller, 1998). It will provide a detailed breakdown of recombination breakpoint locations, and the identities of recombinant and parental sequences. For further downstream analyses, the program enables users to save edited sequence alignments with (i) recombinant sequences removed; (ii) recombinationally derived tracts of sequence removed; or (iii) recombinant sequences split into their constituent parts. An important strength of rdp3 that makes it applicable to a variety of recombination analysis problems is that, unlike many other recombination detection programs such as simplot (Lole et al., 1999), dual brothers (Minin et al., 2005), jphmm (Schultz et al., 2006) or scueal (Kosakovsky et al., 2009), it does not screen predefined sets of potentially recombinant (or query) sequences against other predefined sets of non-recombinant (or reference) sequences. rdp3 instead treats every sequence within an input alignment as a potential recombinant and systematically screens large numbers of sequence triplets and/or quartets to identify sets of three or four sequences that contain a recombinant and two sequences resembling its parents. Such an approach means that rdp3 can simultaneously detect the entire scope of recombination evident within a dataset (i.e. not just that occurring between the reference strains or species) enabling its use in the characterization of complex recombinants such as those derived through recombination between parental sequences that were themselves recombinant. The drawback of such a flexible, exploratory framework is that it can often be difficult to assess the uncertainty associated with inferred recombination patterns. However, with its wide range of cross-checking tools, rpd3 is complementary to probabilistic recombination analysis approaches.",
    "date": "2010",
    "authors": [
        "Darren P. Martin",
        "Philippe Lemey",
        "Martin Lott",
        "Vincent Moulton",
        "David Posada",
        "Pierre Lefeuvre"
    ],
    "related_topics": [
        "Recombination",
        "Sequence",
        "Recombinant DNA"
    ],
    "citation_count": "1,757",
    "reference_count": "27",
    "references": [
        "2146058063",
        "2103546861",
        "2095724872",
        "2111534865",
        "2163400707",
        "2143334889",
        "1973667633",
        "2080655727",
        "2095886196",
        "2153149273"
    ]
},{
    "id": "2049975503",
    "title": "Middle East Respiratory Syndrome Coronavirus in Bats, Saudi Arabia",
    "abstract": "The source of human infection with Middle East respiratory syndrome coronavirus remains unknown. Molecular investigation indicated that bats in Saudi Arabia are infected with several alphacoronaviruses and betacoronaviruses. Virus from 1 bat showed 100% nucleotide identity to virus from the human index case-patient. Bats might play a role in human infection.",
    "date": "2013",
    "authors": [
        "Ziad A. Memish",
        "Nischay Mishra",
        "Kevin J. Olival",
        "Shamsudeen F. Fagbo",
        "Vishal Kapoor",
        "Jonathan H. Epstein",
        "Rafat AlHakeem",
        "Abdulkareem Durosinloun",
        "Mushabab Al Asmari",
        "Ariful Islam",
        "Amit Kapoor",
        "Thomas Briese",
        "Peter Daszak",
        "Abdullah A. Al Rabeeah",
        "W. Ian Lipkin"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Coronavirus"
    ],
    "citation_count": "660",
    "reference_count": "16",
    "references": [
        "2166867592",
        "2107053896",
        "1703839189",
        "2103503670",
        "1852588318",
        "2140338292",
        "2066347985",
        "2131369206",
        "2122576818",
        "1997655974"
    ]
},{
    "id": "2101063972",
    "title": "Genomic Characterization of Severe Acute Respiratory Syndrome-Related Coronavirus in European Bats and Classification of Coronaviruses Based on Partial RNA-Dependent RNA Polymerase Gene Sequences",
    "abstract": "Bats may host emerging viruses, including coronaviruses (CoV). We conducted an evaluation of CoV in rhinolophid and vespertilionid bat species common in Europe. Rhinolophids carried severe acute respiratory syndrome (SARS)-related CoV at high frequencies and concentrations (26% of animals are positive; up to 2.4\u00d710(8) copies per gram of feces), as well as two Alphacoronavirus clades, one novel and one related to the HKU2 clade. All three clades present in Miniopterus bats in China (HKU7, HKU8, and 1A related) were also present in European Miniopterus bats. An additional novel Alphacoronavirus clade (bat CoV [BtCoV]/BNM98-30) was detected in Nyctalus leisleri. A CoV grouping criterion was developed by comparing amino acid identities across an 816-bp fragment of the RNA-dependent RNA polymerases (RdRp) of all accepted mammalian CoV species (RdRp-based grouping units [RGU]). Criteria for defining separate RGU in mammalian CoV were a >4.8% amino acid distance for alphacoronaviruses and a >6.3% distance for betacoronaviruses. All the above-mentioned novel clades represented independent RGU. Strict associations between CoV RGU and host bat genera were confirmed for six independent RGU represented simultaneously in China and Europe. A SARS-related virus (BtCoV/BM48-31/Bulgaria/2008) from a Rhinolophus blasii (Rhi bla) bat was fully sequenced. It is predicted that proteins 3b and 6 were highly divergent from those proteins in all known SARS-related CoV. Open reading frame 8 (ORF8) was surprisingly absent. Surface expression of spike and staining with sera of SARS survivors suggested low antigenic overlap with SARS CoV. However, the receptor binding domain of SARS CoV showed higher similarity with that of BtCoV/BM48-31/Bulgaria/2008 than with that of any Chinese bat-borne CoV. Critical spike domains 472 and 487 were identical and similar, respectively. This study underlines the importance of assessments of the zoonotic potential of widely distributed bat-borne CoV.",
    "date": "2010",
    "authors": [
        "Jan Felix Drexler",
        "Florian Gloza-Rausch",
        "J\u00f6rg Glende",
        "Victor Max Corman",
        "Doreen Muth",
        "Matthias Goettsche",
        "Antje Seebens",
        "Matthias Niedrig",
        "Susanne Pfefferle",
        "Stoian Yordanov",
        "Lyubomir Zhelyazkov",
        "Uwe Hermanns",
        "Peter Vallo",
        "Alexander Lukashev",
        "Marcel Alexander M\u00fcller",
        "Hongkui Deng",
        "Georg Herrler",
        "Christian Drosten"
    ],
    "related_topics": [
        "Alphacoronavirus",
        "Miniopterus",
        "Coronavirus"
    ],
    "citation_count": "225",
    "reference_count": "62",
    "references": [
        "2125121305",
        "2146058063",
        "2132260239",
        "2110835349",
        "2103503670",
        "2134061616",
        "2140338292",
        "1982533785",
        "2170933940",
        "2167080692"
    ]
},{
    "id": "1990059132",
    "title": "Cross-host evolution of severe acute respiratory syndrome coronavirus in palm civet and human",
    "abstract": "The genomic sequences of severe acute respiratory syndrome coronaviruses from human and palm civet of the 2003/2004 outbreak in the city of Guangzhou, China, were nearly identical. Phylogenetic analysis suggested an independent viral invasion from animal to human in this new episode. Combining all existing data but excluding singletons, we identified 202 single-nucleotide variations. Among them, 17 are polymorphic in palm civets only. The ratio of nonsynonymous/synonymous nucleotide substitution in palm civets collected 1 yr apart from different geographic locations is very high, suggesting a rapid evolving process of viral proteins in civet as well, much like their adaptation in the human host in the early 2002\u20132003 epidemic. Major genetic variations in some critical genes, particularly the Spike gene, seemed essential for the transition from animal-to-human transmission to human-to-human transmission, which eventually caused the first severe acute respiratory syndrome outbreak of 2002/2003.",
    "date": "2005",
    "authors": [
        "Huai-Dong Song",
        "Chang-Chun Tu",
        "Guo-Wei Zhang",
        "Sheng-Yue Wang",
        "Kui Zheng",
        "Lian-Cheng Lei",
        "Qiu-Xia Chen",
        "Yu-Wei Gao",
        "Hui-Qiong Zhou",
        "Hua Xiang",
        "Hua-Jun Zheng",
        "Shur-Wern Wang Chern",
        "Feng Cheng",
        "Chun-Ming Pan",
        "Hua Xuan",
        "Sai-Juan Chen",
        "Hui-Ming Luo",
        "Duan-Hua Zhou",
        "Yu-Fei Liu",
        "Jian-Feng He",
        "Peng-Zhe Qin",
        "Ling-Hui Li",
        "Yu-Qi Ren",
        "Wen-Jia Liang",
        "Ye-Dong Yu",
        "Larry Anderson",
        "Ming Wang",
        "Rui-Heng Xu",
        "Xin-Wei Wu",
        "Huan-Ying Zheng",
        "Jin-Ding Chen",
        "Guodong Liang",
        "Yang Gao",
        "Ming Liao",
        "Ling Fang",
        "Li-Yun Jiang",
        "Hui Li",
        "Fang Chen",
        "Biao Di",
        "Li-Juan He",
        "Jin-Yan Lin",
        "Suxiang Tong",
        "Xiangang Kong",
        "Lin Du",
        "Pei Hao",
        "Hua Tang",
        "Andrea Bernini",
        "Xiao-Jing Yu",
        "Ottavia Spiga",
        "Zong-Ming Guo"
    ],
    "related_topics": [
        "Civet",
        "Viverridae",
        "Coronavirus"
    ],
    "citation_count": "667",
    "reference_count": "22",
    "references": [
        "2132260239",
        "2097706568",
        "2104548316",
        "2156434383",
        "2116586125",
        "1966238900",
        "2169198329",
        "2134061616",
        "2159857626",
        "2146476111"
    ]
},{
    "id": "2145758369",
    "title": "Classification of acute pancreatitis\u20142012: revision of the Atlanta classification and definitions by international consensus",
    "abstract": "Background and objective The Atlanta classification of acute pancreatitis enabled standardised reporting of research and aided communication between clinicians. Deficiencies identified and improved understanding of the disease make a revision necessary. Methods A web-based consultation was undertaken in 2007 to ensure wide participation of pancreatologists. After an initial meeting, the Working Group sent a draft document to 11 national and international pancreatic associations. This working draft was forwarded to all members. Revisions were made in response to comments, and the web-based consultation was repeated three times. The final consensus was reviewed, and only statements based on published evidence were retained. Results The revised classification of acute pancreatitis identified two phases of the disease: early and late. Severity is classified as mild, moderate or severe. Mild acute pancreatitis, the most common form, has no organ failure, local or systemic complications and usually resolves in the first week. Moderately severe acute pancreatitis is defined by the presence of transient organ failure, local complications or exacerbation of co-morbid disease. Severe acute pancreatitis is defined by persistent organ failure, that is, organ failure >48 h. Local complications are peripancreatic fluid collections, pancreatic and peripancreatic necrosis (sterile or infected), pseudocyst and walled-off necrosis (sterile or infected). We present a standardised template for reporting CT images. Conclusions This international, web-based consensus provides clear definitions to classify acute pancreatitis using easily identified clinical and radiologic criteria. The wide consultation among pancreatologists to reach this consensus should encourage widespread adoption.",
    "date": "2012",
    "authors": [
        "Peter A Banks",
        "Thomas L Bollen",
        "Christos Dervenis",
        "Hein G Gooszen",
        "Colin D Johnson",
        "Michael G Sarr",
        "Gregory G Tsiotos",
        "Santhi Swaroop Vege"
    ],
    "related_topics": [
        "Acute pancreatitis",
        "Ranson criteria",
        "Exacerbation"
    ],
    "citation_count": "4,539",
    "reference_count": "70",
    "references": [
        "2129688566",
        "1898928487",
        "1972516036",
        "2109057101",
        "2139648891",
        "2085208748",
        "2126413585",
        "2054190773",
        "1985045980",
        "2148658704"
    ]
},{
    "id": "2139937737",
    "title": "Acute renal failure - definition, outcome measures, animal models, fluid therapy and information technology needs: the Second International Consensus Conference of the Acute Dialysis Quality Initiative (ADQI) Group.",
    "abstract": "There is no consensus definition of acute renal failure (ARF) in critically ill patients. More than 30 different definitions have been used in the literature, creating much confusion and making comparisons difficult. Similarly, strong debate exists on the validity and clinical relevance of animal models of ARF; on choices of fluid management and of end-points for trials of new interventions in this field; and on how information technology can be used to assist this process. Accordingly, we sought to review the available evidence, make recommendations and delineate key questions for future studies. We undertook a systematic review of the literature using Medline and PubMed searches. We determined a list of key questions and convened a 2-day consensus conference to develop summary statements via a series of alternating breakout and plenary sessions. In these sessions, we identified supporting evidence and generated recommendations and/or directions for future research. We found sufficient consensus on 47 questions to allow the development of recommendations. Importantly, we were able to develop a consensus definition for ARF. In some cases it was also possible to issue useful consensus recommendations for future investigations. We present a summary of the findings. (Full versions of the six workgroups' findings are available on the internet at http://www.ADQI.net ) Despite limited data, broad areas of consensus exist for the physiological and clinical principles needed to guide the development of consensus recommendations for defining ARF, selection of animal models, methods of monitoring fluid therapy, choice of physiological and clinical end-points for trials, and the possible role of information technology.",
    "date": "2004",
    "authors": [
        "Rinaldo Bellomo",
        "Claudio Ronco",
        "John A Kellum",
        "Ravindra L Mehta",
        "Paul Palevsky"
    ],
    "related_topics": [
        "MEDLINE",
        "Guideline",
        "Health care"
    ],
    "citation_count": "8,505",
    "reference_count": "48",
    "references": [
        "2487377689",
        "2160691650",
        "2107978811",
        "2128349740",
        "1991864206",
        "2097875399",
        "2148973700",
        "2004284087",
        "2171467831",
        "2144408525"
    ]
},{
    "id": "2591646177",
    "title": "Spirit 2013 statement: Defining standard protocol items for clinical trials",
    "abstract": "The protocol of a clinical trial serves as the foundation for study planning, conduct, reporting, and appraisal. However, trial protocols and existing protocol guidelines vary greatly in content and quality. This article describes the systematic development and scope of SPIRIT (Standard Protocol Items: Recommendations for Interventional Trials) 2013, a guideline for the minimum content of a clinical trial protocol.The 33-item SPIRIT checklist applies to protocols for all clinical trials and focuses on content rather than format. The checklist recommends a full description of what is planned; it does not prescribe how to design or conduct a trial. By providing guidance for key content, the SPIRIT recommendations aim to facilitate the drafting of high-quality protocols. Adherence to SPIRIT would also enhance the transparency and completeness of trial protocols for the benefit of investigators, trial participants, patients, sponsors, funders, research ethics committees or institutional review boards, peer reviewers, journals, trial registries, policymakers, regulators, and other key stakeholders.",
    "date": "2012",
    "authors": [
        "An Wen Chan",
        "Jennifer M. Tetzlaff",
        "Douglas G. Altman",
        "Andreas Laupacis",
        "Peter C. G\u00f8tzsche",
        "Karmela Krle\u017ea-Jeri\u0107",
        "Asbj\u00f8rn Hr\u00f3bjartsson",
        "Howard Mann",
        "Kay Dickersin",
        "Jesse A. Berlin",
        "Caroline J. Dor\u00e9",
        "Wendy R. Parulekar",
        "William S.M. Summerskill",
        "Trish Groves",
        "Kenneth F. Schulz",
        "Harold C. Sox",
        "Frank W. Rockhold",
        "Drummond Rennie",
        "David Moher"
    ],
    "related_topics": [
        "Protocol (science)",
        "Clinical trial",
        "Checklist"
    ],
    "citation_count": "3,145",
    "reference_count": "0",
    "references": []
},{
    "id": "2034462612",
    "title": "Treatment with interferon-\u03b12b and ribavirin improves outcome in MERS-CoV\u2013infected rhesus macaques",
    "abstract": "The emergence of Middle East respiratory syndrome coronavirus (MERS-CoV) is of global concern: the virus has caused severe respiratory illness, with 111 confirmed cases and 52 deaths at the time of this article's publication. Therapeutic interventions have not been evaluated in vivo; thus, patient management relies exclusively on supportive care, which, given the high case-fatality rate, is not highly effective. The rhesus macaque is the only known model organism for MERS-CoV infection, developing an acute localized to widespread pneumonia with transient clinical disease that recapitulates mild to moderate human MERS-CoV cases. The combination of interferon-\u03b12b and ribavirin was effective in reducing MERS-CoV replication in vitro; therefore, we initiated this treatment 8 h after inoculation of rhesus macaques. In contrast to untreated, infected macaques, treated animals did not develop breathing abnormalities and showed no or very mild radiographic evidence of pneumonia. Moreover, treated animals showed lower levels of systemic (serum) and local (lung) proinflammatory markers, in addition to fewer viral genome copies, distinct gene expression and less severe histopathological changes in the lungs. Taken together, these data suggest that treatment of MERS-CoV infected rhesus macaques with IFN-\u03b12b and ribavirin reduces virus replication, moderates the host response and improves clinical outcome. As these two drugs are already used in combination in the clinic for other infections, IFN-\u03b12b and ribavirin should be considered for the management of MERS-CoV cases.",
    "date": "2013",
    "authors": [
        "Darryl Falzarano",
        "Emmie de Wit",
        "Angela L Rasmussen",
        "Friederike Feldmann",
        "Atsushi Okumura",
        "Dana P Scott",
        "Doug Brining",
        "Trenton Bushmaker",
        "Cynthia Martellaro",
        "Laura Baseler",
        "Arndt G Benecke",
        "Michael G Katze",
        "Vincent J Munster",
        "Heinz Feldmann"
    ],
    "related_topics": [
        "Ribavirin",
        "Rhesus macaque",
        "Coronavirus"
    ],
    "citation_count": "476",
    "reference_count": "34",
    "references": [
        "2166867592",
        "2129542667",
        "1703839189",
        "2113457186",
        "2163627712",
        "2150120685",
        "2054076340",
        "2073234751",
        "2038576929",
        "1035662337"
    ]
},{
    "id": "1977050884",
    "title": "Distinct immune response in two MERS-CoV-infected patients: can we go from bench to bedside?",
    "abstract": "One year after the occurrence of the first case of infection by the Middle East Respiratory Syndrome coronavirus (MERS-CoV) there is no clear consensus on the best treatment to propose. The World Health Organization, as well as several other national agencies, are still working on different clinical approaches to implement the most relevant treatment in MERS-CoV infection. We compared innate and adaptive immune responses of two patients infected with MERS-CoV to understand the underlying mechanisms involved in the response and propose potential therapeutic approaches. Broncho-alveolar lavage (BAL) of the first week and sera of the first month from the two patients were used in this study. Quantitative polymerase chain reaction (qRTPCR) was performed after extraction of RNA from BAL cells of MERS-CoV infected patients and control patients. BAL supernatants and sera were used to assess cytokines and chemokines secretion by enzyme-linked immunosorbent assay. The first patient died rapidly after 3 weeks in the intensive care unit, the second patient still recovers from infection. The patient with a poor outcome (patient 1), compared to patient 2, did not promote type-1 Interferon (IFN), and particularly IFN\u03b1, in response to double stranded RNA (dsRNA) from MERS-CoV. The absence of IFN\u03b1, known to promote antigen presentation in response to viruses, impairs the development of a robust antiviral adaptive Th-1 immune response. This response is mediated by IL-12 and IFN\u03b3 that decreases viral clearance; levels of both of these mediators were decreased in patient 1. Finally, we confirm previous in vitro findings that MERS-CoV can drive IL-17 production in humans. Host recognition of viral dsRNA determines outcome in the early stage of MERS-CoV infection. We highlight the critical role of IFN\u03b1 in this initial stage to orchestrate a robust immune response and bring substantial arguments for the indication of early IFN\u03b1 treatment during MERS-CoV infection.",
    "date": "2014",
    "authors": [
        "Emmanuel Faure",
        "Julien Poissy",
        "Anne Goffard",
        "Clement Fournier",
        "Eric Kipnis",
        "Marie Titecat",
        "Perinne Bortolotti",
        "Laura Martinez",
        "Sylvain Dubucquoi",
        "Rodrigue Dessein",
        "Philippe Gosset",
        "Daniel Mathieu",
        "Benoit Guery"
    ],
    "related_topics": [
        "Acquired immune system",
        "Immune system",
        "Alpha interferon"
    ],
    "citation_count": "210",
    "reference_count": "23",
    "references": [
        "2166867592",
        "2006434809",
        "2141137217",
        "2046153984",
        "2119775949",
        "2079295092",
        "2117336218",
        "2016921919",
        "2103741738",
        "2007608885"
    ]
},{
    "id": "2586093485",
    "title": "Middle East Respiratory Syndrome",
    "abstract": "Between September 2012 and January 20, 2017, the World Health Organization (WHO) received reports from 27 countries of 1879 laboratory-confirmed cases in humans of the Middle East respiratory syndrome (MERS) caused by infection with the MERS coronavirus (MERS-CoV) and at least 659 related deaths. Cases of MERS-CoV infection continue to occur, including sporadic zoonotic infections in humans across the Arabian Peninsula, occasional importations and associated clusters in other regions, and outbreaks of nonsustained human-to-human transmission in health care settings. Dromedary camels are considered to be the most likely source of animal-to-human transmission. MERS-CoV enters host cells after binding the dipeptidyl peptidase 4 (DPP-4) receptor and the carcinoembryonic antigen\u2013related cell-adhesion molecule 5 (CEACAM5) cofactor ligand, and it replicates efficiently in the human respiratory epithelium. Illness begins after an incubation period of 2 to 14 days and frequently results in hypoxemic respiratory failure and the need for multiorgan support. However, asymptomatic and mild cases also occur. Real-time reverse-transcription\u2013polymerase-chain-reaction (RT-PCR) testing of respiratory secretions is the mainstay for diagnosis, and samples from the lower respiratory tract have the greatest yield among seriously ill patients. There is no antiviral therapy of proven efficacy, and thus treatment remains largely supportive; potential vaccines are at an early developmental stage. There are multiple gaps in knowledge regarding the evolution and transmission of the virus, disease pathogenesis, treatment, and prospects for a vaccine. The ongoing occurrence of MERS in humans and the associated high mortality call for a continued collaborative approach toward gaining a better understanding of the infection both in humans and in animals.MERS-CoV was first identified in September 2012 in a patient from Saudi Arabia who had hypoxemic respiratory failure and multiorgan illness. Subsequent cases have included infections in humans across the Arabian Peninsula, occasional importations and associated clusters in other regions, and outbreaks of nonsustained human-to-human transmission in health care settings (Fig. 1).",
    "date": "2017",
    "authors": [
        "Yaseen M Arabi",
        "Hanan H Balkhy",
        "Frederick G Hayden",
        "Abderrezak Bouchama",
        "Thomas Luke",
        "J Kenneth Baillie",
        "Awad Al-Omari",
        "Ali H Hajeer",
        "Mikiko Senga",
        "Mark R Denison",
        "Jonathan S Nguyen-Van-Tam",
        "Nahoko Shindo",
        "Alison Bermingham",
        "James D Chappell",
        "Maria D Van Kerkhove",
        "Robert A Fowler"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Transmission (medicine)"
    ],
    "citation_count": "365",
    "reference_count": "69",
    "references": [
        "2166867592",
        "1703839189",
        "2112147913",
        "2149508011",
        "2045002682",
        "1852588318",
        "2113457186",
        "2256430766",
        "2109520345",
        "2034462612"
    ]
},{
    "id": "2150120685",
    "title": "Role of lopinavir/ritonavir in the treatment of SARS: initial virological and clinical findings.",
    "abstract": "Background: The clinical response of patients with severe acute respiratory syndrome (SARS) to a combination of lopinavir/ritonavir and ribavirin was examined after establishing the in vitro antiviral susceptibility of the SARS associated coronavirus to a panel of antiviral agents. Methods: The in vitro susceptibility of the prototype of SARS associated coronavirus to a panel of nucleoside analogues and protease inhibitors currently licensed for clinical use was studied. Forty one patients with SARS followed for 3 weeks were treated with a combination of lopinavir/ritonavir and ribavirin. The clinical progress and virological outcomes were monitored and compared with 111 patients treated with ribavirin only who served as historical controls. Results: In vitro antiviral activity against SARS associated coronavirus was demonstrated for lopinavir and ribavirin at concentrations of 4 \u00b5g/ml and 50 \u00b5g/ml, respectively, only at 48 hours. The adverse clinical outcome (ARDS or death) was significantly lower in the treatment group than in the historical controls (2.4% v 28.8%, p Conclusions: The apparent favourable clinical response with lopinavir/ritonavir and ribavirin supports further randomised placebo controlled trials in patients with SARS.",
    "date": "2004",
    "authors": [
        "C M Chu",
        "V C C Cheng",
        "I F N Hung",
        "M M L Wong",
        "K H Chan",
        "K S Chan",
        "R Y T Kao",
        "L L M Poon",
        "C L P Wong",
        "Y Guan",
        "J S M Peiris",
        "K Y Yuen"
    ],
    "related_topics": [
        "Lopinavir/ritonavir",
        "Lopinavir",
        "Ritonavir"
    ],
    "citation_count": "1,526",
    "reference_count": "20",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2161328469",
        "2163627712",
        "1990049863",
        "2167080692",
        "1971054351"
    ]
},{
    "id": "2024938615",
    "title": "To scale or not to scale: the principles of dose extrapolation",
    "abstract": "The principles of inter-species dose extrapolation are poorly understood and applied. We provide an overview of the principles underlying dose scaling for size and dose adjustment for size-independent differences. Scaling of a dose is required in three main situations: the anticipation of first-in-human doses for clinical trials, dose extrapolation in veterinary practice and dose extrapolation for experimental purposes. Each of these situations is discussed. Allometric scaling of drug doses is commonly used for practical reasons, but can be more accurate when one takes into account species differences in pharmacokinetic parameters (clearance, volume of distribution). Simple scaling of drug doses can be misleading for some drugs; correction for protein binding, physicochemical properties of the drug or species differences in physiological time can improve scaling. However, differences in drug transport and metabolism, and in the dose\u2013response relationship, can override the effect of size alone. For this reason, a range of modelling approaches have been developed, which combine in silico simulations with data obtained in vitro and/or in vivo. Drugs that are unlikely to be amenable to simple allometric scaling of their clearance or dose include drugs that are highly protein-bound, drugs that undergo extensive metabolism and active transport, drugs that undergo significant biliary excretion (MW > 500, ampiphilic, conjugated), drugs whose targets are subject to inter-species differences in expression, affinity and distribution and drugs that undergo extensive renal secretion. In addition to inter-species dose extrapolation, we provide an overview of dose extrapolation within species, discussing drug dosing in paediatrics and in the elderly.",
    "date": "2009",
    "authors": [
        "Vijay Sharma",
        "John H McNeill"
    ],
    "related_topics": [
        "Pharmacokinetics",
        "Extrapolation",
        "Drug"
    ],
    "citation_count": "427",
    "reference_count": "91",
    "references": [
        "2078206416",
        "2125121177",
        "2121836743",
        "2144600435",
        "2114795157",
        "3121643507",
        "2122527560",
        "2006998778",
        "2113524447",
        "2081213990"
    ]
},{
    "id": "2100521244",
    "title": "Metabolic Scaling in Animals: Methods, Empirical Results, and Theoretical Explanations",
    "abstract": "Life on earth spans a size range of around 21 orders of magnitude across species and can span a range of more than 6 orders of magnitude within species of animal. The effect of size on physiology is, therefore, enormous and is typically expressed by how physiological phenomena scale with mass(b). When b \u2260 1 a trait does not vary in direct proportion to mass and is said to scale allometrically. The study of allometric scaling goes back to at least the time of Galileo Galilei, and published scaling relationships are now available for hundreds of traits. Here, the methods of scaling analysis are reviewed, using examples for a range of traits with an emphasis on those related to metabolism in animals. Where necessary, new relationships have been generated from published data using modern phylogenetically informed techniques. During recent decades one of the most controversial scaling relationships has been that between metabolic rate and body mass and a number of explanations have been proposed for the scaling of this trait. Examples of these mechanistic explanations for metabolic scaling are reviewed, and suggestions made for comparing between them. Finally, the conceptual links between metabolic scaling and ecological patterns are examined, emphasizing the distinction between (1) the hypothesis that size- and temperature-dependent variation among species and individuals in metabolic rate influences ecological processes at levels of organization from individuals to the biosphere and (2) mechanistic explanations for metabolic rate that may explain the size- and temperature-dependence of this trait.",
    "date": "2014",
    "authors": [
        "Craig R White",
        "Michael R Kearney"
    ],
    "related_topics": [
        "Allometry",
        "Scale (social sciences)",
        "Phylogenetic comparative methods"
    ],
    "citation_count": "112",
    "reference_count": "453",
    "references": [
        "2009435671",
        "2157823046",
        "2141088880",
        "1969761972",
        "2611511275",
        "1489838709",
        "2151409320",
        "1577941315",
        "2114795157",
        "2127779696"
    ]
},{
    "id": "2142366069",
    "title": "A general basis for quarter-power scaling in animals",
    "abstract": "It has been known for decades that the metabolic rate of animals scales with body mass with an exponent that is almost always 2/3, and often very close to 3/4. The 3/4 exponent emerges naturally from two models of resource distribution networks, radial explosion and hierarchically branched, which incorporate a minimum of specific details. Both models show that the exponent is 2/3 if velocity of flow remains constant, but can attain a maximum value of 3/4 if velocity scales with its maximum exponent, 1/12. Quarter-power scaling can arise even when there is no underlying fractality. The canonical \"fourth dimension\" in biological scaling relations can result from matching the velocity of flow through the network to the linear dimension of the terminal \"service volume\" where resources are consumed. These models have broad applicability for the optimal design of biological and engineered systems where energy, materials, or information are distributed from a single source.",
    "date": "2010",
    "authors": [
        "Jayanth R. Banavar",
        "Melanie E. Moses",
        "James H. Brown",
        "John Damuth",
        "Andrea Rinaldo",
        "Richard M. Sibly",
        "Amos Maritan"
    ],
    "related_topics": [
        "Exponent",
        "Scaling",
        "Almost surely"
    ],
    "citation_count": "187",
    "reference_count": "39",
    "references": [
        "3121643507",
        "1574634131",
        "3122270935",
        "2015823673",
        "1763240259",
        "2031770486",
        "1976075335",
        "1558456135",
        "285595691",
        "2054676535"
    ]
},{
    "id": "2065093669",
    "title": "Applications of Human Pharmacokinetic Prediction in First-in-Human Dose Estimation",
    "abstract": "Quantitative estimations of first-in-human (FIH) doses are critical for phase I clinical trials in drug development. Human pharmacokinetic (PK) prediction methods have been developed to project the human clearance (CL) and bioavailability with reasonable accuracy, which facilitates estimation of a safe yet efficacious FIH dose. However, the FIH dose estimation is still very challenging and complex. The aim of this article is to review the common approaches for FIH dose estimation with an emphasis on PK-guided estimation. We discuss 5 methods for FIH dose estimation, 17 approaches for the prediction of human CL, 6 methods for the prediction of bioavailability, and 3 tools for the prediction of PK profiles. This review may serve as a practical protocol for PK- or pharmacokinetic/pharmacodynamic-guided estimation of the FIH dose.",
    "date": "2012",
    "authors": [
        "Peng Zou",
        "Yanke Yu",
        "Nan Zheng",
        "Yongsheng Yang",
        "Hayley J. Paholak",
        "Lawrence X. Yu",
        "Duxin Sun"
    ],
    "related_topics": [
        "Bioavailability",
        "Drug development",
        "Pharmacokinetics"
    ],
    "citation_count": "80",
    "reference_count": "98",
    "references": [
        "2135732933",
        "2141989396",
        "2144465276",
        "1979196526",
        "2133622314",
        "2024938615",
        "2032865438",
        "1574019439",
        "2027179985",
        "2108458189"
    ]
},{
    "id": "2080335269",
    "title": "On Setting the First Dose in Man: Quantitating Biotherapeutic Drug-Target Binding through Pharmacokinetic and Pharmacodynamic Models",
    "abstract": "Although the three (perhaps four) phases of clinical drug development are well known, it is relatively unappreciated that there are similar phases in pre-clinical development. These consist of 'Phase I' the initial, normally Research Discovery driven pharmacology; 'Phase II' non-good laboratory practice (GLP) dose range finding, followed by pivotal 'Phase III' GLP toxicology. Together with an array of in vitro experiments comparing species, these stages should enable an integrated safety assessment prior to entry into man, documenting to investigators and authorities evidence that the new pharmaceutic is unlikely to cause harm. Following the lessons learned from TeGenero TGN1412 and subsequent updates to regulatory guidelines, there are aspects peculiar to biotherapeutics, especially those that target key body systems, where calculations could be made for doses for human studies using pharmacokinetic and pharmacodynamic models. Two of these are exemplified in this paper. In the first, target-mediated drug disposition, where the binding of the drug to a cellular target quantitatively affects the pharmacokinetics, enables occupancy to be estimated without recourse to independent assays. In the second, assaying captured soluble target, as drug-target complexes, allows estimation of the concentration of the free ligand ensuring that in initial clinical studies, soluble targets are not overly suppressed. To support this methodology, it has been demonstrated using omalizumab, free and total IgE data that such analyses do predict the suppression of the free unbound ligand with reasonable accuracy. Overall, the objective of the process is to deliver a justification, through consideration of drug-target binding, of a safe starting and therapeutically relevant escalation doses for human studies.",
    "date": "2010",
    "authors": [
        "Philip J. Lowe",
        "Stacey Tannenbaum",
        "Kai Wu",
        "Peter Lloyd",
        "Jennifer Sims"
    ],
    "related_topics": [
        "Drug development",
        "Pharmacokinetics",
        "Pharmacodynamics"
    ],
    "citation_count": "85",
    "reference_count": "25",
    "references": [
        "3121643507",
        "2029587541",
        "3122270935",
        "2062826169",
        "2110348886",
        "2164977460",
        "1525774039",
        "2011018995",
        "2059889603",
        "1998532042"
    ]
},{
    "id": "2034194552",
    "title": "Estimating the starting dose for entry into humans: principles and practice",
    "abstract": "Background: Selection of the starting dose for the entry into humans (EIH) study is an essential first step in clinical drug development. Objectives: This paper is a review of different approaches that may be used to calculate the starting dose, presents the results of a current practice survey that reflect practice patterns at a large pharmaceutical company, and discusses selected topics related to the calculation of the starting dose. Results: The methods used in the field of oncology for cytotoxic compounds are usually derived from a dose associated with some toxicity in animals multiplied by a safety factor. In therapeutic areas other than oncology, the methods may be classified as four different approaches: (1) dose by factor methods that utilize the no observable adverse effect level (NOAEL) from preclinical toxicology studies multiplied by a safety factor; (2) the similar drug approach that may be used when clinical data are available for another compound of the same chemical class as the investigational drug; (3) the pharmacokinetically guided approach that uses systemic exposure rather than dose for the extrapolation from animal to man; and (4) the comparative approach that consists of utilizing two or more methods to estimate a starting dose and then critically comparing the results to arrive at the optimal starting dose. A \"real-life\" example illustrates the use of each method. Advantages, limitations, and underlying assumptions of each of the methods are discussed. The results of the survey showed that the pharmacokinetically guided approach is the most commonly used method, followed by dose by factor methods. Conclusion: The task of estimating the starting dose is moving beyond empirical methods to those that are increasingly more systematic and theory based.",
    "date": "2002",
    "authors": [
        "Bruno G. Reigner",
        "Karen Smith Blesch"
    ],
    "related_topics": [
        "Effective dose (pharmacology)",
        "Drug development",
        "Absorbed dose"
    ],
    "citation_count": "137",
    "reference_count": "37",
    "references": [
        "2138957803",
        "2126551611",
        "1727163805",
        "182669748",
        "2006702541",
        "2114333459",
        "1837825273",
        "2046726491",
        "2188350343",
        "1998519118"
    ]
},{
    "id": "2160483062",
    "title": "Prediction of pharmacokinetic properties using experimental approaches during early drug discovery",
    "abstract": "There has been a significant increase in the number of compounds synthesized in early drug-discovery programs with the advances in combinatorial chemistry and high-throughput biological screening efforts. Various in silico, in vitro and in situ approaches have been described in literature that achieve higher throughput pharmacokinetic screening. In silico methodologies have mainly attempted to quantify the prospects of oral absorption of compounds based upon their physico-chemical properties. There is a greater availability of in vitro and in situ approaches to screen compounds for intestinal permeability (as a surrogate for absorption) and metabolic stability (as a surrogate for clearance). More recent modifications of the in vitro and in situ approaches to assess the potential of absorption and metabolism have enabled a higher throughput and an ability to correlate better with in vivo pharmacokinetics of compounds.",
    "date": "2001",
    "authors": [
        "Pravin R Chaturvedi",
        "Caroline J Decker",
        "Aleksandrs Odinecs"
    ],
    "related_topics": [
        "In silico",
        "Drug discovery",
        "Chemical biology"
    ],
    "citation_count": "124",
    "reference_count": "71",
    "references": [
        "2135732933",
        "1498305210",
        "2069506489",
        "1979196526",
        "2133622314",
        "2032865438",
        "2046564413",
        "1574019439",
        "2061263372",
        "1997764055"
    ]
},{
    "id": "2057666951",
    "title": "Estimating the safe starting dose in phase I clinical trials and no observed effect level based on QSAR modeling of the human maximum recommended daily dose.",
    "abstract": "Estimating the maximum recommended starting dose (MRSD) of a pharmaceutical for phase I human clinical trials and the no observed effect level (NOEL) for non-pharmaceuticals is currently based exclusively on an extrapolation of the results of animal toxicity studies. This process is inexact and requires the results of toxicity studies in multiple species (rat, dog, and monkey) to identify the no observed adverse effect level (NOAEL) and most sensitive test species. Multiple uncertainty (safety) factors are also necessary to compensate for incompatibility and uncertainty underlying the extrapolation of animal toxicity to humans. The maximum recommended daily dose for pharmaceuticals (MRDD) is empirically derived from human clinical trials. The MRDD is an estimated upper dose limit beyond which a drug's efficacy is not increased and/or undesirable adverse effects begin to outweigh beneficial effects. The MRDD is essentially equivalent to the NOAEL in humans, a dose beyond which adverse (toxicological) or undesirable pharmacological effects are observed. The NOAEL in test animals is currently used to estimate the safe starting dose in human clinical trials. MDL QSAR predictive modeling of the human MRDD may provide a better, simpler and more relevant estimation of the MRSD for pharmaceuticals and the toxic dose threshold of chemicals in humans than current animal extrapolation based risk assessment models and may be a useful addition to current methods. A database of the MRDD for over 1300 pharmaceuticals was compiled and modeled using MDL QSAR software and E-state and connectivity topological descriptors. MDL QSAR MRDD models were found to have good predictive performance with 74-78% of predicted MRDD values for 120 internal and 160 external validation compounds falling within a range of +/-10-fold the actual MRDD value. The predicted MRDD can be used to estimate the MRSD for pharmaceuticals in phase I clinical trials with the addition of a 10-fold safety factor. For non-pharmaceutical chemicals any compound-related effect can be considered an undesirable and adverse toxicological effect and the predicted MRDD can be used to estimate the NOEL with the addition of an appropriate safety factor.",
    "date": "2004",
    "authors": [
        "Joseph F. Contrera",
        "Edwin J. Matthews",
        "Naomi L. Kruhlak",
        "R. Daniel Benz"
    ],
    "related_topics": [
        "No-observed-adverse-effect level",
        "Adverse effect",
        "Clinical trial"
    ],
    "citation_count": "98",
    "reference_count": "19",
    "references": [
        "2063698478",
        "623814603",
        "2104209550",
        "2122689321",
        "421463624",
        "2019980219",
        "2131626361",
        "2146178879",
        "2079436612",
        "1996103084"
    ]
},{
    "id": "311927316",
    "title": "Coronaviruses: An Overview of Their Replication and Pathogenesis",
    "abstract": "Coronaviruses (CoVs), enveloped positive-sense RNA viruses, are characterized by club-like spikes that project from their surface, an unusually large RNA genome, and a unique replication strategy. Coronaviruses cause a variety of diseases in mammals and birds ranging from enteritis in cows and pigs and upper respiratory disease in chickens to potentially lethal human respiratory infections. Here we provide a brief introduction to coronaviruses discussing their replication and pathogenicity, and current prevention and treatment strategies. We also discuss the outbreaks of the highly pathogenic Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) and the recently identified Middle Eastern Respiratory Syndrome Coronavirus (MERS-CoV).",
    "date": "2014",
    "authors": [
        "Anthony R. Fehr",
        "Stanley Perlman"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral replication",
        "Nidovirales"
    ],
    "citation_count": "2,408",
    "reference_count": "160",
    "references": [
        "2166867592",
        "2941307081",
        "2129542667",
        "1993577573",
        "2119111857",
        "2149508011",
        "1966238900",
        "2103503670",
        "2113457186",
        "2134061616"
    ]
},{
    "id": "2597070792",
    "title": "Ventilation with lower tidal volumes as compared with traditional tidal volumes for acute lung injury and the acute respiratory distress syndrome.",
    "abstract": "Background Traditional approaches to mechanical ventilation use tidal volumes of 10 to 15 ml per kilogram of body weight and may cause stretch-induced lung injury in patients with acute lung injury and the acute respiratory distress syndrome. We therefore conducted a trial to determine whether ventilation with lower tidal volumes would improve the clinical outcomes in these patients. Methods Patients with acute lung injury and the acute respiratory distress syndrome were enrolled in a multicenter, randomized trial. The trial compared traditional ventilation treatment, which involved an initial tidal volume of 12 ml per kilogram of predicted body weight and an airway pressure measured after a 0.5-second pause at the end of inspiration (plateau pressure) of 50 cm of water or less, with ventilation with a lower tidal volume, which involved an initial tidal volume of 6 ml per kilogram of predicted body weight and a plateau pressure of 30 cm of water or less. The primary outcomes were death before a patient was discharged home and was breathing without assistance and the number of days without ventilator use from day 1 to day 28. Results The trial was stopped after the enrollment of 861 patients because mortality was lower in the group treated with lower tidal volumes than in the group treated with traditional tidal volumes (31.0 percent vs. 39.8 percent, P=0.007), and the number of days without ventilator use during the first 28 days after randomization was greater in this group (mean [+/-SD], 12+/-11 vs. 10+/-11; P=0.007). The mean tidal volumes on days 1 to 3 were 6.2+/-0.8 and 11.8+/-0.8 ml per kilogram of predicted body weight (P Conclusions In patients with acute lung injury and the acute respiratory distress syndrome, mechanical ventilation with a lower tidal volume than is traditionally used results in decreased mortality and increases the number of days without ventilator use.",
    "date": "2000",
    "authors": [
        "Roy G Brower",
        "Michael A Matthay",
        "Alan Morris",
        "David Schoenfeld",
        "B Taylor Thompson",
        "Arthur Wheeler"
    ],
    "related_topics": [
        "High-frequency ventilation",
        "Tidal volume",
        "Lung volumes"
    ],
    "citation_count": "9,667",
    "reference_count": "43",
    "references": [
        "2060123467",
        "2161328469",
        "2796700885",
        "2143748013",
        "2120156715",
        "2317705795",
        "2059707463",
        "2062082715",
        "2333922183",
        "1898899939"
    ]
},{
    "id": "2093852073",
    "title": "The acute respiratory distress syndrome",
    "abstract": "The acute respiratory distress syndrome is a common, devastating clinical syndrome of acute lung injury that affects both medical and surgical patients. Since the last review of this syndrome appeared in the Journal, 1 more uniform definitions have been devised and important advances have occurred in the understanding of the epidemiology, natural history, and pathogenesis of the disease, leading to the design and testing of new treatment strategies. This article provides an overview of the definitions, clinical features, and epidemiology of the acute respiratory distress syndrome and discusses advances in the areas of pathogenesis, resolution, and treatment. Historical Perspective and Definitions . . .",
    "date": "1996",
    "authors": [
        "Lorraine B. Ware",
        "Michael A. Matthay"
    ],
    "related_topics": [
        "Respiratory distress",
        "Diffuse alveolar damage",
        "ARDS"
    ],
    "citation_count": "6,426",
    "reference_count": "99",
    "references": [
        "2161328469",
        "2005357317",
        "2093216413",
        "2062082715",
        "2166745951",
        "2070506007",
        "1984406996",
        "1766556848",
        "2117860495",
        "2034332958"
    ]
},{
    "id": "2152552492",
    "title": "Characterization of Human Metapneumoviruses Isolated from Patients in North America",
    "abstract": "Human metapneumovirus (HMPV) was recently identified in The Netherlands and was linked to acute respiratory tract illness. In this study, 11 isolates from 10 patients with respiratory disease from Quebec, Canada, were tested by a reverse-transcriptase polymerase chain reaction based on the fusion protein gene. Identified sequences were consistent with HMPV. The patients were 2 months to 87 years of age (median age, 58 years) and presented with acute respiratory tract illness during the winter season. Sequence studies of the nucleocapsid, fusion, and polymerase genes identified 2 main lineages of HMPV and cocirculation of both lineages during the same year. These findings support a previous finding that HMPV is a human respiratory pathogen that merits further study.",
    "date": "2002",
    "authors": [
        "Teresa C. T. Peret",
        "Guy Boivin",
        "Yan Li",
        "Michel Couillard",
        "Charles Humphrey",
        "Albert D. M. E. Osterhaus",
        "Dean D. Erdman",
        "Larry J. Anderson"
    ],
    "related_topics": [
        "Human metapneumovirus",
        "Metapneumovirus",
        "Paramyxoviridae"
    ],
    "citation_count": "527",
    "reference_count": "7",
    "references": [
        "2106882534",
        "2170881661",
        "3035616465",
        "1554745563",
        "2156824664",
        "2096194977",
        "1972117241"
    ]
},{
    "id": "2135259291",
    "title": "Virological Features and Clinical Manifestations Associated with Human Metapneumovirus: A New Paramyxovirus Responsible for Acute Respiratory-Tract Infections in All Age Groups",
    "abstract": "The virological features and clinical findings associated with the new human metapneumovirus (HMPV) were examined retrospectively in Canadian patients hospitalized for various respiratory conditions since 1993. Thirty-eight previously unidentified respiratory viruses isolated from rhesus monkey kindey (LLC-MK2) cells were found to be positive for HMPV by reverse-transcription polymerase chain reaction, and those strains clustered in 2 phylogenetic groups. Children aged 65 years represented 35.1% and 45.9% of the HMPV-infected cases, respectively. In hospitalized children, the most frequent diagnoses were pneumonitis (66.7%) and bronchiolitis (58.3%), whereas bronchitis and/or bronchospasm (60%) and pneumonitis (40%) were most commonly seen in elderly subjects. Of the 15 patients with pneumonitis, 4 (26.7%) had immunosuppressive conditions and 6 (40%) were infants aged <15 months. These findings suggest that HMPV can be associated with severe lower-respiratory-tract infections in very young children, the elderly, and immunocompromised patients.",
    "date": "2002",
    "authors": [
        "Guy Boivin",
        "Yacine Abed",
        "Gilles Pelletier",
        "Louisette Ruel",
        "Danielle Moisan",
        "St\u00e9phanie C\u00f4t\u00e9",
        "Teresa C. T. Peret",
        "Dean D. Erdman",
        "Larry J. Anderson"
    ],
    "related_topics": [
        "Pneumonitis",
        "Human metapneumovirus",
        "Respiratory tract infections"
    ],
    "citation_count": "725",
    "reference_count": "15",
    "references": [
        "2170881661",
        "2152552492",
        "1589490904",
        "2122034291",
        "1907972820",
        "2140173012",
        "2158407455",
        "1950423469",
        "2166096923",
        "2340540364"
    ]
},{
    "id": "2136166622",
    "title": "Hemorrhagic Fever Viruses as Biological Weapons: Medical and Public Health Management",
    "abstract": "ObjectiveTo develop consensus-based recommendations for measures to be taken by medical and public health professionals if hemorrhagic fever viruses (HFVs) are used as biological weapons against a civilian population.ParticipantsThe Working Group on Civilian Biodefense included 26 representatives from academic medical centers, public health, military services, governmental agencies, and other emergency management institutions.EvidenceMEDLINE was searched from January 1966 to January 2002. Retrieved references, relevant material published prior to 1966, and additional sources identified by participants were reviewed.Consensus ProcessThree formal drafts of the statement that synthesized information obtained in the evidence-gathering process were reviewed by the working group. Each draft incorporated comments and judgments of the members. All members approved the final draft.ConclusionsWeapons disseminating a number of HFVs could cause an outbreak of an undifferentiated febrile illness 2 to 21 days later, associated with clinical manifestations that could include rash, hemorrhagic diathesis, and shock. The mode of transmission and clinical course would vary depending on the specific pathogen. Diagnosis may be delayed given clinicians' unfamiliarity with these diseases, heterogeneous clinical presentation within an infected cohort, and lack of widely available diagnostic tests. Initiation of ribavirin therapy in the early phases of illness may be useful in treatment of some of these viruses, although extensive experience is lacking. There are no licensed vaccines to treat the diseases caused by HFVs.",
    "date": "2002",
    "authors": [
        "Luciana Borio",
        "Thomas Inglesby",
        "C. J. Peters",
        "Alan L. Schmaljohn",
        "James M. Hughes",
        "Peter B. Jahrling",
        "Thomas Ksiazek",
        "Karl M. Johnson",
        "Andrea Meyerhoff",
        "Tara O'Toole",
        "Michael S. Ascher",
        "John Bartlett",
        "Joel G. Breman",
        "Edward M. Eitzen",
        "Margaret Hamburg",
        "Jerry Hauer",
        "D. A. Henderson",
        "Richard T. Johnson",
        "Gigi Kwik",
        "Marci Layton",
        "Scott Lillibridge",
        "Gary J. Nabel",
        "Michael T. Osterholm",
        "Trish M. Perl",
        "Philip Russell",
        "Kevin Tonat"
    ],
    "related_topics": [
        "Viral hemorrhagic fever",
        "Public health",
        "Hemorrhagic Fevers"
    ],
    "citation_count": "877",
    "reference_count": "123",
    "references": [
        "1833207062",
        "2109779439",
        "2103828083",
        "2137889830",
        "2558766452",
        "2100511744",
        "2167960824",
        "2118488619",
        "1545248704",
        "2145710422"
    ]
},{
    "id": "2097665403",
    "title": "Injurious Mechanical Ventilation and End-Organ Epithelial Cell Apoptosis and Organ Dysfunction in an Experimental Model of Acute Respiratory Distress Syndrome",
    "abstract": "ContextRecent clinical trials have demonstrated a decrease in multiple organ dysfunction syndrome (MODS) and mortality in patients with acute respiratory distress syndrome (ARDS) treated with a protective ventilatory strategy.ObjectiveTo examine the hypothesis that an injurious ventilatory strategy may lead to end-organ epithelial cell apoptosis and organ dysfunction.Design and SettingIn vivo animals: 24 rabbits with acid-aspiration lung injury were ventilated with injurious or noninjurious ventilatory strategies. In vitro: rabbit epithelial cells were exposed to plasma from in vivo rabbit studies. In vivo human: plasma samples from patients included in a previous randomized controlled trial examining a lung protective strategy were analyzed (lung protection group, n = 9 and controls, n = 11).Main Outcome MeasuresIn vivo animals: biochemical markers of liver and renal dysfunction; apoptosis in end organs. In vitro: induction of apoptosis in LLC-RK1 renal tubular epithelial cells. In vivo human: correlation of plasma creatinine and soluble Fas ligand.ResultsThe injurious ventilatory strategy led to increased rates of epithelial cell apoptosis in the kidney (mean [SE]: injurious, 10.9% [0.88%]; noninjurious, 1.86% [0.17%]; P<.001) and small intestine villi (injurious, 6.7% [0.66%]; noninjurious, 0.97% [0.14%]; P<.001), and led to the elevation of biochemical markers indicating renal dysfunction in vivo. Induction of apoptosis was increased in LLC-RK1 cells incubated with plasma from rabbits ventilated with injurious ventilatory strategy at 4 hours (P = .03) and 8 hours (P = .002). The Fas:Ig, a fusion protein that blocks soluble Fas ligand, attenuated induction of apoptosis in vitro. There was a significant correlation between changes in soluble Fas ligand and changes in creatinine in patients with ARDS (R = 0.64, P = .002).ConclusionsMechanical ventilation can lead to epithelial cell apoptosis in the kidney and small intestine, accompanied by biochemical evidence of organ dysfunction. This may partially explain the high rate of MODS observed in patients with ARDS and the decrease in morbidity and mortality in patients treated with a lung protective strategy.",
    "date": "2003",
    "authors": [
        "Yumiko Imai",
        "Jean Parodo",
        "Osamu Kajikawa",
        "Marc de Perrot",
        "Stefan Fischer",
        "Vern Edwards",
        "Ernest Cutz",
        "Mingyao Liu",
        "Shaf Keshavjee",
        "Thomas R. Martin",
        "John C. Marshall",
        "V. Marco Ranieri",
        "Arthur S. Slutsky"
    ],
    "related_topics": [
        "Lung injury",
        "Organ dysfunction",
        "Multiple organ dysfunction syndrome"
    ],
    "citation_count": "782",
    "reference_count": "48",
    "references": [
        "2597070792",
        "2002503549",
        "2143748013",
        "2093852073",
        "1974873560",
        "2085208748",
        "2140066904",
        "1979129905",
        "2167743972",
        "2317705795"
    ]
},{
    "id": "1898899939",
    "title": "Multiple system organ failure. Is mechanical ventilation a contributing factor",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Arthur S. Slutsky",
        "Lorraine N. Tremblay"
    ],
    "related_topics": [
        "Mechanical ventilation",
        "Artificial ventilation",
        "Intensive care"
    ],
    "citation_count": "1,017",
    "reference_count": "55",
    "references": [
        "2143748013",
        "2005929586",
        "2062082715",
        "1766556848",
        "2085911628",
        "1993947411",
        "2005999688",
        "2048519644",
        "2125764762",
        "2077539093"
    ]
},{
    "id": "1607298558",
    "title": "Communicable Disease Control Handbook",
    "abstract": "Section 1 - introduction section 2 - common topics section 3 - diseases section 4 - services and organization section 5 - communicable disease control in individual countries appendices - resources for the CCDC.",
    "date": "2001",
    "authors": [
        "Jeremy Hawker",
        "Norman T. Begg",
        "Iain Blair",
        "Ralf Reintjes",
        "Julius Weinberg"
    ],
    "related_topics": [
        "Communicable disease",
        "Section (typography)",
        "Public health"
    ],
    "citation_count": "110",
    "reference_count": "0",
    "references": []
},{
    "id": "1982444609",
    "title": "Bronchiolitis obliterans organizing pneumonia: CT features in 14 patients.",
    "abstract": "Bronchiolitis obliterans organizing pneumonia is a disease characterized by the presence of granulation tissue within small airways and the presence of areas of organizing pneumonia. We retrospectively reviewed the chest radiographs, CT scans, and biopsy specimens in 14 consecutive patients with proved bronchiolitis obliterans organizing pneumonia. Six patients were immunocompromised because of leukemia or bone-marrow transplantation. In all patients, 10-mm collimation CT scans were available. In 11 of the 14 patients, select 1.5-mm scans were obtained. The CT findings included patchy unilateral (n = 1) or bilateral air-space consolidation (n = 9), small nodular opacities (n = 7), irregular linear opacities (n = 2), bronchial wall thickening and dilatation (n = 6), and small pleural effusions (n = 4). All patients had areas of air-space consolidation, small nodules, or both. A predominantly subpleural distribution of the air-space consolidation was apparent on the radiographs of two patients and on CT scans of six. Pathologically, the nodules and the consolidation represented different degrees of inflammation in bronchioles, alveolar ducts, and alveoli. Although most of the findings were apparent on the radiographs, the CT scans depicted the anatomic distribution and extent of bronchiolitis obliterans organizing pneumonia more accurately than did the plain chest radiographs.",
    "date": "1990",
    "authors": [
        "N L M\u00fcller",
        "C A Staples",
        "R R Miller"
    ],
    "related_topics": [
        "Bronchiolitis obliterans organizing pneumonia",
        "Bronchiolitis obliterans",
        "Pneumonia"
    ],
    "citation_count": "272",
    "reference_count": "0",
    "references": []
},{
    "id": "2041775285",
    "title": "Cryptogenic organizing pneumonia: CT findings in 43 patients.",
    "abstract": "Description of the CT findings of cryptogenic organizing pneumonia has been limited to a small number of cases. This study was performed to characterize the CT findings of this disease in a larger number of cases and to compare the findings in immunocompetent and immunocompromised patients.The CT scans of 43 (32 immunocompetent and 11 immunocompromised) patients who had biopsy-proved cryptogenic organizing pneumonia were reviewed. The scans were obtained by using contiguous 8- or 10-mm collimation and selected thin (1.5 or 2.0 mm) section (n = 23), thin-section collimation at 10-mm intervals (n = 12), or 8- or 10-mm collimation only (n = 8). The scans were analyzed by three observers, and final decisions were reached by consensus.The most common pattern seen was consolidation, which was present alone or as part of a mixed pattern in 34 cases (79%). The consolidation had a predominantly subpleural and/or peribronchovascular distribution in 27 cases (63%). Ground-glass attenuation and nodules were seen in 2...",
    "date": "1994",
    "authors": [
        "Kyung Soo Lee",
        "P. Kullnig",
        "T. E. Hartman",
        "N. L. M\u00fcller"
    ],
    "related_topics": [
        "Cryptogenic Organizing Pneumonia",
        "Pneumonia",
        "Bronchiolitis obliterans"
    ],
    "citation_count": "362",
    "reference_count": "7",
    "references": [
        "3025576394",
        "2022096221",
        "1977780478",
        "2157808430",
        "2086628290",
        "2161522565",
        "1973495495"
    ]
},{
    "id": "2132293969",
    "title": "Acute interstitial pneumonia: Radiographic and CT findings in nine patients",
    "abstract": "The radiologic findings were reviewed in nine patients with biopsy- or autopsy-proved acute interstitial pneumonia (AIP). All patients had bilateral air-space opacification on radiographs and bilateral, symmetric areas of ground-glass attenuation on computed tomographic (CT) scans. The areas of ground-glass attenuation had a patchy distribution in six patients (67%) and were diffuse in three patients. Air-space consolidation was seen at CT in six patients (67%) and involved mainly the lower lung zones in three patients and upper lung zones in one patient and was diffuse in two patients. A predominantly subpleural distribution of the consolidation was present in two patients. Eight of the nine patients died within 3 months of presentation. The authors conclude that the radiographic and CT features of AIP are similar to those of adult respiratory distress syndrome and represent acute alveolar damage. AIP differs from the more chronic forms of interstitial pneumonia in clinical presentation and in pathologic and radiologic findings.",
    "date": "1993",
    "authors": [
        "S L Primack",
        "T E Hartman",
        "J Ikezoe",
        "M Akira",
        "M Sakatani",
        "N L M\u00fcller"
    ],
    "related_topics": [
        "Acute Interstitial Pneumonia",
        "Diffuse alveolar damage",
        "Respiratory disease"
    ],
    "citation_count": "187",
    "reference_count": "0",
    "references": []
},{
    "id": "2047480444",
    "title": "Avoiding false positives with PCR",
    "abstract": "The exquisite sensitivity of the polymerase chain reaction means DNA contamination can ruin an entire experiment. Tidiness and adherence to a strict set of protocols can avoid disaster.",
    "date": "1989",
    "authors": [
        "S Kwok",
        "R Higuchi"
    ],
    "related_topics": [
        "False positive paradox",
        "DNA Contamination",
        "Polymerase chain reaction"
    ],
    "citation_count": "5,790",
    "reference_count": "7",
    "references": [
        "2032118018",
        "1517480469",
        "2063392648",
        "2056224227",
        "1969267177",
        "2058619857",
        "2004367648"
    ]
},{
    "id": "2131589770",
    "title": "Quantification of low-copy transcripts by continuous SYBR\u00ae Green I monitoring during amplification",
    "abstract": "Abstract Continuous fluorescence observation of amplifying DNA allows rapid and accurate quantification of initial transcript copy number. A simple and generic method for monitoring product synthesis with the double-stranded DNA dye, SYBR Green I provides initial template copy number estimation limited only by stochastic effects. To reach this degree of sensitivity, two methods were used. First, specific products generally have a higher melting temperature than nonspecific products, and therefore, specific product formation was monitored by fluorescence acquisition at temperatures at which only specific products are double-stranded. Second, anti-Taq antibodies were used to reduce nonspecific product generation. The log-linear portion of the fluorescence vs. cycle plot was extended to determine a fractional cycle number at which a threshold fluorescence was obtained. These fractional cycle numbers were plotted against the log of starting template copies to give linear standard curves from purified PCR products, allowing easy estimation of cDNA unknowns over a 10(6)-fold range. A single template molecule per reaction could be distinguished from the absence of template, although stochastic effects increased the variance of concentration estimates below 10 copies. Above 10 copies per reaction, typical replicate coefficients of variation were 6%-37%, with better precision at higher copy numbers.",
    "date": "1998",
    "authors": [
        "Tom B. Morrison",
        "Janis J. Weis",
        "Carl T. Wittwer"
    ],
    "related_topics": [
        "SYBR Green I",
        "Replicate",
        "Complementary DNA"
    ],
    "citation_count": "1,386",
    "reference_count": "0",
    "references": []
},{
    "id": "2137089963",
    "title": "Multiplex PCR: Optimization and Application in Diagnostic Virology",
    "abstract": "PCR has revolutionized the field of infectious disease diagnosis. To overcome the inherent disadvantage of cost and to improve the diagnostic capacity of the test, multiplex PCR, a variant of the test in which more than one target sequence is amplified using more than one pair of primers, has been developed. Multiplex PCRs to detect viral, bacterial, and/or other infectious agents in one reaction tube have been described. Early studies highlighted the obstacles that can jeopardize the production of sensitive and specific multiplex assays, but more recent studies have provided systematic protocols and technical improvements for simple test design. The most useful of these are the empirical choice of oligonucleotide primers and the use of hot start-based PCR methodology. These advances along with others to enhance sensitivity and specificity and to facilitate automation have resulted in the appearance of numerous publications regarding the application of multiplex PCR in the diagnosis of infectious agents, especially those which target viral nucleic acids. This article reviews the principles, optimization, and application of multiplex PCR for the detection of viruses of clinical and epidemiological importance.",
    "date": "2000",
    "authors": [
        "Elfath M. Elnifro",
        "Ahmed M. Ashshi",
        "Robert J. Cooper",
        "Paul E. Klapper"
    ],
    "related_topics": [
        "Multiplex",
        "Multiplex polymerase chain reaction",
        "Polymerase chain reaction"
    ],
    "citation_count": "989",
    "reference_count": "127",
    "references": [
        "2989345970",
        "2047480444",
        "2118537438",
        "2156465688",
        "2162578061",
        "1974590216",
        "2096298665",
        "2001278481",
        "2084507708",
        "2079112687"
    ]
},{
    "id": "2163760194",
    "title": "Ebola Hemorrhagic Fever in Kikwit, Democratic Republic of the Congo: Clinical Observations in 103 Patients",
    "abstract": "During the 1995 outbreak of Ebola hemorrhagic fever in the Democratic Republic of the Congo, a series of 103 cases (one-third of the total number of cases) had clinical symptoms and signs accurately recorded by medical workers, mainly in the setting of the urban hospital in Kikwit. Clinical diagnosis was confirmed retrospectively in cases for which serum samples were available (n = 63, 61% of the cases). The disease began unspecifically with fever, asthenia, diarrhea, headaches, myalgia, arthralgia, vomiting, and abdominal pain. Early inconsistent signs and symptoms included conjunctival injection, sore throat, and rash. Overall, bleeding signs were observed in <45% of the cases. Typically, terminally ill patients presented with obtundation, anuria, shock, tachypnea, and normothermia. Late manifestations, most frequently arthralgia and ocular diseases, occurred in convalescent patients. This series is the most extensive number of cases of Ebola hemorrhagic fever observed during an outbreak.",
    "date": "1999",
    "authors": [
        "Mpia A. Bwaka",
        "Marie-Jos\u00e9 Bonnet",
        "Philippe Calain",
        "Robert Colebunders",
        "Ann De Roo",
        "Yves Guimard",
        "Kasongo R. Katwiki",
        "Kapay Kibadi",
        "Mungala A. Kipasa",
        "Kivudi J. Kuvula",
        "Bwas B. Mapanda",
        "Matondo Massamba",
        "Kibadi D. Mupapa",
        "Jean-Jacques Muyembe-Tamfum",
        "Edouard Ndaberey",
        "Clarence J. Peters",
        "Pierre E. Rollin",
        "Erwin Van den Enden"
    ],
    "related_topics": [
        "Ebola Hemorrhagic Fever",
        "Headaches",
        "Sore throat"
    ],
    "citation_count": "560",
    "reference_count": "32",
    "references": [
        "2141568825",
        "2160047153",
        "1978996068",
        "2097378446",
        "1528877926",
        "2007655315",
        "2124521507",
        "643951684",
        "2169958312",
        "2133600490"
    ]
},{
    "id": "2134971582",
    "title": "Establishment of the First International Standard for Nucleic Acid Amplification Technology (NAT) Assays for HCV RNA",
    "abstract": "Background and Objectives: The aims of this study were the establishment of a WHO International standard for HCV RNA for nucleic acid amplification technology (NAT) assays and the d",
    "date": "1999",
    "authors": [
        "J. Saldanha",
        "N. Lelie",
        "A. Heath"
    ],
    "related_topics": [
        "Nucleic acid",
        "RNA",
        "Nat"
    ],
    "citation_count": "387",
    "reference_count": "6",
    "references": [
        "1977258390",
        "1997282583",
        "2064186866",
        "2069212870",
        "2052885167",
        "2137007796"
    ]
},{
    "id": "2171308211",
    "title": "Detection and Molecular Characterization of Ebola Viruses Causing Disease in Human and Nonhuman Primates",
    "abstract": "Ebola (EBO) viruses were detected in specimens obtained during the hemorrhagic fever outbreak among humans in Kikwit, Democratic Republic of the Congo (DRC), in 1995 (subtype Zaire) and during an outbreak of disease in cynomolgus macaques in Alice, Texas, and the Philippines in 1996 (subtype Reston). Reverse transcriptase-polymerase chain reaction assays were developed and proven effective for detecting viral RNA in body fluids and tissues of infected individuals. Little change was seen in the nucleotide or deduced amino acid sequences of the glycoprotein (GP) of these EBO virus subtypes compared with those of their original representatives (i.e., the 1976 Yambuku, DRC, EBO isolate [subtype Zaire] and the 1989 Philippines and Reston, Virginia, isolates [subtype Reston]). The nonstructural secreted GP (SGP), the primary product of the GP gene, was more highly conserved than the structural GP, indicating different functional roles or evolutionary constraints for these proteins. Significant amounts of SGP were detected in acutely infected humans.",
    "date": "1999",
    "authors": [
        "Anthony Sanchez",
        "Thomas G. Ksiazek",
        "Pierre E. Rollin",
        "Mary E. G. Miranda",
        "Sam G. Trappier",
        "Ali S. Khan",
        "Clarence J. Peters",
        "Stuart T. Nichol"
    ],
    "related_topics": [
        "Ebola virus",
        "Filoviridae",
        "Mononegavirales"
    ],
    "citation_count": "254",
    "reference_count": "14",
    "references": [
        "2131706225",
        "2160047153",
        "1978996068",
        "2097378446",
        "1969661655",
        "1825594680",
        "1993048073",
        "1995116321",
        "2014418657",
        "2084944660"
    ]
},{
    "id": "2798078005",
    "title": "Probit Analysis (3rd ed).",
    "abstract": "",
    "date": "1971",
    "authors": [
        "J. A. Lewis",
        "D. Finney"
    ],
    "related_topics": [
        "Probit model",
        "Econometrics",
        "Biology"
    ],
    "citation_count": "4,597",
    "reference_count": "0",
    "references": []
},{
    "id": "2055750915",
    "title": "Do antimicrobials increase the carriage rate of penicillin resistant pneumococci in children? Cross sectional prevalence study.",
    "abstract": "Abstract Objective: To study the correlation of antimicrobial consumption with the carriage rate of penicillin resistant and multiresistant pneumococci in children. Design: Cross sectional and analytical prevalence study. Setting: Five different communities in Iceland. Main outcome measure: Prevalence of nasopharyngeal carriage of penicillin resistant pneumococci in children aged under 7 years in relation to antibiotic use as determined by information from parents, patient9s records, and total sales of antimicrobials from local pharmacies in four study areas. Results: Total antimicrobial sales for children (6223 prescriptions) among the four areas for which data were available ranged from 9.6 to 23.2 defined daily doses per 1000 children daily (1.1 to 2.6 courses yearly per child). Children under 2 consumed twice as much as 2-6 year olds (20.5 v 10.9 defined daily doses per 1000 children daily). Nasopharyngeal specimens were obtained from 919 children, representing 15-38% of the peer population groups in the different areas. Pneumococci were carried by 484 (52.7%) of the children, 47 (9.7%) of the isolates being resistant to penicillin or multiresistant. By multivariate analysis age ( Conclusions: Antimicrobial use, with regard to both individual use and total antimicrobial consumption in the community, is strongly associated with nasopharyngeal carriage of penicillin resistant pneumococci in children. Control measures to reduce the prevalence of penicillin resistant pneumococci should include reducing the use of antimicrobials in community health care. Key messages Study of the carriage of penicillin resistant pneumococci in 919 children in five different com- munities clearly showed the association of anti- microbial use with the level of resistance Repeated antimicrobial treatment courses and selective antimicrobial pressure may be particular risks for carrying resistant pneumococci Reducing the usage of antimicrobials, especially in children, is likely to be effective in preventing or reducing the spread of penicillin resistant and multiresistant pneumococci",
    "date": "1996",
    "authors": [
        "Vilhjalmur A Arason",
        "Karl G Kristinsson",
        "Johann A Sigurdsson",
        "Gudrun Stefansdottir",
        "Sigvard Molstad",
        "Sigurdur Gudmundsson"
    ],
    "related_topics": [
        "Penicillin",
        "Population",
        "Carriage"
    ],
    "citation_count": "633",
    "reference_count": "24",
    "references": [
        "1973948212",
        "1833207062",
        "2166785990",
        "1980595924",
        "2051039256",
        "2318532494",
        "1987747972",
        "2148030279",
        "1977676376",
        "2335653734"
    ]
},{
    "id": "2337555053",
    "title": "Computed Tomographic Study of the Common Cold",
    "abstract": "Background Colds are common, but the abnormalities they produce in the nasal passages and sinus cavities have not been well defined. Methods We studied healthy adult volunteers with self-diagnosed colds of 48 to 96 hours' duration and obtained the following data: information on symptoms, computed tomographic (CT) studies of the nasal passages and sinuses, mucosal-transport times, measures of nasal-airway resistance, and viral-culture studies. Thirty-one subjects (mean age, 24 years) had complete evaluations, including CT scans, which were read without knowledge of the clinical data. An additional 79 subjects underwent the same evaluations, except the CT scans. Results Of the 31 subjects with CT scans, 24 (77 percent) had occlusion of the ethmoid infundibulum; 27 (87 percent) had abnormalities of one or both maxillary-sinus cavities; 20 (65 percent) had abnormalities of the ethmoid sinuses; 10 (32 percent) had abnormalities of the frontal sinuses; and 12 (39 percent) had abnormalities of the sphenoid sinus...",
    "date": "1994",
    "authors": [
        "Gwaltney Jm",
        "Phillips Cd",
        "Miller Rd",
        "Riker Dk"
    ],
    "related_topics": [
        "Sinus (anatomy)",
        "Occlusion",
        "Tomography"
    ],
    "citation_count": "851",
    "reference_count": "16",
    "references": [
        "1565923748",
        "2064919590",
        "50010349",
        "2171294198",
        "1968740719",
        "2081137492",
        "1993290685",
        "2047884381",
        "1997052614",
        "2413001142"
    ]
},{
    "id": "2098388207",
    "title": "Frequency and natural history of rhinovirus infections in adults during autumn.",
    "abstract": "Human rhinovirus (HRV) accounts for a significant portion of common-cold illness, with the peak incidence being in the early fall. Three hundred forty-six adults who had self-diagnosed colds of 48 h or less were enrolled in a study during September and October 1994 to determine the frequency and clinical course of HRV infections. Nasal wash specimens for viral culture and reverse transcription-PCR (RT-PCR) for HRV RNA and human coronavirus OC43 and 229E RNA detection were collected on enrollment, and participants recorded their symptoms twice daily for 14 days. Middle ear pressure (MEP) was measured with a digital tympanometer on days 1 and 7. Picornaviruses (224 HRV and 7 enterovirus isolates) were detected by culture in 67% (231 of 346) of the subjects. Among 114 samples negative by culture, HRV was detected by RT-PCR in 52 (46%) for an overall picornavirus infection rate of 82% (283 of 346 subjects). Among the remaining 62 negative samples, human coronavirus RNA was detected by RT-PCR in 5 patients, so that 288 (83%) of patients had documented viral infection. The first symptom noticed most often was sore throat (40%) in HRV culture- or PCR-positive patients and stuffy nose in HRV-negative patients (27%). No differences in symptom scores over time or in the presence of individual symptoms were noted between groups. The median duration of the cold episodes was 11 days in HRV culture-positive patients, 9.5 days in HRV RT-PCR-positive patients, and 11.5 days in HRV-negative patients. On enrollment, abnormal MEPs ( or = +100 mm of H2O) were found for 21% of HRV culture-positive patients, 14% of HRV RT-PCR-positive patients, and 10% of HRV-negative patients. No important differences in the clinical course of HRV culture-positive, HRV culture-negative and RT-PCR-positive, or HRV-negative colds were found. These results represent the highest frequency of virologically confirmed natural colds to date and document the importance of rhinoviruses as the cause of colds during fall months.",
    "date": "1997",
    "authors": [
        "E Arruda",
        "A Pitk\u00e4ranta",
        "T J Witek",
        "C A Doyle",
        "F G Hayden"
    ],
    "related_topics": [
        "Rhinovirus",
        "Common cold",
        "Pharyngitis"
    ],
    "citation_count": "385",
    "reference_count": "24",
    "references": [
        "1980185618",
        "1998342643",
        "1936311738",
        "2108308695",
        "2026871972",
        "1830634530",
        "2135637080",
        "2095531431",
        "2065366950",
        "2036923488"
    ]
},{
    "id": "163073849",
    "title": "Antibiotics and upper respiratory infection: do some folks think there is a cure for the common cold.",
    "abstract": "BACKGROUND Symptomatic treatment is the only recommended therapy for the uncomplicated \"common cold.\" The purpose of this study was to examine the use of antibiotics and other prescription medications for the common cold in a Medicaid population seen in ambulatory care settings. METHODS A cross-sectional sample of Kentucky Medicaid claims from July 1, 1993, through June 30, 1994, was analyzed. Subjects were patients seen in an ambulatory setting for the common cold, defined as acute nasopharyngitis. A total of 1439 individuals were seen for 2171 separate outpatient and emergency department encounters for the common cold. Outpatient visits accounted for 99% (2144) of the encounters. RESULTS Patients in 35% (752) of the encounters did not fill a prescription for medication, 6% (129) filled a prescription for an antihistamine or other symptomatic medication, and 60% (1290) filled a prescription for an antibiotic for the common cold. Nineteen different antibiotics, 54% of which were amoxicillin, were prescribed for the common cold. Less than 2% of the encounters had a secondary diagnosis of either acute sinusitis or otitis media. These encounters were not more likely than the total sample to receive antibiotics. Adults were more likely than children to receive an antibiotic (P<.001), and urban physicians were more likely than rural physicians to prescribe antibiotics (P=.02). A conservative estimate of the annual cost of antibiotic prescribing for the common cold in the United States was $37.5 million. CONCLUSIONS A majority of persons receiving medical care for the common cold are given prescriptions for an unnecessary antibiotic. Unchecked, this practice may lead to greater antibiotic resistance and unnecessary use of health care resources. Future research should focus on the ability to institute behavioral changes for treatment of the common cold in both closed systems (eg, managed care) and open systems (eg, general community of physicians).",
    "date": "1996",
    "authors": [
        "Arch G. Mainous",
        "William J. Hueston",
        "Jonathan R. Clark"
    ],
    "related_topics": [
        "Ambulatory care",
        "Medical prescription",
        "Common cold"
    ],
    "citation_count": "296",
    "reference_count": "0",
    "references": []
},{
    "id": "2032842024",
    "title": "Zinc Gluconate Lozenges for Treating the Common Cold: A Randomized, Double-Blind, Placebo-Controlled Study",
    "abstract": "Background : The common cold is one of the most frequent human illnesses and is responsible for substantial morbidity and economic loss. No consistently effective therapy for the common cold has been well documented, but evidence suggests that several possible mechanisms may make zinc an effective treatment. Objective : To test the efficacy of zinc gluconate lozenges in reducing the duration of symptoms caused by the common cold. Design : Randomized, double-blind, placebo-controlled study. Setting : Outpatient department of a large tertiary care center. Patients : 100 employees of the Cleveland Clinic who developed symptoms of the common cold within 24 hours before enrollment. Intervention : Patients in the zinc group (n = 50) received lozenges (one lozenge every 2 hours while awake) containing 13.3 mg of zinc from zinc gluconate as long as they had cold symptoms. Patients in the placebo group (n = 50) received similarly administered lozenges that contained 5% calcium lactate pentahydrate instead of zinc gluconate. Main Outcome Measures : Subjective daily symptom scores for cough, headache, hoarseness, muscle ache, nasal drainage, nasal congestion, scratchy throat, sore throat, sneezing, and fever (assessed by oral temperature). Results : The time to complete resolution of symptoms was significantly shorter in the zinc group than in the placebo group (median, 4.4 days compared with 7.6 days ; P< 0.001). The zinc group had significantly fewer days with coughing (median, 2.0 days compared with 4.5 days ; P= 0.04), headache (2.0 days and 3.0 days ; P = 0.02), hoarseness (2.0 days and 3.0 days ; P = 0.02), nasal congestion (4.0 days and 6.0 days ; P = 0.002), nasal drainage (4.0 days and 7.0 days ; P < 0.001), and sore throat (1.0 day and 3.0 days ; P < 0.001). The groups did not differ significantly in the resolution of fever, muscle ache, scratchy throat, or sneezing. More patients in the zinc group than in the placebo group had side effects (90% compared with 62% ; P < 0.001), nausea (20% compared with 4% ; P = 0.02), and bad-taste reactions (80% compared with 30% ; P < 0.001). Conclusion : Zinc gluconate in the form and dosage studied significantly reduced the duration of symptoms of the common cold. The mechanism of action of this substance in treating the common cold remains unknown. Individual patients must decide whether the possible beneficial effects of zinc gluconate on cold symptoms outweigh the possible adverse effects.",
    "date": "1996",
    "authors": [
        "S B Mossad",
        "M L Macknin",
        "S V Medendorp",
        "P Mason"
    ],
    "related_topics": [
        "Common cold",
        "Sore throat",
        "Outpatient clinic"
    ],
    "citation_count": "279",
    "reference_count": "0",
    "references": []
},{
    "id": "1856165804",
    "title": "Studies of the Community and Family: Acute Respiratory Illness and Infection",
    "abstract": "Studies of acute respiratory illnesses in families and their communities have been carried out for most of this century. The initial studies established the importance of these illnesses in terms of their frequency and severity. Age-specific illness rates and principles concerning disease transmission were documented in the period before identification of the etiologic agents. Since that time, the knowledge base has been expanded dramatically. Of all the viruses, rhinoviruses cause more illness of any severity than any other in all age groups. As a result, rates of rhinovirus-specific illnesses resemble those of all-cause respiratory illnesses. The greatest advantage of community-based studies is their ability to study transmission. Since control of infection for most of the agents has been difficult to achieve by conventional means, interruption of transmission should be examined as a possible alternative (97).",
    "date": "1993",
    "authors": [
        "Arnold S. Monto"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Transmission (medicine)",
        "Epidemiology"
    ],
    "citation_count": "276",
    "reference_count": "89",
    "references": [
        "1994119684",
        "2145445974",
        "2059684539",
        "2023194081",
        "2025391611",
        "2121744293",
        "2115517252",
        "2145230724",
        "2044860515",
        "2339962763"
    ]
},{
    "id": "2018812376",
    "title": "Effects of antibiotic treatment in the subset of common-cold patients who have bacteria in nasopharyngeal secretions",
    "abstract": "Abstract Summary Background Upper-respiratory-tract infection is one of the main causes of overuse of antibiotics. We have found previously that bacteria such as Haemophilus influenzae, Moraxella catarrhalis, and Streptococcus pneumoniae can be isolated from the nasopharyngeal secretions of a substantial proportion of adults with upper-respiratory-tract infections. We have assessed the efficacy of co-amoxiclav in patients with common colds but no clinical signs of sinusitis or other indications for antibiotics. Methods Between January, 1992, and March, 1994, 314 patients who presented to our outpatient clinic with common colds were enrolled in the double-blind, placebo-controlled study. They were randomly assigned 5 days' treatment with co-amoxiclav (375 mg three times daily) or identical placebo. Clinical examinations were done at enrolment and on day 5-7 to assess outcome (cured, persistent symptoms, worse symptoms). Seven patients were excluded after randomisation, seven did not have nasopharyngeal aspiration, and 12 did not return for follow-up assessment. Findings Of 300 patients with nasopharyngeal aspirates, 72 had negative bacterial cultures, 167 had cultures positive only for bacteria unrelated to respiratory infections, and 61 had cultures positive for H influenzae, M catarrhalis, or S pneumoniae . At 5-day follow-up of these culture-positive patients, the distribution of outcome was significantly better among co-amoxiclav-treated (n=30) than placebo-treated (n=28) patients (cured 27 vs 4%; persistent symptoms 70 vs 60%; worse symptoms 3 vs 36%; p=0\u00b7001). Patients on co-amoxiclav also scored their symptoms significantly lower than patients on placebo (p=0\u00b7008). Among culture-negative patients (n=230), the outcome distribution did not differ between the treatment groups (p=0\u00b7392). Interpretation The majority of patients with upper-respiratory-tract infection do not benefit from antibiotics and side-effects are frequent. However, for the subgroup whose nasopharyngeal secretions contain H influenzae, M catarrhalis, or S pneumoniae, antibiotics are clinically beneficial.",
    "date": "1996",
    "authors": [
        "L Kaiser",
        "D Lew",
        "B Hirschel",
        "R Auckenthaler",
        "A Morabia",
        "A Heald",
        "J Voegli",
        "H Stalder",
        "P Benedict",
        "F Terrier",
        "W Wunderli",
        "L Matter",
        "D Germann"
    ],
    "related_topics": [
        "Outpatient clinic",
        "Sinusitis",
        "Common cold"
    ],
    "citation_count": "233",
    "reference_count": "19",
    "references": [
        "2076983043",
        "1833207062",
        "1969595878",
        "2337555053",
        "2043257375",
        "2103091271",
        "2020215807",
        "2068094897",
        "2001418646",
        "1968740719"
    ]
},{
    "id": "2146133178",
    "title": "Primary-care-based randomised placebo-controlled trial of antibiotic treatment in acute maxillary sinusitis",
    "abstract": "Summary Background The value of antibiotics in acute rhinosinusitis is uncertain. Although maxillary sinusitis is commonly diagnosed and treated in general practice, no effectiveness studies have been done on unselected primary-care patients. We used a randomised, placebo-controlled design to test the hypothesis that there would be an improvement associated with amoxycillin treatment for acute maxillary sinusitis patients presenting to general practice. Methods Adult patients with suspected acute maxillary sinusitis were referred by general practitioners for radiographs of the maxillary sinus. Those with radiographic abnormalities (n=214) were randomly assigned treatment with amoxycillin (750 mg three times daily for 7 days; n=108) or placebo (n=106). Clinical course was assessed after 1 week and 2 weeks, and reported relapses and complications were recorded during the following year. Findings After 2 weeks, symptoms had improved substantially or disappeared in 83% of patients in the study group and 77% of patients taking placebo. Amoxycillin did not influence the clinical course of maxillary sinusitis nor the frequency of relapses during the 1-year follow-up. Radiographs had no prognostic value, nor were they an effect modifier. Side-effects were recorded in 28% of patients given amoxycillin and in 9% of those taking placebo (p vs 17%) during the follow-up year. Interpretation Antibiotic treatment did not improve the clinical course of acute maxillary sinusitis presenting to general practice. For these patients, an initial radiographic examination is not necessary and initial management can be limited to symptomatic treatment. Whether antibiotics are necessary in more severe cases warrants further study.",
    "date": "1997",
    "authors": [
        "F. L. Van Buchem",
        "J. A. Knottnerus",
        "V. J. J. Schrijnemaekers",
        "M. F. Peeters"
    ],
    "related_topics": [
        "Sinusitis",
        "Placebo-controlled study",
        "Maxillary sinus"
    ],
    "citation_count": "278",
    "reference_count": "13",
    "references": [
        "2337555053",
        "2018812376",
        "2163113134",
        "2324030906",
        "2153494006",
        "2394589111",
        "2057800579",
        "1978537960",
        "2074678330",
        "2081628914"
    ]
},{
    "id": "1830634530",
    "title": "Detection of enteroviruses and rhinoviruses in clinical specimens by PCR and liquid-phase hybridization.",
    "abstract": "A sensitive method based on PCR followed by liquid-phase hybridization for detection of enterovirus and rhinovirus RNAs in clinical specimens and cell culture supernatants is described. RNA was extracted from stool samples, throat swabs, nasopharyngeal aspirates, cerebrospinal fluid, urine, and plasma with a commercial phenol-guanidinium-chloroform reagent and purified on a polysulfone membrane, on which the reverse transcriptase reaction was also done. Two sets of oligonucleotide primers from the 5' noncoding region of picornaviruses were selected for DNA amplification of 153-bp (enterovirus) and 120-bp (rhinovirus) regions. Double-stranded amplicons were digested into single strands with T7 gene 6 exonuclease and quantitated by an assay using a europium-labeled probe, streptavidin- and biotinylated probe-coated microtitration wells, and time-resolved fluorometry. The sensitivity of the assay was about one template molecule when purified coxsackievirus A9 RNA was used. All enterovirus prototype strains, except echoviruses 22 and 23, and clinical isolates grown in cell culture or suckling mice were strongly positive by the enterovirus PCR-hybridization, as were selected prototype strains and untyped isolates of rhinoviruses by the rhinovirus PCR-hybridization. In a series of 100 clinical specimens tested, the results for 92 agreed with virus culture results. The detection method described will be useful in etiopathogenic studies on enteroviruses and rhinoviruses.",
    "date": "1995",
    "authors": [
        "P Halonen",
        "E Rocha",
        "J Hierholzer",
        "B Holloway",
        "T Hyypi\u00e4",
        "P Hurskainen",
        "M Pallansch"
    ],
    "related_topics": [
        "Echovirus",
        "Enterovirus",
        "Rhinovirus"
    ],
    "citation_count": "179",
    "reference_count": "35",
    "references": [
        "2035792726",
        "1936311738",
        "1515242323",
        "1735834838",
        "2076862415",
        "1996006630",
        "2135637080",
        "1590324651",
        "1486765837",
        "2095531431"
    ]
},{
    "id": "1699035432",
    "title": "Rapid diagnosis of respiratory syncytial virus infections in immunocompromised adults.",
    "abstract": "Although rapid antigen detection methods for the documentation of respiratory syncytial virus (RSV) infections are widely used with pediatric patients, these tests have not been prospectively evaluated in immunocompromised (IC) adults. For bone marrow transplant recipients and adult patients undergoing chemotherapy for leukemia who had recent onset of respiratory symptoms, respiratory samples (combined nasal wash [NW]-throat swab [TS], endotracheal tube [ET] aspirate, or bronchoalveolar lavage [BAL] samples) were collected for simultaneous culture and rapid antigen detection with the Directigen test kit (Becton Dickinson, Cockeysville, Md.). NW specimens from hospitalized pediatric patients with suspected RSV infection were also evaluated. Viral quantitation was performed on aliquots of the original specimens. A total of 539 samples from 372 adult patients were evaluated. RSV was isolated from 56 specimens (40 NW-TS, 7 ET aspirate, and 9 BAL specimens). By using culture as the \"gold standard,\" rapid antigen detection had a sensitivity of 15% for adult NW-TS specimens, 71.4% for ET aspirate specimens, and 88.9% for BAL specimens; the specificity was > or = 97% for all specimen types. Significantly greater viral quantities were present in pediatric NW specimens than in adult NW specimens. In adults, more virus was present in BAL and ET aspirate specimens than in NW-TS specimens. Rapid detection of antigen respiratory samples obtained from the lower respiratory tracts of IC adults is sensitive and specific, but detection in upper respiratory tract samples is insensitive. The lower sensitivity of antigen detection in NW-TS specimens may be due to decreased viral load. A BAL specimen is more sensitive than an NW-TS specimen for the rapid diagnosis of RSV disease in IC adults.",
    "date": "1996",
    "authors": [
        "J A Englund",
        "P A Piedra",
        "A Jewell",
        "K Patel",
        "B B Baxter",
        "E Whimbey"
    ],
    "related_topics": [
        "Becton dickinson",
        "Viral load",
        "Respiratory disease"
    ],
    "citation_count": "193",
    "reference_count": "17",
    "references": [
        "2076770315",
        "2122536566",
        "111873078",
        "2155757329",
        "2142623363",
        "1831139827",
        "2006371327",
        "1768102247",
        "2050838429",
        "1996218943"
    ]
},{
    "id": "2134812217",
    "title": "Single-step method of RNA isolation by acid guanidinium thiocyanate-phenol-chloroform extraction",
    "abstract": "A new method of total RNA isolation by a single extraction with an acid guanidinium thiocyanate-phenol-chloroform mixture is described. The method provides a pure preparation of undegraded RNA in high yield and can be completed within 4 h. It is particularly useful for processing large numbers of samples and for isolation of RNA from minute quantities of cells or tissue samples.",
    "date": "1987",
    "authors": [
        "Piotr Chomczynski",
        "Nicoletta Sacchi"
    ],
    "related_topics": [
        "Acid guanidinium thiocyanate-phenol-chloroform extraction",
        "Guanidinium thiocyanate",
        "RNA extraction"
    ],
    "citation_count": "76,615",
    "reference_count": "10",
    "references": [
        "2060333964",
        "2057885570",
        "2071429697",
        "1969190934",
        "1967346650",
        "188926460",
        "2154347114",
        "1906197854",
        "1974848291",
        "1935984619"
    ]
},{
    "id": "2009310436",
    "title": "A comprehensive set of sequence analysis programs for the VAX",
    "abstract": "The University of Wisconsin Genetics Computer Group (UWGCG) has been organized to develop computational tools for the analysis and publication of biological sequence data. A group of programs that will interact with each other has been developed for the Digital Equipment Corporation VAX computer using the VMS operating system. The programs available and the conditions for transfer are described.",
    "date": "1984",
    "authors": [
        "John Devereux",
        "Paul Haeberli",
        "Oliver Smithies"
    ],
    "related_topics": [
        "Type IV pilus biogenesis",
        "Software",
        "Set (abstract data type)"
    ],
    "citation_count": "21,583",
    "reference_count": "10",
    "references": [
        "2074231493",
        "2025763720",
        "2052503008",
        "2048124712",
        "2027059027",
        "1987809783",
        "1982743354",
        "2069630430",
        "2032215335",
        "2169766521"
    ]
},{
    "id": "132455992",
    "title": "Nidovirales: a new order comprising Coronaviridae and Arteriviridae.",
    "abstract": "",
    "date": "1996",
    "authors": [
        "Cavanagh D"
    ],
    "related_topics": [
        "Torovirus",
        "Nidovirales",
        "Coronaviridae"
    ],
    "citation_count": "1,786",
    "reference_count": "0",
    "references": []
},{
    "id": "2156596665",
    "title": "Identification and Assessment Of Known And Novel Human Papillomaviruses by Polymerase Chain Reaction Amplification, Restriction Fragment Length Polymorphisms, Nucleotide Sequence, and Phylogenetic Algorithms",
    "abstract": "The identification and taxonomy of papillomaviruses has become increasingly complex, as approximately 70 human papillomavirus (HPV) types have been described and novel HPV genomes continue to be identified. Methods and corresponding DNA sequence data bases were designed for the reliable identification of mucosal HPV genomes from clinical specimens. HPVs are identified by the amplification of a fragment of the L1 region by consensus primer polymerase chain reaction (PCR) and subsequent hybridization or restriction fragment length polymorphism analysis. L1 PCR fragments may be further characterized by nucleotide sequencing. Conservation of 30 (of 151) predicted amino acids identifies HPV genomic fragments, and nucleotide sequence alignments allow calculation of their phylogenetic relatedness. Sequence differences > 10% from any known HPV type suggest a novel HPV type. Phylogenetic relationships with known HPV types may permit predictions of biology. With these criteria, 10 PCR fragments were identified that would qualify as new genital HPV types after complete genomic isolation.",
    "date": "1994",
    "authors": [
        "Hans-Ulrich Bernard",
        "Shih-Yen Chan",
        "M. Michele Manos",
        "Chi-Keong Ong",
        "Luisa L. Villa",
        "Hajo Delius",
        "Cheri L. Peyton",
        "Heidi M. Bauer",
        "Cosette M. Wheeler"
    ],
    "related_topics": [
        "Inverse polymerase chain reaction",
        "Multiple displacement amplification",
        "Restriction fragment length polymorphism"
    ],
    "citation_count": "524",
    "reference_count": "19",
    "references": [
        "2030966943",
        "2120655585",
        "2969431143",
        "2125748368",
        "1500130815",
        "2485235476",
        "2114405603",
        "1567506364",
        "1562069246",
        "1729854193"
    ]
},{
    "id": "1582561043",
    "title": "Identification of four conserved motifs among the RNA-dependent polymerase encoding elements.",
    "abstract": "Four consensus sequences are conserved with the same linear arrangement in RNA-dependent DNA polymerases encoded by retroid elements and in RNA-dependent RNA polymerases encoded by plus-, minus- and double-strand RNA viruses. One of these motifs corresponds to the YGDD span previously described by Kamer and Argos (1984). These consensus sequences altogether lead to 4 strictly and 18 conservatively maintained amino acids embedded in a large domain of 120 to 210 amino acids. As judged from secondary structure predictions, each of the 4 motifs, which may cooperate to form a well-ordered domain, places one invariant amino acid in or proximal to turn structures that may be crucial for their correct positioning in a catalytic process. We suggest that this domain may constitute a prerequisite 'polymerase module' implicated in template seating and polymerase activity. At the evolutionary level, the sequence similarities, gap distribution and distances between each motif strongly suggest that the ancestral polymerase module was encoded by an individual genetic element which was most closely related to the plus-strand RNA viruses and the non-viral retroposons. This polymerase module gene may have subsequently propagated in the viral kingdom by distinct gene set recombination events leading to the wide viral variety observed today.",
    "date": "1989",
    "authors": [
        "O Poch",
        "I Sauvaget",
        "M Delarue",
        "N Tordo"
    ],
    "related_topics": [
        "Polymerase",
        "Consensus sequence",
        "RNA"
    ],
    "citation_count": "1,387",
    "reference_count": "97",
    "references": [
        "2009310436",
        "2074231493",
        "1969051510",
        "1542067597",
        "2095450147",
        "2117149353",
        "2059910556",
        "1981906666",
        "2027598863",
        "1997110527"
    ]
},{
    "id": "2149495938",
    "title": "Equine arteritis virus is not a togavirus but belongs to the coronaviruslike superfamily.",
    "abstract": "The nucleotide sequence of the genome of equine arteritis virus (EAV) was determined from a set of overlapping cDNA clones and was found to contain eight open reading frames (ORFs). ORFs 2 through 7 are expressed from six 3'-coterminal subgenomic mRNAs, which are transcribed from the 3'-terminal quarter of the viral genome. A number of these ORFs are predicted to encode structural EAV proteins. The organization and expression of the 3' part of the EAV genome are remarkably similar to those of coronaviruses and toroviruses. The 5'-terminal three-quarters of the genome contain the putative EAV polymerase gene, which also shares a number of features with the corresponding gene of corona- and toroviruses. The gene contains two large ORFs, ORF1a and ORF1b, with an overlap region of 19 nucleotides. The presence of a \"shifty\" heptanucleotide sequence in this region and a downstream RNA pseudoknot structure indicate that ORF1b is probably expressed by ribosomal frameshifting. The frameshift-directing potential of the ORF1a/ORF1b overlap region was demonstrated by using a reporter gene. Moreover, the predicted ORF1b product was found to contain four domains which have been identified in the same relative positions in coronavirus and torovirus ORF1b products. The sequences of the EAV and coronavirus ORF1a proteins were found to be much more diverged. The EAV ORF1a product contains a putative trypsinlike serine protease motif. Our data indicate that EAV, presently considered a togavirus, is evolutionarily related to viruses from the coronaviruslike superfamily.",
    "date": "1991",
    "authors": [
        "J. A. Den Boon",
        "E. J. Snijder",
        "E. D. Chirnside",
        "A. A. F. De Vries",
        "M. C. Horzinek",
        "W. J. M. Spaan"
    ],
    "related_topics": [
        "ORFS",
        "Genomic organization",
        "Nucleic acid sequence"
    ],
    "citation_count": "505",
    "reference_count": "0",
    "references": []
},{
    "id": "2087363345",
    "title": "The complete sequence (22 kilobases) of murine coronavirus gene 1 encoding the putative proteases and RNA polymerase.",
    "abstract": "The 5'-most gene, gene 1, of the genome of murine coronavirus, mouse hepatitis virus (MHV), is presumed to encode the viral RNA-dependent RNA polymerase. We have determined the complete sequence of this gene of the JHM strain by cDNA cloning and sequencing. The total length of this gene is 21,798 nucleotides long, which includes two overlapping, large open reading frames. The first open reading frame, ORF 1a, is 4488 amino acids long. The second open reading frame, ORF 1b, overlaps ORF 1a for 75 nucleotides, and is 2731 amino acids long. The overlapping region may fold into a pseudoknot RNA structure, similar to the corresponding region of the RNA of avian coronavirus, infectious bronchitis virus (IBV). The in vitro transcription and translation studies of this region indicated that these two ORFs were most likely translated into one polyprotein by a ribosomal frameshifting mechanism. Thus, the predicted molecular weight of the gene 1 product is more than 800,000 Da. The sequence of ORF 1b is very similar to the corresponding ORF of IBV. In contrast, the ORF 1a of these two viruses differ in size and have a high degree of divergence. The amino acid sequence analysis suggested that ORF 1a contains several functional domains, including two hydrophobic, membrane-anchoring domains, and three cysteine-rich domains. It also contains a picornaviral 3C-like protease domain and two papain-like protease domains. The presence of these protease domains suggests that the polyprotein is most likely processed into multiple protein products. In contrast, the ORF 1b contains polymerase, helicase, and zinc-finger motifs. These sequence studies suggested that the MHV gene 1 product is involved in RNA synthesis, and that this product is processed autoproteolytically after translation. This study completes the sequence of the MHV genome, which is 31 kb long, and constitutes the largest viral RNA known.",
    "date": "1991",
    "authors": [
        "Han-Jung Lee",
        "Chien-Kou Shieh",
        "Alexander E. Gorbalenya",
        "Eugene V. Koonin",
        "Nicola La Monica",
        "Jeremy Tuler",
        "Anush Bagdzhadzhyan",
        "Michael M.C. Lai"
    ],
    "related_topics": [
        "Open reading frame",
        "Nucleic acid sequence",
        "RNA"
    ],
    "citation_count": "385",
    "reference_count": "53",
    "references": [
        "2032118018",
        "2138270253",
        "2009310436",
        "1975304761",
        "1558516755",
        "2282054059",
        "2091239909",
        "2034767282",
        "2025450446",
        "751697167"
    ]
},{
    "id": "2329318335",
    "title": "Antigenic Characterization of a Turkey Coronavirus Identified in Poult Enteritis- and Mortality Syndrome-Affected Turkeys",
    "abstract": "SUMMARY. A turkey coronavirus (TCV [NC95]) was characterized by antigenic comparison with other avian and mammalian coronaviruses using immunofluorescence (FA) and immunoperoxidase (IP) procedures. Based on FA and IP procedures, TCV (NC95) was determined to be antigenically indistinguishable from turkey enteric (bluecomb) coronavirus (TECV). In addition, TCV (NC95) and TECV were found to be closely related to infectious bronchitis virus (IBV); a one-way antigenic relationship was demonstrated. Polyclonal antibodies specific for TECV and IBV reacted strongly against TCV (NC95), as determined by FA procedures. Monoclonal antibodies (MAbs) specific for IBV matrix protein (MAb 919) reacted strongly against TCV (NC95) and TECV as determined by FA and IP procedures; an IBV peplomer protein-specific MAb (MAb 94) did not recognize the two viruses. These studies suggest an identification of TCV (NC95) as a strain of TECV, and provide evidence of a close antigenic relationship between these viruses and IBV.",
    "date": "1997",
    "authors": [
        "Guy Js",
        "Barnes Hj",
        "Smith Lg",
        "Breslin J"
    ],
    "related_topics": [
        "Turkey coronavirus",
        "Coronavirus",
        "Peplomer"
    ],
    "citation_count": "123",
    "reference_count": "11",
    "references": [
        "568872722",
        "1409028342",
        "2050147900",
        "1527662113",
        "2035706567",
        "207632116",
        "1996600982",
        "2327789625",
        "2320382456",
        "2312625356"
    ]
},{
    "id": "3011200155",
    "title": "The Coronaviridae: An Introduction",
    "abstract": "",
    "date": "1994",
    "authors": [
        "Stuart G. Siddell"
    ],
    "related_topics": [
        "Coronaviridae",
        "Biology",
        "Virology"
    ],
    "citation_count": "157",
    "reference_count": "11",
    "references": [
        "2097706568",
        "2106258670",
        "2153127922",
        "2055757365",
        "2110414335",
        "2049526168",
        "1527662113",
        "1985916880",
        "2027910008",
        "2035920610"
    ]
},{
    "id": "1994193749",
    "title": "Completion of the sequence of the genome of the coronavirus avian infectious bronchitis virus.",
    "abstract": "The nucleotide sequence determination of the genome of the Beaudette strain of the coronavirus avian infectious bronchitis virus (IBV) has been completed. The complete sequence has been obtained from 17 overlapping cDNA clones, the 5'-most of which contains the leader sequence (as determined by direct sequencing of the genome) and the 3'-most of which contains the poly(A) tail. Approximately 8 kilobases at the 3' end of this sequence have already been published. These contain the sequences of mRNAs A to E within which are the genes for the spike, the membrane and the nucleocapsid polypeptides: the main structural components of the virion. The remainder of the sequence, equivalent to the 'unique' region of mRNA F, is some 20 kilobases in length and is thought to code for a polymerase or polymerases which are involved in the replication of the genome and the production of the subgenomic messenger RNAs. This sequence contains two large open reading frames, potentially coding for polypeptides of molecular weights 441,000 and 300,000. Unlike other large open reading frames in the virus, the 300,000 open reading frame appears to have no subgenomic RNA associated with it which would allow it to be at the 5' end of an mRNA species. Because of this, and because of the characteristics of the sequence in the region immediately upstream of its start codon, other mechanisms of translation, such as ribosome slippage, must be postulated.",
    "date": "1986",
    "authors": [
        "M. E. G. Boursnell",
        "T. D. K. Brown",
        "I. J. Foulds",
        "P. F. Green",
        "F. M. Tomley",
        "M. M. Binns"
    ],
    "related_topics": [
        "Consensus sequence",
        "Nucleic acid sequence",
        "Complete sequence"
    ],
    "citation_count": "547",
    "reference_count": "61",
    "references": [
        "2138270253",
        "2009310436",
        "2063450941",
        "1975304761",
        "1558516755",
        "2029195137",
        "2014689788",
        "2061057528",
        "1980680467",
        "2132897827"
    ]
},{
    "id": "2154128645",
    "title": "Point mutations define a sequence flanking the AUG initiator codon that modulates translation by eukaryotic ribosomes.",
    "abstract": "By analyzing the effects of single base substitutions around the ATG initiator codon in a cloned preproinsulin gene, I have identified ACCATGG as the optimal sequence for initiation by eukaryotic ribosomes. Mutations within that sequence modulate the yield of proinsulin over a 20-fold range. A purine in position -3 (i.e., 3 nucleotides upstream from the ATG codon) has a dominant effect; when a pyrimidine replaces the purine in position -3, translation becomes more sensitive to changes in positions -1, -2, and +4. Single base substitutions around an upstream, out-of-frame ATG codon affect the efficiency with which it acts as a barrier to initiating at the downstream start site for preproinsulin. The optimal sequence for initiation defined by mutagenesis is identical to the consensus sequence that emerged previously from surveys of translational start sites in eukaryotic mRNAs. The mechanism by which nucleotides flanking the ATG codon might exert their effect is discussed.",
    "date": "1986",
    "authors": [
        "Marilyn Kozak"
    ],
    "related_topics": [
        "Leaky scanning",
        "Start codon",
        "Shine-Dalgarno sequence"
    ],
    "citation_count": "6,801",
    "reference_count": "45",
    "references": [
        "1558516755",
        "2078119356",
        "2009105413",
        "2088167128",
        "2020828649",
        "2132897827",
        "1998162329",
        "2170293208",
        "1751218746",
        "2039034666"
    ]
},{
    "id": "1967150940",
    "title": "Phylogenetic Analysis of theArenaviridae:Patterns of Virus Evolution and Evidence for Cospeciation between Arenaviruses and Their Rodent Hosts\u2606\u2606\u2606",
    "abstract": "Abstract Viruses of theArenaviridaecause hemorrhagic fevers and neurologic disease in humans. Historically, the arenaviruses have been divided into two complexes (LASV-LCMV, Tacaribe) through the use of antigenic typing. The phylogeny of theArenaviridaeas a whole has not been estimated previously due to a lack of sequence data for all members of the family. In this study, nucleocapsid protein gene sequence data were obtained for all currently known arenaviruses and used to estimate, for the first time, a phylogeny of the entire virus family. The LCMV-LASV complex arenaviruses are monophyletic and comprise three distinct lineages. The Tacaribe complex viruses also are monophyletic and occupy three distinct lineages. Comparisons of arenavirus phylogeny with rodent host phylogeny and taxonomic relationships provide several examples in which virus\u2013host cospeciation is potentially occurring. The pathogenic arenaviruses do not appear to be monophyletic, suggesting that the pathogenic phenotype has arisen in multiple independent events during virus evolution.",
    "date": "1997",
    "authors": [
        "Michael D Bowen",
        "Clarence J Peters",
        "Stuart T Nichol"
    ],
    "related_topics": [
        "Tacaribe Complex Virus",
        "Arenavirus",
        "Viral evolution"
    ],
    "citation_count": "262",
    "reference_count": "49",
    "references": [
        "2030966943",
        "1522592213",
        "2065461553",
        "2037667459",
        "2086920518",
        "1990263013",
        "1989841259",
        "2086178730",
        "2113499434",
        "2138694080"
    ]
},{
    "id": "2044967254",
    "title": "Increased neurovirulence associated with a single nucleotide change in a noncoding region of the Sabin type 3 poliovaccine genome",
    "abstract": "Most of the small number of cases of poliomyelitis which occur in countries where Sabin's attenuated poliovirus vaccines are used are temporally associated with administration of vaccine and involve polioviruses of types 2 and 3 (ref. 1). Recent studies have provided convincing evidence that the Sabin type 2 and 3 viruses themselves may revert to a neurovirulent phenotype on passage in man2\u20136. We report here that a point mutation in the 5\u2032 noncoding region of the genome of the poliovirus type 3 vaccine consistently reverts to wild type in strains isolated from cases of vaccine-associated poliomyelitis. Virus with this change is rapidly selected on passage through the human gastrointestinal tract. The change is associated with a demonstrable increase in the neurovirulence of the virus.",
    "date": "1985",
    "authors": [
        "D. M. A. Evans",
        "G. Dunn",
        "P. D. Minor",
        "G. C. Schild",
        "A. J. Cann",
        "G. Stanway",
        "J. W. Almond",
        "K. Currey",
        "J. V. Maizel"
    ],
    "related_topics": [
        "Poliovirus",
        "Enterovirus",
        "Virus"
    ],
    "citation_count": "485",
    "reference_count": "15",
    "references": [
        "2138270253",
        "1570828652",
        "2081231862",
        "1991624039",
        "2017367016",
        "2019910194",
        "1984776359",
        "2030583381",
        "2032360710",
        "1583790259"
    ]
},{
    "id": "2163443142",
    "title": "A Case-Control Study of the Clinical Diagnosis and Course of Lassa Fever",
    "abstract": "A prospective case-control study of Lassa fever was established in Sierra Leone to measure the frequency and case-fatality ratio of Lassa fever among febrile hospital admissions and to better delineate the clinical diagnosis and course of this disease. Lassa fever was responsible for 10%-16% of all adult medical admissions and for approximately 30% of adult deaths in the two hospitals studied. The case-fatality ratio for 441 hospitalized patients was 16.5%. We found the best predictor of Lassa fever to be the combination of fever, pharyngitis, retrosternal pain, and proteinuria (predictive value together, .81); of outcome, the best predictor was the combination of fever, sore throat, and vomiting (relative risk of death, 5.5). Complications included mucosal bleeding (17%), bilateral or unilateral eighth-nerve deafness (4%), and pleural (3%) or pericardial (2%) effusion. Lassa fever is endemic in this area and is a more-common cause of hospital admission and death than has previously been described; this disease must be considered when diagnosing febrile illness in West Africa.",
    "date": "1987",
    "authors": [
        "Joseph B. McCormick",
        "Isabel J. King",
        "Patricia A. Webb",
        "Karl M. Johnson",
        "Renie O'Sullivan",
        "Ethleen S. Smith",
        "Sally Trippel",
        "Tony C. Tong"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Pharyngitis"
    ],
    "citation_count": "415",
    "reference_count": "17",
    "references": [
        "2294550615",
        "1554701668",
        "2153476503",
        "1543288877",
        "2138694080",
        "1509033271",
        "2217227839",
        "2082214627",
        "1808337354",
        "2169304392"
    ]
},{
    "id": "1845818816",
    "title": "Early diagnosis of Lassa fever by reverse transcription-PCR.",
    "abstract": "We developed a method based on a coupled reverse transcription-PCR (RT-PCR) for the detection of Lassa virus using primers specific for regions of the S RNA segment which are well conserved between isolates from Sierra Leone, Liberia, and Nigeria. The specificity of the assay was confirmed by Southern blotting with a chemiluminescent probe. The assay was able to detect 1 to 10 copies of a plasmid or an RNA transcript containing the target sequence. There was complete concordance between RT-PCR and virus culture for the detection of Lassa virus in a set of 29 positive and 32 negative serum samples obtained on admission to the hospital from patients suspected of having Lassa fever in Sierra Leone. Specificity was confirmed by the failure of amplification of specific products from serum samples collected from 129 healthy blood donors in Sierra Leone or from tissue culture supernatants from cells infected with related arenaviruses (Mopeia, lymphocytic choriomeningitis, Tacaribe, and Pichinde viruses). Sequential serum samples from 29 hospitalized patients confirmed to have Lassa fever were tested by RT-PCR and for Lassa virus-specific antibodies by indirect immunofluorescence (IF). RT-PCR detected virus RNA in 79% of the patients at the time of admission, comparing favorably with IF, which detected antibodies in only 21% of the patients. Lassa virus RNA was detected by RT-PCR in all 29 patients by the third day of admission, whereas antibody was detectable by IF in only 52% of the patients. These results point to an important role for RT-PCR in the management of suspected cases of Lassa fever.",
    "date": "1994",
    "authors": [
        "A. H. Demby",
        "J. Chamberlain",
        "D. W. G. Brown",
        "C. S. Clegg"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Sierra leone"
    ],
    "citation_count": "153",
    "reference_count": "19",
    "references": [
        "2166229810",
        "1543288877",
        "2138694080",
        "2084892947",
        "2163443142",
        "2132877371",
        "2065071934",
        "1509033271",
        "2217227839",
        "2401708905"
    ]
},{
    "id": "2326037208",
    "title": "Lassa fever in the United States. Investigation of a case and new guidelines for management.",
    "abstract": "LASSA fever, first identified in northeastern Nigeria in 1969,1 is endemic in much of western Africa. Mastomys natalensis, a rat that is common around human habitations in the region, is the host of enzootic Lassa fever virus.2 The virus is spread to humans primarily through the urine of infected rats and is also transmissible from person to person. Its incubation period ranges from 7 to 18 days.3 Lassa fever virus may cause as many as 300,000 human infections and 5000 deaths per year in areas where the disease is endemic.4 Lassa fever is infrequently encountered in areas where the disease . . .",
    "date": "1990",
    "authors": [
        "Gary P. Holmes",
        "Joseph B. McCormick",
        "Susan C. Trock",
        "Robert A. Chase",
        "Steven M. Lewis",
        "Carol A. Mason",
        "Patricia A. Hall",
        "Lynnette S. Brammer",
        "Gilda I. Perez-Oronoz",
        "Mary Kay McDonnell",
        "James P. Paulissen",
        "Lawrence B. Schonberger",
        "Susan P. Fisher-Hoch"
    ],
    "related_topics": [
        "Lassa fever",
        "Enzootic",
        "Ribavirin"
    ],
    "citation_count": "187",
    "reference_count": "10",
    "references": [
        "1543288877",
        "2138694080",
        "2163443142",
        "1509033271",
        "2036374965",
        "2004019452",
        "1984191997",
        "2017658729",
        "1968761793",
        "2313368330"
    ]
},{
    "id": "2109638242",
    "title": "Characterization of Human CD4+ T-Cell Clones Recognizing Conserved and Variable Epitopes of the Lassa Virus Nucleoprotein",
    "abstract": "Lassa virus is a negative-strand RNA virus belonging to the family Arenaviridae. It is the causative agent of Lassa fever, a reemerging viral hemorrhagic fever, which accounts for significant human morbidity in regions of endemicity in western Africa, with approximately 300,000 to 500,000 infections occurring each year (20). An estimated 30% of infections are symptomatic, and the clinical picture ranges from flu-like illness to fulminant hemorrhagic fever with an overall mortality of 10 to 15% (19). Humans recover from acute Lassa fever in the absence of a measurable neutralizing (N) antibody response (12). Low-titer N antibodies develop only late in convalescence (9, 28) and preferentially neutralize Lassa virus strains isolated in the same geographical region (9). Their role in protection from reinfection is presently not clear. Lassa virus reinfections presumably occur without clinically overt disease, as suggested by prospective seroprevalence studies in areas of endemicity (20). However, more clinical and virological data on this issue are needed. Attempts to vaccinate against Lassa fever in animal models, including nonhuman primates, have revealed that eliciting a strong cellular immune response protects from clinical disease, but not from infection, in the absence of measurable N antibodies (reviewed in reference 4). Even after challenge the animals developed only a very low-titer N antibody response. It was shown in the guinea pig model that infection with heterologous arenaviruses of low pathogenicity confers protection against challenge with highly virulent Lassa virus strains (10). This immunity could be passed on to naive animals only by syngeneic transfer of CD8+ cytotoxic T lymphocytes (CTLs) obtained in the early phase of convalescence. Evidence for an important role for CD4+ cells in protection comes from an experiment in which vaccination of mice with recombinant vaccinia virus-Lassa virus constructs elicited a response consisting of CD4+ CTLs, which protected the animals from infection with lymphocytic choriomeningitis virus (LCMV), in the absence of N antibodies (16). The role of Lassa virus-specific CD4+ and CD8+ cells has to date not been evaluated in human disease. As cellular immunity is associated with recovery in the natural course of Lassa fever and is essential in the setting of experimental vaccines, we were interested in investigating T-cell responses of persons from areas of endemicity who were exposed to the virus. Because the structural proteins from Lassa virus strains differ by up to 10 to 15% in their amino acid sequences, with only the strains Josiah (JOS) and Nigeria (NIG) having been sequenced completely to date, we placed a special emphasis on the question of whether naturally acquired immunity was cross-protective against different Lassa virus strains.",
    "date": "2000",
    "authors": [
        "Jan ter Meulen",
        "Marlis Badusche",
        "Kristiane Kuhnt",
        "Andrea Doetze",
        "Judith Satoguina",
        "Thomas Marti",
        "Cornelius Loeliger",
        "Kekoura Koulemou",
        "Lamine Koivogui",
        "Herbert Schmitz",
        "Bernhard Fleischer",
        "Achim Hoerauf"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Viral hemorrhagic fever"
    ],
    "citation_count": "112",
    "reference_count": "33",
    "references": [
        "2069340283",
        "2150492554",
        "2041218370",
        "2155025120",
        "1760886018",
        "1483035379",
        "1993027018",
        "2138694080",
        "2116525981",
        "2144304716"
    ]
},{
    "id": "1941129807",
    "title": "Detection of Lassa Virus Antinucleoprotein Immunoglobulin G (IgG) and IgM Antibodies by a Simple Recombinant Immunoblot Assay for Field Use",
    "abstract": "The nucleoprotein of Lassa virus, strain Josiah, was expressed in Escherichia coli as an N-terminally truncated, histidine-tagged recombinant protein. Following affinity purification the protein was completely denatured and spotted onto nitrocellulose membrane. A total of 1 \u03bcg of protein was applied for detection of Lassa virus antibodies (LVA) in a simple immunoblot assay. Specific anti-Lassa immunoglobulin M (IgM) antibodies could be detected by increasing the amount of protein to 5 \u03bcg. A panel of 913 serum specimens from regions in which Lassa virus was endemic and from regions in which Lassa virus was not endemic was used for evaluating the sensitivity and specificity of the LVA immunoblot in comparison to those of an indirect immunofluorescence (IIF) assay. The sera originated from field studies conducted in the Republic of Guinea (570 serum samples) and Liberia (99 serum samples), from inpatients of the clinical department of the Bernhard-Nocht-Institute, Hamburg, Germany (94 serum samples), and from healthy German blood donors (150 serum samples). In comparison to the IIF assay the LVA immunoblot assay had a specificity of 90.0 to 99.3%, depending on the origin of the specimens. The sensitivity was found to be highest for the Guinean samples (90.7%) and was lower for the Liberian samples (75%). Acute Lassa fever was diagnosed by PCR in 12 of 59 (20.3%) patients with fever of unknown origin (FUO) from the Republic of Guinea. On admission to the hospital, nine Lassa fever patients (75%) were reactive by the IgM immunoblot assay. One of the patients was infected with a new Lassa variant, which showed 10.4% variation on the amino acid level in comparison to the prototype strain of Lassa virus, Josiah. Seven PCR-negative patients were reactive by immunoblotting. The positive and negative predictive values of a single IgM immunoblot result for acute, PCR-confirmed Lassa fever were therefore 53.6 and 93.0%, respectively. Because of its high negative predictive value, a single IgM immunoblot result will be valuable for excluding acute Lassa fever for cases of FUO in areas where Lassa fever is endemic.",
    "date": "1998",
    "authors": [
        "J. ter Meulen",
        "K. Koulemou",
        "T. Wittekindt",
        "K. Windisch",
        "S. Strigl",
        "S. Conde",
        "H. Schmitz"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Arenavirus"
    ],
    "citation_count": "73",
    "reference_count": "21",
    "references": [
        "2166229810",
        "2097504226",
        "1595102292",
        "2138694080",
        "2163443142",
        "2013470743",
        "1796364838",
        "1507400041",
        "2130125858",
        "2028066851"
    ]
},{
    "id": "1509033271",
    "title": "Lassa fever, a new virus disease of man from West Africa. I. Clinical description and pathological findings.",
    "abstract": "Abstract Lassa Fever, a hitherto unknown virus disease from Nigeria, caused the death of two missionary-nurses and the grave illness of a third. The onset is gradual with fever, weakness, myositis and ulcerative pharyngitis, progressing to symptoms of myocarditis, pneumonitis and pleuritis, encephalopathy, and evidences of a hemorrhagic diathesis. It is characterized in the early stages by moderate leukopenia, with increase of immature neutrophilic elements. It may be transmitted directly from person to person; the incubation period is about a week. It is likely to be of increasing public-health importance as travel to the interior parts of Nigeria increases, and as the area is developed because of future population pressures.",
    "date": "1970",
    "authors": [
        "John D. Frame",
        "John M. Baldwin",
        "David J. Gocke",
        "Jeanette M. Troup"
    ],
    "related_topics": [
        "Lassa fever",
        "Lassa virus",
        "Population"
    ],
    "citation_count": "551",
    "reference_count": "0",
    "references": []
},{
    "id": "50597173",
    "title": "Isolation of bovine respiratory coronaviruses from feedlot cattle and comparison of their biological and antigenic properties with bovine enteric coronaviruses",
    "abstract": "Objective To isolate bovine coronaviruses from the respiratory tracts of feedlot cattle and compare antigenic and biological properties of these strains with bovine enteric coronaviruses. Animals 5- to 8-month-old mixed-breed cattle at 4 feedlots. Procedure Samples were obtained from the nasal passages for testing. The 13 samples with the highest magnitude of positive values for bovine coronavirus (BCV) were cultured. Ten strains of bovine respiratory coronavirus (BRCV) were adapted successfully to serial passage. After observation of cytopathic effects (CPE) and confirmation of BRCV by immune electron microscopy and immunofluorescence testing, cell culture-adapted strains were cloned by limiting dilution. These isolates then were compared with a panel of bovine enteric coronaviruses (BECV), using hemagglutination (HA), receptor-destroying enzyme activity (RDE), hemagglutination inhibition (HI), and virus neutralization (VN) assays. Antigenic relatedness values then were calculated. Results The BRCV were detected in 105 of 488 (21.5%) of the cattle tested. Of 13 strains tested, 10 were isolated in cell culture. Six of the BRCV strains were similar to 2 strains obtained from neonatal calves with diarrhea and 2 strains from adult cattle with winter dysentery. The other 4 BRCV isolates had high RDE activity against mouse erythrocytes but differed from other strains of BECV Nine of 10 BRCV isolates had properties similar to the 2 BECV subtypes. Conclusions and clinical relevance The BRCV can be isolated from nasal passages of cattle entering feedlots. Most BRCV were similar to BECV strains, although a few had unique properties. Vaccines developed to protect against enteric strains also may protect against respiratory tract strains.",
    "date": "1999",
    "authors": [
        "M Hasoksuz",
        "S L Lathrop",
        "K L Gadfield",
        "L J Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Coronavirus",
        "Hemagglutination assay"
    ],
    "citation_count": "98",
    "reference_count": "0",
    "references": []
},{
    "id": "2072381230",
    "title": "Experimental inoculation of adult dairy cows with bovine coronavirus and detection of coronavirus in feces by RT-PCR",
    "abstract": "A reverse transcriptase PCR (RT-PCR) targeting a 407 bp fragment of the nucleocapsid gene of bovine coronavirus (BCV) was developed for detection of BCV RNA in feces of experimentally inoculated cattle. The sensitivity and specificity of the RT-PCR were confirmed using tissue culture-adapted BCV strains and feces of 2 calves inoculated with BCV. Ten nonpregant, BCV seropositive, adult dairy cows were inoculated with winter dysentery (WD) (n = 8) or calf diarrhea (CD) (n = 2) strains of BCV intranasally and orally (n = 2) or through a surgically-placed duodenal catheter (n = 8) with and without dexamethasone treatment or feeding ice water. The 6 cows inoculated with BCV intranasally and through a duodenal catheter (2 of 2 cows given CD BCV and 4 of 6 cows given WD BCV) developed mild diarrhea, and BCV was detected in diarrheal feces by RT-PCR, ELISA or immune electron microscopy. These results suggest that CD and WD strains of BCV can cause diarrhea in adult cows in conjunction with host or environmental factors and that RT-PCR might be useful to diagnose BCV infections in calves and adult cows.",
    "date": "1998",
    "authors": [
        "H. Tsunemitsu",
        "D. R. Smith",
        "L. J. Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Feces",
        "Coronavirus"
    ],
    "citation_count": "115",
    "reference_count": "28",
    "references": [
        "1909357041",
        "1951854256",
        "2026871972",
        "1623873373",
        "2088244647",
        "2004442551",
        "1963591796",
        "2171543640",
        "1979854169",
        "2302897180"
    ]
},{
    "id": "2409643934",
    "title": "Coronavirus isolation from nasal swab samples in cattle with signs of respiratory tract disease after shipping.",
    "abstract": "Objective To monitor the prevailing viral respiratory tract infections in cattle after transportation to feedlots. Animals 100 cattle with signs of respiratory tract disease on arrival at 2 feedlots. Procedures Nasal swab samples were obtained from each animal and were used for inoculation of defined cell culture systems that detected bovine viruses known to cause respiratory tract infections, as well as viruses previously not recognized as respiratory pathogens for cattle. Results Bovine respiratory coronaviruses were isolated from 38 of the 100 cattle, including 6 of 50 cattle from California, 22 of 31 cattle from Oklahoma, 6 of 11 cattle from Texas, and 4 of 8 cattle of unknown origin. Parainfluenza 3 viruses also were isolated from 5 California cattle, but other bovine viruses were not detected. Clinical implications The high rate of coronavirus isolations from feedlot cattle with signs of respiratory tract disease implied wide distribution and high susceptibility among cattle to this infection, which had not been detected by use of viral isolation systems in previous etiologic evaluations of feedlot cattle affected with bovine respiratory disease complex.",
    "date": "1996",
    "authors": [
        "J Storz",
        "L Stine",
        "A Liem",
        "G A Anderson"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Bovine Respiratory Disease Complex",
        "Coronavirus"
    ],
    "citation_count": "125",
    "reference_count": "0",
    "references": []
},{
    "id": "2045765248",
    "title": "Antibody titers against bovine coronavirus and shedding of the virus via the respiratory tract in feedlot cattle.",
    "abstract": "Objective\u2014To describe patterns of seroconversion to bovine coronavirus (BCV) and shedding of BCV from the respiratory tract in feedlot cattle. Animals\u20141,074 calves in feedlots in Ohio, Texas, and Nebraska. Procedure\u2014Nasal swab specimens were obtained at time of arrival (day 0) and at various times during the initial 28 days after arrival at feedlots. Specimens were tested for BCV, using an antigen-capture ELISA. Serum samples were obtained at time of arrival and again 28 days after arrival; sera were analyzed for antibodies to BCV, using an antibody-detection ELISA. Results\u2014Samples from 12 groups of cattle entering 7 feedlots during a 3-year period revealed that 78 of 1,074 (7.3%) cattle were shedding BCV (range, 0 to 35.9% within specific groups). At time of arrival, 508 of 814 (62.4%) cattle had low (< 50) or undetectable BCV antibody titers. Seroconversion to BCV during the initial 28 days after arrival was detected in 473 of 814 (58%) cattle tested (range, 20.3 to 84.1% within specific groups). In cat...",
    "date": "2000",
    "authors": [
        "Sarah L. Lathrop",
        "Thomas E. Wittum",
        "Steven C. Loerch",
        "Louis J. Perino",
        "Linda J. Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Seroconversion",
        "Antibody titer"
    ],
    "citation_count": "65",
    "reference_count": "11",
    "references": [
        "50597173",
        "2409643934",
        "1987051173",
        "1979854169",
        "235033005",
        "1559220665",
        "2427167782",
        "322437712",
        "2415511848",
        "1997508906"
    ]
},{
    "id": "1963591796",
    "title": "Antigenic and biological comparisons of bovine coronaviruses derived from neonatal calf diarrhea and winter dysentery of adult cattle",
    "abstract": "The antigenic and biological properties of 6 strains of bovine coronavirus (BCV) derived from neonatal calf diarrhea (CD) and 8 strains of BCV from winter dysentery (WD) of adult cattle, propagated in HRT-18 cells, were compared to determine if CD and WD strains belong to distinct serotypes or subtypes of BCV. All strains hemagglutinated both mouse and chicken erythrocytes at 4 \u00b0C, but the ratios of hemagglutination titers with mouse erythrocytes compared to chicken erythrocytes showed diversity for both CD and WD strains. Some CD and WD strains did not hemagglutinate chicken erythrocytes at 37 \u00b0C and showed receptor-destroying enzyme activity against chicken erythrocytes. Hyperimmune antisera were produced in guinea pigs against 3 and 7 strains of BCV from CD and WD, respectively. No significant differences in antibody titers against these strains were observed by indirect immunofluorescence tests. However, in virus neutralization tests, antisera to 1 CD and 2 WD strains had 16-fold or lower antibody titers against 3 WD and 1 CD strains than against the homologous strains, and this variation reflected low antigenic relatedness values (R=13\u201325%), suggesting the presence of different subtypes among BCV. In hemagglutination inhibition tests, some one-way antigenic variations among strains were also observed. These results suggest that some antigenic and biological diversity exists among BCV strains, but these variations were unrelated to the clinical source of the strains; i.e. CD or WD.",
    "date": "1994",
    "authors": [
        "H. Tsunemitsu",
        "L. J. Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Antigenic variation",
        "Hemagglutination assay"
    ],
    "citation_count": "72",
    "reference_count": "26",
    "references": [
        "2153127922",
        "2134972446",
        "1542641435",
        "131087488",
        "1751183456",
        "2145122445",
        "2233229970",
        "2019400272",
        "1976074519",
        "2416402921"
    ]
},{
    "id": "2406151794",
    "title": "Effect of concurrent experimentally induced bovine respiratory syncytial virus and bovine viral diarrhea virus infection on respiratory tract and enteric diseases in calves.",
    "abstract": "OBJECTIVE To compare experimentally induced concurrent bovine viral diarrhea virus (BVDV) and bovine respiratory syncytial virus (BRSV) infection with single virus infection. ANIMALS 9- to 12-month-old calves. PROCEDURE Calves were allotted to 4 groups: 1, mock-infected control (n = 3); 2, BRSV infected (5); 3, BVDV infected (5); and 4, concurrent BRSV and BVDV infected (5). Total and differential WBC counting was done. Concentration and duration of BVDV in nasal secretions and serum, and duration of BRSV in nasal secretions were determined. Concentration of BVDV in various tissues was determined, and isolation of BRSV from lung tissue was attempted. Histologic examination and immunohistochemical analysis were done to detect lesions and distribution of viral antigens, respectively. RESULTS Calves with concurrent infection developed more severe clinical signs of disease (fever and diarrhea), leukopenia, and more severe lesions. They also shed virus from nasal secretions in greater concentration and for longer duration, and BRSV was isolated from their lungs. Calves with concurrent infection also had more extensive lung lesions. Alimentary epithelial necrosis and severe lymphoid depletion were associated with BVDV infection in calves with or without concurrent BRSV infection. BVDV antigen in lymphatic tissue was detected in stromal cells only. CONCLUSIONS Concurrent infection with BRSV and BVDV resulted in more severe respiratory tract and enteric disease than did infection with either virus alone, possibly indicating synergistic effect between the viruses. BVDV's role in causing respiratory tract disease is attributable, indirectly, to effects on the host's immune system, not to infection of the lungs.",
    "date": "1998",
    "authors": [
        "Bruce W. Brodersen",
        "Clayton L Kelling"
    ],
    "related_topics": [
        "Virus",
        "Respiratory tract",
        "Immune system"
    ],
    "citation_count": "104",
    "reference_count": "0",
    "references": []
},{
    "id": "2032346601",
    "title": "Detection of bovine coronaviruses from adult cows with epizootic diarrhea and their antigenic and biological diversities.",
    "abstract": "Bovine coronavirus (BCV) was detected by reverse transcriptase-PCR, immune electron microscopy or virus isolation from adult cows at 6 out of 6 outbreaks of epizootic diarrhea in Japan. Six BCVs isolated in feces, intestinal content or tracheal exudate of the cows were analyzed for their antigenic properties by cross virus neutralization (VN) tests. The isolates were divided into two groups, one of which had closely related antigenicity with the reference Mebus and Kakegawa strains of BCV, and another which showed significant differences in VN antibody titers from the reference strains. Two isolates in the latter group, which were from the enteric and respiratory tracts of the same cows, respectively, were distinguished from each other by ELISA using monoclonal antibodies against the Kakegawa strain. The isolates showed various hemagglutination and receptor destroying enzyme titers against chicken or mouse erythrocytes.",
    "date": "1998",
    "authors": [
        "T. Fukutomi",
        "H. Tsunemitsu",
        "H. Akashi"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Coronavirus",
        "Antigenic variation"
    ],
    "citation_count": "30",
    "reference_count": "28",
    "references": [
        "2088244647",
        "2409643934",
        "1542641435",
        "1963591796",
        "131087488",
        "1751183456",
        "2412806106",
        "2418279095",
        "2145122445",
        "2233229970"
    ]
},{
    "id": "1979854169",
    "title": "Evaluation of Two Antigen-Capture ELISAs using Polyclonal or Monoclonal Antibodies for the Detection of Bovine Coronavirus",
    "abstract": "diarrhea and winter dysentery in cattle in Quebec: evaluation of three diagnostic methods. Can Vet J 35:163-169. 2. Benfield DA, Saif LJ: 1990, Cell culture propagation of a coronavirus isolated from cows with winter dysentery. J Clin Microbiol 28:1454-1457. 3. Bridger JC, Caul EO, Egglestone SI: 1978, Replication of an enteric bovine coronavirus in intestinal organ cultures. Arch Virol 57:43-51. 4. Clark MA: 1993, Bovine coronavirus. Br Vet J 149:51-70. 5. Craig RA, Kapil S: 1994, Proc Annu Meet Am Assoc Vet Lab Diagn 37: 107. 6. Cyr-Coats KST, Payne HR, Storz J: 1988, The influence of the host cell and trypsin treatment on bovine coronavirus infectivity. J Vet Med B 35:752-759. 7. Dea S, Roy RS, Begin ME: 1980, Bovine coronavirus isolation and cultivation in continuous cell lines. Am J Vet Res 41:3038. 8. Flewett TH: 1978, Electron microscopy in the diagnosis of infectious diarrhea. J Am Vet Med Assoc 173:538-541. 9. Inaba Y, Sato K, Kurogi H, et al.: 1976, Replication of bovine coronavirus in cell line BEK-1 culture. Arch Virol 50:339-342. 10. Kapil S: 1991, Intestinal immune response(s) of newborn calves to bovine enteric coronavirus infection. PhD Dissertation, University of Minnesota, St. Paul, MN. 11. Kapil S: 1995, Laboratory diagnosis of canine viral enteritis. In: Current veterinary therapy 12, ed. Bonugura JD, Kirk RW, pp. 697-701. WB Saunders Co., Philadelphia, PA. 12. Kapil S, Goyal SM: 1995, Bovine coronavirus-associated respiratory disease. Compend Cont Ed Pract Vet 17:179-181. 13. Laporte J, L\u2019Haridon R, Bobulesco P: 1979, In vitro culture of bovine enteric coronavirus (BEC). Colloq INSERM 90:99102. 14. Storz J, Rott R, Kaluza G: 1981, Enhancement of plaque formation and cell fusion of an enteropathogenic coronavirus by trypsin treatment. Infect Immun 31:1214-1222. 15. Stott EJ, Thomas LH, Bridger JC, et al.: 1976, Replication of a bovine coronavirus in organ cultures of fetal trachea. Vet Microbiol 5:151-154. 16. Tompkins WAF, Watrach AM, Schmale RM, et al.: 1974, Cultural and antigenic properties of newly established cell strains derived from adenocarcinomas of the human colon and rectum. J Natl Cancer Inst 52:1101-1110.",
    "date": "1995",
    "authors": [
        "David R. Smith",
        "Hiroshi Tsunemitsu",
        "Robert A. Heckert",
        "Linda J. Saif"
    ],
    "related_topics": [
        "Bovine coronavirus",
        "Coronavirus",
        "Infectivity"
    ],
    "citation_count": "55",
    "reference_count": "30",
    "references": [
        "1865165998",
        "2058322564",
        "2112888780",
        "1963591796",
        "96361486",
        "1965353790",
        "1751183456",
        "2145122445",
        "2233229970",
        "1728948094"
    ]
},{
    "id": "2302897180",
    "title": "Epidemiologic herd-level assessment of causative agents and risk factors for winter dysentery in dairy cattle",
    "abstract": "OBJECTIVE: To test the association between exposure to bovine coronavirus (BCV) and outbreaks of winter dysentery (WD) in dairy herds and to examine other risk factors for outbreaks of WD in dairy herds. ANIMALS: 12 dairy herds in Ohio affected with WD (case herds). For each case herd, 2 unaffected herds from the same area were concurrently used as control herds. PROCEDURE: A case-control study was conducted, using herds as the unit of investigation. Multivariate logistic regression modeling was used to identify risk factors for contracting disease. RESULTS: 4 factors appeared to increase a herd's risk for WD: increase in herd prevalence of adult cows that had a fourfold or more increase in BCV serum IgG antibody titer; increase in herd prevalence of adult cows that had a fourfold or more increase in bovine viral diarrhea virus (BVDV) titer; housing cattle in tiestall or stanchion barns rather than free-stall facilities; and use of equipment to handle manure and subsequently handle feed. The adjusted population-attributable risk for these variables was 71, 43, 53, and 31%, respectively, and 99% overall, indicating that these variables had considerable impact on WD outbreaks for the study population. CONCLUSIONS AND CLINICAL RELEVANCE: In dairies in Ohio, recent herd exposure to BCV appeared to increase the risk for WD outbreaks. Some WD outbreaks might have been associated with acute BVDV infection. Certain housing and management practices may have increased the risk of an outbreak of WD.",
    "date": "1998",
    "authors": [
        "David R. Smith",
        "Paula J. Fedorka-Cray",
        "Ram Mohan",
        "Kenny V. Brock",
        "Thomas E. Wittum",
        "Paul S. Morley",
        "Kent H. Hoblet",
        "Linda J. Saif"
    ],
    "related_topics": [
        "Herd",
        "Dairy cattle",
        "Outbreak"
    ],
    "citation_count": "20",
    "reference_count": "0",
    "references": []
},{
    "id": "2038264706",
    "title": "A novel DNA virus (TTV) associated with elevated transaminase levels in posttransfusion hepatitis of unknown etiology.",
    "abstract": "By means of representational difference analysis, a viral clone (N22) of 500 nucleotides was isolated from serum of a patient (TT) with posttransfusion hepatitis of unknown etiology. The N22 clone showed a poor homology to any reported sequences. Oligonucleotide primers were deduced from the N22 sequence for detecting it by polymerase chain reaction. N22 sequence in serum banded at a sucrose density of 1.26 g/cm3, indicating its association with a viral particle which was designated TT virus (TTV). Since nucleic acids of TTV were sensitive to DNase I, it would be a DNA virus. TTV DNA was detected in sera from three of the five patients with posttransfusion non-A to G hepatitis, including the index case (TT). TTV DNA titers closely correlated with aminotransferase levels in the three patients. These results indicate that TTV would be a novel DNA virus with a possible capacity to induce posttransfusion non-A to G hepatitis.",
    "date": "1997",
    "authors": [
        "Tsutomu Nishizawa",
        "Hiroaki Okamoto",
        "Keiko Konishi",
        "Hiroshi Yoshizawa",
        "Yuzo Miyakawa",
        "Makoto Mayumi"
    ],
    "related_topics": [
        "Hepatitis B virus DNA polymerase",
        "Torque teno virus",
        "DNA virus"
    ],
    "citation_count": "1,630",
    "reference_count": "26",
    "references": [
        "2083266836",
        "2005453259",
        "1963636589",
        "2336905550",
        "1887371688",
        "2052041745",
        "123099",
        "2089463925",
        "2094778792",
        "2098232111"
    ]
},{
    "id": "2089551619",
    "title": "Molecular cloning and characterization of a novel DNA virus (TTV) associated with posttransfusion hepatitis of unknown etiology",
    "abstract": "Abstract The genomic DNA of a novel virus named TT virus (TTV), associated with posttransfusion hepatitis of unknown etiology, was cloned from plasma of a blood donor with an elevated transaminase level but without serological markers of known hepatitis viruses, and its sequence of 3739 bases was determined. TTV had a density of 1.26 g/cm3 in sucrose, which did not change after the treatment with Tween 80. The viral genome was sensitive to DNase I and Mung Bean Nuclease. Hence, TTV would be an unenveloped, single-stranded DNA virus. Two possible open reading frames in different frames were identified, capable of encoding 770 and 202 amino acids, respectively. When a partial sequence of 356 bases was compared among TTV isolates from 78 sera from blood donors and hepatitis patients, it showed considerable divergence with differences of up to 30%. Oligonucleotide primers were designed on two well-conserved regions for the detection of TTV DNA in serum and biopsied liver tissues by polymerase chain reaction. TTV DNA was detected in sera from 9 of 19 (47%) patients with fulminant hepatitis and 41 of 90 (46%) patients with chronic liver disease of unknown etiology. TTV DNA was detected in liver tissues of all the five patients tested, in titers equal or 10\u2013100 times higher than those in the corresponding sera. These results indicate that TTV would be responsible for a part of acute and chronic liver disease of unknown etiology.",
    "date": "1997",
    "authors": [
        "Hiroaki Okamoto",
        "Tsutomu Nishizawa",
        "Naomi Kato",
        "Masato Ukita",
        "Hiroki Ikeda",
        "Hisao Iizuka",
        "Yuzo Miyakawa",
        "Makoto Mayumi"
    ],
    "related_topics": [
        "Torque teno virus",
        "Viral hepatitis",
        "DNA virus"
    ],
    "citation_count": "982",
    "reference_count": "30",
    "references": [
        "2055043387",
        "2015292449",
        "2083266836",
        "2053418558",
        "2057381677",
        "1963636589",
        "1887371688",
        "2153509945",
        "2047549417",
        "2171191174"
    ]
},{
    "id": "2016137045",
    "title": "The incidence of transfusion-associated hepatitis G virus infection and its relation to liver disease",
    "abstract": "Background The role of hepatitis G virus (HGV) in transfusion-associated infection and its relation to liver disease are not well understood. Methods Serum samples collected between 1972 and 1995 from 357 transfusion recipients, 157 controls who did not receive transfusions, 500 randomly selected volunteer blood donors, and 230 donors of blood received by HGV-infected patients were tested for HGV RNA by qualitative and quantitative polymerase-chain-reaction assays. Samples obtained before transfusion and serially after transfusion from 79 of the 81 transfusion recipients who had transfusion-associated non-A, non-B hepatitis were available for testing. Results Of the 79 patients with transfusion-associated hepatitis, 63 (80 percent) had infections related to the hepatitis C virus (HCV) and 3 had preexisting HCV and the cause of their acute hepatitis could not be determined; of the remaining 13 patients, 3 had acute HGV infection, and 10 were infected with unidentified agents. Six of the 63 patients with HC...",
    "date": "1997",
    "authors": [
        "H. J. Alter",
        "Y. Nakatsuji",
        "J. Melpolder",
        "J. Wages",
        "R. Wesley",
        "J. W.-K. Shih",
        "J. P. Kim"
    ],
    "related_topics": [
        "Viral hepatitis",
        "Hepatitis",
        "Hepatitis C virus"
    ],
    "citation_count": "797",
    "reference_count": "11",
    "references": [
        "2006309458",
        "2066124462",
        "2083266836",
        "2328171401",
        "1974879228",
        "2336905550",
        "1967573895",
        "2019308386",
        "2085220251",
        "2074300799"
    ]
},{
    "id": "2328399749",
    "title": "Acute non-A-E hepatitis in the United States and the role of hepatitis G virus infection",
    "abstract": "Background Little is known about the relation of the newly discovered hepatitis G virus (HGV) to the cause and clinical course of acute and chronic viral hepatitis. Methods We selected patients from a surveillance study of acute viral hepatitis in four U.S. counties who had acute disease during 1985 to 1986 or 1991 to 1995. Serum samples were tested for HGV RNA by the polymerase chain reaction. Results HGV RNA was detected in 4 of 45 patients with a diagnosis of non-A\u2013E hepatitis (9 percent), 23 of 116 patients with hepatitis C (20 percent), 25 of 100 patients with hepatitis A (25 percent), and 32 of 100 patients with hepatitis B (32 percent) (P<0.05 for the comparison of hepatitis B with hepatitis non-A\u2013E or C). The clinical characteristics of the acute illness were similar for patients with HGV alone and those with hepatitis A, B, or C with or without HGV infection. During a follow-up period of one to nine years, chronic hepatitis did not develop in any of the patients with HGV alone, but 75 percent wer...",
    "date": "1997",
    "authors": [
        "Miriam J. Alter",
        "Margaret Gallagher",
        "Timothy T. Morris",
        "Linda A. Moyer",
        "Emory L. Meeks",
        "Krzysztof Krawczynski",
        "Jungsuh P. Kim",
        "Harold S. Margolis"
    ],
    "related_topics": [
        "Viral hepatitis",
        "Hepatitis",
        "Hepatitis A"
    ],
    "citation_count": "552",
    "reference_count": "22",
    "references": [
        "2083266836",
        "2328171401",
        "2059372215",
        "2016137045",
        "2150482242",
        "1999334158",
        "1968566170",
        "2336905550",
        "2000390686",
        "1991143151"
    ]
},{
    "id": "2022277835",
    "title": "PARVOVIRUS INFECTIONS AND HYPOPLASTIC CRISIS IN SICKLE-CELL ANAEMIA",
    "abstract": "",
    "date": "1981",
    "authors": [
        "J.R. Pattison",
        "S.E. Jones",
        "J. Hodgson",
        "L.R. Davis",
        "J.M. White",
        "C.E. Stroud",
        "L. Murtaza"
    ],
    "related_topics": [
        "Parvovirus infection",
        "Parvovirus",
        "Anemia"
    ],
    "citation_count": "910",
    "reference_count": "3",
    "references": [
        "2028973331",
        "1966895326",
        "2092366606"
    ]
},{
    "id": "2028973331",
    "title": "Parvovirus-like particles in human sera.",
    "abstract": "A parvovirus-like antigen has been found in sera of nine healthy blood-donors and two patients. Its pathogenicity is unknown, but 30% of adults possess specific antibody. The new agent can be confused with hepatitis-B antigen both morphologically and serologically.",
    "date": "1975",
    "authors": [
        "Y.E. Cossart",
        "B. Cant",
        "A.M. Field",
        "D. Widdows"
    ],
    "related_topics": [
        "Antigen",
        "Parvovirus",
        "Parvovirus infection"
    ],
    "citation_count": "1,157",
    "reference_count": "4",
    "references": [
        "2063313528",
        "2055549037",
        "2093552574",
        "2428865190"
    ]
},{
    "id": "2083266836",
    "title": "Molecular Cloning and Disease Association of Hepatitis G Virus: A Transfusion-Transmissible Agent",
    "abstract": "An RNA virus, designated hepatitis G virus (HGV), was identified from the plasma of a patient with chronic hepatitis. Extension from an immunoreactive complementary DNA clone yielded the entire genome (9392 nucleotides) encoding a polyprotein of 2873 amino acids. The virus is closely related to GB virus C (GBV-C) and distantly related to hepatitis C virus, GBV-A, and GBV-B. HGV was associated with acute and chronic hepatitis. Persistent viremia was detected for up to 9 years in patients with hepatitis. The virus is transfusion-transmissible. It has a global distribution and is present within the volunteer blood donor population in the United States.",
    "date": "1996",
    "authors": [
        "Jeff Linnen",
        "John Wages",
        "Zhen-Yong Zhang-Keck",
        "Kirk E. Fry",
        "Krzysztof Z. Krawczynski",
        "Harvey Alter",
        "Eugene Koonin",
        "Margaret Gallagher",
        "Miriam Alter",
        "Stephanos Hadziyannis",
        "Peter Karayiannis",
        "Kevin Fung",
        "Yoshiyuki Nakatsuji",
        "J. Wai-Kuo Shih",
        "Lavonne Young",
        "Michael Piatak",
        "Cameron Hoover",
        "John Fernandez",
        "Stacie Chen",
        "Jian-Chao Zou",
        "Timothy Morris",
        "Kenneth C. Hyams",
        "Susan Ismay",
        "Jeffrey D. Lifson",
        "Georg Hess",
        "Steven K. H. Foung",
        "Howard Thomas",
        "Daniel Bradley",
        "Harold Margolis",
        "Jungsuh P. Kim"
    ],
    "related_topics": [
        "Viral hepatitis",
        "GB virus C",
        "Hepatitis C virus"
    ],
    "citation_count": "2,014",
    "reference_count": "27",
    "references": [
        "2055043387",
        "2015292449",
        "2066124462",
        "2108388593",
        "2091239909",
        "2002180966",
        "2328171401",
        "1974879228",
        "37545008",
        "2059372215"
    ]
},{
    "id": "2313004219",
    "title": "The sequencing of chemotherapy and radiation therapy after conservative surgery for early-stage breast cancer.",
    "abstract": "Background Patients with early-stage breast cancer who are at substantial risk for systemic metastases are increasingly treated with breast-conserving therapy and adjuvant chemotherapy. However, the optimal sequencing of chemotherapy and radiation therapy is not clear. Methods Two hundred forty-four patients with stage I or II breast cancer who were at substantial risk for distant metastases were randomly assigned to receive a 12-week course of chemotherapy either before or after radiation therapy. All had had breast-conserving surgery. The median length of follow-up in surviving patients was 58 months (range, 10 to 124). Results The five-year actuarial rates of cancer recurrence at any site and of distant metastases in the radiotherapy-first group and the chemotherapy-first group were 38 percent and 31 percent (P = 0.17) and 36 percent and 25 percent (P = 0.05), respectively. Overall survival was 73 percent and 81 percent (P = 0.11), respectively. The five-year crude rates of first recurrence according t...",
    "date": "1996",
    "authors": [
        "A. Recht",
        "S. E. Come",
        "I. C. Henderson",
        "R. S. Gelman",
        "B. Silver",
        "D. F. Hayes",
        "L. N. Shulman",
        "J. R. Harris"
    ],
    "related_topics": [
        "Breast cancer",
        "Radiation therapy",
        "Metastasis"
    ],
    "citation_count": "598",
    "reference_count": "21",
    "references": [
        "1973948212",
        "2313308602",
        "2105365583",
        "2214029008",
        "2095349827",
        "2052577752",
        "2029902156",
        "1767955168",
        "111776290",
        "2046518833"
    ]
},{
    "id": "2023962288",
    "title": "The cloning and clinical implications of HGV and HGBV-C.",
    "abstract": "The cloning of the hepatitis C virus (HCV)1 established that important human pathogens, which could not be seen microscopically, grown in cell culture, or detected serologically, could nonetheless ...",
    "date": "1996",
    "authors": [
        "Harvey J. Alter"
    ],
    "related_topics": [
        "GB virus C",
        "Hepatitis C virus",
        "Cloning"
    ],
    "citation_count": "372",
    "reference_count": "7",
    "references": [
        "2006309458",
        "2083266836",
        "2059372215",
        "2319055243",
        "1968566170",
        "2336905550",
        "208665126"
    ]
},{
    "id": "2155517838",
    "title": "High Prevalence of GB Virus C Infection in a Group of Italian Patients with Hepatitis of Unknown Etiology",
    "abstract": "Prevalence of the recently discovered GB virus C (GBV-C) was evaluated in a cohort of 49 Italian patients with acute or chronic hepatitis of unknown etiology (non-A-E hepatitis) and in a control group of 100 healthy blood donors. The GBV-C genomes could be detected by polymerase chain reaction (PCR) with reverse transcription in 35% of the acute and 39% of the chronic hepatitis patients ; only 1 of the control subjects had a positive response. All PCR products hybridized with a specific probe in a colorimetric assay, and the analysis of the sequences of the amplified cDNAs fully confirmed the specificity of the assay. Furthermore, the alignment of the predicted translation products identified two recurrent amino acid substitutions in 6 patients, suggesting the possible existence of at least 2 different GBV-C subtypes. Thus, GBV-C may be an important agent, contributing, at least in Italy, to a significant number of the cases of hepatitis of unknown etiology.",
    "date": "1996",
    "authors": [
        "Gianfranco Fiordalisi",
        "Isabella Zanella",
        "Giovanni Mantero",
        "Alessandra Bettinardi",
        "Roberto Stellini",
        "Giuseppe Paraninfo",
        "Gianpietro Cadeo",
        "Daniele Primi"
    ],
    "related_topics": [
        "GB virus C",
        "Hepatitis",
        "Reverse transcriptase"
    ],
    "citation_count": "198",
    "reference_count": "9",
    "references": [
        "2094031081",
        "2083266836",
        "2328171401",
        "2059372215",
        "2132608906",
        "1968566170",
        "2010203103",
        "2054790792",
        "2059725392"
    ]
},{
    "id": "2075432722",
    "title": "Effects of ursodeoxycholic acid on survival in patients with primary biliary cirrhosis",
    "abstract": "Abstract BACKGROUND & AIMS: Ursodeoxycholic acid (UDCA) has been shown to be a safe and effective treatment for patients with primary biliary cirrhosis; however, its effect on patient survival is less certain. To study this issue, the survival of patients receiving long-term UDCA treatment was compared with that of a control group, adjusting for their risk scores based on the Mayo model. METHODS: One hundred eighty patients were randomized to receive either 13-15 mg.kg-1.day-1 UDCA (n = 89) of placebo (n = 91). After the study closure, the patients originally receiving placebo were switched to active drug, and prospective follow-up was continued for 3 years. Patients were censored at the time of transplantation, voluntary withdrawal, of crossover of the placebo group (efficacy analysis). The survival of the two groups was adjusted for risk scores at the time of entry to the study. A secondary analysis was an intent-to-treat analysis, whereby patients were followed up regardless of their voluntary withdrawal or crossover. RESULTS: At the time of analysis, the patients receiving placebo had a significantly increased risk of death and/or requiring transplantation (relative risk, 2.6; P=0.04) compared with the UDCA-treated patients CONCLUSIONS: UDCA should be considered as a safe, effective, and life- extending treatment for patients with primary biliary cirrhosis. (Gastroenterology 1996 May;110(5):1515-8)",
    "date": "1996",
    "authors": [
        "KD Lindor",
        "TM Therneau",
        "RA Jorgensen",
        "M Malinchoc",
        "ER Dickson"
    ],
    "related_topics": [
        "Ursodeoxycholic acid",
        "Transplantation",
        "Placebo"
    ],
    "citation_count": "291",
    "reference_count": "0",
    "references": []
},{
    "id": "1984200234",
    "title": "Acute liver damage and ecstasy ingestion.",
    "abstract": "Eight cases of ecstasy related acute liver damage referred to a specialised liver unit are described. Two patients presented after collapse within six hours of ecstasy ingestion with hyperthermia, hypotension, fitting, and subsequently disseminated intravascular coagulation with rhabdomyolysis together with biochemical evidence of severe hepatic damage. One patient recovered and the other with evidence of hyperacute liver failure was transplanted but subsequently died, histological examination showing widespread microvesicular fatty change. Four patients presented with acute liver failure without hyperthermia. All four fulfilled criteria for transplantation, one died before a donor organ became available, and two died within one month post-transplantation of overwhelming sepsis. Histological examination showed submassive lobular collapse. Two patients presented with abdominal pain and jaundice and recovered over a period of three weeks; histological examination showed a lobular hepatitis with cholestasis. Patients developing jaundice or with evidence of hepatic failure particularly encephalopathy and prolongation of the international normalised ratio, or both, whether or not preceded by hyperthermia, should be referred to a specialised liver unit as liver transplantation probably provides the only chance of recovery.",
    "date": "1996",
    "authors": [
        "A J Ellis",
        "J A Wendon",
        "B Portmann",
        "R Williams"
    ],
    "related_topics": [
        "Liver transplantation",
        "Transplantation",
        "Jaundice"
    ],
    "citation_count": "201",
    "reference_count": "25",
    "references": [
        "1608215573",
        "2082669257",
        "2020344558",
        "2138700431",
        "2066108155",
        "2044165548",
        "1998083637",
        "2043802160",
        "2057528351",
        "1995396807"
    ]
},{
    "id": "2149687213",
    "title": "Acute Renal Failure in Critically Ill Patients: A Multinational, Multicenter Study",
    "abstract": "ContextAlthough acute renal failure (ARF) is believed to be common in the setting of critical illness and is associated with a high risk of death, little is known about its epidemiology and outcome or how these vary in different regions of the world.ObjectivesTo determine the period prevalence of ARF in intensive care unit (ICU) patients in multiple countries; to characterize differences in etiology, illness severity, and clinical practice; and to determine the impact of these differences on patient outcomes.Design, Setting, and PatientsProspective observational study of ICU patients who either were treated with renal replacement therapy (RRT) or fulfilled at least 1 of the predefined criteria for ARF from September 2000 to December 2001 at 54 hospitals in 23 countries.Main Outcome MeasuresOccurrence of ARF, factors contributing to etiology, illness severity, treatment, need for renal support after hospital discharge, and hospital mortality.ResultsOf 29 269 critically ill patients admitted during the study period, 1738 (5.7%; 95% confidence interval [CI], 5.5%-6.0%) had ARF during their ICU stay, including 1260 who were treated with RRT. The most common contributing factor to ARF was septic shock (47.5%; 95% CI, 45.2%-49.5%). Approximately 30% of patients had preadmission renal dysfunction. Overall hospital mortality was 60.3% (95% CI, 58.0%-62.6%). Dialysis dependence at hospital discharge was 13.8% (95% CI, 11.2%-16.3%) for survivors. Independent risk factors for hospital mortality included use of vasopressors (odds ratio [OR], 1.95; 95% CI, 1.50-2.55; P<.001), mechanical ventilation (OR, 2.11; 95% CI, 1.58-2.82; P<.001), septic shock (OR, 1.36; 95% CI, 1.03-1.79; P = .03), cardiogenic shock (OR, 1.41; 95% CI, 1.05-1.90; P = .02), and hepatorenal syndrome (OR, 1.87; 95% CI, 1.07-3.28; P = .03).ConclusionIn this multinational study, the period prevalence of ARF requiring RRT in the ICU was between 5% and 6% and was associated with a high hospital mortality rate.",
    "date": "2005",
    "authors": [
        "Shigehiko Uchino",
        "John A Kellum",
        "Rinaldo Bellomo",
        "Gordon S Doig",
        "Hiroshi Morimatsu",
        "Stanislao Morgera",
        "Miet Schetz",
        "Ian Tan",
        "Catherine Bouman",
        "Ettiene Macedo",
        "Noel Gibney",
        "Ashita Tolwani",
        "Claudio Ronco"
    ],
    "related_topics": [
        "Severity of illness",
        "Intensive care unit",
        "Hemodialysis"
    ],
    "citation_count": "4,281",
    "reference_count": "26",
    "references": [
        "2128349740",
        "2148973700",
        "1997278766",
        "1988629947",
        "2036544704",
        "1970593590",
        "2156916779",
        "2139529386",
        "1980336273",
        "2135398566"
    ]
},{
    "id": "2116909658",
    "title": "An assessment of the RIFLE criteria for acute renal failure in hospitalized patients.",
    "abstract": "Objective:The Acute Dialysis Quality Initiative (ADQI) Group published a consensus definition (the RIFLE criteria) for acute renal failure. We sought to assess the ability of the RIFLE criteria to predict mortality in hospital patients.Design:Retrospective single-center study.Setting:University-affi",
    "date": "2006",
    "authors": [
        "Shigehiko Uchino",
        "Rinaldo Bellomo",
        "Donna Goldsmith",
        "Samantha Bates",
        "Claudio Ronco"
    ],
    "related_topics": [
        "Rifle",
        "Acute kidney injury",
        "Intensive care"
    ],
    "citation_count": "1,129",
    "reference_count": "19",
    "references": [
        "2487377689",
        "2597070792",
        "2139937737",
        "2161328469",
        "1996020381",
        "2123151246",
        "2043132544",
        "1967237457",
        "1988629947",
        "2083931054"
    ]
},{
    "id": "2043132544",
    "title": "Effect of acute renal failure requiring renal replacement therapy on outcome in critically ill patients.",
    "abstract": "ObjectivesAcute renal failure is a complication in critically ill patients that has been associated with an excess risk of hospital mortality. Whether this reflects the severity of the disease or whether acute renal failure is an independent risk factor is unknown. The aim of this study was to analy",
    "date": "2002",
    "authors": [
        "Philipp G H Metnitz",
        "Claus G Krenn",
        "Heinz Steltzer",
        "Thomas Lang",
        "J\u00fcrgen Ploder",
        "Kurt Lenz",
        "Jean-Roger Le Gall",
        "Wilfred Druml"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Hemodialysis",
        "Kidney disease"
    ],
    "citation_count": "1,137",
    "reference_count": "29",
    "references": [
        "2107978811",
        "2128349740",
        "2148973700",
        "1967237457",
        "2029723446",
        "1988629947",
        "2036544704",
        "2043436644",
        "2156301104",
        "2080551841"
    ]
},{
    "id": "2069722312",
    "title": "Spectrum of acute renal failure in the intensive care unit: The PICARD experience",
    "abstract": "Spectrum of acute renal failure in the intensive care unit: The PICARD experience. Background Acute renal failure (ARF) in the critically ill is associated with extremely high mortality rates. Understanding the changing spectrum of ARF will be necessary to facilitate quality improvement efforts and to design successful interventional trials. Methods We conducted an observational cohort study of 618 patients with ARF in intensive care units at five academic medical centers in the United States. Participants were required to sign (or have a proxy sign) informed consent for data collection. A comprehensive data collection instrument captured more than 800 variables, most on a daily basis, throughout the course of ARF. Patient characteristics, dialysis status, and major outcomes were determined and stratified by clinical site. Results The mean age was 59.5 years, 41% were women, and 20% were of minority race or ethnicity. There was extensive comorbidity; 30% had chronic kidney disease, 37% had coronary artery disease, 29% had diabetes mellitus, and 21% had chronic liver disease. Acute renal failure was accompanied by extrarenal organ system failure in most patients, even those who did not require dialysis. Three hundred and ninety-eight (64%) patients required dialysis. The in-hospital mortality rate was 37%, and the rate of mortality or nonrecovery of renal function was 50%. The median hospital length of stay was 25 days (26 days, excluding patients who died). Conclusion There is a changing spectrum of ARF in the critically ill, characterized by a large burden of comorbid disease and extensive extrarenal complications, obligating the need for dialysis in the majority of patients. There is wide variation across institutions in patient characteristics and practice patterns. These differences highlight the need for additional multicenter observational and interventional studies in ARF.",
    "date": "2004",
    "authors": [
        "Ravindra L. Mehta",
        "Maria T. Pascual",
        "Sharon Soroko",
        "Brandon R. Savage",
        "Jonathan Himmelfarb",
        "T. Alp Ikizler",
        "Emil P. Paganini",
        "Glenn M. Chertow"
    ],
    "related_topics": [
        "Intensive care",
        "Intensive care unit",
        "Kidney disease"
    ],
    "citation_count": "1,062",
    "reference_count": "54",
    "references": [
        "2087378917",
        "2043132544",
        "1988629947",
        "2036544704",
        "2050196352",
        "1970593590",
        "2139529386",
        "2085440534",
        "1980336273",
        "2135398566"
    ]
},{
    "id": "2009995285",
    "title": "The burden of kidney disease: Improving global outcomes",
    "abstract": "The burden of kidney disease: Improving global outcomes. Chronic kidney disease (CKD) is a worldwide public health problem. There is an increasing incidence and prevalence of patients with kidney failure requiring replacement therapy, with poor outcomes and high cost. There is an even higher prevalence of patients in earlier stages of CKD, with adverse outcomes such as kidney failure, cardiovascular disease, and premature death. Patients at earlier stages of CKD can be detected through laboratory testing and their treatment is effective in slowing the progression to kidney failure and reducing cardiovascular events. The science and evidence-based care of these patients are universal and independent of their geographic location. There is a clear need to develop a uniform and global public health approach to the worldwide epidemic of CKD. It is to this end that a new initiative \"Kidney Disease: Improving Global Outcomes\" has been established. Its stated mission is \"Improve the care and outcomes of kidney disease patients worldwide through promoting coordination, collaboration and integration of initiatives to develop and implement clinical practice guidelines.\"",
    "date": "2004",
    "authors": [
        "Garabed Eknoyan",
        "Norbert Lameire",
        "Rashad Barsoum",
        "Kai-Uwe Eckardt",
        "Adeera Levin",
        "Nathan Levin",
        "Francesco Locatelli",
        "Alison Macleod",
        "Raymond Vanholder",
        "Rowan Walker",
        "Haiyan Wang"
    ],
    "related_topics": [
        "Kidney disease",
        "Nephrology",
        "Global health"
    ],
    "citation_count": "685",
    "reference_count": "47",
    "references": [
        "2156121263",
        "2120309176",
        "2157105773",
        "2070309439",
        "2136066292",
        "2141297458",
        "1986347387",
        "2028933700",
        "2132803823",
        "2169075800"
    ]
},{
    "id": "2073859061",
    "title": "Challenges in end-of-life care in the ICU",
    "abstract": "The jurors identified numerous problems with end of life in the ICU including variability in practice, inadequate predictive models for death, elusive knowledge of patient preferences, poor communication between staff and surrogates, insufficient or absent training of health-care providers, the use of imprecise and insensitive terminology, and incomplete documentation in the medical records. The jury strongly recommends that research be conducted to improve end-of-life care. The jury advocates a \u201cshared\u201d approach to end-of-life decision-making involving the caregiver team and patient surrogates. Respect for patient autonomy and the intention to honour decisions to decline unwanted treatments should be conveyed to the family. The process is one of negotiation, and the outcome will be determined by the personalities and beliefs of the participants. Ultimately, it is the attending physician\u2019s responsibility, as leader of the health-care team, to decide on the reasonableness of the planned action. In the event of conflict, the ICU team may agree to continue support for a predetermined time. Most conflicts can be resolved. If the conflict persists, however, an ethics consultation may be helpful. Nurses must be involved in the process. The patient must be assured of a pain-free death. The jury of the Consensus Conference subscribes to the moral and legal principles that prohibit administering treatments specifically designed to hasten death. The patient must be given sufficient analgesia to alleviate pain and distress; if such analgesia hastens death, this \u201cdouble effect\u201d should not detract from the primary aim to ensure comfort.",
    "date": "2004",
    "authors": [
        "Jean Carlet",
        "Lambertus G. Thijs",
        "Massimo Antonelli",
        "Joan Cassell",
        "Peter Cox",
        "Nicholas Hill",
        "Charles Hinds",
        "Jorge Manuel Pimentel",
        "Konrad Reinhart",
        "Boyd Taylor Thompson"
    ],
    "related_topics": [
        "Intensive care",
        "Ethics Consultation",
        "End-of-life care"
    ],
    "citation_count": "591",
    "reference_count": "68",
    "references": [
        "2137325786",
        "2150469511",
        "2103968057",
        "2141791438",
        "2089687441",
        "2059270934",
        "2019053188",
        "2148270065",
        "2074546317",
        "2155860263"
    ]
},{
    "id": "1992332433",
    "title": "What's the relative risk? A method of correcting the odds ratio in cohort studies of common outcomes.",
    "abstract": "Logistic regression is used frequently in cohort studies and clinical trials. When the incidence of an outcome of interest is common in the study population (>10%), the adjusted odds ratio derived from the logistic regression can no longer approximate the risk ratio. The more frequent the outcome, the more the odds ratio overestimates the risk ratio when it is more than 1 or underestimates it when it is less than 1. We propose a simple method to approximate a risk ratio from the adjusted odds ratio and derive an estimate of an association or treatment effect that better represents the true relative risk.",
    "date": "1998",
    "authors": [
        "Jun Zhang",
        "Kai F. Yu"
    ],
    "related_topics": [
        "Odds ratio",
        "Relative risk",
        "Diagnostic odds ratio"
    ],
    "citation_count": "3,369",
    "reference_count": "6",
    "references": [
        "1973948212",
        "2071790093",
        "2164254918",
        "2150000105",
        "2144422782",
        "1980498946"
    ]
},{
    "id": "1996020381",
    "title": "Hospital-acquired renal insufficiency.",
    "abstract": "Despite myriad improvements in the care of hospitalized patients, a decline in renal function remains a common event. Renal function in 4,622 consecutive patients admitted to the medical and surgical services of an urban tertiary care hospital was followed up prospectively from the time of admission. Some degree of renal insufficiency developed in 7.2% of patients. Decreased renal perfusion, medications, surgery, and radiographic contrast media were the most common causes of hospital-acquired renal insufficiency (HARI). The overall mortality rate was 19.4% and was similar among patients for all causes of renal insufficiency, except sepsis. For patients with a greater than 3.0-mg/dL increase in serum creatinine level, the mortality rate was 37.8%. As shown by previous investigators, age and preexisting renal insufficiency were risk factors for HARI. Women and blacks had less hospital-acquired renal failure. The increasing acuity of hospital admissions has been accompanied by a greater incidence of acute renal insufficiency in patients admitted to hospitals. There is a trend toward better survival in patients with a severe deterioration in renal function.",
    "date": "2002",
    "authors": [
        "Kevin Nash",
        "Abdul Hafeez",
        "Susan Hou"
    ],
    "related_topics": [
        "Kidney disease",
        "Renal function",
        "Radiographic contrast media"
    ],
    "citation_count": "2,339",
    "reference_count": "21",
    "references": [
        "1967237457",
        "2057571412",
        "2036544704",
        "2139529386",
        "2018224788",
        "2728772779",
        "2018202108",
        "2158830464",
        "3026502384",
        "2159927029"
    ]
},{
    "id": "1550111394",
    "title": "Prediction of Creatinine Clearance from Serum Creatinine",
    "abstract": "A formula has been developed to predict creatinine clearance (Ccr) from serum creatinine (Scr) in adult males: Ccr = (140 \u2013 age) (wt kg)/72 \u00d7 Scr(mg/100ml) (15% less i",
    "date": "1975",
    "authors": [
        "D W Cockcroft",
        "M H Gault"
    ],
    "related_topics": [
        "Serum Creatinine Measurement",
        "Serum Creatinine Assay",
        "Creatinine Measurement"
    ],
    "citation_count": "26,673",
    "reference_count": "0",
    "references": []
},{
    "id": "2072075701",
    "title": "Serum cystatin C is superior to serum creatinine as a marker of kidney function: A meta-analysis",
    "abstract": "Abstract Background: Serum cystatin C (Cys C) has been proposed as a simple, accurate, and rapid endogenous marker of glomerular filtration rate (GFR) in research and clinical practice. However, there are conflicting reports regarding the superiority of Cys C over serum creatinine (Cr), with a few studies suggesting no significant difference. Methods: We performed a meta-analysis of available data from various studies to compare the accuracy of Cys C and Cr in relation to a reference standard of GFR. A bibliographic search showed 46 articles until December 31, 2001. We also retrieved data from eight other studies presented and published in abstract form. Results: The overall correlation coefficient for the reciprocal of serum Cys C ( r = 0.816; 95% confidence interval [CI], 0.804 to 0.826) was superior to that of the reciprocal of serum Cr ( r = 0.742; 95% CI, 0.726 to 0.758; P P r = 0.846 versus r = 0.784; P Conclusion: In this meta-analysis using currently available data, serum Cys C is clearly superior to serum Cr as a marker of GFR measured by correlation or mean ROC-plot AUC. \u00a9 2002 by the National Kidney Foundation, Inc.",
    "date": "2002",
    "authors": [
        "Vikas R. Dharnidharka",
        "Charles Kwon",
        "Gary Stevens"
    ],
    "related_topics": [
        "Renal function",
        "Cystatin C",
        "Creatinine"
    ],
    "citation_count": "2,004",
    "reference_count": "44",
    "references": [
        "2104960492",
        "2121943809",
        "2077641457",
        "2042272211",
        "1496215511",
        "2166027867",
        "2100510417",
        "2051873425",
        "2144367890",
        "2059342423"
    ]
},{
    "id": "2029723446",
    "title": "The Effect of Acute Renal Failure on Mortality: A Cohort Analysis",
    "abstract": "Objective. \u2014To determine if the high mortality in acute renal failure is explained by underlying illnesses (comorbidity). Design. \u2014Cohort analytic study. Setting. \u2014An 826-bed general hospital providing primary, secondary, and tertiary care. Patients. \u2014From 16248 inpatients undergoing radiocontrast procedures between 1987 and 1989, we identified 183 index subjects who developed contrast media\u2014associated renal failure (defined as an increase in serum creatinine level of at least 25%, to at least 177 \u03bcmol/L [2 mg/dL], within 2 days of receiving contrast material) and 174 paired subjects, matched for age and baseline serum creatinine level, who underwent similar contrast procedures without developing renal failure. Main Outcome Measure. \u2014Death during hospitalization. Results. \u2014The mortality rate in subjects without renal failure was 7%, compared with 34% in the corresponding index subjects with renal failure (odds ratio, 6.5;P Conclusions. \u2014The high mortality rate in acute renal failure is not explained by the underlying conditions alone. Renal failure appears to increase the risk of developing severe nonrenal complications that lead to death and should not be regarded as a treatable complication of serious illness. (JAMA. 1996;275:1489-1494)",
    "date": "1996",
    "authors": [
        "Elliott M. Levy",
        "Catherine M. Viscoli",
        "Ralph I. Horwitz"
    ],
    "related_topics": [
        "Acute kidney injury",
        "Creatinine",
        "Mortality rate"
    ],
    "citation_count": "1,839",
    "reference_count": "33",
    "references": [
        "1973948212",
        "2107978811",
        "2313581450",
        "1976927254",
        "1997013992",
        "2316461329",
        "2728772779",
        "2083669508",
        "2039464237",
        "1487297692"
    ]
},{
    "id": "2153767046",
    "title": "Guided medication dosing for inpatients with renal insufficiency.",
    "abstract": "ContextUsual drug-prescribing practices may not consider the effects of renal insufficiency on the disposition of certain drugs. Decision aids may help optimize prescribing behavior and reduce medical error.ObjectiveTo determine if a system application for adjusting drug dose and frequency in patients with renal insufficiency, when merged with a computerized order entry system, improves drug prescribing and patient outcomes.Design, Setting, and PatientsFour consecutive 2-month intervals consisting of control (usual computerized order entry) alternating with intervention (computerized order entry plus decision support system), conducted in September 1997\u2013April 1998 with outcomes assessed among a consecutive sample of 17 828 adults admitted to an urban tertiary care teaching hospital.InterventionReal-time computerized decision support system for prescribing drugs in patients with renal insufficiency. During intervention periods, the adjusted dose list, default dose amount, and default frequency were displayed to the order-entry user and a notation was provided that adjustments had been made based on renal insufficiency. During control periods, these recommended adjustments were not revealed to the order-entry user, and the unadjusted parameters were displayed.Main Outcome MeasuresRates of appropriate prescription by dose and frequency, length of stay, hospital and pharmacy costs, and changes in renal function, compared among patients with renal insufficiency who were hospitalized during the intervention vs control periods.ResultsA total of 7490 patients were found to have some degree of renal insufficiency. In this group, 97 151 orders were written on renally cleared or nephrotoxic medications, of which 14 440 (15%) had at least 1 dosing parameter modified by the computer based on renal function. The fraction of prescriptions deemed appropriate during the intervention vs control periods by dose was 67% vs 54% (P<.001) and by frequency was 59% vs 35% (P<.001). Mean (SD) length of stay was 4.3 (4.5) days vs 4.5 (4.8) days in the intervention vs control periods, respectively (P = .009). There were no significant differences in estimated hospital and pharmacy costs or in the proportion of patients who experienced a decline in renal function during hospitalization.ConclusionsGuided medication dosing for inpatients with renal insufficiency appears to result in improved dose and frequency choices. This intervention demonstrates a way in which computer-based decision support systems can improve care.",
    "date": "2001",
    "authors": [
        "Glenn M. Chertow",
        "Joshua Lee",
        "Gilad J. Kuperman",
        "Elisabeth Burdick",
        "Jan Horsky",
        "Diane L. Seger",
        "Rita Lee",
        "Aparna Mekala",
        "Jean Song",
        "Anthony L. Komaroff",
        "David W. Bates"
    ],
    "related_topics": [
        "Kidney disease",
        "Dosing",
        "Renal function"
    ],
    "citation_count": "504",
    "reference_count": "15",
    "references": [
        "2095818009",
        "1550111394",
        "3141512384",
        "2029723446",
        "1970448985",
        "2014738583",
        "2100899314",
        "2092491126",
        "2095587358",
        "2011542177"
    ]
},{
    "id": "2768146862",
    "title": "Definitions for Sepsis and Organ Failure and Guidelines for the Use of Innovative Therapies in Sepsis",
    "abstract": "An American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference was held in Northbrook in August 1991 with the goal of agreeing on a set of definitions that could be applied to patients with sepsis and its sequelae. New definitions were offered for some terms, while others were discarded. Broad definitions of sepsis and the systemic inflammatory response syndrome were proposed, along with detailed physiologic parameters by which a patient may be categorized. Definitions for severe sepsis, septic shock, hypotension, and multiple organ dysfunction syndrome were also offered. The use of severity scoring methods when dealing with septic patients was recommended as an adjunctive tool to assess mortality. Appropriate methods and applications for the use and testing of new therapies were recommended. The use of these terms and techniques should assist clinicians and researchers who deal with sepsis and its sequelae.",
    "date": "1992",
    "authors": [
        "R. C. Bone",
        "R. A. Balk",
        "F. B. Cerra",
        "R. P. Dellinger",
        "A. M. Fein",
        "W. A. Knaus",
        "R. M. H. Schein",
        "W. J. Sibbald"
    ],
    "related_topics": [
        "Surviving Sepsis Campaign",
        "Systemic inflammatory response syndrome",
        "Multiple organ dysfunction syndrome"
    ],
    "citation_count": "17,348",
    "reference_count": "44",
    "references": [
        "2120156715",
        "2039602526",
        "2038434279",
        "2000421482",
        "2080813431",
        "2057212716",
        "2045010042",
        "1989586079",
        "2004536137",
        "2112875552"
    ]
},{
    "id": "2599527603",
    "title": "Members of the American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference Committee: American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference: Definitions for sepsis and organ failure and guidelines for the use of innovative therapies in sepsis",
    "abstract": "",
    "date": "1992",
    "authors": [
        "RC Bone",
        "RA Balk",
        "FB Cerra",
        "RP Dellinger",
        "AM Fein",
        "WA Knaus",
        "RM Schein",
        "WJ Sibbald",
        "WA Knous",
        "JH Abrams",
        "GR Bernard",
        "JW Biondi",
        "JE Calvin",
        "R Demling",
        "PJ Fahey",
        "CJ Fisher",
        "C Franklin",
        "KJ Gorelick",
        "MA Kelley",
        "DG Maki",
        "JC Marshall",
        "WW Merrill",
        "JP Pribble",
        "EC Rackow",
        "TC Rodell",
        "JN Sheagren",
        "M Silver",
        "CL Sprung",
        "RC Straube",
        "MJ Tobin",
        "GM Trenholme",
        "DP Wagner",
        "CD Webb",
        "JC Wherry",
        "HP Wiedemann",
        "CH Wortel",
        "M. Kyl\u00e4np\u00e4\u00e4-B\u00e4ck"
    ],
    "related_topics": [
        "Systemic inflammatory response syndrome",
        "Family medicine",
        "Intensive care medicine"
    ],
    "citation_count": "6,569",
    "reference_count": "0",
    "references": []
},{
    "id": "1554783366",
    "title": "Cochrane Injuries Group Albumin ReviewersWhy albumin may not work",
    "abstract": "Abstract Objective: To quantify effect on mortality of administering human albumin or plasma protein fraction during management of critically ill patients. Design: Systematic review of randomised controlled trials comparing administration of albumin or plasma protein fraction with no administration or with administration of crystalloid solution in critically ill patients with hypovolaemia, burns, or hypoalbuminaemia. Subjects: 30 randomised controlled trials including 1419 randomised patients. Main outcome measure:Mortality from all causes at end of follow up for each trial. Results: For each patient category the risk of death in the albumin treated group was higher than in the comparison group.For hypovolaemia the relative risk of death after albuminadministration was 1.46 (95% confidence interval 0.97 to 2.22), for burns the relative risk was 2.40 (1.11 to 5.19),and for hypoalbuminaemia it was 1.69 (1.07 to 2.67). Pooled relative risk of death with albumin administration was 1.68 (1.26 to 2.23). Pooled difference in the risk of death with albumin was 6% (95% confidence interval 3% to 9%) with a fixed effects model. These data suggest that for every 17 critically ill patients treated with albumin there is one additional death. Conclusions: There is no evidence that albumin administration reduces mortality incritically ill patients with hypovolaemia,burns, or hypoalbuminaemia and a strong suggestion that it may increase mortality. These data suggest that use of human albumin in critically ill patients should be urgently reviewed and that it should not be used outside the context of rigorously conducted, randomised controlled trials.",
    "date": "1998",
    "authors": [
        "Abi Berger"
    ],
    "related_topics": [
        "Relative risk",
        "Context (language use)",
        "Albumin"
    ],
    "citation_count": "1,222",
    "reference_count": "38",
    "references": [
        "2157823046",
        "2011932878",
        "2129829737",
        "2090119255",
        "2150563200",
        "2080942352",
        "2073940375",
        "1995096417",
        "2089169276",
        "2017973849"
    ]
},{
    "id": "2112577081",
    "title": "Human albumin administration in critically ill patients: systematic review of randomised controlled trials",
    "abstract": "Objective: To quantify effect on mortality of administering human albumin or plasma protein fraction during management of critically ill patients. Design: Systematic review of randomised controlled trials comparing administration of albumin or plasma protein fraction with no administration or with administration of crystalloid solution in critically ill patients with hypovolaemia, burns, or hypoalbuminaemia. Subjects: 30 randomised controlled trials including 1419 randomised patients. Main outcome measure: Mortality from all causes at end of follow up for each trial. Results: For each patient category the risk of death in the albumin treated group was higher than in the comparison group. For hypovolaemia the relative risk of death after albumin administration was 1.46 (95% confidence interval 0.97 to 2.22), for burns the relative risk was 2.40 (1.11 to 5.19), and for hypoalbuminaemia it was 1.69 (1.07 to 2.67). Pooled relative risk of death with albumin administration was 1.68 (1.26 to 2.23). Pooled difference in the risk of death with albumin was 6% (95% confidence interval 3% to 9%) with a fixed effects model. These data suggest that for every 17 critically ill patients treated with albumin there is one additional death. Conclusions: There is no evidence that albumin administration reduces mortality in critically ill patients with hypovolaemia, burns, or hypoalbuminaemia and a strong suggestion that it may increase mortality. These data suggest that use of human albumin in critically ill patients should be urgently reviewed and that it should not be used outside the context of rigorously conducted, randomised controlled trials.",
    "date": "1997",
    "authors": [
        "Cochrane Injuries",
        "Ian Roberts"
    ],
    "related_topics": [
        "Relative risk",
        "Context (language use)",
        "Confidence interval"
    ],
    "citation_count": "849",
    "reference_count": "42",
    "references": [
        "2157823046",
        "2011932878",
        "2129829737",
        "2986772077",
        "2090119255",
        "2150563200",
        "2080942352",
        "2126639731",
        "2073940375",
        "1995096417"
    ]
},{
    "id": "1603121691",
    "title": "ASSESSMENT OF COMA AND IMPAIRED CONSCIOUSNESS: A Practical Scale",
    "abstract": "Abstract A clinical scale has been evolved for assessing the depth and duration of impaired consciousness and coma. Three aspects of behaviour are independently measured\u2014motor responsiveness, verbal performance, and eye opening. These can be evaluated consistently by doctors and nurses and recorded on a simple chart which has proved practical both in a neurosurgical unit and in a general hospital. The scale facilitates consultations between general and special units in cases of recent brain damage, and is useful also in defining the duration of prolonged coma.",
    "date": "1974",
    "authors": [
        "Graham M. Teasdale",
        "Bryan Jennett"
    ],
    "related_topics": [
        "Glasgow Coma Scale",
        "Coma",
        "Reaction Level Scale"
    ],
    "citation_count": "15,134",
    "reference_count": "13",
    "references": [
        "2159778865",
        "2083523346",
        "2160858053",
        "2316975339",
        "2007635105",
        "1992589542",
        "2058770997",
        "2081800466",
        "2000007285",
        "3127305915"
    ]
},{
    "id": "2046852559",
    "title": "Epidemiology: Study Design and Data Analysis",
    "abstract": "PREFACE FUNDAMENTAL ISSUES What is Epidemiology? Case Studies: The Work of Doll and Hill Populations and Samples Measuring Disease Measuring the Risk Factor Causality Studies Using Routine Data Study Design Data Analysis Exercises BASIC ANALYTICAL PROCEDURES Introduction Case Study Types of Variables Tables and Charts Inferential Techniques for Categorical Variables Descriptive Techniques for Quantitative Variables Inferences about Means Inferential Techniques for Non-Normal Data Measuring Agreement Assessing Diagnostic Tests Exercises ASSESSING RISK FACTORS Risk and Relative Risk Odds and Odds Ratio Relative Risk or Odds Ratio? Prevalence Studies Testing Association Risk Factors Measured at Several Levels Attributable Risk Rate and Relative Rate Measures of Difference Exercises CONFOUNDING AND INTERACTION Introduction The Concept of Confounding Identification of Confounders Assessing Confounding Standardization Mantel-Haenszel Methods The Concept of Interaction Testing for Interaction Dealing with Interaction Exercises COHORT STUDIES Design Considerations Analytical Considerations Cohort Life Tables Kaplan-Meier Estimation Comparison of Two Sets of Survival Probabilities The Person-Years Method Period-Cohort Analysis Exercises CASE-CONTROL STUDIES Basic Design Concepts Basic Methods of Analysis Selection of Cases Selection of Controls Matching The Analysis of Matched Studies Nested Case-Control Studies Case-Cohort Studies Case-Crossover Studies Exercises INTERVENTION STUDIES Introduction Ethical Considerations Avoidance of Bias Parallel Group Studies Cross-Over Studies Sequential Studies Allocation to Treatment Group Exercises SAMPLE SIZE DETERMINATION Introduction Power Testing a Mean Value Testing a Difference Between Means Testing a Proportion Testing a Relative Risk Case-Control Studies Complex Sampling Designs Concluding Remarks Exercises MODELLING QUANTITATIVE OUTCOME VARIABLES Statistical Models One Categorical Explanatory Variable One Quantitative Explanatory Variable Two Categorical Explanatory Variables Model Building General Linear Models Several Explanatory Variables Model Checking Confounding Longitudinal Data Non-Normal Alternatives Exercises MODELLING BINARY OUTCOME DATA Introduction Problems with Standard Regression Models Logistic Regression Interpretation of Logistic Regression Coefficients Generic Data Multiple Logistic Regression Models Tests of Hypotheses Confounding Interaction Model Checking Regression Dilution Case-Control Studies Outcomes with Several Ordered Levels Longitudinal Data Complex Sampling Designs Exercises MODELLING FOLLOW-UP DATA Introduction Basic Functions of Survival Time Estimating the Hazard Function Probability Models Proportional Hazards Regression Models The Cox Proportional Hazards Model The Weibull Proportional Hazards Model Model Checking Poisson Regression Pooled Logistic Regression Exercises META-ANALYSIS Reviewing Evidence Systematic Review A General Approach to Pooling Investigating Heterogeneity Pooling Tabular Data Individual Participant Data Dealing with Aspects of Study Quality Publication Bias Is Meta-Analysis a Valid Tool in Epidemiology? Exercises APPENDIX A: MATERIALS AVAILABLE FROM THE WEBSITE APPENDIX B: STATISTICAL TABLES APPENDIX C: EXAMPLE DATA SETS SOLUTIONS TO EXERCISES REFERENCES INDEX",
    "date": "1999",
    "authors": [
        "Mark Woodward"
    ],
    "related_topics": [
        "Categorical variable",
        "Regression analysis",
        "Logistic regression"
    ],
    "citation_count": "1,110",
    "reference_count": "0",
    "references": []
},{
    "id": "1898928487",
    "title": "The SOFA (Sepsis-related Organ Failure Assessment) score to describe organ dysfunction/failure. On behalf of the Working Group on Sepsis-Related Problems of the European Society of Intensive Care Medicine.",
    "abstract": "",
    "date": "1996",
    "authors": [
        "J. L. Vincent",
        "R. Moreno",
        "J. Takala",
        "S. Willatts",
        "A. De Mendon\u00e7a",
        "H. Bruining",
        "C. K. Reinhart",
        "P. M. Suter",
        "L. G. Thijs"
    ],
    "related_topics": [
        "Organ dysfunction",
        "SOFA score",
        "Organ Dysfunction Scores"
    ],
    "citation_count": "11,127",
    "reference_count": "16",
    "references": [
        "2085208748",
        "2002008524",
        "1996907628",
        "2005118831",
        "1980446427",
        "2004536137",
        "2052070515",
        "1999351703",
        "2059670160",
        "1979109569"
    ]
},{
    "id": "2148973700",
    "title": "Effects of different doses in continuous veno-venous haemofiltration on outcomes of acute renal failure: a prospective randomised trial.",
    "abstract": "Summary Background Continuous veno-venous haemofiltration is increasingly used to treat acute renal failure in critically ill patients, but a clear definition of an adequate treatment dose has not been established. We undertook a prospective randomised study of the impact different ultrafiltration doses in continuous renal replacement therapy on survival. Methods We enrolled 425 patients, with a mean age of 61 years, in intensive care who had acute renal failure. Patients were randomly assigned ultrafiltration at 20 mL h \u22121 kg \u22121 (group 1, n=146), 35 mL h \u22121 kg \u22121 (group 2, n=139), or 45 mL h \u22121 kg \u22121 (group 3, n=140). The primary endpoint was survival at 15 days after stopping haemofiltration. We also assessed recovery of renal function and frequency of complications during treatment. Analysis was by intention to treat. Results Survival in group 1 was significantly lower than in groups 2 (p=0\u00b70007) and 3 (p=0\u00b70013). Survival in groups 2 and 3 did not differ significantly (p=0\u00b787). Adjustment for possible confounding factors did not change the pattern of differences among the groups. Survivors in all groups had lower concentrations of blood urea nitrogen before continuous haemofiltration was started than non-survivors. 95%, 92%, and 90% of survivors in groups 1, 2, and 3, respectively, had full recovery of renal function. The frequency of complications was similarly low in all groups. Interpretation Mortality among these critically ill patients was high, but increase in the rate of ultrafiltration improved survival significantly. We recommend that ultrafiltration should be prescribed according to patient's bodyweight and should reach at least 35 mL h \u22121 kg \u22121 .",
    "date": "2000",
    "authors": [
        "Claudio Ronco",
        "Rinaldo Bellomo",
        "Peter Homel",
        "Alessandra Brendolan",
        "Maurizio Dan",
        "Pasquale Piccinni",
        "Gluseppe La Greca"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Intensive care",
        "Blood urea nitrogen"
    ],
    "citation_count": "2,168",
    "reference_count": "22",
    "references": [
        "2054361787",
        "1968121673",
        "2272732540",
        "2801585826",
        "1987586397",
        "2125895036",
        "62289269",
        "199794892",
        "2002487190",
        "3152062928"
    ]
},{
    "id": "1980228387",
    "title": "Acute kidney injury in the intensive care unit according to RIFLE",
    "abstract": "Objectives:To apply the RIFLE criteria \u201crisk,\u201d \u201cinjury,\u201d and \u201cfailure\u201d for severity of acute kidney injury to patients admitted to the intensive care unit and to evaluate the significance of other prognostic factors.Design:Retrospective analysis of the Riyadh Intensive Care Program database.Setting:",
    "date": "2007",
    "authors": [
        "Marlies Ostermann",
        "Ren\u00e9 W. S. Chang"
    ],
    "related_topics": [
        "Intensive care",
        "Intensive care unit",
        "Rifle"
    ],
    "citation_count": "881",
    "reference_count": "38",
    "references": [
        "2055864845",
        "1967300023",
        "2139937737",
        "2149687213",
        "2131419242",
        "1489794536",
        "2116909658",
        "2069722312",
        "2087016628",
        "1988629947"
    ]
},{
    "id": "1997278766",
    "title": "Daily Hemodialysis and the Outcome of Acute Renal Failure",
    "abstract": "Background Intermittent hemodialysis is widely used as renal-replacement therapy in patients with acute renal failure, but an adequate dose has not been defined. We performed a prospective study to determine the effect of daily intermittent hemodialysis, as compared with conventional (alternate-day) intermittent hemodialysis, on survival among patients with acute renal failure. Methods A total of 160 patients with acute renal failure were assigned to receive daily or conventional intermittent hemodialysis. Survival was the primary end point of the study. The duration of acute renal failure and the frequency of therapy-related complications were secondary end points. Results The two study groups were similar with respect to age, sex, cause and severity of acute renal failure, medical or surgical intensive care setting, and the score on the Acute Physiology, Age, and Chronic Health Evaluation. Daily hemodialysis resulted in better control of uremia, fewer hypotensive episodes during hemodialysis, and more r...",
    "date": "2002",
    "authors": [
        "Helmut Schiffl",
        "Susanne M Lang",
        "Rainald Fischer"
    ],
    "related_topics": [
        "Hemodialysis",
        "Acute kidney injury",
        "Kidney disease"
    ],
    "citation_count": "1,105",
    "reference_count": "15",
    "references": [
        "2120156715",
        "2148973700",
        "1967237457",
        "2029723446",
        "2143345898",
        "1979517515",
        "1968121673",
        "2058269063",
        "1975948182",
        "1970986797"
    ]
},{
    "id": "2107538404",
    "title": "Incidence and Mortality of Acute Renal Failure in Medicare Beneficiaries, 1992 to 2001",
    "abstract": "This study's objective was to determine the incidence and mortality of acute renal failure (ARF) in Medicare beneficiaries. Data were from hospitalized Medicare beneficiaries (5,403,015 discharges) between 1992 and 2001 from the 5% sample of Medicare claims. For 1992 to 2001, the overall incidence rate of ARF was 23.8 cases per 1000 discharges, with rates increasing by approximately 11% per year. Older age, male gender, and black race were strongly associated (P < 0.0001) with ARF. The overall in-hospital death rate was 4.6% in discharges without ARF, 15.2% in discharges with ARF coded as the principal diagnosis, and 32.6% in discharges with ARF as a secondary diagnosis. In-hospital death rates were 32.9% in discharges with ARF that required renal dialysis and 27.5% in those with ARF that did not require dialysis. Death within 90 d after hospital admission was 13.1% in discharges without ARF, 34.5% in discharges with ARF coded as the principal diagnosis, and 48.6% in discharges with ARF as a secondary diagnosis. Discharges with ARF were more (P < 0.0001) likely to have intensive care and other acute organ dysfunction than those without ARF. For discharges both with and without ARF, rates for death within 90 d after hospital admission showed a declining trend. In conclusion, the incidence rate of ARF in Medicare beneficiaries has been increasing. Those of older age, male gender, and black race are more likely to have ARF. These data show ARF to be a major contributor to morbidity and mortality in hospitalized patients.",
    "date": "2006",
    "authors": [
        "Jay L. Xue",
        "Frank Daniels",
        "Robert A. Star",
        "Paul L. Kimmel",
        "Paul W. Eggers",
        "Bruce A. Molitoris",
        "Jonathan Himmelfarb",
        "Allan J. Collins"
    ],
    "related_topics": [
        "Intensive care",
        "Mortality rate",
        "Incidence (epidemiology)"
    ],
    "citation_count": "935",
    "reference_count": "34",
    "references": [
        "2049927822",
        "2145577370",
        "1996020381",
        "2153104532",
        "1967237457",
        "2151517451",
        "2029723446",
        "1997278766",
        "2050034771",
        "2046852559"
    ]
},{
    "id": "1988629947",
    "title": "Acute renal failure in the ICU: risk factors and outcome evaluated by the SOFA score",
    "abstract": "Objectives: To describe risk factors for the development of acute renal failure (ARF) in a population of intensive care unit (ICU) patients, and the association of ARF with multiple organ failure (MOF) and outcome using the sequential organ failure assessment (SOFA) score. Design: Prospective, multicenter, observational cohort analysis. Setting: Forty ICUs in 16 countries. Patients: All patients admitted to one of the participating ICUs in May 1995, except those who stayed in the ICU for less than 48 h after uncomplicated surgery, were included. After the exclusion of 38 patients with a history of chronic renal failure requiring renal replacement therapy, a total of 1411 patients were studied. Measurements and results: Of the patients, 348 (24.7 %) developed ARF, as diagnosed by a serum creatinine of 300 \u03bcmol/l (3.5 mg/dl) or more and/or a urine output of less than 500 ml/day. The most important risk factors for the development of ARF present on admission were acute circulatory or respiratory failure; age more than 65 years, presence of infection, past history of chronic heart failure (CHF), lymphoma or leukemia, or cirrhosis. ARF patients developed MOF earlier than non-ARF patients (median 24 vs 48 h after ICU admission, p < 0.05). ARF patients older than 65 years with a past history of CHF or with any organ failure on admission were most likely to develop MOF. ICU mortality was 3 times higher in ARF than in other patients (42.8 % vs 14.0 %, p < 0.01). Oliguric ARF was an independent risk factor for overall mortality as determined by a multivariate regression analysis (OR = 1.59 [CI 95 %: 1.23\u20132.06], p < 0.01). Infection increased the risk of death associated with all factors. Factors that increased the ICU mortality of ARF patients were a past history of hematologic malignancy, age more than 65 years, the number of failing organs on admission and the presence of acute cardiovascular failure. Conclusion: In ICU patients, the most important risk factors for ARF or mortality from ARF are often present on admission. During the ICU stay, other organ failures (especially cardiovascular) are important risk factors. Oliguric ARF was an independent risk factor for ICU mortality, and infection increased the contribution to mortality by other factors. The severity of circulatory shock was the most important factor influencing outcome in ARF patients.",
    "date": "2000",
    "authors": [
        "A. de Mendon\u00e7a",
        "J.-L. Vincent",
        "P. M. Suter",
        "R. Moreno",
        "N. M. Dearden",
        "M. Antonelli",
        "J. Takala",
        "C. Sprung",
        "F. Cantraine"
    ],
    "related_topics": [
        "SOFA score",
        "Risk factor",
        "Intensive care unit"
    ],
    "citation_count": "962",
    "reference_count": "0",
    "references": []
},{
    "id": "1970593590",
    "title": "A randomized clinical trial of continuous versus intermittent dialysis for acute renal failure",
    "abstract": "A randomized clinical trial of continuous versus intermittent dialysis for acute renal failure. Background Acute renal failure (ARF) requiring dialysis in critically ill patients is associated with an in-hospital mortality rate of 50 to 80%. The worldwide standard for renal replacement therapy is intermittent hemodialysis (IHD). Continuous hemodialysis and hemofiltration techniques have recently emerged as alternative modalities. These two therapies have not been directly compared. Methods A multicenter, randomized, controlled trial was conducted comparing two dialysis modalities (IHD vs. continuous hemodiafiltration) for the treatment of ARF in the intensive care unit (ICU). One hundred sixty-six patients were randomized. Principal outcome measures were ICU and hospital mortality, length of stay, and recovery of renal function. Results Using intention-to-treat analysis, the overall ICU and in-hospital mortalities were 50.6 and 56.6%, respectively. Continuous therapy was associated with an increase in ICU (59.5 vs. 41.5%, P P P = NS). A detailed investigation of the randomization process failed to explain the marked differences in patient assignment. Conclusions A randomized controlled trial of alternative dialysis modalities in ARF is feasible. Despite the potential advantages of continuous techniques, this study provides no evidence of a survival benefit of continuous hemodiafiltration compared with IHD. This study did not control for other major clinical decisions or other supportive management strategies that are widely variable (for example, nutrition support, hemodynamic support, timing of initiation, and dose of dialysis) and might materially influence outcomes in ARF. Standardization of several aspects of care or extremely large sample sizes will be required to answer optimally the questions originally posed by this investigation.",
    "date": "2001",
    "authors": [
        "Ravindra L. Mehta",
        "Brian Mcdonald",
        "Francis B. Gabbai",
        "Madeleine Pahl",
        "Maria T.A. Pascual",
        "Arthur Farkas",
        "Robert M. Kaplan"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Hemodialysis",
        "Dialysis"
    ],
    "citation_count": "755",
    "reference_count": "23",
    "references": [
        "2036544704",
        "87960664",
        "2056699935",
        "1986562125",
        "2157450955",
        "1987586397",
        "62289269",
        "2021661396",
        "2133720519",
        "2027534721"
    ]
},{
    "id": "2156916779",
    "title": "Effects of early high-volume continuous venovenous hemofiltration on survival and recovery of renal function in intensive care patients with acute renal failure: A prospective, randomized trial",
    "abstract": "ObjectiveTo study the effects of the initiation time of continuous venovenous hemofiltration and of the ultrafiltrate rate in patients with circulatory and respiratory insufficiency developing early oliguric acute renal failure. The primary end points were mortality at 28 days and recovery of renal",
    "date": "2002",
    "authors": [
        "Catherine S C Bouman",
        "Heleen M Oudemans-Van Straaten",
        "Jan G P Tijssen",
        "Durk F Zandstra",
        "Jozef Kesecioglu"
    ],
    "related_topics": [
        "Hemofiltration",
        "Intensive care",
        "Kidney disease"
    ],
    "citation_count": "830",
    "reference_count": "32",
    "references": [
        "2060123467",
        "2107978811",
        "1898928487",
        "2128349740",
        "2120156715",
        "2148973700",
        "1550111394",
        "1967237457",
        "2043436644",
        "2086402680"
    ]
},{
    "id": "2159674113",
    "title": "Adding a dialysis dose to continuous hemofiltration increases survival in patients with acute renal failure.",
    "abstract": "Acute renal failure (ARF) in critically ill patients is associated with high mortality. Optimal method and dose of continuous renal replacement therapy could improve survival in these patients. We studied the hypothesis that an increase in dialysis dose obtained by continuous veno-venous hemodiafiltration (CVVHDF) is associated with a better survival than continuous veno-venous hemofiltration (CVVH) among critically ill patients with ARF. In a prospective randomized trial, these two methods were compared in patients undergoing renal replacement therapy in two intensive care units (ICUs). The patients had either CVVH (1\u20132.5l/h replacement fluid) or continuous CVVHDF (1\u20132.5l/h replacement fluid+1\u20131.5l/h dialysate) according to their body weight. 28- and 90-day mortalities, renal recovery, and duration of ICU stay were the main outcome measures. Two hundred and six patients were randomized from October 2000 to December 2003. Twenty-eight-day survivals (%) were, respectively, 39 and 59 ( P =0.03) in the CVVH and CVVHDF groups. Three months survivals (%) were, respectively, 34 and 59 ( P =0.0005) in the CVVH and CVVHDF groups. Apache II score, age, baseline blood urea nitrogen, and hemodiafiltration (hazard ratio 0.59, 95% confidence interval 0.40\u20130.87; P =0.008) were independent predictors of survival at 90 days. Renal recovery rate among survivors (71 versus 78% in the CVVH and CVVHDF groups respectively, P =0.62) was not affected by the type of renal replacement therapy. These results suggest that increasing the dialysis dose especially for low molecular weight solutes confers a better survival in severely ill patients with ARF.",
    "date": "2006",
    "authors": [
        "P. Saudan",
        "M. Niederberger",
        "S. De Seigneux",
        "J. Romand",
        "J. Pugin",
        "T. Perneger",
        "P.Y. Martin"
    ],
    "related_topics": [
        "Renal replacement therapy",
        "Hemofiltration",
        "Dialysis"
    ],
    "citation_count": "524",
    "reference_count": "23",
    "references": [
        "2768146862",
        "2148973700",
        "2043132544",
        "2069722312",
        "2151517451",
        "1997278766",
        "2156916779",
        "2028618147",
        "2008501189",
        "2039464237"
    ]
},{
    "id": "2085529382",
    "title": "Changes in the incidence and outcome for early acute kidney injury in a cohort of Australian intensive care units",
    "abstract": "Introduction There is limited information on whether the incidence of acute kidney injury (AKI) in critically ill patients has changed over time and there is controversy on whether its outcome has improved.",
    "date": "2007",
    "authors": [
        "Sean M Bagshaw",
        "Carol George",
        "Rinaldo Bellomo"
    ],
    "related_topics": [
        "Intensive care",
        "Acute kidney injury",
        "Cohort"
    ],
    "citation_count": "304",
    "reference_count": "44",
    "references": [
        "2107978811",
        "2149687213",
        "2128349740",
        "2148973700",
        "2061596342",
        "2043132544",
        "2069722312",
        "1997278766",
        "2107538404",
        "1988629947"
    ]
},{
    "id": "2118858814",
    "title": "Surviving Sepsis Campaign: international guidelines for management of severe sepsis and septic shock: 2008.",
    "abstract": "Objective To provide an update to the original Surviving Sepsis Campaign clinical management guidelines, \u201cSurviving Sepsis Campaign guidelines for management of severe sepsis and septic shock,\u201d published in 2004.",
    "date": "2007",
    "authors": [
        "R. Phillip Dellinger",
        "Mitchell M. Levy",
        "Jean M. Carlet",
        "Julian Bion",
        "Margaret M. Parker",
        "Roman Jaeschke",
        "Konrad Reinhart",
        "Derek C. Angus",
        "Christian Brun-Buisson",
        "Richard Beale",
        "Thierry Calandra",
        "Jean Francois Dhainaut",
        "Herwig Gerlach",
        "Maurene Harvey",
        "John J. Marini",
        "John Marshall",
        "Marco Ranieri",
        "Graham Ramsay",
        "Jonathan Sevransky",
        "B. Taylor Thompson",
        "Sean Townsend",
        "Jeffrey S. Vender",
        "Janice L. Zimmerman",
        "Jean Louis Vincent"
    ],
    "related_topics": [
        "Surviving Sepsis Campaign",
        "Sepsis",
        "Septic shock"
    ],
    "citation_count": "10,665",
    "reference_count": "366",
    "references": [
        "1980717583",
        "2160691650",
        "2597070792",
        "1247968195",
        "2049927822",
        "2151426785",
        "1993397663",
        "2322121630",
        "2115285670",
        "2768146862"
    ]
},{
    "id": "1980717583",
    "title": "Intensive Insulin Therapy in Critically Ill Patients",
    "abstract": "Background Hyperglycemia and insulin resistance are common in critically ill patients, even if they have not previously had diabetes. Whether the normalization of blood glucose levels with insulin therapy improves the prognosis for such patients is not known. Methods We performed a prospective, randomized, controlled study involving adults admitted to our surgical intensive care unit who were receiving mechanical ventilation. On admission, patients were randomly assigned to receive intensive insulin therapy (maintenance of blood glucose at a level between 80 and 110 mg per deciliter) or conventional treatment (infusion of insulin only if the blood glucose level exceeded 215 mg per deciliter and maintenance of glucose at a level between 180 and 200 mg per deciliter). Results At 12 months, with a total of 1548 patients enrolled, intensive insulin therapy reduced mortality during intensive care from 8.0 percent with conventional treatment to 4.6 percent (P<0.04, with adjustment for sequential analyses). The ...",
    "date": "2001",
    "authors": [
        "Greet Van den Berghe",
        "Pieter Wouters",
        "Frank Weekers",
        "Charles Verwaest",
        "Frans Bruyninckx",
        "Miet Schetz",
        "Dirk Vlasselaers",
        "Patrick Ferdinande",
        "Peter Lauwers",
        "Roger Bouillon"
    ],
    "related_topics": [
        "Insulin resistance",
        "Intensive care",
        "Artificial endocrine pancreas"
    ],
    "citation_count": "14,386",
    "reference_count": "41",
    "references": [
        "2769264260",
        "2134293572",
        "2322121630",
        "2107978811",
        "2107545755",
        "1990050552",
        "1840840071",
        "2009649501",
        "2027702390",
        "1990639292"
    ]
},{
    "id": "1986215651",
    "title": "Assessing the quality of reports of randomized clinical trials : is blinding necessary?",
    "abstract": "It has been suggested that the quality of clinical trials should be assessed by blinded raters to limit the risk of introducing bias into meta-analyses and systematic reviews, and into the peer-review process. There is very little evidence in the literature to substantiate this. This study describes the development of an instrument to assess the quality of reports of randomized clinical trials (RCTs) in pain research and its use to determine the effect of rater blinding on the assessments of quality. A multidisciplinary panel of six judges produced an initial version of the instrument. Fourteen raters from three different backgrounds assessed the quality of 36 research reports in pain research, selected from three different samples. Seven were allocated randomly to perform the assessments under blind conditions. The final version of the instrument included three items. These items were scored consistently by all the raters regardless of background and could discriminate between reports from the different samples. Blind assessments produced significantly lower and more consistent scores than open assessments. The implications of this finding for systematic reviews, meta-analytic research and the peer-review process are discussed.",
    "date": "1996",
    "authors": [
        "A. R. Jadad",
        "R. A. Moore",
        "D. Carroll",
        "C. Jenkinson",
        "D. J. M. Reynolds",
        "D. J. Gavaghan",
        "H. J. Mcquay"
    ],
    "related_topics": [
        "Blinding",
        "Jadad scale",
        "Systematic review"
    ],
    "citation_count": "23,200",
    "reference_count": "20",
    "references": [
        "2011932878",
        "2019398887",
        "2141403362",
        "2031385454",
        "2087851547",
        "2057631921",
        "1994898034",
        "2118266607",
        "2050802944",
        "2168909631"
    ]
},{
    "id": "2145053281",
    "title": "Intensive versus conventional glucose control in critically ill patients.",
    "abstract": "Background: The optimal target range for blood glucose in critically ill patients remains unclear. Methods: Within 24 hours after admission to an intensive care unit (ICU), adults who were expected to require treatment in the ICU on 3 or more consecutive days were randomly assigned to undergo either intensive glucose control, with a target blood glucose range of 81 to 108 mg per deciliter (4.5 to 6.0 mmol per liter), or conventional glucose control, with a target of 180 mg or less per deciliter (10.0 mmol or less per liter). We defined the primary end point as death from any cause within 90 days after randomization. Results: Of the 6104 patients who underwent randomization, 3054 were assigned to undergo intensive control and 3050 to undergo conventional control; data with regard to the primary outcome at day 90 were available for 3010 and 3012 patients, respectively. The two groups had similar characteristics at baseline. A total of 829 patients (27.5%) in the intensive-control group and 751 (24.9%) in the conventional-control group died (odds ratio for intensive control, 1.14; 95% confidence interval, 1.02 to 1.28; P=0.02). The treatment effect did not differ significantly between operative (surgical) patients and nonoperative (medical) patients (odds ratio for death in the intensive-control group, 1.31 and 1.07, respectively; P=0.10). Severe hypoglycemia (blood glucose level, < or = 40 mg per deciliter [2.2 mmol per liter]) was reported in 206 of 3016 patients (6.8%) in the intensive-control group and 15 of 3014 (0.5%) in the conventional-control group (P<0.001). There was no significant difference between the two treatment groups in the median number of days in the ICU (P=0.84) or hospital (P=0.86) or the median number of days of mechanical ventilation (P=0.56) or renal-replacement therapy (P=0.39). Conclusions: In this large, international, randomized trial, we found that intensive glucose control increased mortality among adults in the ICU: a blood glucose target of 180 mg or less per deciliter resulted in lower mortality than did a target of 81 to 108 mg per deciliter. (ClinicalTrials.gov number, NCT00220987.)",
    "date": "2009",
    "authors": [
        "Nice-Sugar Study Investigators",
        "D. Chittock",
        "S. Su",
        "D. Blair",
        "D. Foster",
        "Rinaldo Bellomo",
        "D. Cook",
        "V. Dhingra",
        "P. Dodek",
        "P. Hebert",
        "W. Henderson",
        "Stephane Heritier",
        "D. Heyland",
        "C. McArthur",
        "E. McDonald",
        "I. Mitchell",
        "R Norton",
        "J. Potter",
        "B. Robinson",
        "J. Ronco"
    ],
    "related_topics": [
        "Artificial endocrine pancreas",
        "Intensive care unit",
        "Stress hyperglycemia"
    ],
    "citation_count": "5,161",
    "reference_count": "36",
    "references": [
        "172609984",
        "1526927233",
        "1980717583",
        "2158666727",
        "2115285670",
        "2768146862",
        "2107978811",
        "2148706741",
        "1991864206",
        "2599527603"
    ]
},{
    "id": "2107328434",
    "title": "Meta-Analysis in Clinical Trials*",
    "abstract": "This paper examines eight published reviews each reporting results from several related trials. Each review pools the results from the relevant trials in order to evaluate the efficacy of a certain treatment for a specified medical condition. These reviews lack consistent assessment of homogeneity of treatment effect before pooling. We discuss a random effects approach to combining evidence from a series of experiments comparing two treatments. This approach incorporates the heterogeneity of effects in the analysis of the overall treatment efficacy. The model can be extended to include relevant covariates which would reduce the heterogeneity and allow for more specific therapeutic recommendations. We suggest a simple noniterative procedure for characterizing the distribution of treatment effects in a series of studies.",
    "date": "1986",
    "authors": [
        "Rebecca DerSimonian",
        "Nan Laird"
    ],
    "related_topics": [
        "Study heterogeneity",
        "Meta-analysis",
        "Funnel plot"
    ],
    "citation_count": "31,740",
    "reference_count": "19",
    "references": [
        "2049633694",
        "3085323863",
        "1999649023",
        "2059356295",
        "1982585616",
        "2043526487",
        "1984578273",
        "2951773335",
        "2942434766",
        "2037219714"
    ]
},{
    "id": "2115285670",
    "title": "Intensive insulin therapy in the medical ICU.",
    "abstract": "Background Intensive insulin therapy reduces morbidity and mortality in patients in surgical intensive care units (ICUs), but its role in patients in medical ICUs is unknown. Methods In a prospective, randomized, controlled study of adult patients admitted to our medical ICU, we studied patients who were considered to need intensive care for at least three days. On admission, patients were randomly assigned to strict normalization of blood glucose levels (80 to 110 mg per deciliter [4.4 to 6.1 mmol per liter]) with the use of insulin infusion or to conventional therapy (insulin administered when the blood glucose level exceeded 215 mg per deciliter [12 mmol per liter], with the infusion tapered when the level fell below 180 mg per deciliter [10 mmol per liter]). There was a history of diabetes in 16.9 percent of the patients. Results In the intention-to-treat analysis of 1200 patients, intensive insulin therapy reduced blood glucose levels but did not significantly reduce in-hospital mortality (40.0 percent in the conventional-treatment group vs. 37.3 percent in the intensive-treatment group, P = 0.33). However, morbidity was significantly reduced by the prevention of newly acquired kidney injury, accelerated weaning from mechanical ventilation, and accelerated discharge from the ICU and the hospital. Although length of stay in the ICU could not be predicted on admission, among 433 patients who stayed in the ICU for less than three days, mortality was greater among those receiving intensive insulin therapy. In contrast, among 767 patients who stayed in the ICU for three or more days, in-hospital mortality in the 386 who received intensive insulin therapy was reduced from 52.5 to 43.0 percent (P = 0.009) and morbidity was also reduced. Conclusions Intensive insulin therapy significantly reduced morbidity but not mortality among all patients in the medical ICU. Although the risk of subsequent death and disease was reduced in patients treated for three or more days, these patients could not be identified before therapy. Further studies are needed to confirm these preliminary data. (ClinicalTrials.gov number, NCT00115479.)",
    "date": "2006",
    "authors": [
        "Greet Van den Berghe",
        "Alexander Wilmer",
        "Greet Hermans",
        "Wouter Meersseman",
        "Pieter J. Wouters",
        "Ilse Milants",
        "Eric Van Wijngaerden",
        "Herman Bobbaers",
        "Roger Bouillon"
    ],
    "related_topics": [
        "Intensive care",
        "Intensive care unit",
        "Insulin"
    ],
    "citation_count": "4,936",
    "reference_count": "24",
    "references": [
        "2769264260",
        "1980717583",
        "2139937737",
        "2107978811",
        "2107545755",
        "2135143587",
        "2163567504",
        "2092998122",
        "2118828771",
        "1990050552"
    ]
},{
    "id": "2081040380",
    "title": "Systematic Reviews in Health Care : Meta-Analysis in Context",
    "abstract": "The second edition of this best-selling book has been thoroughly revised and expanded to reflect the significant changes and advances made in systematic reviewing. New features include discussion on the rationale, meta-analyses of prognostic and diagnostic studies and software, and the use of systematic reviews in practice.",
    "date": "2000",
    "authors": [
        "Matthias Egger",
        "George Davey Smith",
        "Douglas G Altman"
    ],
    "related_topics": [
        "Systematic review",
        "Context (language use)",
        "Health care"
    ],
    "citation_count": "2,520",
    "reference_count": "0",
    "references": []
},{
    "id": "2007884458",
    "title": "Standards of Medical Care in Diabetes\u20142008: Response to Hirsch, Inzucchi, and Kirkman",
    "abstract": "The American Diabetes Association (ADA) has released a Standards of Medical Care in Diabetes Position Statement for 2008 (1). In this document, it is stated that aspirin therapy should be used as a primary prevention strategy in diabetic patients at increased cardiovascular (CV) risk, including those who are >40 years old or have additional risk factors. The recommendation is based on evidence graded \u201cA,\u201d which is defined by the ADA as \u201cevidence from well-conducted, randomized controlled trials that are adequately powered or compelling nonexperimental evidence.\u201d As this indication seemed very \u2026",
    "date": "2008",
    "authors": [
        "Jos\u00e9 Miguel Dora",
        "Caroline K. Kramer",
        "Luis Henrique Canani"
    ],
    "related_topics": [
        "Randomized controlled trial",
        "Diabetes mellitus",
        "Risk assessment"
    ],
    "citation_count": "1,860",
    "reference_count": "3",
    "references": [
        "2165884492",
        "2117191092",
        "2105881737"
    ]
},{
    "id": "2536590171",
    "title": "Chronic kidney disease and the risks of death, cardiovascular events, and hospitalization",
    "abstract": "Background End-stage renal disease substantially increases the risks of death, cardiovascular disease, and use of specialized health care, but the effects of less severe kidney dysfunction on these outcomes are less well defined. Methods We estimated the longitudinal glomerular filtration rate (GFR) among 1,120,295 adults within a large, integrated system of health care delivery in whom serum creatinine had been measured between 1996 and 2000 and who had not undergone dialysis or kidney transplantation. We examined the multivariable association between the estimated GFR and the risks of death, cardiovascular events, and hospitalization. Results The median follow-up was 2.84 years, the mean age was 52 years, and 55 percent of the group were women. After adjustment, the risk of death increased as the GFR decreased below 60 ml per minute per 1.73 m2 of body-surface area: the adjusted hazard ratio for death was 1.2 with an estimated GFR of 45 to 59 ml per minute per 1.73 m2 (95 percent confidence interval, 1....",
    "date": "2004",
    "authors": [
        "A.S. Go",
        "G.M. Chertow",
        "D. Fan",
        "C.E. McCulloch",
        "C.Y. Hsu"
    ],
    "related_topics": [
        "Renal function",
        "Kidney disease",
        "Dialysis"
    ],
    "citation_count": "11,910",
    "reference_count": "0",
    "references": []
},{
    "id": "1979423827",
    "title": "Meta-analysis of observational studies in epidemiology - A proposal for reporting",
    "abstract": "ObjectiveBecause of the pressure for timely, informed decisions in public health and clinical practice and the explosion of information in the scientific literature, research results must be synthesized. Meta-analyses are increasingly used to address this problem, and they often evaluate observational studies. A workshop was held in Atlanta, Ga, in April 1997, to examine the reporting of meta-analyses of observational studies and to make recommendations to aid authors, reviewers, editors, and readers.ParticipantsTwenty-seven participants were selected by a steering committee, based on expertise in clinical practice, trials, statistics, epidemiology, social sciences, and biomedical editing. Deliberations of the workshop were open to other interested scientists. Funding for this activity was provided by the Centers for Disease Control and Prevention.EvidenceWe conducted a systematic review of the published literature on the conduct and reporting of meta-analyses in observational studies using MEDLINE, Educational Research Information Center (ERIC), PsycLIT, and the Current Index to Statistics. We also examined reference lists of the 32 studies retrieved and contacted experts in the field. Participants were assigned to small-group discussions on the subjects of bias, searching and abstracting, heterogeneity, study categorization, and statistical methods.Consensus ProcessFrom the material presented at the workshop, the authors developed a checklist summarizing recommendations for reporting meta-analyses of observational studies. The checklist and supporting evidence were circulated to all conference attendees and additional experts. All suggestions for revisions were addressed.ConclusionsThe proposed checklist contains specifications for reporting of meta-analyses of observational studies in epidemiology, including background, search strategy, methods, results, discussion, and conclusion. Use of the checklist should improve the usefulness of meta-analyses for authors, reviewers, editors, readers, and decision makers. An evaluation plan is suggested and research areas are explored.",
    "date": "2000",
    "authors": [
        "D F Stroup",
        "J A Berlin",
        "S C Morton",
        "I Olkin",
        "G D Williamson",
        "D Rennie",
        "D Moher",
        "B J Becker",
        "T A Sipe",
        "S B Thacker"
    ],
    "related_topics": [
        "Observational study",
        "Checklist",
        "Scientific literature"
    ],
    "citation_count": "15,959",
    "reference_count": "26",
    "references": [
        "2005775721",
        "2134338262",
        "2051556928",
        "1999649023",
        "2112339576",
        "2977262736",
        "2033238186",
        "1978868802",
        "2006546769",
        "1894101563"
    ]
},{
    "id": "75245760",
    "title": "Age-specific relevance of usual blood pressure to vascular mortality: a meta-analysis of individual data for one million adults in 61 prospective studies.",
    "abstract": "The age-specific relevance of blood pressure to cause-specific mortality is best assessed by collaborative meta-analysis of individual participant data from the separate prospective studies. Methods Information was obtained on each of one million adults with no previous vascular disease recorded at baseline in 61 prospective observational studies of blood pressure and mortality. During 12.7 million person-years at risk, there were about 56 000 vascular deaths (12 000 stroke, 34000 ischaemic heart disease [IHD], 10000 other vascular) and 66 000 other deaths at ages 40-89 years. Meta-analyses, involving \"time-dependent\" correction for regression dilution, related mortality during each decade of age at death to the estimated usual blood pressure at the start of that decade. Findings Within each decade of age at death, the proportional difference in the risk of vascular death associated with a given absolute difference in usual blood pressure is about the same down to at least 115 mm Hg usual systolic blood pressure (SBP) and 75 mm Hg usual diastolic blood pressure (DBP), below which there is little evidence. At ages 40-69 years, each difference of 20 mm Hg usual SBP (or, approximately equivalently, 10 mm Hg usual DBP) is associated with more than a twofold difference in the stroke death rate, and with twofold differences in the death rates from IHD and from other vascular causes. All of these proportional differences in vascular mortality are about half as extreme at ages 80-89 years as at,ages 40-49 years, but the annual absolute differences in risk are greater in old age. The age-specific associations are similar for men and women, and for cerebral haemorrhage and cerebral ischaemia. For predicting vascular mortality from a single blood pressure measurement, the average of SBP and DBP is slightly more informative than either alone, and pulse pressure is much less informative. Interpretation Throughout middle and old age, usual blood pressure is strongly and directly related to vascular (and overall) mortality, without any evidence of a threshold down to at least 115/75 mm Hg.",
    "date": "2002",
    "authors": [
        "Sarah Lewington",
        "Robert Clarke",
        "Nawab Qizilbash",
        "Richard Peto",
        "Rory Collins"
    ],
    "related_topics": [
        "Prehypertension",
        "Blood pressure",
        "Pulse pressure"
    ],
    "citation_count": "14,539",
    "reference_count": "20",
    "references": [
        "180946569",
        "2321007701",
        "1592471891",
        "2139480984",
        "2141659719",
        "2066187800",
        "2170831516",
        "2074644304",
        "2147254207",
        "2270496223"
    ]
},{
    "id": "2153104532",
    "title": "Incidence and Prognostic Importance of Acute Renal Failure After Percutaneous Coronary Intervention",
    "abstract": "Background\u2014 In patients undergoing percutaneous coronary intervention (PCI) in the modern era, the incidence and prognostic implications of acute renal failure (ARF) are unknown. Methods and Results\u2014 With a retrospective analysis of the Mayo Clinic PCI registry, we determined the incidence of, risk factors for, and prognostic implications of ARF (defined as an increase in serum creatinine [Cr] >0.5 mg/dL from baseline) after PCI. Of 7586 patients, 254 (3.3%) experienced ARF. Among patients with baseline Cr 2.0, all had a significant risk of ARF. In multivariate analysis, ARF was associated with baseline serum Cr, acute myocardial infarction, shock, and volume of contrast medium administered. Twenty-two percent of patients with ARF died during the index hospitalization compared with only 1.4% of patients without ARF (P<0.0001). After adjustment, ARF remained strongly associated with death. Amo...",
    "date": "2002",
    "authors": [
        "Charanjit S. Rihal",
        "Stephen C. Textor",
        "Diane E. Grill",
        "Peter B. Berger",
        "Henry H. Ting",
        "Patricia J. Best",
        "Mandeep Singh",
        "Malcolm R. Bell",
        "Gregory W. Barsness",
        "Verghese Mathew",
        "Kirk N. Garratt",
        "David R. Holmes"
    ],
    "related_topics": [
        "Percutaneous coronary intervention",
        "Conventional PCI",
        "Myocardial infarction"
    ],
    "citation_count": "2,262",
    "reference_count": "19",
    "references": [
        "2159718794",
        "2011862587",
        "2018224788",
        "2316461329",
        "2062655222",
        "2011500053",
        "2567975079",
        "2031040755",
        "1571203233",
        "1982473642"
    ]
},{
    "id": "2122814783",
    "title": "Evaluation of the quality of prognosis studies in systematic reviews.",
    "abstract": "In examining how researchers assess the quality of individual studies in systematic reviews about prognosis, the authors found that appraisal of the quality of the article, a necessary step in syst...",
    "date": "2006",
    "authors": [
        "Jill A Hayden",
        "Pierre C\u00f4t\u00e9",
        "Claire Bombardier"
    ],
    "related_topics": [
        "Systematic review",
        "Quality (business)",
        "Evidence-based medicine"
    ],
    "citation_count": "1,222",
    "reference_count": "176",
    "references": [
        "1247968195",
        "1981501248",
        "2797811632",
        "1978209044",
        "2107545755",
        "2160153755",
        "2135962256",
        "1853602163",
        "2131556432",
        "2099769947"
    ]
},{
    "id": "2487377689",
    "title": "K/DOQI clinical practice guidelines for chronic kidney disease: Evaluation, classification, and stratification",
    "abstract": "Introduction: Chronic kidney disease as a public health problem. Chronic kidney disease is a worldwide public health problem. In the United States, there is a rising incidence and prevalence of kidney failure, with poor outcomes and high cost. There is an even higher prevalence of earlier stages of chronic kidney disease. Increasing evidence, accrued in the past decades, indicates that the adverse outcomes of chronic kidney disease, such as kidney failure, cardiovascular disease, and premature death, can be prevented or delayed. Earlier stages of chronic kidney disease can be detected through laboratory testing. Treatment of earlier stages of chronic kidney disease is effective in slowing the progression toward kidney failure. Initiation of treatment for cardiovascular risk factors at earlier stages of chronic kidney disease should be effective in reducing cardiovascular disease events both before and after the onset of kidney failure. Unfortunately, chronic kidney disease is \"under-diagnosed\" and \"under-treated\" in the United States, resulting in lost opportunities for prevention. One reason is the lack of agreement on a definition and classification of stages in the progression of chronic kidney disease. A clinically applicable classification would be based on laboratory evaluation of the severity of kidney disease, association of level of kidney function with complications, and stratification of risks for loss of kidney function and development of cardiovascular disease. Charge to the K/DOQI work group on chronic kidney disease. In 2000, the National Kidney Foundation (NKF) Kidney Disease Outcome Quality Initiative (K/DOQI) Advisory Board approved development of clinical practice guidelines to define chronic kidney disease and to classify stages in the progression of chronic kidney disease. The Work Group charged with developing the guidelines consisted of experts in nephrology, pediatric nephrology, epidemiology, laboratory medicine, nutrition, social work, gerontology, and family medicine. An Evidence Review Team, consisting of nephrologists and methodologists, was responsible for assembling the evidence. Defining chronic kidney disease and classifying the stages of severity would provide a common language for communication among providers, patients and their families, investigators, and policy-makers and a framework for developing a public health approach to affect care and improve outcomes of chronic kidney disease. A uniform terminology would permit: 1. More reliable estimates of the prevalence of earlier stages of disease and of the population at increased risk for development of chronic kidney disease 2. Recommendations for laboratory testing to detect earlier stages and progression to later stages 3. Associations of stages with clinical manifestations of disease 4. Evaluation of factors associated with a high risk of progression from one stage to the next or of development of other adverse outcomes 5. Evaluation of treatments to slow progression or prevent other adverse outcomes. Clinical practice guidelines, clinical performance measures, and continuous quality improvement efforts could then be directed to stages of chronic kidney disease. The Work Group did not specifically address evaluation and treatment for chronic kidney disease. However, this guideline contains brief reference to diagnosis and clinical interventions and can serve as a \"road map\" linking other clinical practice guidelines and pointing out where other guidelines need to be developed. Eventually, K/DOQI will include interventional guidelines. The first three of these, on bone disease, dyslipidemia, and blood pressure management are currently under development. Other guidelines on cardiovascular disease in dialysis patients and kidney biopsy will be initiated in the Winter of 2001. This report contains a summary of background information available at the time the Work Group began its deliberations, the 15 guidelines and the accompanying rationale, suggestions for clinical performance measures, a clinical approach to chronic kidney disease using these guidelines, and appendices to describe methods for the review of evidence. The guidelines are based on a systematic review of the literature and the consensus of the Work Group. The guidelines have been reviewed by the K/DOQI Advisory Board, a large number of professional organizations and societies, selected experts, and interested members of the public and have been approved by the Board of Directors of the NKF. Framework. The Work Group defined \"chronic kidney disease\" to include conditions that affect the kidney, with the potential to cause either progressive loss of kidney function or complications resulting from decreased kidney function. Chronic kidney disease was thus defined as the presence of kidney damage or decreased level of kidney function for three months or more, irrespective of diagnosis. The target population includes individuals with chronic kidney disease or at increased risk of developing chronic kidney disease. The majority of topics focus on adults (age \u226518 years). Many of the same principles apply to children as well. In particular, the classification of stages of disease and principles of diagnostic testing are similar. A subcommittee of the Work Group examined issues related to children and participated in development of the first six guidelines of the present document. However, there are sufficient differences between adults and children in the association of GFR with signs and symptoms of uremia and in stratification of risk for adverse outcomes that these latter issues are addressed only for adults. A separate set of guidelines for children will have to be developed by a later Work Group. The target audience includes a wide range of individuals: those who have or are at increased risk of developing chronic kidney disease (the target population) and their families; health care professionals caring for the target population; manufacturers of instruments and diagnostic laboratories performing measurements of kidney function; agencies and institutions planning, providing or paying for the health care needs of the target population; and investigators studying chronic kidney disease. There will be only brief reference to clinical interventions, sufficient to provide a basis for other clinical practice guidelines relevant to the evaluation and management of chronic kidney disease. Subsequent K/DOQI clinical practice guidelines will be based on the framework developed here. Definition of chronic kidney disease. Why \"Kidney\"? The word \"kidney\" is of Middle English origin and is immediately understood by patients, their families, providers, health care professionals, and the lay public of native English speakers. On the other hand, \"renal\" and \"nephrology,\" derived from Latin and Greek roots, respectively, commonly require interpretation and explanation. The Work Group and the NKF are committed to communicating in language that can be widely understood, hence the preferential use of \"kidney\" throughout these guidelines. The term \"End-Stage Renal Disease\" (ESRD) has been retained because of its administrative usage in the United States referring to patients treated by dialysis or transplantation, irrespective of their level of kidney function. Why Develop a New Classification? Currently, there is no uniform classification of the stages of chronic kidney disease. A review of textbooks and journal articles clearly demonstrates ambiguity and overlap in the meaning of current terms. The Work Group concluded that uniform definitions of terms and stages would improve communication between patients and providers, enhance public education, and promote dissemination of research results. In addition, it was believed that uniform definitions would enhance conduct of clinical research. Why Base a New Classification System on Severity of Disease? Adverse outcomes of kidney disease are based on the level of kidney function and risk of loss of function in the future. Chronic kidney disease tends to worsen over time. Therefore, the risk of adverse outcomes increases over time with disease severity. Many disciplines in medicine, including related specialties of hypertension, cardiovascular disease, diabetes, and transplantation, have adopted classification systems based on severity to guide clinical interventions, research, and professional and public education. Such a model is essential for any public health approach to disease. Why Classify Severity as the Level of GFR? The level of glomerular filtration rate (GFR) is widely accepted as the best overall measure of kidney function in health and disease. Providers and patients are familiar with the concept that \"the kidney is like a filter.\" GFR is the best measure of the kidneys' ability to filter blood. In addition, expressing the level of kidney function on a continuous scale allows development of patient and public education programs that encourage individuals to \"Know your number!\" The term \"GFR\" is not intuitively evident to anyone. Rather, it is a learned term, which allows the ultimate expression of the complex functions of the kidney in one single numerical expression. Conversely, numbers are an intuitive concept and easily understandable by everyone.",
    "date": "2002",
    "authors": [
        "Andrew S. Levey",
        "Josef Coresh",
        "Kline Bolton",
        "Bruce Culleton",
        "Kathy Schiro Harvey",
        "T. Alp Ikizler",
        "Cynda Ann Johnson",
        "Annamaria Kausz",
        "Paul L. Kimmel",
        "John Kusek",
        "Adeera Levin",
        "Kenneth L. Minaker",
        "Robert Nelson",
        "Helmut Rennke",
        "Michael Steffes",
        "Beth Witten",
        "Ronald J. Hogg",
        "Susan Furth",
        "Kevin V. Lemley",
        "Ronald J. Portman",
        "George Schwartz",
        "Joseph Lau",
        "Ethan Balk",
        "Ronald D. Perrone",
        "Tauqeer Karim",
        "Lara Rayan",
        "Inas Al-Massry",
        "Priscilla Chew",
        "Brad C. Astor",
        "Deirdre De Vine",
        "Garabed Eknoyan",
        "Nathan Levin",
        "Sally Burrows-Hudson",
        "William Keane",
        "Alan Kliger",
        "Derrick Latos",
        "Donna Mapes",
        "Edith Oberley",
        "Kerry Willis",
        "George Bailie",
        "Gavin Becker",
        "Jerrilynn Burrowes",
        "David Churchill",
        "Allan Collins",
        "William Couser",
        "Dick DeZeeuw",
        "Alan Garber",
        "Thomas Golper",
        "Frank Gotch",
        "Antonio Gotto"
    ],
    "related_topics": [
        "Kidney disease",
        "Stage 4 chronic kidney disease",
        "Dialysis"
    ],
    "citation_count": "9,292",
    "reference_count": "0",
    "references": []
},{
    "id": "2036544704",
    "title": "Acute renal failure in intensive care units : causes, outcome, and prognostic factors of hospital mortality : a prospective, multicenter study",
    "abstract": "ObjectiveTo assess the causes, the prognostic factors, and the outcome of patients with severe acute renal failure.DesignProspective, multicenter study.SettingTwenty French multidisciplinary intensive care units (ICUs).PatientsAll patients with severe acute renal failure were prospectively enrolled",
    "date": "1996",
    "authors": [
        "Francois G. Brivet",
        "Dieter J. Kleinknecht",
        "Philippe Loirat",
        "Paul J. M. Landais"
    ],
    "related_topics": [
        "Intensive care",
        "Prospective cohort study",
        "Intensive care medicine"
    ],
    "citation_count": "1,066",
    "reference_count": "40",
    "references": [
        "2107978811",
        "1996907628",
        "2086247090",
        "2083634842",
        "2266995761",
        "1986562125",
        "2001014310",
        "1972308004",
        "2042083863",
        "2012849561"
    ]
},{
    "id": "2139529386",
    "title": "Epidemiology of acute renal failure: A prospective, multicenter, community-based study",
    "abstract": "Epidemiology of acute renal failure (ARF): A prospective, multicenter, community-based study. There are very limited data on overall epidemiology of ARF. It is crucial to know the incidence, etiology and clinical features of ARF to promote prevention strategies and to implement adequate resources for the management of this entity. During a nine month period, a collaborative prospective protocol with 98 variables was developed to assess all ARF episodes encountered in the 13 tertiary-care hospitals in Madrid, Spain (covering 4.2 million people of over 14 years of age). ARF was considered when a sudden rise in serum creatinine concentration (S Cr ) to more than 177 \u00b5 mol/liter was found in patients with normal renal function, or when the sudden rise (50% or more) was observed in patients with previous mild-to-moderate chronic renal failure (S Cr \u00b5 mol/liter). Of the 748 cases of ARF studied, 665 episodes presented in inhabitans from the Madrid area. This gives an overall incidence of ARF of 209 cases per million population (p.m.p.; 95% CI 195 to 223). The incidence of acute tubular necrosis (ATN) was 88 cases p.m.p. (95% CI 79 to 97), prerenal ARF 46 p.m.p (95% CI 40 to 52), acute-onset chronic ARF 29 p.m.p. (95% CI 24 to 34), and obstructive ARF 23 p.m.p. (95% CI 19 to 27). The mean age was 63 \u00b1 17 years. The most frequent causes of ARF were ATN (45%), prerenal (21%), acute-onset chronic renal failure (12.7%) and obstructive ARF (10%). Renal function was normal at admission in 48% of patients who later developed ARF. Mortality (45%) was much higher than that of the other patients admitted (5.4%, P P P N = 50) was similar to that observed with cellulosic ones ( N = 84; 66% vs. 59.5%, NS). Mortality was higher in patients with coma, assisted respiration, hypotension, jaundice (all P P",
    "date": "1996",
    "authors": [
        "Fernando Lia\u00f1o",
        "Julio Pascual"
    ],
    "related_topics": [
        "Population",
        "Acute tubular necrosis",
        "Incidence (epidemiology)"
    ],
    "citation_count": "1,273",
    "reference_count": "39",
    "references": [
        "2728772779",
        "2083669508",
        "2039464237",
        "1487297692",
        "2089374147",
        "2012849561",
        "1987823269",
        "1964799636",
        "2273320536",
        "1999032036"
    ]
},{
    "id": "2095573004",
    "title": "The Outcome of Acute Renal Failure in the Intensive Care Unit According to RIFLE: Model Application, Sensitivity, and Predictability",
    "abstract": "Background: The definition, classification, and choice of management of acute renal failure (ARF) in the setting of the intensive care unit (ICU) remain subjects of debate. To improve our approach to ARF in the ICU setting, we retrospectively applied the new classification of ARF put forward by the Acute Dialysis Quality Initiative group, RIFLE (acronym indicating Risk of renal failure, Injury to the kidney, Failure of kidney function, Loss of kidney function, and End-stage renal failure), to evaluate its sensitivity and specificity to predict renal and patient outcomes. Methods: RIFLE classification was applied to 183 patients with ARF admitted to the ICU (2002 to 2003) at the Northern General Hospital, Sheffield, UK. Patients were divided into 4 groups according to percentage of decrease in glomerular filtration rate from baseline. The risk group included 60 patients; injury group, 56 patients; failure group, 43 patients; and control group, 24 patients. Demographic, biochemical, hematologic, clinical, and long-term health status were studied and compared in the 4 groups. An attempt was made to evaluate, by means of logistic regression analysis and receiver operator characteristic curve analysis, the predictive value of RIFLE classification for mortality in the ICU. Results: The failure group showed the worst parameters with regard to Acute Physiology and Chronic Health Evaluation (APACHE) II score, pH, lowest and highest mean arterial pressures, and Glasgow Coma Scale ( P P P P P = 0.14; injury group: SAPS II, 0.76 \u00b1 0.08; P P = 0.006). Conclusion: RIFLE classification can improve the ability of such older and established ICU scoring systems as APACHE II and SAPS II in predicting outcome of ICU patients with ARF.",
    "date": "2005",
    "authors": [
        "Nihal Y. Abosaif",
        "Yasser A. Tolba",
        "Mike Heap",
        "Jean Russell",
        "A. Meguid El Nahas"
    ],
    "related_topics": [
        "SAPS II",
        "APACHE II",
        "Rifle"
    ],
    "citation_count": "425",
    "reference_count": "46",
    "references": [
        "2139937737",
        "2107978811",
        "2157825442",
        "2128349740",
        "2043132544",
        "1967237457",
        "2036544704",
        "2080551841",
        "2150098992",
        "2135398566"
    ]
},{
    "id": "2150098992",
    "title": "Acute renal failure in patients with sepsis in a surgical ICU: predictive factors, incidence, comorbidity, and outcome.",
    "abstract": "Acute renal failure (ARF) is a common complication in intensive care unit (ICU) patients. Although there are several reports on outcome of septic patients with ARF, there are no data regarding predisposing factors for ARF. Therefore, the incidence of ARF was investigated in 185 sepsis patients admitted in a surgical ICU during a 16-mo period. Variables predisposing to ARF on day 1 of sepsis were evaluated with univariate and multivariable analyses. APACHE II and SOFA scores were compared during a 14-d period. Additionally, the impact of organ failure on mortality was evaluated. ARF developed in 16.2% of the patients, and 70.0% of these needed renal replacement therapy (RRT). Patients with ARF were more severely ill and had a higher mortality. Remarkably, serum creatinine was already increased on day 1. Creatinine > 1 mg/dl and pH < 7.30, both on day 1 of sepsis, were independently associated with ARF. Age, need for vasoactive therapy, mechanical ventilation, and RRT, but not ARF itself, were associated with mortality. In conclusion, ARF was a frequent complication in sepsis. Sepsis patients with ARF were more severely ill and had a higher mortality. Need for RRT was independently associated with mortality. A simple risk model for ARF, on basis of two readily available parameters on day 1 of sepsis, was developed. This model allows initiating specific therapeutic measures earlier in the course of sepsis, hopefully resulting in a lower incidence of ARF and needi for RRT, thereby lowering mortality.",
    "date": "2003",
    "authors": [
        "Eric A.J. Hoste",
        "Norbert H. Lameire",
        "Raymond C. Vanholder",
        "Dominique D. Benoit",
        "Johan M.A. Decruyenaere",
        "Francis A. Colardyn"
    ],
    "related_topics": [
        "APACHE II",
        "Sepsis",
        "Intensive care unit"
    ],
    "citation_count": "516",
    "reference_count": "42",
    "references": [
        "2160691650",
        "2049927822",
        "2322121630",
        "2768146862",
        "2107978811",
        "1898928487",
        "2599527603",
        "1996020381",
        "2148973700",
        "1967237457"
    ]
},{
    "id": "1973948212",
    "title": "Applied Logistic Regression",
    "abstract": "\"A new edition of the definitive guide to logistic regression modeling for health science and other applicationsThis thoroughly expanded Third Edition provides an easily accessible introduction to the logistic regression (LR) model and highlights the power of this model by examining the relationship between a dichotomous outcome and a set of covariables. Applied Logistic Regression, Third Edition emphasizes applications in the health sciences and handpicks topics that best suit the use of modern statistical software. The book provides readers with state-of-the-art techniques for building, interpreting, and assessing the performance of LR models. New and updated features include: A chapter on the analysis of correlated outcome data. A wealth of additional material for topics ranging from Bayesian methods to assessing model fit Rich data sets from real-world studies that demonstrate each method under discussion. Detailed examples and interpretation of the presented results as well as exercises throughout Applied Logistic Regression, Third Edition is a must-have guide for professionals and researchers who need to model nominal or ordinal scaled outcome variables in public health, medicine, and the social sciences as well as a wide range of other fields and disciplines\"--",
    "date": "1988",
    "authors": [
        "David W. Hosmer",
        "Stanley Lemeshow"
    ],
    "related_topics": [
        "Multinomial logistic regression",
        "Logistic model tree",
        "Generalised logistic function"
    ],
    "citation_count": "68,341",
    "reference_count": "0",
    "references": []
},{
    "id": "2071273488",
    "title": "Preoperative Renal Risk Stratification",
    "abstract": "Background After cardiac surgery, acute renal failure (ARF) requiring dialysis develops in 1% to 5% of patients and is strongly associated with perioperative morbidity and mortality. Prior studies have attempted to identify predictors of ARF but have had insufficient power to perform multivariable analyses or to develop risk stratification algorithms. Methods and Results We conducted a prospective cohort study of 43\u2009642 patients who underwent coronary artery bypass or valvular heart surgery in 43 Department of Veterans Affairs medical centers between April 1987 and March 1994. Logistic regression analysis was used to identify independent predictors of ARF requiring dialysis. A risk stratification algorithm derived from recursive partitioning was constructed and was validated on an independent sample of 3795 patients operated on between April and December 1994. The overall risk of ARF requiring dialysis was 1.1%. Thirty-day mortality in patients with ARF was 63.7%, compared with 4.3% in patients without AR...",
    "date": "1997",
    "authors": [
        "G M Chertow",
        "J M Lazarus",
        "C L Christiansen",
        "E F Cook",
        "K E Hammermeister",
        "F Grover",
        "J Daley"
    ],
    "related_topics": [
        "Risk factor",
        "Dialysis",
        "Perioperative"
    ],
    "citation_count": "973",
    "reference_count": "25",
    "references": [
        "2010295655",
        "1550111394",
        "1976927254",
        "2150000105",
        "2059368542",
        "2728772779",
        "2083669508",
        "2039464237",
        "1988464782",
        "1487297692"
    ]
},{
    "id": "2330776976",
    "title": "Effects of Saline, Mannitol, and Furosemide on Acute Decreases in Renal Function Induced by Radiocontrast Agents",
    "abstract": "Background Injections of radiocontrast agents are a frequent cause of acute decreases in renal function, occurring most often in patients with chronic renal insufficiency and diabetes mellitus. Methods We prospectively studied 78 patients with chronic renal insufficiency (mean [\u00b1SD] serum creatinine concentration, 2.1 \u00b10.6 mg per deciliter [186 \u00b153 \u03bcmol per liter]) who underwent cardiac angiography. The patients were randomly assigned to receive 0.45 percent saline alone for 12 hours before and 12 hours after angiography, saline plus mannitol, or saline plus furosemide. The mannitol and furosemide were given just before angiography. Serum creatinine was measured before and for 48 hours after angiography, and urine was collected for 24 hours after angiography. An acute radiocontrast-induced decrease in renal function was defined as an increase in the base-line serum creatinine concentration of at least 0.5 mg per deciliter (44 \u03bcmol per liter) within 48 hours after the injection of radiocontrast agents. Res...",
    "date": "1994",
    "authors": [
        "Richard Solomon",
        "Craig Werner",
        "Denise Mann",
        "John D'Elia",
        "Patricio Silva"
    ],
    "related_topics": [
        "Contrast-induced nephropathy",
        "Renal function",
        "Creatinine"
    ],
    "citation_count": "1,794",
    "reference_count": "21",
    "references": [
        "1550111394",
        "2728772779",
        "2011500053",
        "2032097996",
        "2091443934",
        "2032949562",
        "2145416664",
        "2027695475",
        "1980489046",
        "2042106394"
    ]
},{
    "id": "1996698106",
    "title": "Clinical and echocardiographic disease in patients starting end-stage renal disease therapy",
    "abstract": "Clinical and echocardiographic disease in patients starting end-stage renal disease therapy. End-stage renal disease (ESRD) patients have a high cardiovascular mortality rate. Precise estimates of the prevalence, risk factors and prognosis of different manifestations of cardiac disease are unavailable. In this study a prospective cohort of 433 ESRD patients was followed from the start of ESRD therapy for a mean of 41 months. Baseline clinical assessment and echocardiography were performed on all patients. The major outcome measure was death while on dialysis therapy. Clinical manifestations of cardiovascular disease were highly prevalent at the start of ESRD therapy: 14% had coronary artery disease, 19% angina pectoris, 31% cardiac failure, 7% dysrhythmia and 8% peripheral vascular disease. On echocardiography 15% had systolic dysfunction, 32% left ventricular dilatation and 74% left ventricular hypertrophy. The overall median survival time was 50 months. Age, diabetes mellitus, cardiac failure, peripheral vascular disease and systolic dysfunction independently predicted death in all time frames. Coronary artery disease was associated with a worse prognosis in patients with cardiac failure at baseline. High left ventricular cavity volume and mass index were independently associated with death after two years. The independent associations of the different echocardiographic abnormalities were: systolic dysfunction\u2013older age and coronary artery disease; left ventricular dilatation\u2013male gender, anemia, hypocalcemia and hyperphosphatemia; left ventricular hypertrophy\u2013older age, female gender, wide arterial pulse pressure, low blood urea and hypoalbuminemia. We conclude that clinical and echocardiographic cardiovascular disease are already present in a very high proportion of patients starting ESRD therapy and are independent mortality factors.",
    "date": "1994",
    "authors": [
        "Robert N. Foley",
        "Patrick S. Parfrey",
        "John D. Harnett",
        "Gloria M. Kent",
        "Christopher J. Martin",
        "David C. Murray",
        "Paul E. Barre"
    ],
    "related_topics": [
        "End stage renal disease",
        "Heart disease",
        "Coronary artery disease"
    ],
    "citation_count": "1,717",
    "reference_count": "36",
    "references": [
        "2334499091",
        "2042293234",
        "2333333141",
        "1992890029",
        "2067951404",
        "2097808383",
        "2038135923",
        "2052295435",
        "2041203247",
        "2061569406"
    ]
},{
    "id": "2018224788",
    "title": "Nephrotoxicity of ionic and nonionic contrast media in 1196 patients: A randomized trial",
    "abstract": "Nephrotoxicity of ionic and nonionic contrast media in 1196 patients: A randomized trial. The incidence of nephrotoxicity occurring with the nonionic contrast agent, iohexol, and the ionic contrast agent, meglumine/sodium diatrizoate, was compared in 1196 patients undergoing cardiac angiography in a prospective, randomized, double-blind multicenter trial. Patients were stratified into four groups: renal insufficiency (RI), diabetes mellitus (DM) both absent (N = 364); RI absent, DM present (N = 318); RI present, DM absent (N = 298); and RI and DM both present (N = 216). Serum creatinine levels were measured at \u2013 18 to 24, 0, and 24, 48, and 72 hours following contrast administration. Prophylactic hydration was administered pre- and post-angiography. Acute nephrotoxicity (increase in serum creatinine of \u22651 mg/dl 48 to 72 hours post-contrast) was observed in 42 (7%) patients receiving diatrizoate compared to 19 (3%) patients receiving iohexol, P",
    "date": "1994",
    "authors": [
        "Michael R. Rudnick",
        "Stanley Goldfarb",
        "Lewis Wexler",
        "Philip A. Ludbrook",
        "Mary J. Murphy",
        "Elkan F. Halpern",
        "James A. Hill",
        "Michael Winniford",
        "Martin B. Cohen",
        "Douglas B. VanFossen"
    ],
    "related_topics": [
        "Nephrotoxicity",
        "Iohexol",
        "Contrast-induced nephropathy"
    ],
    "citation_count": "1,245",
    "reference_count": "37",
    "references": [
        "2316461329",
        "2073085411",
        "2728772779",
        "2073463191",
        "1487297692",
        "2567975079",
        "2032097996",
        "1970547337",
        "2091443934",
        "2032949562"
    ]
},{
    "id": "2056699935",
    "title": "Prognostic stratification in critically ill patients with acute renal failure requiring dialysis",
    "abstract": "Background: Despite the widespread availability of dialytic and intensive care unit technology, the probability of early mortality in critically ill persons with acute renal failure is distressingly high. Previous efforts to predict outcome in this population have been limited by small sample size and the absence of uniform exclusion criteria. Additionally, data obtained decades ago may not apply today owing to changes in case mix. Methods: The medical records of 132 consecutive patients in the intensive care unit with acute renal failure who required dialysis from 1991 through 1993 were evaluated by a blinded reviewer. Results: The overall in-hospital mortality rate was 70%. Twelve readily available historical, clinical, and laboratory variables were significantly associated with in-hospital mortality. Multivariate logistic regression analysis showed that mechanical ventilation, malignancy, and nonrespiratory organ system failure were independently associated with in-hospital mortality. Using a 95% positivity criterion, this model identified 24% of high-risk patients who died, without misclassification of any survivors. Of those who survived to hospital discharge, 33% were dialysis dependent and 28% were institutionalized long-term. Conclusions: Among critically ill patients, acute renal failure requiring dialysis is an ominous condition with a high risk of in-hospital mortality. This risk appears to depend largely on comorbid conditions, such as the need for mechanical ventilation and underlying malignancy. While this prognostic model requires prospective validation, it appears to identify a substantial fraction of patients for whom dialysis may be of limited or no benefit. (Arch Intern Med. 1995;155:1505-1511)",
    "date": "1995",
    "authors": [
        "G M Chertow",
        "C L Christiansen",
        "P D Cleary",
        "C Munro",
        "J M Lazarus"
    ],
    "related_topics": [
        "Intensive care unit",
        "Dialysis",
        "Intensive care"
    ],
    "citation_count": "486",
    "reference_count": "51",
    "references": [
        "2107978811",
        "1979300931",
        "1976927254",
        "2081385953",
        "2333333141",
        "2176123686",
        "2139984188",
        "2012301002",
        "2728772779",
        "2083669508"
    ]
},{
    "id": "2073085411",
    "title": "Metaanalysis of the relative nephrotoxicity of high- and low-osmolality iodinated contrast media.",
    "abstract": "To determine whether low-osmolality contrast media (LOCM) are less nephrotoxic than high-osmolality contrast media (HOCM), the authors searched MEDLINE and EMBASE databases and other sources to find randomized trials with data collected on changes in glomerular filtration rate or serum creatinine (SCr) level with LOCM and HOCM. Forty-five trials were found. Data were unavailable from 14 trials. When the P values from the other 31 trials were pooled, an overall P value of .02 was found. Among 24 trials with available data, the mean change in SCr was 0.2-6.2 mumol/L less with LOCM than HOCM. Among 25 trials with available data, the pooled odds of a rise in SCr level of more than 44 mumol/L with LOCM was 0.61 (95% confidence interval [CI], 0.48-0.77) times that after HOCM. For patients with existing renal failure, this odds ratio was 0.5 (CI, 0.36-0.68), while it was 0.75 (CI, 0.52-1.1) in patients without prior renal failure. Greater changes in SCr level occurred only in those with existing renal failure and were less common with LOCM (odds ratio, 0.44; CI, 0.26-0.73). Use of LOCM may be beneficial in patients with existing renal failure.",
    "date": "1993",
    "authors": [
        "B J Barrett",
        "E J Carlisle"
    ],
    "related_topics": [
        "Renal function",
        "Odds ratio",
        "Creatinine"
    ],
    "citation_count": "965",
    "reference_count": "0",
    "references": []
},{
    "id": "2015292449",
    "title": "Improved tools for biological sequence comparison.",
    "abstract": "We have developed three computer programs for comparisons of protein and DNA sequences. They can be used to search sequence data bases, evaluate similarity scores, and identify periodic structures based on local sequence similarity. The FASTA program is a more sensitive derivative of the FASTP program, which can be used to search protein or DNA sequence data bases and can compare a protein sequence to a DNA sequence data base by translating the DNA data base as it is searched. FASTA includes an additional step in the calculation of the initial pairwise similarity score that allows multiple regions of similarity to be joined to increase the score of related sequences. The RDF2 program can be used to evaluate the significance of similarity scores using a shuffling method that preserves local sequence composition. The LFASTA program can display all the regions of local similarity between two sequences with scores greater than a threshold, using the same scoring parameters and a similar alignment algorithm; these local similarities can be displayed as a \"graphic matrix\" plot or as individual alignments. In addition, these programs have been generalized to allow comparison of DNA or protein sequences based on a variety of alternative scoring matrices.",
    "date": "1988",
    "authors": [
        "William R. Pearson",
        "David J. Lipman"
    ],
    "related_topics": [
        "Multiple sequence alignment",
        "Gap penalty",
        "Alignment-free sequence analysis"
    ],
    "citation_count": "14,859",
    "reference_count": "1",
    "references": [
        "2601913882"
    ]
},{
    "id": "2143210482",
    "title": "Amino acid substitution matrices from protein blocks",
    "abstract": "Methods for alignment of protein sequences typically measure similarity by using a substitution matrix with scores for all possible exchanges of one amino acid with another. The most widely used matrices are based on the Dayhoff model of evolutionary rates. Using a different approach, we have derived substitution matrices from about 2000 blocks of aligned sequence segments characterizing more than 500 groups of related proteins. This led to marked improvements in alignments and in searches using queries from each of the groups.",
    "date": "1992",
    "authors": [
        "Steven Henikoff",
        "Jorja G. Henikoff"
    ],
    "related_topics": [
        "Substitution matrix",
        "BLOSUM",
        "Structural alignment"
    ],
    "citation_count": "7,234",
    "reference_count": "24",
    "references": [
        "2055043387",
        "2087064593",
        "2017519756",
        "1982996449",
        "2601913882",
        "2034767282",
        "1558365920",
        "2040703580",
        "1973578915",
        "2156899368"
    ]
},{
    "id": "2065461553",
    "title": "A simple method for estimating evolutionary rates of base substitutions through comparative studies of nucleotide sequences.",
    "abstract": "Some simple formulae were obtained which enable us to estimate evolutionary distances in terms of the number of nucleotide substitutions (and, also, the evolutionary rates when the divergence times are known). In comparing a pair of nucleotide sequences, we distinguish two types of differences; if homologous sites are occupied by different nucleotide bases but both are purines or both pyrimidines, the difference is called type I (or \u201ctransition\u201d type), while, if one of the two is a purine and the other is a pyrimidine, the difference is called type II (or \u201ctransversion\u201d type). Letting P and Q be respectively the fractions of nucleotide sites showing type I and type II differences between two sequences compared, then the evolutionary distance per site is K = \u2014 (1/2) ln {(1 \u2014 2P \u2014 Q) }. The evolutionary rate per year is then given by k = K/(2T), where T is the time since the divergence of the two sequences. If only the third codon positions are compared, the synonymous component of the evolutionary base substitutions per site is estimated by K'S = \u2014 (1/2) ln (1 \u2014 2P \u2014 Q). Also, formulae for standard errors were obtained. Some examples were worked out using reported globin sequences to show that synonymous substitutions occur at much higher rates than amino acid-altering substitutions in evolution.",
    "date": "1980",
    "authors": [
        "Motoo Kimura"
    ],
    "related_topics": [
        "Ka/Ks ratio",
        "Models of DNA evolution",
        "Transversion"
    ],
    "citation_count": "44,252",
    "reference_count": "17",
    "references": [
        "1525734744",
        "1967290545",
        "2740556548",
        "1993054962",
        "1967318154",
        "1983519005",
        "1990058505",
        "1968647996",
        "2080721346",
        "2046575349"
    ]
},{
    "id": "2008708467",
    "title": "Dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features",
    "abstract": "For a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. We have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern-recognition process of hydrogen-bonded and geometrical features extracted from x-ray coordinates. Cooperative secondary structure is recognized as repeats of the elementary hydrogen-bonding patterns \u201cturn\u201d and \u201cbridge.\u201d Repeating turns are \u201chelices,\u201d repeating bridges are \u201cladders,\u201d connected ladders are \u201csheets.\u201d Geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. Local chain \u201cchirality\u201d is the torsional handedness of four consecutive C\u03b1 positions and is positive for right-handed helices and negative for ideal twisted \u03b2-sheets. Curved pieces are defined as \u201cbends.\u201d Solvent \u201cexposure\u201d is given as the number of water molecules in possible contact with a residue. The end result is a compilation of the primary structure, including SS bonds, secondary structure, and solvent exposure of 62 different globular proteins. The presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. The dictionary is also available in computer-readable form for protein structure prediction work.",
    "date": "1983",
    "authors": [
        "Wolfgang Kabsch",
        "Christian Sander"
    ],
    "related_topics": [
        "Protein structure prediction",
        "Protein secondary structure",
        "Protein contact map"
    ],
    "citation_count": "15,185",
    "reference_count": "31",
    "references": [
        "1978763597",
        "2113403117",
        "1984412128",
        "2004360551",
        "2094077114",
        "2144134055",
        "2092875818",
        "2088774638",
        "2031647295",
        "1984640820"
    ]
},{
    "id": "2045391589",
    "title": "The Neutral Theory of Molecular Evolution",
    "abstract": "Motoo Kimura, as founder of the neutral theory, is uniquely placed to write this book. He first proposed the theory in 1968 to explain the unexpectedly high rate of evolutionary change and very large amount of intraspecific variability at the molecular level that had been uncovered by new techniques in molecular biology. The theory - which asserts that the great majority of evolutionary changes at the molecular level are caused not by Darwinian selection but by random drift of selectively neutral mutants - has caused controversy ever since. This book is the first comprehensive treatment of this subject and the author synthesises a wealth of material - ranging from a historical perspective, through recent molecular discoveries, to sophisticated mathematical arguments - all presented in a most lucid manner.",
    "date": "1982",
    "authors": [
        "Motoo Kimura"
    ],
    "related_topics": [
        "Neutral theory of molecular evolution",
        "Nearly neutral theory of molecular evolution",
        "Neutral mutation"
    ],
    "citation_count": "16,573",
    "reference_count": "0",
    "references": []
},{
    "id": "2149208773",
    "title": "CLUSTAL V: improved software for multiple sequence alignment.",
    "abstract": "The CLUSTAL package of multiple sequence alignment programs has been completely rewritten and many new features added. The new software is a single program called CLUSTAL V, which is written in C and can be used on any machine with a standard C compiler. The main new features are the ability to store and reuse old alignments and the ability to calculate phylogenetic trees after alignment. The program is simple to use, completely menu driven and on-line help is provided.",
    "date": "1992",
    "authors": [
        "Desmond G. Higgins",
        "Alan J. Bleasby",
        "Rainer Fuchs"
    ],
    "related_topics": [
        "MUSCLE",
        "Multiple sequence alignment",
        "Compiler"
    ],
    "citation_count": "3,165",
    "reference_count": "0",
    "references": []
},{
    "id": "2102122585",
    "title": "HIDDEN MARKOV MODELS IN COMPUTATIONAL BIOLOGY: APPLICATIONS TO PROTEIN MODELING",
    "abstract": "Hidden Markov Models (HMMs) are applied to the problems of statistical modeling, database searching and multiple sequence alignment of protein families and protein domains. These methods are demonstrated on the globin family, the protein kinase catalytic domain, and the EF-hand calcium binding motif. In each case the parameters of an HMM are estimated from a training set of unaligned sequences. After the HMM is built, it is used to search the SWISS-PROT 22 database for other sequences that are members of the given protein family, or contain the given domain. The HMM produces multiple alignments of good quality that agree closely with the alignments produced by programs that incorporate three-dimensional structural information. When employed in discrimination tests (by examining how closely the sequences in a database fit the globin, kinase and EF-hand HMMs), the HMM is able to distinguish members of these families from non-members with a high degree of accuracy. Both the HMM and PROFILESEARCH (a technique used to search for relationships between a protein sequence and multiply aligned sequences) perform better in these tests than PROSITE (a dictionary of sites and patterns in proteins). The HMM appears to have a slight advantage over PROFILESEARCH in terms of lower rates of false negatives and false positives, even though the HMM is trained using only unaligned sequences, whereas PROFILESEARCH requires aligned training sequences. Our results suggest the presence of an EF-hand calcium binding motif in a highly conserved and evolutionarily preserved putative intracellular region of 155 residues in the alpha-1 subunit of L-type calcium channels which play an important role in excitation-contraction coupling. This region has been suggested to contain the functional domains that are typical or essential for all L-type calcium channels regardless of whether they couple to ryanodine receptors, conduct ions or both.",
    "date": "1993",
    "authors": [
        "Anders Krogh",
        "Michael Brown",
        "I. S Mian",
        "Kimmen Sjolander",
        "David Haussler"
    ],
    "related_topics": [
        "PROSITE",
        "Multiple sequence alignment",
        "Protein structure prediction"
    ],
    "citation_count": "2,611",
    "reference_count": "33",
    "references": [
        "2125838338",
        "2020257412",
        "2011495938",
        "1998158007",
        "1014698510",
        "2156899368",
        "1422803820",
        "1574109141",
        "1565582771",
        "1988171432"
    ]
},{
    "id": "2089784797",
    "title": "A review of the Royal Perth Hospital Bali experience: an infection control perspective.",
    "abstract": "Thirty five patients were transferred to Royal Perth Hospital (RPH) after the Bali bombings. The patients had severe burn injuries and were considered to be at high-risk of both the carriage and acquisition of multi-resistant organisms (MROs). Whilst seeking to protect the Bali patients with a comprehensive infection control response, we also sought to protect other high-risk patients from nosocomial acquisition of MROs. MROs were detected from 25 (82%) of the 29 Bali patients admitted to RPH. Bali patients were colonised, or infected, with one or more of the following MROs: multi-resistant Acinetobacter baumannii (MRAB) (19 patients), extended-spectrum s-lactamase (ESBL) producing Gram-negative bacteria (15 patients), vancomycin-resistant enterococci (VRE) (nine patients), multi-resistant Pseudomonas aeruginosa (MRPA) (six patients), multi-resistant Chryseobacterium sp. (four patients), and methicillin-resistant Staphylococcus aureus (MRSA) (three patients). Five Bali patients developed a total of eight bacteraemic episodes, with MRPA sepsis contributing to death in two patients. Since the Bali bombings horizontal transmission of Bali MROs has occurred in 41 non-Bali patients in RPH. MRPA has had the greatest clinical impact. Eight non-Bali patients developed a total of 11 bacteraemic episodes, with MRPA sepsis contributing to death in four patients. However, apart from MRPA, we have now controlled transmission of the other MROs in RPH. The emergency response to the Bali disaster required strong leadership, good communication and multi-disciplinary teamwork. The infection control strategy contributed to good outcomes for most Bali bombing patients. However, many patients within the Bali cohort were heavily colonised with MROs, and some developed invasive infection. Subsequent nosocomial transmission of these MROs to non-Bali patients has been a legacy of the Bali tragedy.",
    "date": "2003",
    "authors": [
        "Christopher H Heath",
        "C Terri Orrell",
        "Rosie Ce Lee",
        "John W Pearman",
        "Cheryll McCullough",
        "Keryn J Christiansen"
    ],
    "related_topics": [
        "Infection control",
        "Carriage",
        "Acinetobacter baumannii"
    ],
    "citation_count": "21",
    "reference_count": "21",
    "references": [
        "1955612312",
        "2463755683",
        "2041613596",
        "2097293600",
        "1514083101",
        "2109520143",
        "2419838214",
        "2155251813",
        "2074479590",
        "2017661616"
    ]
},{
    "id": "2094644220",
    "title": "Clinical virology of Ebola hemorrhagic fever (EHF): Virus, virus antigen, and IgG and IgM antibody findings among EHF patients in Kikwit, Democratic Republic of the Congo, 1995",
    "abstract": "Ebola hemorrhagic fever (EHF) patients treated at Kikwit General Hospital during the 1995 outbreak were tested for viral antigen, IgG and IgM antibody, and infectious virus. Viral antigen could be detected in virtually all patients during the acute phase of illness, while antibody was not always detectable before death. Virus was also isolated from patients during the course of their febrile illness, but attempts to quantify virus in Vero E6 cells by standard plaque assay were often unsuccessful. IgG and IgM antibody appeared at approximately the same time after disease onset (8-10 days), but IgM persisted for a much shorter period among the surviving convalescent patients. IgG antibody was detectable in surviving patients through about 2 years after onset, the latest time that samples were obtained. Detection of Ebola virus antigens or virus isolation appears to be the most reliable means of diagnosis for patients with suspected acute EHF, since patients with this often-fatal disease (80% mortality) may not develop detectable antibodies before death.",
    "date": "1999",
    "authors": [
        "T. G. Ksiazek",
        "P. E. Rollin",
        "A. J. Williams",
        "D. S. Bressler",
        "M. L. Martin",
        "R. Swanepoel",
        "F. J. Burt",
        "P. A. Leman",
        "Ali S Khan",
        "A. K. Rowe",
        "R. Mukunu",
        "A. Sanchez",
        "C. J. Peters"
    ],
    "related_topics": [
        "Virus antigen",
        "Ebola virus",
        "Ebola Hemorrhagic Fever"
    ],
    "citation_count": "374",
    "reference_count": "19",
    "references": [
        "2141568825",
        "1749864346",
        "2163760194",
        "2160047153",
        "2130063921",
        "2167946781",
        "2097378446",
        "2171308211",
        "1969661655",
        "1853748609"
    ]
},{
    "id": "1981329413",
    "title": "Outbreak of Nipah-virus infection among abattoir workers in Singapore",
    "abstract": "Summary Background In March 1999, an outbreak of encephalitis and pneumonia occurred in workers at an abattoir in Singapore. We describe the clinical presentation and the results of investigations in these patients. Methods Clinical and laboratory data were collected by systemic review of the case records. Serum and cerebrospinal fluid (CSF) samples were tested for IgM antibodies to Nipah virus with an IgM capture ELISA. Reverse-transcriptase PCR was done on the CSF and tissue samples from one patient who died. Findings Eleven patients were confirmed to have acute Npah-virus infection based on raised IgM in serum. Mpah virus was identified by reverse-transcriptase PCR in the CSF and tissue of the patient who died. The patients were all men, with a median age of 44 years. The commonest presenting symptoms were fever, headache, and drowsiness. Eght patients presented with signs of encephalitis (decreased level of consciousness or focal neurological signs). Three patients presented with atypical pneumonia, but one later developed hallucinations and had evidence of encephalitis on CSF examination Abnormal laboratory findings included a bw lymphocyte count (nine patients), low platelet count, low serum sodium, and high aspartate aminostransferase concentration (each observed in five patients). The CSF protein was high in eight patients and white-blood-cell count was high in seven Chest radiography showed mild interstitial shadowing in eight patients. Magnetic resonance imaging (MRI) showed focal areas of increased signal intensity in the cortical white marker in all eight patients who were scanned. The nine patients with encephalitis received empirical treatment with intravenous aciclovir and eight survived. Interpretation Infection with Nipah virus caused an encephalitis illness with characteristic focal areas of increased intensity seen on MRI Lung involvement was also common, and the disease may present as an atypical pneumonia.",
    "date": "1999",
    "authors": [
        "Nicholas I. Paton",
        "Yee Sin Leo",
        "Sherif R. Zaki",
        "Alexander P. Auchus",
        "Kim En Lee",
        "Ai Ee Ling",
        "Suok Kai Chew",
        "Brenda Ang",
        "Pierre E. Rollin",
        "T. Umapathi",
        "Ivy Sng",
        "Cheng Chuan Lee",
        "Erle Lim",
        "Thomas Ksiazek"
    ],
    "related_topics": [
        "Encephalitis",
        "Atypical pneumonia",
        "Pneumonia"
    ],
    "citation_count": "445",
    "reference_count": "6",
    "references": [
        "2076620790",
        "2137477090",
        "1207182455",
        "2319815586",
        "2047077350",
        "2117458119"
    ]
},{
    "id": "1983097458",
    "title": "Comparison of sequences of the H, F, and N coding genes of measles virus vaccine strains",
    "abstract": "Many live-attenuated vaccines for measles virus have been developed using either the prototype Edmonston strain or other locally isolated measles strains. The attenuation methods used to develop these vaccines have differed in the type(s) of cell line(s) used, number of passages, and temperatures of incubation. To assess the extent of genetic diversity within vaccine strains and to determine the extent to which the varied passage histories may have affected the viruses, we conducted sequence analyses of the fusion, hemagglutinin, nucleoprotein, and matrix genes of Edmonston-derived and non-Edmonston-derived strains. Despite the diverse geographic origins of the vaccine viruses and the different attenuation methods used, there was remarkable sequence similarity among all strains examined. The sequences of all of the vaccine strains were very similar to the sequences of a low-passage seed of the original Edmonston strain. The most divergent sequences were from two of the non-Edmonston-derived vaccines: CAM-70, a vaccine developed from a Japanese wild-type virus, and S-191, which was developed in China.",
    "date": "1994",
    "authors": [
        "Jennifer S. Rota",
        "Wang Zhong-De",
        "Paul A. Rota",
        "William J. Bellini"
    ],
    "related_topics": [
        "Measles virus",
        "Paramyxoviridae",
        "Morbillivirus"
    ],
    "citation_count": "271",
    "reference_count": "43",
    "references": [
        "2009310436",
        "2154284350",
        "2132233145",
        "2124838434",
        "1982691876",
        "2001949677",
        "2064611509",
        "1972759043",
        "2068530885",
        "1832268633"
    ]
},{
    "id": "2130324980",
    "title": "A Novel P/V/C Gene in a New Member of the Paramyxoviridae Family, Which Causes Lethal Infection in Humans, Horses, and Other Animals",
    "abstract": "In 1994, a new member of the family Paramyxoviridae isolated from fatal cases of respiratory disease in horses and humans was shown to be distantly related to morbilliviruses and provisionally called equine morbillivirus (K. Murray et al., Science 268:94-97, 1995). To facilitate characterization and classification, the virus was purified, viral proteins were identified, and the P/V/C gene was cloned and sequenced. The coding strategy of the gene is similar to that of Sendai and measles viruses, members of the Paramyxovirus and Morbillivirus genera, respectively, in the subfamily Paramyxovirinae. The P/V/C gene contains four open reading frames, three of which, P, C, and V, have Paramyxovirinae counterparts. The P and C proteins are larger and smaller, respectively, than are cognate proteins in members of the subfamily, and the V protein is made as a result of a single G insertion during transcription. The P/V/C gene has two unique features. (i) A fourth open reading frame is located between those of the C and V proteins and potentially encodes a small basic protein similar to those found in some members of the Rhabdoviridae and Filoviridae families. (ii) There is also a long untranslated 3' sequence, a feature common in Filoviridae members. Sequence comparisons confirm that although the virus is a member of the Paramyxovirinae subfamily, it displays only low levels of homology with paramyxoviruses and morbilliviruses and negligible homologies with rubulaviruses.",
    "date": "1998",
    "authors": [
        "Lin-Fa Wang",
        "Wojtek P. Michalski",
        "Meng Yu",
        "L. Ian Pritchard",
        "Gary Crameri",
        "Brian Shiell",
        "Bryan T. Eaton"
    ],
    "related_topics": [
        "Paramyxovirinae",
        "Rubulavirus",
        "Paramyxoviridae"
    ],
    "citation_count": "156",
    "reference_count": "49",
    "references": [
        "2106882534",
        "2134812217",
        "2102122585",
        "177909858",
        "2076620790",
        "1546570611",
        "1969304546",
        "1600871831",
        "2137477090",
        "1207182455"
    ]
},{
    "id": "2040567164",
    "title": "Isolation and Molecular Characterization of a Novel Cytopathogenic Paramyxovirus from Tree Shrews",
    "abstract": "A cytopathic infectious agent was isolated from the kidneys of an apparently healthy tree shrew (Tupaia belangeri) that had been captured in the area around Bangkok. The infectivity was propagated in Tupaia fibroblast and kidney cell cultures. Paramyxovirus-like pleomorphic enveloped particles and helical nucleocapsids were observed by electron microscopy and accordingly the infectious agent was termed Tupaia paramyxovirus (TPMV). However, no serological cross-reactions were detected between TPMV and known paramyxoviruses. For the molecular characterization of TPMV an experimental strategy that allows the random-primed synthesis of relatively large cDNA molecules from viral genomic RNA was applied. Nucleotide sequence analysis of a TPMV-specific cDNA fragment (1544 bp) revealed two nonoverlapping partial open reading frames corresponding to paramyxoviral N and P transcription units. Using modified rapid amplification of cDNA ends techniques, a substantial contiguous portion of the viral genome (4065 nt) was elucidated including the complete N and P/V/C genes. The coding strategy of TPMV as well as significant amino acid sequence homologies clearly indicates an evolutionary relationship between TPMV and members of the genus Morbillivirus. Highest homologies were detected between TPMV and Hendra virus (equine morbillivirus), which recently emerged in Australia, causing outbreaks of fatal respiratory and neurological disease in horses and humans.",
    "date": "1999",
    "authors": [
        "Christian A. Tidona",
        "Hans W. Kurz",
        "Hans R. Gelderblom",
        "Gholamreza Darai"
    ],
    "related_topics": [
        "Rapid amplification of cDNA ends",
        "Hendra Virus",
        "Tupaia"
    ],
    "citation_count": "127",
    "reference_count": "46",
    "references": [
        "2097382368",
        "2108388593",
        "177909858",
        "1594381616",
        "2076620790",
        "1984178787",
        "2087530582",
        "2079285691",
        "2076892293",
        "1502226870"
    ]
},{
    "id": "1699123896",
    "title": "New virus fingered in Malaysian epidemic.",
    "abstract": "Scientists have unmasked a killer responsible for the deaths of at least 95 people in Malaysia in the last 6 months, most of them pig farm workers. The culprit, named the Nipah virus for the small town from whence the strain was first identified, is a previously unknown virus that replicates in pigs and seems to be easily transmitted to humans. It is closely related to another notorious agent, the Hendra virus, which surfaced in Australia in 1994. But the new virus spreads much more rapidly, making it an emerging virus of grave concern, researchers say.",
    "date": "1999",
    "authors": [
        "Martin Enserink"
    ],
    "related_topics": [
        "Hendra Virus",
        "Japanese encephalitis",
        "Paramyxoviridae"
    ],
    "citation_count": "27",
    "reference_count": "0",
    "references": []
},{
    "id": "2029131064",
    "title": "Two mRNAs that differ by two nontemplated nucleotides encode the amino coterminal proteins P and V of the paramyxovirus SV5",
    "abstract": "Summary The \"P\u2253 gene of the paramyxovirus SV5 encodes two known proteins, P (M r \u2248 44,000) and V (M r \u2248 24,000). The complete nucleotide sequence of the \"P\u2253 gene has been obtained and is found to contain two open reading frames, neither of which is large enough to encode the P protein. We have shown that the P and V proteins are translated from two mRNAs that differ by the presence of two nontemplated G residues in the P mRNA. These two additional nucleotides convert the two open reading frames to one of 392 amino acids. The P and V proteins are amino coterminal and have 164 amino acids in common. The unique C terminus of V consists of a cysteine-rich region that resembles a cysteine-rich metal binding domain. An open reading frame that contains this cysteine-rich region exists in all other paramyxovirus \"P\u2253 gene sequences examined, which suggests that it may have important biological significance.",
    "date": "1988",
    "authors": [
        "Sheila M. Thomas",
        "Robert A. Lamb",
        "Reay G. Paterson"
    ],
    "related_topics": [
        "Nucleic acid sequence",
        "Open reading frame",
        "Amino acid"
    ],
    "citation_count": "413",
    "reference_count": "65",
    "references": [
        "2138270253",
        "1558516755",
        "2085124463",
        "2157815953",
        "2084884863",
        "3021597811",
        "2061424654",
        "2118189700",
        "1966933803",
        "2006244184"
    ]
},{
    "id": "367527820",
    "title": "Genetics and pathogenicity of negative strand viruses",
    "abstract": "",
    "date": "1988",
    "authors": [
        "Daniel Kolakofsky",
        "Brian W. J. Mahy"
    ],
    "related_topics": [
        "Genetics",
        "Biology",
        "Negative strand"
    ],
    "citation_count": "96",
    "reference_count": "0",
    "references": []
},{
    "id": "2055043387",
    "title": "Basic Local Alignment Search Tool",
    "abstract": "A new approach to rapid sequence comparison, basic local alignment search tool (BLAST), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair (MSP) score. Recent mathematical results on the stochastic properties of MSP scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. The basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straight-forward DNA and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long DNA sequences. In addition to its flexibility and tractability to mathematical analysis, BLAST is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity.",
    "date": "1990",
    "authors": [
        "Stephen F. Altschul",
        "Warren Gish",
        "Webb C. Miller",
        "Eugene W. Myers",
        "David J. Lipman"
    ],
    "related_topics": [
        "Substitution matrix",
        "Sim4",
        "Alignment-free sequence analysis"
    ],
    "citation_count": "92,941",
    "reference_count": "19",
    "references": [
        "2015292449",
        "2029195137",
        "2094519647",
        "1501400124",
        "1982996449",
        "2601913882",
        "2074231493",
        "2008610661",
        "1501264308",
        "2113580605"
    ]
},{
    "id": "1502936039",
    "title": "Expression profiling using microarrays fabricated by an ink-jet oligonucleotide synthesizer.",
    "abstract": "We describe a flexible system for gene expression profiling using arrays of tens of thousands of oligonucleotides synthesized in situ by an ink-jet printing method employing standard phosphoramidite chemistry. We have characterized the dependence of hybridization specificity and sensitivity on parameters including oligonucleotide length, hybridization stringency, sequence identity, sample abundance, and sample preparation method. We find that 60-mer oligonucleotides reliably detect transcript ratios at one copy per cell in complex biological samples, and that ink-jet arrays are compatible with several different sample amplification and labeling techniques. Furthermore, results using only a single carefully selected oligonucleotide per gene correlate closely with those obtained using complementary DNA (cDNA) arrays. Most of the genes for which measurements differ are members of gene families that can only be distinguished by oligonucleotides. Because different oligonucleotide sequences can be specified for each array, we anticipate that ink-jet oligonucleotide array technology will be useful in a wide variety of DNA microarray applications.",
    "date": "2001",
    "authors": [
        "Timothy R. Hughes",
        "Mao Mao",
        "Allan R. Jones",
        "Julja Burchard",
        "Matthew J. Marton",
        "Karen W. Shannon",
        "Steven M. Lefkowitz",
        "Michael Ziman",
        "Janell M. Schelter",
        "Michael R. Meyer",
        "Sumire Kobayashi",
        "Colleen Davis",
        "Hongyue Dai",
        "Yudong D. He",
        "Sergey B. Stephaniants",
        "Guy Cavet",
        "Wynn L. Walker",
        "Anne West",
        "Ernest Coffey",
        "Daniel D. Shoemaker",
        "Roland Stoughton",
        "Alan P. Blanchard",
        "Stephen H. Friend",
        "Peter S. Linsley"
    ],
    "related_topics": [
        "DNA-encoded chemical library",
        "Oligonucleotide",
        "DNA microarray"
    ],
    "citation_count": "1,588",
    "reference_count": "26",
    "references": [
        "2109363337",
        "1970156673",
        "2165011536",
        "2130494035",
        "2135187880",
        "2146264532",
        "2135951244",
        "2155612034",
        "2159511216",
        "2165054897"
    ]
},{
    "id": "1549647993",
    "title": "DNA arrays for analysis of gene expression.",
    "abstract": "Publisher Summary This chapter describes one of the currently used microarray technologies commonly called \u201cspotting\u201d or \u201cprinting\u201d because DNAs are physically spotted on a solid substrate in which short oligonucleotides is synthesized directly on a solid support. In standard spotting applications, large collections of DNA samples are assembled in 96- or 384-well plates. DNA microarrays are used for a variety of purposes; essentially any property of a DNA sequence that can be made experimentally to result in differential recovery of that sequence can be assayed for thousands of sequences at once by DNA microarray hybridization. The chapter focuses on the application of DNA microarrays to gene expression studies and discusses general principles of whole genome expression monitoring as well as detailing the specific process of making and using spotted DNA microarrays.",
    "date": "1998",
    "authors": [
        "Michael B. Eisen",
        "Patrick O. Brown"
    ],
    "related_topics": [
        "Sequencing by hybridization",
        "DNA microarray",
        "Protein microarray"
    ],
    "citation_count": "1,462",
    "reference_count": "16",
    "references": [
        "1970156673",
        "2165011536",
        "2063450941",
        "238668910",
        "2069271664",
        "2037509330",
        "2068719237",
        "1968164578",
        "1593794455",
        "1992108607"
    ]
},{
    "id": "2028318125",
    "title": "Lytic growth of Kaposi's sarcoma\u2013associated herpesvirus (human herpesvirus 8) in culture",
    "abstract": "Kaposi's sarcoma (KS) is the leading neoplasm of AIDS patients, and HIV infection is known to be a major risk factor for its development. However, KS can occur in the absence of HIV infection and the risk of KS development varies widely even among HIV-infected patients, with homosexual men with AIDS being 20 times more likely to develop KS than AIDS-afflicted children or hemophiliacs. These and other data strongly suggest that a sexually transmitted agent or co-factor may be involved in KS pathogenesis. Recently, DNA sequences corresponding to the genome of a novel member of the herpesvirus family have been identified within AIDS-KS biopsies, and several reports indicate that these sequences are also present in all forms of HIV-negative KS. These and other findings suggest this new agent, referred to as KS-associated herpesvirus (KSHV) or human herpesvirus 8 (HHV8), as a candidate for the putative etiologic cofactor. However, the role of this agent in KS remains hotly debated. Further progress in understanding its biology has been severely hampered by the lack of a cell culture system for virus growth. Here we report the development of a system for the lytic growth of this virus in a latently infected B cell line and present the first ultrastructural visualization of the virus. This system will facilitate the detailed study of the molecular biology of viral replication, the testing of antiviral drugs and the development of diagnostic tests for viral infection.",
    "date": "1996",
    "authors": [
        "Rolf Renne",
        "Weidong Zhong",
        "Brian Herndier",
        "Michael Mcgrath",
        "Nancy Abbey",
        "Dean Kedes",
        "Don Ganem"
    ],
    "related_topics": [
        "Kaposi's sarcoma-associated herpesvirus",
        "Rhadinovirus",
        "Herpesviridae"
    ],
    "citation_count": "1,161",
    "reference_count": "29",
    "references": [
        "2032438721",
        "2576734941",
        "2336241188",
        "2410723119",
        "2226175820",
        "2312580646",
        "1972008542",
        "2028840705",
        "3146308493",
        "2110863828"
    ]
},{
    "id": "2099369211",
    "title": "SIMULTANEOUS GENOTYPING AND SPECIES IDENTIFICATION USING HYBRIDIZATION PATTERN RECOGNITION ANALYSIS OF GENERIC MYCOBACTERIUM DNA ARRAYS",
    "abstract": "High-density oligonucleotide arrays can be used to rapidly examine large amounts of DNA sequence in a high throughput manner. An array designed to determine the specific nucleotide sequence of 705 bp of the rpoB gene of Mycobacterium tuberculosis accurately detected rifampin resistance associated with mutations of 44 clinical isolates of M. tuberculosis. The nucleotide sequence diversity in 121 Mycobacterial isolates (comprised of 10 species) was examined by both conventional dideoxynucleotide sequencing of the rpoB and 16S genes and by analysis of the rpoB oligonucleotide array hybridization patterns. Species identification for each of the isolates was similar irrespective of whether 16S sequence, rpoB sequence, or the pattern of rpoB hybridization was used. However, for several species, the number of alleles in the 16S and rpoB gene sequences provided discordant estimates of the genetic diversity within a species. In addition to confirming the array\u2019s intended utility for sequencing the region of M. tuberculosis that confers rifampin resistance, this work demonstrates that this array can identify the species of nontuberculous Mycobacteria. This demonstrates the general point that DNA microarrays that sequence important genomic regions (such as drug resistance or pathogenicity islands) can simultaneously identify species and provide some insight into the organism\u2019s population structure. [The sequence data described in this paper have been submitted to GenBank under accession nos. AF09766\u2010 AF059853 and AF060279\u2010AF060367.] For patients infected with Mycobacteria, especially those coinfected with the human immunodeficiency virus type 1 and type 2 (HIV-1, HIV-2), the identity of the Mycobacterium species and the presence of mutations that confer both biologically and clinically important phenotypes are of critical importance. Both of these issues have implications for the appropriate care and treatment of the infected patient. For example, although M. avium complex (MAC) is the most common cause for both disseminated Mycobacterium disease and death in patients with AIDS in the developed world (~25%\u201050% of adults and 10% of children with AIDS are infected",
    "date": "1998",
    "authors": [
        "Thomas R. Gingeras",
        "Ghassan Ghandour",
        "Eugene Wang",
        "Anthony Berno",
        "Peter M. Small",
        "Francis Drobniewski",
        "David Alland",
        "Edward Desmond",
        "Mark Holodniy",
        "Jorg Drenkow"
    ],
    "related_topics": [
        "rpoB",
        "Genotyping",
        "GenBank"
    ],
    "citation_count": "413",
    "reference_count": "46",
    "references": [
        "1995945562",
        "2130494035",
        "2069271664",
        "2037509330",
        "2166785990",
        "2100887397",
        "2073036100",
        "2000334423",
        "2038636949",
        "2052422622"
    ]
},{
    "id": "2169391021",
    "title": "Genetic clustering of all 102 human rhinovirus prototype strains: serotype 87 is close to human enterovirus 70",
    "abstract": "Human rhinoviruses (HRV), common agents of respiratory infections, comprise 102 designated serotypes. The genetic relationships of HRV prototype strains and the possibility of using genetic identification of a given HRV field strain were studied. Genomic sequences in the VP4/VP2 region were obtained from all 102 prototype strains. Phylogenetic analysis included 61 recently isolated Finnish field strains. Seventy-six out of the 102 prototype strains clustered in the HRV genetic group A and 25 in group B. Serotype 87 clustered separately and together with human enterovirus 70. The \u2018percentage\u2019 interserotypic differences were generally similar to those between different enterovirus serotypes, but for six pairs of HRV serotypes they were less than 10%. The maximum variation in genetic group A was 41% at the nucleotide level and 28% at the amino acid level, and in genetic group B 34% and 20%, respectively. Judging from the observed interserotypic differences, the 61 Finnish field isolates might represent as many as 19 different serotypes. One cluster of the field strains did not directly associate with any of the prototype strains and might represent a new serotype. However, larger numbers of field isolates of known serotype need to be characterized, possibly also in the VP1 region, to evaluate the feasibility of genetic typing of HRV strains.",
    "date": "2002",
    "authors": [
        "Carita Savolainen",
        "Soile Blomqvist",
        "Mick N. Mulders",
        "Tapani Hovi"
    ],
    "related_topics": [
        "Serotype",
        "Enterovirus",
        "Phylogenetic tree"
    ],
    "citation_count": "299",
    "reference_count": "29",
    "references": [
        "1964779747",
        "2127062009",
        "2162318638",
        "1540139062",
        "2129612627",
        "1936311738",
        "2059875807",
        "2051429840",
        "2003919681",
        "1830634530"
    ]
},{
    "id": "2033380151",
    "title": "Sequence-specific identification of 18 pathogenic microorganisms using microarray technology",
    "abstract": "We have developed a Multi-Pathogen Identification (MPID) microarray for high confidence identification of eighteen pathogenic prokaryotes, eukaryotes and viruses. Analysis of amplified products from pathogen genomic DNA using microarray hybridization allows for highly specific and sensitive detection, and allows the discrimination between true amplification products and false positive amplification products that might be derived from primers annealing to non-target sequences. Species-specific primer sets were used to amplify multiple diagnostic regions unique to each individual pathogen. Amplified products were washed over the surface of the microarray, and labelled with phycoerythrin-streptavidin for fluorescence detection. A series of overlapping 20-mer oligonucleotide probes hybridize to the entire diagnostic region, while parallel hybridizations on the same surface allow simultaneous screening for all organisms. Comparison to probes that differ by a single mismatch at the central position reduced the contribution of non-specific hybridization. Samples containing individual pathogens were analyzed in separate experiments and the corresponding species-specific diagnostic regions were identified by fluorescence among their highly redundant probe sets. On average, 91% of the 53 660 pathogen probes on the MPID microarray performed as predicted. The limit of detection was found to be as little as 10 fg of B. anthracis DNA in samples that were amplified with six diagnostic primer-pairs. In contrast, PCR products were not observed at this concentration when identical samples were prepared and visualized by agarose gel electrophoresis.",
    "date": "2002",
    "authors": [
        "W.J. Wilson",
        "C.L. Strout",
        "T.Z. DeSantis",
        "J.L. Stilwell",
        "A.V. Carrano",
        "G.L. Andersen"
    ],
    "related_topics": [
        "Gene chip analysis",
        "genomic DNA",
        "Agarose gel electrophoresis"
    ],
    "citation_count": "375",
    "reference_count": "18",
    "references": [
        "2164578725",
        "2029441111",
        "2159511216",
        "2138952930",
        "2001852290",
        "1555782211",
        "2107468770",
        "1793129498",
        "2170574885",
        "2482927381"
    ]
},{
    "id": "2037142940",
    "title": "A method for the rapid sequence-independent amplification of microdissected chromosomal material.",
    "abstract": "Abstract We have developed a simple, efficient method by which microdissected material can be amplified directly in the collection container in a few hours. The procedure involves two initial rounds of DNA synthesis with T7 DNA polymerase, using a primer that contains a random pentanucleotide sequence at its 3\u2032 end and a defined sequence at its 5\u2032 end, followed by PCR amplification with the defined sequence as the primer. The resulting products can be biotinylated and used for fluorescence in situ hybridization (FISH) to confirm their chromosomal location. As few as 17 dissected chromosomal regions provide sufficient material for a specific FISH signal on the appropriate band of metaphase chromosomes. We have obtained a chromosome 6q25-qter-specific painting probe in this way.",
    "date": "1992",
    "authors": [
        "Stefan K. Bohlander",
        "Rafael Espinosa",
        "Michelle M. Le Beau",
        "Janet D. Rowley",
        "Manuel O. D\u00edaz"
    ],
    "related_topics": [
        "Multiplex ligation-dependent probe amplification",
        "Chromosome microdissection",
        "Primer (molecular biology)"
    ],
    "citation_count": "284",
    "reference_count": "6",
    "references": [
        "2072180899",
        "2158507204",
        "1986565746",
        "1992586724",
        "2069428560",
        "1972881190"
    ]
},{
    "id": "2048618475",
    "title": "Human metapneumovirus as a cause of community-acquired respiratory illness",
    "abstract": "Human metapneumovirus (HMPV) is a recently identified Paramyxovirus first isolated from hospitalized children with acute respiratory tract infections (ARTI). We sought evidence of HMPV infection in patients who had visited general practitioners, had influenzalike illnesses (ILI), and had negative tests for influenza and Human respiratory syncytial virus (HRSV). As part of national virologic surveillance, sentinel general practices in England and Wales collected samples from patients of all ages with ILI during winter 2000\u201301. Reverse transcriptase-polymerase chain reaction (PCR) for HMPV, influenza A (H1 and H3), influenza B, and HRSV (A and B) was used to screen combined nose and throat swabs. PCR products from the HMPVpositive samples were sequenced to confirm identity and construct phylogenetic trees. Of 711 swabs submitted, 408 (57.3%) were negative for influenza and HRSV; HMPV was identified in 9 (2.2%) patients. HMPV appears to be associated with community-acquired ARTI. The extent of illness and possible complications related to this new human virus need to be clarified. espite control of many infectious diseases in the industrialized world, acute viral respiratory tract infections (ARTI) remain a leading cause of illness. Although usually self-limiting in healthy adults, these infections are responsible for a substantial loss of productive time and are important factors in the illness and death of the elderly population. Various genetically diverse viruses, often with multiple types, may cause respiratory illness; of these, influenza receives the greatest attention (1). Human respiratory syncytial virus (HRSV) is also increasingly implicated as an important pathogen (2). The association between the incidence of ARTI and excess winter deaths in the United Kingdom is well recognized (1). Regression modeling associates excess winter deaths with influenza and HRSV but also suggests that other pathogens may be involved (3). Studies of the impact of respiratory virus infections are limited by difficulty in distinguishing respiratory pathogens clinically and in the laboratory (4,5). Despite improved sensitivity with diagnostic techniques such as reverse transcriptasepolymerase chain reaction (RT-PCR), approximately 40% of specimens from patients with community-acquired respiratory illnesses during peak winter months contain no identified viral pathogen (2,5,6). A new pneumovirus, Human Metapneumovirus (HMPV), has recently been isolated in the Netherlands (7). The Pneumovirinae subfamily is classified into Pneumovirus, containing HRSV, and Metapneumovirus genera. In 2001, Van den Hoogen et al. (7) reported the detection of HMPV in nasopharyngeal aspirates taken in a 10-year period from 28 hospitalized children and infants with respiratory tract infections who had signs and symptoms similar to those of HRSV infection. Establishing sensitive methods for virus detection helps to clarify the relative contribution of different pathogens to the extent of illness in the community. This information is important for future development of specific antiviral therapies and vaccines. We examined specimens submitted from patients seen in general practice with influenzalike illnesses (ILI) during winter 2000\u201301 to detect HMPV as a possible cause of influenza- and HRSV-negative ILI.",
    "date": "2002",
    "authors": [
        "Joanne Stockton",
        "Iain Stephenson",
        "Douglas Fleming",
        "Maria Zambon"
    ],
    "related_topics": [
        "Human metapneumovirus",
        "Respiratory tract infections",
        "Respiratory virus"
    ],
    "citation_count": "394",
    "reference_count": "14",
    "references": [
        "2170881661",
        "2152552492",
        "1589490904",
        "2110198546",
        "2170920304",
        "1956667192",
        "2047381054",
        "2260338823",
        "2132721709",
        "1550670450"
    ]
},{
    "id": "1589490904",
    "title": "Evidence of human metapneumovirus in Australian children.",
    "abstract": "Michael D Nissen,* David J Siebert,\u2020 Ian M Mackay,\u2021 Theo P Sloots,\u00a7 Stephen J Withers\u00b6 * Director of Infectious Diseases, Royal Children\u2019s Hospital, Herston Road, Herston, QLD 4029 \u2020 Director of Virology, Queensland Health Pathology Service, Royal Brisbane Hospital Complex, QLD; \u2021 PhD Research Scholar; \u00a7 Head, Clinical Virology Research Unit, Sir Albert Sakzewski Viral Research Centre, Royal Children\u2019s Hospital, Herston, QLD; \u00b6 Director of Paediatrics, Logan Hospital, Logan, QLD. theniss@mailbox.uq.edu.au",
    "date": "2002",
    "authors": [
        "Michael D. Nissen",
        "David J. Siebert",
        "Ian M. Mackay",
        "Theo P. Sloots",
        "Stephen J. Withers"
    ],
    "related_topics": [
        "Library science",
        "Medicine",
        "Pediatrics"
    ],
    "citation_count": "280",
    "reference_count": "3",
    "references": [
        "2039773313",
        "2137937904",
        "2103351684"
    ]
},{
    "id": "2110198546",
    "title": "Analysis of the genomic sequence of a human metapneumovirus.",
    "abstract": "We recently described the isolation of a novel paramyxovirus from children with respiratory tract disease in The Netherlands. Based on biological properties and limited sequence information the virus was provisionally classified as the first nonavian member of the Metapneumovirus genus and named human metapneumovirus (hMPV). This report describes the analysis of the sequences of all hMPV open reading frames (ORFs) and intergenic sequences as well as partial sequences of the genomic termini. The overall percentage of amino acid sequence identity between APV and hMPV N, P, M, F, M2-1, M2-2, and L ORFs was 56 to 88%. Some nucleotide sequence identity was also found between the noncoding regions of the APV and hMPV genomes. Although no discernible amino acid sequence identity was found between two of the ORFs of hMPV and ORFs of other paramyxoviruses, the amino acid content, hydrophilicity profiles, and location of these ORFs in the viral genome suggest that they represent SH and G proteins. The high percentage of sequence identity between APV and hMPV, their similar genomic organization (3'-N-P-M-F-M2-SH-G-L-5'), and phylogenetic analyses provide evidence for the proposed classification of hMPV as the first mammalian metapneumovirus.",
    "date": "2002",
    "authors": [
        "Bernadette G. van den Hoogen",
        "Theo M. Bestebroer",
        "Albert D.M.E. Osterhaus",
        "Ron A.M. Fouchier"
    ],
    "related_topics": [
        "ORFS",
        "Metapneumovirus",
        "Human metapneumovirus"
    ],
    "citation_count": "538",
    "reference_count": "58",
    "references": [
        "1483247593",
        "1975304761",
        "2170881661",
        "177909858",
        "2558766452",
        "1582561043",
        "3035616465",
        "2068160897",
        "2103488145",
        "2081977505"
    ]
},{
    "id": "2165127900",
    "title": "Respiratory tract reinfections by the new human Metapneumovirus in an immunocompromised child.",
    "abstract": "The human Metapneumovirus (HMPV), a new member of the Paramyxoviridae family, has been recently associated with respiratory tract infections in young children. We report the case of a young, immunocompromised child who had severe lower respiratory tract infections during two consecutive winter seasons caused by genetically distinct HMPV strains.",
    "date": "2002",
    "authors": [
        "Gilles Pelletier",
        "Pierre D\u00e9ry",
        "Yacine Abed",
        "Guy Boivin"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Human metapneumovirus",
        "Metapneumovirus"
    ],
    "citation_count": "293",
    "reference_count": "12",
    "references": [
        "2106882534",
        "2170881661",
        "2322654587",
        "2152552492",
        "2170920304",
        "2146987033",
        "2125798282",
        "1966623111",
        "2079378048",
        "2318832328"
    ]
},{
    "id": "2076770315",
    "title": "Respiratory Syncytial Virus and Influenza A Infections in the Hospitalized Elderly",
    "abstract": "Respiratory syncytial virus (RSV) infections in the institutionalized elderly have been described; however, there is little information on the impact of RSV infection on community-dwelling elderly. The purpose of this study was to determine the relative numbers of hospitalizations associated with RSV infection and compare the clinical manifestations with influenza A infection. Between November and April during 1989-1992, persons > or = 65 years old hospitalized with acute cardiopulmonary conditions or influenza-like illnesses were evaluated. Evaluation included viral culture, RSV antigen detection, and serologic analysis; 159 (10%) of 1580 had RSV infection and 221 (11%) of 2091 had influenza A. RSV and influenza A cases occurred simultaneously throughout the 3 years. Clinical manifestations were similar; however, patients with RSV infection were more likely to receive therapy for bronchospasm. Death rates were 10% and 6% for RSV infection and influenza A, respectively. RSV infection is the cause of serious disease in community-dwelling older persons.",
    "date": "1995",
    "authors": [
        "Ann R. Falsey",
        "Coleen K. Cunningham",
        "William H. Barker",
        "Ruth W. Kouides",
        "John B. Yuen",
        "Marilyn Menegus",
        "Leonard B. Weiner",
        "Cynthia A. Bonville",
        "Robert F. Betts"
    ],
    "related_topics": [
        "Viral culture",
        "Orthomyxoviridae",
        "Viral disease"
    ],
    "citation_count": "449",
    "reference_count": "23",
    "references": [
        "2122536566",
        "1979157689",
        "1974047133",
        "1982107565",
        "2155757329",
        "2128135383",
        "2110839208",
        "2029684209",
        "2044115620",
        "2413845869"
    ]
},{
    "id": "2079378048",
    "title": "Respiratory Syncytial Virus Infections in Previously Healthy Working Adults",
    "abstract": "During 1975-1995, a total of 2960 healthy adults, 18-60 years of age, were prospectively evaluated for respiratory virus infections. Of these subjects, 211 (7%) acquired respiratory syncytial virus (RSV) infection. The infections were symptomatic in 84% of subjects, involved only the upper respiratory tract in 74%, and included lower respiratory tract symptoms in 26%. Overall, 40% of the subjects were febrile. Lower respiratory tract signs developed in 26%. RSV illnesses were more prolonged than non-RSV respiratory illnesses. Compared with influenza, RSV infections were less frequently associated with fever and headache, but were associated significantly more often with nasal congestion, ear and sinus involvement, and productive cough. Absence from work during the acute phase of the illness resulted from 38% of RSV infections and 66% of influenza cases. The mean duration of RSV illness (9.5 days), however, was significantly longer than that of influenza (6.8 days). The occurrence of annual epidemics of RSV, the virus' potential to reinfect all age groups, and the morbidity associated with these reinfections suggest that RSV infections in working adults may result in appreciable costs for medical visits and absence from work.",
    "date": "2001",
    "authors": [
        "Caroline Breese Hall",
        "Christine E. Long",
        "Kenneth C. Schnabel"
    ],
    "related_topics": [
        "Respiratory virus",
        "Respiratory disease",
        "Respiratory tract"
    ],
    "citation_count": "279",
    "reference_count": "40",
    "references": [
        "2077290707",
        "1565923748",
        "2136123493",
        "2060132446",
        "2076770315",
        "2145445974",
        "2154888143",
        "1966623111",
        "2001556430",
        "1974542809"
    ]
},{
    "id": "2068094897",
    "title": "Epidemiology of community-acquired respiratory tract infections in adults: Incidence, etiology, and impact",
    "abstract": "Upper respiratory tract infections are the most common types of infectious diseases among adults. It is estimated that each adult in the United States experiences two to four respiratory infections annually. The morbidity of these infections is measured by an estimated 75 million physician visits per year, almost 150 million days lost from work, and more than $10 billion in costs for medical care. Serotypes of the rhinoviruses account for 20 to 30 percent of episodes of the common cold. However, the specific causes of most upper respiratory infections are undefined. Pneumonia remains an important cause of morbidity and mortality for nonhospitalized adults despite the widespread use of effective antimicrobial agents. There are no accurate figures on the number of episodes of pneumonia that occur each year in ambulatory patients. In younger adults, the atypical pneumonia syndrome is the most common clinical presentation; Mycoplasma pneumoniae is the most frequently identified causative agent. Other less common agents include Legionella pneumophila, influenza viruses, adenoviruses, and Chlamydia. More than half a million adults are hospitalized each year with pneumonia. Persons older than 65 years of age have the highest rate of pneumonia admissions, 11.5 per 1,000 population. Pneumonia ranks as the sixth leading cause of death in the United States. The pathogens responsible for community-acquired pneumonias are changing. Forty years ago, Streptococcus pneumoniae accounted for the majority of infections. Today, a broad array of community-acquired pathogens have been implicated as etiologic agents including Legionella species, gram-negative bacilli, Hemophilus influenzae, Staphylococcus aureus and nonbacterial pathogens. Given the diversity of pathogenic agents, it has become imperative for clinicians to establish a specific etiologic diagnosis before initiating therapy or to consider the diagnostic possibilities and treat with antimicrobial agents that are effective against the most likely pathogens.",
    "date": "1985",
    "authors": [
        "Richard A. Garibaldi"
    ],
    "related_topics": [
        "Atypical pneumonia",
        "Respiratory tract infections",
        "Pneumonia"
    ],
    "citation_count": "558",
    "reference_count": "22",
    "references": [
        "1566936261",
        "1971857640",
        "2213964329",
        "1980203012",
        "2022600374",
        "2015088755",
        "1980477727",
        "1762572886",
        "2035238578",
        "2045428555"
    ]
},{
    "id": "2065996927",
    "title": "Can respiratory syncytial virus and influenza A be distinguished clinically in institutionalized older persons",
    "abstract": "",
    "date": "1995",
    "authors": [
        "T. G. Wald",
        "B. A. Miller",
        "P. Shult",
        "Paul Drinka",
        "L. Langer",
        "Stefan Gravenstein"
    ],
    "related_topics": [
        "Pneumovirus",
        "Paramyxoviridae",
        "Viral disease"
    ],
    "citation_count": "79",
    "reference_count": "30",
    "references": [
        "2122536566",
        "1982107565",
        "2155757329",
        "1987205969",
        "3022163106",
        "2024279507",
        "2032305979",
        "2034404185",
        "2110839208",
        "2029684209"
    ]
},{
    "id": "2034148010",
    "title": "Dolphin and porpoise morbilliviruses are genetically distinct from phocine distemper virus.",
    "abstract": "The morbilliviruses recently isolated from two cetacean species in the North and Mediterranean Seas have been shown to differ from phocine distemper virus isolated from European seals using monoclonal antibodies. We have identified a \"universal\" morbillivirus primer set, based on highly conserved regions of the morbillivirus phosphoprotein (P) gene and used this to amplify a region surrounding the RNA editing site from all known members of the group. Sequence analysis of this region of the gene shows that the dolphin and porpoise viruses are related but quite different from all other members of the group, forming a distinct lineage more closely related to the ruminant morbilliviruses than to the carnivore viruses.",
    "date": "1993",
    "authors": [
        "T. Barrett",
        "I.K.G. Visser",
        "L. Mamaev",
        "L. Goatley",
        "M.-F. van Bressem",
        "A.D.M.E. Osterhaus"
    ],
    "related_topics": [
        "Phocine distemper virus",
        "Cetacean morbillivirus",
        "Morbillivirus"
    ],
    "citation_count": "387",
    "reference_count": "0",
    "references": []
},{
    "id": "2123427059",
    "title": "Characterization of morbilliviruses isolated from dolphins and porpoises in Europe",
    "abstract": "A previously unidentified morbillivirus was isolated from two harbour porpoises (Phocoena phocoena) that had died in the Dutch Waddensea (North Sea) in 1990. This porpoise morbillivirus (PMV) and a dolphin morbillivirus (DMV), which had recently caused a heavy mortality in Mediterranean striped dolphins (Stenella coeruleoalba), were compared antigenically with other members of the genus Morbillivirus, including the newly recognized phocine distemper virus type 1. DMV and PMV proved to be similar but distinct morbilliviruses, closely related to rinderpest virus and peste-des-petits-ruminants virus. Cell cultures of cetacean, pinniped, ruminant and canine origin showed a different pattern of susceptibility to DMV and PMV infection. Ruminants and dogs proved to be susceptible to experimental infection with DMV and PMV, which both caused a transient leukopenia most pronounced in the ruminants. Pre-exposure of dogs to DMV and PMV protected them from developing CDV viraemia and clinical signs upon challenge infection with virulent CDV. A serological survey among stranded animals of different cetacean species in Europe indicated that infections with DMV- and PMV-like morbilliviruses are not uncommon among these aquatic mammals.",
    "date": "1993",
    "authors": [
        "Ilona K. G. Visser",
        "Marie-Fran\u00e7oise Van Bressem",
        "Rik L. de Swart",
        "Marco W. G. van de Bildt",
        "Helma W. Vos",
        "Roger W. J. van der Heijden",
        "Jeremiah T. Saliki",
        "Claes \u00d6rvell",
        "Paul Kitching",
        "Th\u00ffs Kuiken",
        "Tom Barrett",
        "Albert D. M. E. Osterhaus"
    ],
    "related_topics": [
        "Cetacean morbillivirus",
        "Phocine distemper virus",
        "Morbillivirus"
    ],
    "citation_count": "146",
    "reference_count": "37",
    "references": [
        "2101108802",
        "2068679526",
        "2038983160",
        "2167665444",
        "2983342799",
        "1992441331",
        "1971049442",
        "2138356239",
        "621677454",
        "1978867656"
    ]
},{
    "id": "1972759043",
    "title": "Mutated and hypermutated genes of persistent measles viruses which caused lethal human brain diseases",
    "abstract": "Persistent measles viruses (MVs) causing lethal human brain diseases are defective, and the structure of several mutated matrix genes has been elucidated previously. The present study of four persistent MVs revealed a high number of differences from a consensus sequence also in other genes. Amino acid changes accumulated in the carboxyl terminus of the nucleocapsid protein and in the amino terminus of the phosphoprotein, but did not significantly alter these products, which are implicated in viral replication and transcription. The contrary is true for the envelope glycoproteins: In three of four cases, mutations caused partial deletion of the short intracellular domain of the fusion protein, most likely compromising efficient viral budding. Moreover, in the hemagglutinin gene of a strain showing strongly reduced hemadsorption, 20 clustered A to G mutations, resulting in 16 amino acid changes, were detected. This hypermutation might be due to unwinding modification of a part of the MV RNA genome accidentally present in a double-stranded form. Finally, we classified four lytic and seven persistent MV strains on the basis of their sequences. Surprisingly, the four lytic viruses considered belong to the same class. The persistent viruses form more loosely defined groups, which all differ from the vaccine strain Edmonston.",
    "date": "1989",
    "authors": [
        "Roberto Cattaneo",
        "Anita Schmid",
        "Pius Spielhofer",
        "Karin Kaelin",
        "Knut Baczko",
        "Volker Ter Meulen",
        "Jancu Pardowitz",
        "Stephen Flanagan",
        "Bert K. Rima",
        "Stephen A. Udem",
        "Martin A. Billeter"
    ],
    "related_topics": [
        "Viral replication",
        "Viral budding",
        "Gene"
    ],
    "citation_count": "236",
    "reference_count": "68",
    "references": [
        "2022291864",
        "1996063915",
        "2029131064",
        "2038030881",
        "2001949677",
        "1906936018",
        "2017284486",
        "1987530472",
        "1624020394",
        "1832268633"
    ]
},{
    "id": "2020526182",
    "title": "The evolution of virus diseases: their emergence, epidemicity, and control.",
    "abstract": "Abstract The evolution of virus diseases, both their emergence and disappearance, involves complex interactions between the agent, the host, and the environment. These themes are illustrated by three examples, poliomyelitis of humans, bovine spongiform encephalopathy of cattle, and AIDS of humans. Emergence may be due to evolution of the virus genome, such as probably occurred in parvovirus infection of dogs and human immunodeficiency virus infection of humans. However, emergence of some new viral diseases can be traced to host or environmental factors with no change in the agent. Poliomyelitis, an enteric infection, probably emerged as an epidemic disease due to improvements in personal hygiene and public sanitation which led to a delay in the occurrence of initial infections from the perinatal period (when maternal antibody protected against paralysis) to later childhood when passive immunity had waned. Bovine spongiform encephalopathy is a common source epidemic which was transmitted through nutritional supplements which became contaminated due to a change in the method of production of bone meal supplements in rendering plants. The reduction or disappearance of virus diseases usually involves human intervention, as exemplified by immunization for smallpox and other virus diseases of humans and animals. Naturally occurring immunity may lead to fadeout of a virus as seen with measles in isolated island populations. Evolution of a virus can also result in waning of a disease as seen with myxomatosis among rabbits in Australia. The evolution of virus diseases is a provocative scientific topic and carries lessons relevant to the control of important diseases of humans, animals, and plants.",
    "date": "1993",
    "authors": [
        "Neal Nathanson",
        "Kathleen A. McGann",
        "John Wilesmith",
        "Ronald C. Desrosiers",
        "Ronald Brookmeyer"
    ],
    "related_topics": [
        "Virus",
        "Personal hygiene",
        "Myxomatosis"
    ],
    "citation_count": "27",
    "reference_count": "33",
    "references": [
        "2014199542",
        "2039902123",
        "2021906926",
        "2175004672",
        "1737901895",
        "2033078023",
        "2056502819",
        "2162585352",
        "1512640808",
        "2394625654"
    ]
},{
    "id": "2002849005",
    "title": "Micro neuraminidase-inhibition assay for classification of influenza A virus neuraminidases.",
    "abstract": "SUMMARY A neuraminidase-inhibition (NI) assay performed in microtiter plates is described. This micro-NI assay is a modification of the NI assay recommended by the World Health Organization. It reduces the quantity of reagents required and permits antigenic classification of many isolates simultaneously. To determine the accuracy and sensitivity of this micro-NI assay, 110 influenza A viruses, representing all subtypes, based upon the nine known neuraminidases (NAs), were classified by both the micro-NI and macro-NI assays in two separate laboratories. The NAs were identified accurately by the micro-NI assay. Virus mixtures were detected by both assays, although the macro-NI was clearly more sensitive. The micro-NI assay was also suitable for testing sera for the presence of antibodies to the NAs. Although the micro-NI assay did not provide the quantitation of the macro-NI assay, it did prove to be a rapid method for virus classification and antibody studies on influenza A viruses.",
    "date": "1983",
    "authors": [
        "R. A. Van Deusen",
        "V. S. Hinshaw",
        "D. A. Senne",
        "D. Pellacani"
    ],
    "related_topics": [
        "Assay",
        "Influenza A virus",
        "Virus"
    ],
    "citation_count": "100",
    "reference_count": "7",
    "references": [
        "2043818985",
        "2007740214",
        "2008810568",
        "2074421553",
        "1706817178",
        "2463161801",
        "1967930762"
    ]
},{
    "id": "2078406556",
    "title": "Cloning and Sequence Analysis of the Matrix (M) Protein Gene of Rinderpest Virus and Evidence for Another Bovine Morbillivirus",
    "abstract": "We have cloned and sequenced the entire M gene of the vaccine strain of rinderpest virus and that of the virulent Kabete \"O\" strain from which it was derived. The sequences of these two genes are essentially identical (99% at the nucleotide level), but were very different from a previously published Kabete O M gene sequence (M. Limo and T. Yilma, 1990, Virology 175, 323-327). Inspection of the nucleotide and deduced amino acid sequences of known morbillivirus M genes showed that the earlier sequence was clearly from a morbillivirus, but neither from rinderpest virus nor from peste des petits ruminants virus.",
    "date": "1994",
    "authors": [
        "Michael D. Baron",
        "Lynette Goatley",
        "Tom Barrett"
    ],
    "related_topics": [
        "Rinderpest virus",
        "Peste-des-petits-ruminants virus",
        "Morbillivirus"
    ],
    "citation_count": "27",
    "reference_count": "0",
    "references": []
},{
    "id": "1582863396",
    "title": "Matrix genes of measles virus and canine distemper virus: cloning, nucleotide sequences, and deduced amino acid sequences.",
    "abstract": "The nucleotide sequences encoding the matrix (M) proteins of measles virus (MV) and canine distemper virus (CDV) were determined from cDNA clones containing these genes in their entirety. In both cases, single open reading frames specifying basic proteins of 335 amino acid residues were predicted from the nucleotide sequences. Both viral messages were composed of approximately 1,450 nucleotides and contained 400 nucleotides of presumptive noncoding sequences at their respective 39 ends. MV and CDV M-protein-coding regions were 67% homologous at the nucleotide level and 76% homologous at the amino acid level. Only chance homology was observed in the 400-nucleotide trailer sequences. Comparisons of the M protein sequences of MV and CDV with the sequence reported for Sendai virus (B. M. Blumberg, K. Rose, M. G. Simona, L. Roux, C. Giorgi, and D. Kolakofsky, J. Virol. 52:656-663; Y. Hidaka, T. Kanda, K. Iwasaki, A. Nomoto, T. Shioda, and H. Shibuta, Nucleic Acids Res. 12:7965-7973) indicated the greatest homology among these M proteins in the carboxyterminal third of the molecule. Secondary-structure analyses of this shared region indicated a structurally conserved, hydrophobic sequence which possibly interacted with the lipid bilayer. Images",
    "date": "1986",
    "authors": [
        "W J Bellini",
        "G Englund",
        "C D Richardson",
        "S Rozenblatt",
        "R A Lazzarini"
    ],
    "related_topics": [
        "Measles virus",
        "Peptide sequence",
        "Sendai virus"
    ],
    "citation_count": "175",
    "reference_count": "0",
    "references": []
},{
    "id": "2148205933",
    "title": "Nucleotide sequence analysis of a matrix and small hydrophobic protein dicistronic mRNA of bovine respiratory syncytial virus demonstrates extensive sequence divergence of the small hydrophobic protein from that of human respiratory syncytial virus.",
    "abstract": "The nucleotide and deduced amino acid sequences of the matrix (M) and small hydrophobic (SH) proteins of bovine respiratory syncytial virus (BRSV) have been determined from a dicistronic mRNA. Comparison of these sequences with the corresponding published sequences of human respiratory syncytial virus (HRSV) revealed extensive overall homology at both the nucleotide and amino acid levels in the M protein, but low overall homology at both the nucleotide and amino acid levels in the SH protein. There was only 16 to 22% identity between the BRSV SH protein and the HRSV SH proteins at the C terminus. There were also an additional eight amino acids at the C terminus of BRSV. Despite the low level of identity, there were similarities in the predicted hydropathy profiles of BRSV and HRSV SH proteins. The transcription start and stop signals, which are conserved among HRSV mRNAs, were also identified in the M-SH dicistronic mRNA of BRSV. In addition, the intergenic sequence for the M-SH gene junction of BRSV was determined.",
    "date": "1991",
    "authors": [
        "Siba K. Samal",
        "Miguel Zamora"
    ],
    "related_topics": [
        "Nucleic acid sequence",
        "Paramyxoviridae",
        "Amino acid"
    ],
    "citation_count": "69",
    "reference_count": "21",
    "references": [
        "2138270253",
        "2045348184",
        "2108215151",
        "2081114699",
        "2066148522",
        "2083875562",
        "1595873807",
        "2118156456",
        "2157533018",
        "1637699647"
    ]
},{
    "id": "1997387663",
    "title": "Molecular cloning and sequence analysis of the human parainfluenza 3 virus mRNA encoding the P and C proteins",
    "abstract": "The sequence of the mRNA encoding the phosphoprotein (P protein) of the human parainfluenza virus 3 (PF3) was determined by molecular cloning. In other Parmyxoviridae the P protein mRNA is functionally bicistronic and encodes an additional smaller nonstructural protein termed C. In this report three open reading frames (ORF) are described. These consist of a single long ORF encoding the P protein, and two shorter ORFs encoding the structural Vp18 protein (analogous to the Sendai C protein) and a putative polypeptide termed D protein. The encoded phosphoprotein consists of 603 amino acids and has a predicted molecular weight of 67,683. The C protein consists of 199 amino acids and has a predicted molecular weight of 23,288. The D protein consists of 140 amino acids and has a predicted molecular weight of 16,270. Although the D protein has not yet been demonstrated in vivo its synthesis could be demonstrated in vitro using a rabbit reticulocyte lysate system. Thus it appears that unlike the other paramyxoviruses, the PF3 P protein mRNA may be functionally tricistronic.",
    "date": "1986",
    "authors": [
        "Mark S. Galinski",
        "Michael A. Mink",
        "Dennis M. Lambert",
        "Steven L. Wechsler",
        "Marcel W. Pons"
    ],
    "related_topics": [
        "Open reading frame",
        "Phosphoprotein",
        "Sequence analysis"
    ],
    "citation_count": "123",
    "reference_count": "76",
    "references": [
        "1975304761",
        "1558516755",
        "2045348184",
        "2029987769",
        "2078119356",
        "2282054059",
        "2034277598",
        "2009105413",
        "2089617243",
        "2008000048"
    ]
},{
    "id": "2106255335",
    "title": "Introduction: New and emerging virus diseases",
    "abstract": "",
    "date": "1994",
    "authors": [
        "Frederick A. Murphy",
        "Neal Nathanson"
    ],
    "related_topics": [
        "Virology",
        "Biology",
        "Virus diseases"
    ],
    "citation_count": "5",
    "reference_count": "0",
    "references": []
},{
    "id": "2113457186",
    "title": "Genomic Characterization of a Newly Discovered Coronavirus Associated with Acute Respiratory Distress Syndrome in Humans",
    "abstract": "ABSTRACT A novel human coronavirus (HCoV-EMC/2012) was isolated from a man with acute pneumonia and renal failure in June 2012. This report describes the complete genome sequence, genome organization, and expression strategy of HCoV-EMC/2012 and its relation with known coronaviruses. The genome contains 30,119 nucleotides and contains at least 10 predicted open reading frames, 9 of which are predicted to be expressed from a nested set of seven subgenomic mRNAs. Phylogenetic analysis of the replicase gene of coronaviruses with completely sequenced genomes showed that HCoV-EMC/2012 is most closely related to Tylonycteris bat coronavirus HKU4 (BtCoV-HKU4) and Pipistrellus bat coronavirus HKU5 (BtCoV-HKU5), which prototype two species in lineage C of the genus Betacoronavirus . In accordance with the guidelines of the International Committee on Taxonomy of Viruses, and in view of the 75% and 77% amino acid sequence identity in 7 conserved replicase domains with BtCoV-HKU4 and BtCoV-HKU5, respectively, we propose that HCoV-EMC/2012 prototypes a novel species in the genus Betacoronavirus . HCoV-EMC/2012 may be most closely related to a coronavirus detected in Pipistrellus pipistrellus in The Netherlands, but because only a short sequence from the most conserved part of the RNA-dependent RNA polymerase-encoding region of the genome was reported for this bat virus, its genetic distance from HCoV-EMC remains uncertain. HCoV-EMC/2012 is the sixth coronavirus known to infect humans and the first human virus within betacoronavirus lineage C. IMPORTANCE Coronaviruses are capable of infecting humans and many animal species. Most infections caused by human coronaviruses are relatively mild. However, the outbreak of severe acute respiratory syndrome (SARS) caused by SARS-CoV in 2002 to 2003 and the fatal infection of a human by HCoV-EMC/2012 in 2012 show that coronaviruses are able to cause severe, sometimes fatal disease in humans. We have determined the complete genome of HCoV-EMC/2012 using an unbiased virus discovery approach involving next-generation sequencing techniques, which enabled subsequent state-of-the-art bioinformatics, phylogenetics, and taxonomic analyses. By establishing its complete genome sequence, HCoV-EMC/2012 was characterized as a new genotype which is closely related to bat coronaviruses that are distant from SARS-CoV. We expect that this information will be vital to rapid advancement of both clinical and vital research on this emerging pathogen.",
    "date": "2012",
    "authors": [
        "Sander van Boheemen",
        "Miranda de Graaf",
        "Chris Lauber",
        "Theo M. Bestebroer",
        "V. Stalin Raj",
        "Ali Moh Zaki",
        "Albert D. M. E. Osterhaus",
        "Bart L. Haagmans",
        "Alexander E. Gorbalenya",
        "Eric J. Snijder",
        "Ron A. M. Fouchier"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Pipistrellus bat coronavirus HKU5"
    ],
    "citation_count": "807",
    "reference_count": "54",
    "references": [
        "2166867592",
        "2111211467",
        "1483247593",
        "2132260239",
        "2082928585",
        "2127774996",
        "1703839189",
        "2116586125",
        "2169198329",
        "2103503670"
    ]
},{
    "id": "2058144955",
    "title": "Influenza-associated hospitalizations in the United States",
    "abstract": "ContextRespiratory viral infections are responsible for a large number of hospitalizations in the United States each year.ObjectiveTo estimate annual influenza-associated hospitalizations in the United States by hospital discharge category, discharge type, and age group.Design, Setting, and ParticipantsNational Hospital Discharge Survey (NHDS) data and World Health Organization Collaborating Laboratories influenza surveillance data were used to estimate annual average numbers of hospitalizations associated with the circulation of influenza viruses from the 1979-1980 through the 2000-2001 seasons in the United States using age-specific Poisson regression models.Main Outcome MeasuresWe estimated influenza-associated hospitalizations for primary and any listed pneumonia and influenza and respiratory and circulatory hospitalizations.ResultsAnnual averages of 94 735 (range, 18 908-193 561) primary and 133 900 (range, 30 757-271 529) any listed pneumonia and influenza hospitalizations were associated with influenza virus infections. Annual averages of 226 054 (range, 54 523-430 960) primary and 294 128 (range, 86 494-544 909) any listed respiratory and circulatory hospitalizations were associated with influenza virus infections. Persons 85 years or older had the highest rates of influenza-associated primary respiratory and circulatory hospitalizations (1194.9 per 100 000 persons). Children younger than 5 years (107.9 primary respiratory and circulatory hospitalizations per 100 000 persons) had rates similar to persons aged 50 through 64 years. Estimated rates of influenza-associated hospitalizations were highest during seasons in which A(H3N2) viruses predominated, followed by B and A(H1N1) seasons. After adjusting for the length of each influenza season, influenza-associated primary pneumonia and influenza hospitalizations increased over time among the elderly. There were no significant increases in influenza-associated primary respiratory and circulatory hospitalizations after adjusting for the length of the influenza season.ConclusionsSignificant numbers of influenza-associated hospitalizations in the United States occur among the elderly, and the numbers of these hospitalizations have increased substantially over the last 2 decades due in part to the aging of the population. Children younger than 5 years had rates of influenza-associated hospitalizations similar to those among individuals aged 50 through 64 years. These findings highlight the need for improved influenza prevention efforts for both young and older US residents.",
    "date": "2004",
    "authors": [
        "William W. Thompson",
        "David K. Shay",
        "Eric Weintraub",
        "Lynnette Brammer",
        "Carolyn B. Bridges",
        "Nancy J. Cox",
        "Keiji Fukuda"
    ],
    "related_topics": [
        "Influenza A virus",
        "Population",
        "Influenza prevention"
    ],
    "citation_count": "2,530",
    "reference_count": "39",
    "references": [
        "1886211768",
        "2139841187",
        "1607091144",
        "1977775160",
        "2065420324",
        "2159850238",
        "2016383224",
        "2116971894",
        "2417807721",
        "2100620897"
    ]
},{
    "id": "1690366459",
    "title": "Severe respiratory illness caused by a novel coronavirus, in a patient transferred to the United Kingdom from the Middle East, September 2012.",
    "abstract": "Coronaviruses have the potential to cause severe transmissible human disease, as demonstrated by the severe acute respiratory syndrome (SARS) outbreak of 2003. We describe here the clinical and virological features of a novel coronavirus infection causing severe respiratory illness in a patient transferred to London, United Kingdom, from the Gulf region of the Middle East.",
    "date": "2012",
    "authors": [
        "Alison Bermingham",
        "M.A. Chand",
        "C.S. Brown",
        "E. Aarons",
        "C. Tong",
        "C. Langrish",
        "K. Hoschler",
        "Kevin Brown",
        "Monica Galiano",
        "Richard Myers",
        "R.G. Pebody",
        "H.K. Green",
        "N.L. Boddington",
        "Robin Gopal",
        "N. Price",
        "W. Newsholme",
        "Christian Drosten",
        "Ron Fouchier",
        "Maria Zambon"
    ],
    "related_topics": [
        "Coronavirus",
        "Disease reservoir",
        "Outbreak"
    ],
    "citation_count": "524",
    "reference_count": "8",
    "references": [
        "1703839189",
        "2101063972",
        "53805394",
        "2044343035",
        "1966459725",
        "1963888094",
        "2089796754",
        "2092162071"
    ]
},{
    "id": "2066347985",
    "title": "Human betacoronavirus 2c EMC/2012-related viruses in bats, Ghana and Europe.",
    "abstract": "We screened fecal specimens of 4,758 bats from Ghana and 272 bats from 4 European countries for betacoronaviruses. Viruses related to the novel human betacoronavirus EMC/2012 were detected in 46 (24.9%) of 185 Nycteris bats and 40 (14.7%) of 272 Pipistrellus bats. Their genetic relatedness indicated EMC/2012 originated from bats.",
    "date": "2013",
    "authors": [
        "Augustina Annan",
        "Heather J. Baldwin",
        "Victor Max Corman",
        "Stefan M. Klose",
        "Michael Owusu",
        "Evans Ewald Nkrumah",
        "Ebenezer Kofi Badu",
        "Priscilla Anti",
        "Olivia Agbenyega",
        "Benjamin Meyer",
        "Samuel Oppong",
        "Yaw Adu Sarkodie",
        "Elisabeth K.V. Kalko",
        "Peter H.C. Lina",
        "Elena V. Godlevska",
        "Chantal Reusken",
        "Antje Seebens",
        "Florian Gloza-Rausch",
        "Peter Vallo",
        "Marco Tschapka",
        "Christian Drosten",
        "Jan Felix Drexler"
    ],
    "related_topics": [
        "Pipistrellus",
        "Betacoronavirus",
        "Zoology"
    ],
    "citation_count": "395",
    "reference_count": "16",
    "references": [
        "2166867592",
        "2132260239",
        "1703839189",
        "2103503670",
        "2101063972",
        "2102229939",
        "2137569894",
        "2108204675",
        "2060720058",
        "2105870155"
    ]
},{
    "id": "2105558355",
    "title": "Full-genome deep sequencing and phylogenetic analysis of novel human betacoronavirus.",
    "abstract": "A novel betacoronavirus associated with lethal respiratory and renal complications was recently identified in patients from several countries in the Middle East. We report the deep genome sequencing of the virus directly from a patient\u2019s sputum sample. Our high-throughput sequencing yielded a substantial depth of genome sequence assembly and showed the minority viral variants in the specimen. Detailed phylogenetic analysis of the virus genome (England/Qatar/2012) revealed its close relationship to European bat coronaviruses circulating among the bat species of the Vespertilionidae family. Molecular clock analysis showed that the 2 human infections of this betacoronavirus in June 2012 (EMC/2012) and September 2012 (England/Qatar/2012) share a common virus ancestor most likely considerably before early 2012, suggesting the human diversity is the result of multiple zoonotic events.",
    "date": "2013",
    "authors": [
        "Matthew Cotten",
        "Tommy T-Y Lam",
        "Simon J. Watson",
        "Anne L. Palser",
        "Velislava Petrova",
        "Paul Grant",
        "Oliver G. Pybus",
        "Andrew Rambaut",
        "Yi Guan",
        "Deenan Pillay",
        "Paul Kellam",
        "Eleni Nastouli"
    ],
    "related_topics": [
        "Betacoronavirus",
        "Deep sequencing",
        "Genome"
    ],
    "citation_count": "191",
    "reference_count": "29",
    "references": [
        "2132632499",
        "2103441770",
        "2166867592",
        "2132926880",
        "2160969485",
        "2111211467",
        "2130362098",
        "1703839189",
        "2113457186",
        "2134061616"
    ]
},{
    "id": "1035662337",
    "title": "Evidence of person-to-person transmission within a family cluster of novel coronavirus infections, United Kingdom, February 2013.",
    "abstract": "In February 2013, novel coronavirus (nCoV) infection was diagnosed in an adult male in the United Kingdom with severe respiratory illness, who had travelled to Pakistan and Saudi Arabia 10 days before symptom onset. Contact tracing identified two secondary cases among family members without recent travel: one developed severe respiratory illness and died, the other an influenza-like illness. No other severe cases were identified or nCoV detected in respiratory samples among 135 contacts followed for 10 days.",
    "date": "2012",
    "authors": [
        "Mamoona Tahir",
        "Roger Gajraj",
        "Madhu Bardhan",
        "Huda Mohammed",
        "Louise Dyke",
        "Petra Charlemagne",
        "Rea Alves",
        "David Kirrage",
        "Dan Killalea",
        "Kate James",
        "Melinda Kemp",
        "Harsh Duggal",
        "Robert Carr",
        "Musarrat Afza",
        "Nicholas Aigbogun",
        "Bharat Sibal",
        "Ruth Harrell",
        "Obaghe Edeghere",
        "Keith Neal",
        "Sue Ibbotson",
        "Nimal Wickramasinghe",
        "Nick Sherwood",
        "Beryl Oppenheim",
        "Louise Hopton",
        "Husam Osman",
        "Erasmus Smit",
        "Sowsan Atabani",
        "Judith Workman",
        "Steve Wilson",
        "Clair Overton-Lewis",
        "Margaret Logan",
        "Rosemary McCann",
        "Marko Petrovic",
        "Vinay Bothra",
        "William Welfare",
        "Barbara Isalska",
        "Julian Barker",
        "Alan Ashworth",
        "Igor Fedor",
        "Claude Seng",
        "Deepti Kumar",
        "Suzanna Matthews",
        "Brian McCloskey",
        "Jonathan Nguyen-Van-Tam",
        "Paul Cosford",
        "Alison Bermingham",
        "Joanna Ellis",
        "Monica Galiano",
        "Angie Lackenby",
        "Richard Myers"
    ],
    "related_topics": [
        "Coronavirus",
        "Contact tracing",
        "Pediatrics"
    ],
    "citation_count": "140",
    "reference_count": "0",
    "references": []
},{
    "id": "2102229939",
    "title": "Coronavirus Diversity, Phylogeny and Interspecies Jumping:",
    "abstract": "The SARS epidemic has boosted interest in research on coronavirus biodiversity and genomics. Before 2003, there were only 10 coronaviruses with complete genomes available. After the SARS epidemic, up to December 2008, there was an addition of 16 coronaviruses with complete genomes sequenced. These include two human coronaviruses (human coronavirus NL63 and human coronavirus HKU1), 10 other mammalian coronaviruses [bat SARS coronavirus, bat coronavirus (bat-CoV) HKU2, bat-CoV HKU4, bat-CoV HKU5, bat-CoV HKU8, bat-CoV HKU9, bat-CoV 512/2005, bat-CoV 1A, equine coronavirus, and beluga whale coronavirus] and four avian coronaviruses (turkey coronavirus, bulbul coronavirus HKU11, thrush coronavirus HKU12, and munia coronavirus HKU13). Two novel subgroups in group 2 coronavirus (groups 2c and 2d) and two novel subgroups in group 3 coronavirus (groups 3b and 3c) have been proposed. The diversity of coronaviruses is a result of the infidelity of RNA-dependent RNA polymerase, high frequency of homologous RNA recombination, and the large genomes of coronaviruses. Among all hosts, the diversity of coronaviruses is most evidenced in bats and birds, which may be a result of their species diversity, ability to fly, environmental pressures, and habits of roosting and flocking. The present evidence supports that bat coronaviruses are the gene pools of group 1 and 2 coronaviruses, whereas bird coronaviruses are the gene pools of group 3 coronaviruses. With the increasing number of coronaviruses, more and more closely related coronaviruses from distantly related animals have been observed, which were results of recent interspecies jumping and may be the cause of disastrous outbreaks of zoonotic diseases.",
    "date": "2009",
    "authors": [
        "Patrick C.Y. Woo",
        "Susanna K.P. Lau",
        "Yi Huang",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Coronavirus",
        "Alphacoronavirus",
        "Bulbul coronavirus HKU11"
    ],
    "citation_count": "570",
    "reference_count": "79",
    "references": [
        "2116586125",
        "1966238900",
        "2169198329",
        "2103503670",
        "2111412754",
        "2140338292",
        "2170933940",
        "2162496804",
        "2159857626",
        "2122576818"
    ]
},{
    "id": "2079206979",
    "title": "Detection of alpha and betacoronaviruses in multiple Iberian bat species",
    "abstract": "Bat coronaviruses (CoV) are putative precursors of the severe acute respiratory syndrome (SARS) CoV and other CoV that crossed the species barrier from zoonotic reservoirs into the human population. To determine the presence and distribution of CoV in Iberian bats, 576 individuals of 26 different bat species were captured in 13 locations in Spain. We report for the first time the presence of 14 coronaviruses in 9 Iberian bat species. Phylogenetic analysis of a conserved CoV genome region (RdRp gene) shows a wide diversity and distribution of alpha and betacoronavirus in Spain. Interestingly, although some of these viruses are related to other European BatCoV, or to Asian CoV, some of the viruses found in Spain cluster in new groups of \u03b1 and \u03b2 CoV.",
    "date": "2011",
    "authors": [
        "Ana Falc\u00f3n",
        "Sonia V\u00e1zquez-Mor\u00f3n",
        "Inmaculada Casas",
        "Carolina Aznar",
        "Guillermo Ruiz",
        "Francisco Pozo",
        "Pilar Perez-Bre\u00f1a",
        "Javier Juste",
        "Carlos Ib\u00e1\u00f1ez",
        "Inazio Garin",
        "Joxerra Aihartza",
        "Juan E. Echevarr\u00eda"
    ],
    "related_topics": [
        "Betacoronavirus",
        "Population",
        "Phylogenetic tree"
    ],
    "citation_count": "76",
    "reference_count": "26",
    "references": [
        "2132260239",
        "2161444534",
        "2103503670",
        "2111412754",
        "2170933940",
        "2101063972",
        "2139153938",
        "2102229939",
        "2108204675",
        "2105357365"
    ]
},{
    "id": "2158773042",
    "title": "Recovery from severe novel coronavirus infection",
    "abstract": "We describe the third confirmed case of novel coronavirus infection in a resident of the Arabian Peninsula. Our patient presented, as did 2 prior cases, with severe pneumonia and renal dysfunction requiring intensive care support including assisted ventilation. However, unlike the earlier cases, and despite underlying chronic disease and a single kidney, he survived his infection and has been discharged home. The Ministry of Health continues active surveillance for additional cases. As this case report goes to press, 2 additional confirmed cases have been identified in Riyadh, Saudi Arabia. Contact investigations are in progress. Future work will focus not only on the origin of the virus and mechanisms of transmission, but also the host factors that influence pathogenesis and prognosis.",
    "date": "2012",
    "authors": [
        "Ali M. AlBarrak",
        "Gwen M. Stephens",
        "Roger Hewson",
        "Ziad A. Memish"
    ],
    "related_topics": [
        "Intensive care",
        "Coronavirus",
        "Pneumonia"
    ],
    "citation_count": "98",
    "reference_count": "5",
    "references": [
        "2166867592",
        "2129542667",
        "1703839189",
        "1690366459",
        "2117698342"
    ]
},{
    "id": "2130450914",
    "title": "Haematological manifestations in patients with severe acute respiratory syndrome : retrospective analysis",
    "abstract": "Abstract Objectives To evaluate the haematological findings of patients with severe acute respiratory syndrome (SARS). Design Analysis of the demographic, clinical, and laboratory characteristics of patients with SARS. Setting Prince of Wales Hospital, Hong Kong. Subjects All patients with a diagnosis of SARS between 11 March and 29 March 2003 who had no pre-existing haematological disorders. Main outcome measures Clinical end points included the need for intensive care and death. Univariate and multivariate analyses were performed to examine factors associated with adverse outcome. Results 64 male and 93 female patients were included in this study. The most common findings included lymphopenia in 153 (98%) of the 157 patients, neutrophilia in 129 (82%), thrombocytopenia in 87 patients (55%), followed by thrombocytosis in 77 (49%), and isolated prolonged activated partial thromboplastin time in 96 patients (63%). The haemoglobin count dropped by more than 20 g/l from baseline in 95 (61%) patients. Four patients (2.5%) developed disseminated intravascular coagulation. Lymphopenia was shown in haemato-lymphoid organs at postmortem examination. Multivariate analysis showed that advanced age and a high concentration of lactate dehydrogenase at presentation were independent predictors of an adverse outcome. Subsets of peripheral blood lymphocytes were analysed in 31 patients. The counts of CD4 positive and CD8 positive T cells fell early in the course of illness. Low counts of CD4 and CD8 cells at presentation were associated with adverse outcomes. Conclusions Abnormal haematological variables were common among patients with SARS. Lymphopenia and the depletion of T lymphocyte subsets may be associated with disease activity.",
    "date": "2003",
    "authors": [
        "Raymond S M Wong",
        "Alan Wu",
        "K F To",
        "Nelson Lee",
        "Christopher W K Lam",
        "C K Wong",
        "Paul K S Chan",
        "Margaret H L Ng",
        "L M Yu",
        "David S Hui",
        "John S Tam",
        "Gregory Cheng",
        "Joseph J Y Sung"
    ],
    "related_topics": [
        "Intensive care",
        "Thrombocytosis",
        "Lymphocytopenia"
    ],
    "citation_count": "574",
    "reference_count": "15",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2100820722",
        "1543288877",
        "2045321764",
        "2021398464",
        "2060041703",
        "117812911",
        "73172610"
    ]
},{
    "id": "2088479029",
    "title": "Rapid diagnostics urgently needed for killer infections",
    "abstract": "Respiratory tract infections (RTIs) cause millions of deaths worldwide. They are caused by disparate bacteria, viruses, fungi, and parasites that have similar presentations and thus cannot be easily distinguished clinically. There is presently no standardised, rapid, accurate, sensitive, and specific point-of-care diagnostic test available that can identify causative pathogens within a few hours of consultation. Therefore, patients presenting with RTIs at all points of health care are empirically treated with broad-spectrum antibiotics designed to cover many possible pathogens.",
    "date": "2013",
    "authors": [
        "Alimuddin Zumla",
        "Vanya Gant",
        "Matthew Bates",
        "Peter Mwaba",
        "Markus Maeurer",
        "Ziad A Memish"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Global health",
        "Antibiotics"
    ],
    "citation_count": "9",
    "reference_count": "13",
    "references": [
        "2159773654",
        "2163941297",
        "2112332584",
        "2101996554",
        "2134638464",
        "2078626331",
        "2012327124",
        "1972874505",
        "2117305364",
        "65936750"
    ]
},{
    "id": "297155885",
    "title": "Clinical Presentation and Diagnosis",
    "abstract": "Tumors and pseudotumors of the liver account for less than 2% of all childhood tumors and vary considerably in incidence throughout the pediatric age range, with hepatoblastoma, rhabdoid tumor of the liver, hemangioendothelioma, biliary tract rhabdomyosarcoma, and mesenchymal hamartoma in the first 2 years of life and hepatocellular carcinoma, focal nodular hyperplasia, and undifferentiated sarcoma in older children and adolescents. The main elements for the diagnosis are age at presentation, the clinical symptoms, the association with an underlying disease, the alphafetoprotein (AFP) level, and the radiological characteristics. In most cases, a biopsy is mandatory to confirm the diagnosis.",
    "date": "2010",
    "authors": [
        "Laurence Brugi\u00e8res"
    ],
    "related_topics": [
        "Hepatoblastoma",
        "Focal nodular hyperplasia",
        "Rhabdomyosarcoma"
    ],
    "citation_count": "24",
    "reference_count": "42",
    "references": [
        "2034320803",
        "2160894166",
        "2016158954",
        "1938502624",
        "1917601863",
        "2143551300",
        "1564820488",
        "1581757807",
        "2006965831",
        "2012819984"
    ]
},{
    "id": "2122612816",
    "title": "Plaque assay for human coronavirus NL63 using human colon carcinoma cells",
    "abstract": "Coronaviruses cause a broad range of diseases in animals and humans. Human coronavirus (hCoV) NL63 is associated with up to 10% of common colds. Viral plaque assays enable the characterization of virus infectivity and allow for purifying virus stock solutions. They are essential for drug screening. Hitherto used cell cultures for hCoV-NL63 show low levels of virus replication and weak and diffuse cytopathogenic effects. It has not yet been possible to establish practicable plaque assays for this important human pathogen. 12 different cell cultures were tested for susceptibility to hCoV-NL63 infection. Human colon carcinoma cells (CaCo-2) replicated virus more than 100 fold more efficiently than commonly used African green monkey kidney cells (LLC-MK2). CaCo-2 cells showed cytopathogenic effects 4 days post infection. Avicel, agarose and carboxymethyl-cellulose overlays proved suitable for plaque assays. Best results were achieved with Avicel, which produced large and clear plaques from the 4th day of infection. The utility of plaque assays with agrose overlay was demonstrated for purifying virus, thereby increasing viral infectivity by 1 log 10 PFU/mL. CaCo-2 cells support hCoV-NL63 better than LLC-MK2 cells and enable cytopathogenic plaque assays. Avicel overlay is favourable for plaque quantification, and agarose overlay is preferred for plaque purification. HCoV-NL63 virus stock of increased infectivity will be beneficial in antiviral screening, animal modelling of disease, and other experimental tasks.",
    "date": "2008",
    "authors": [
        "Petra Herzog",
        "Christian Drosten",
        "Marcel A M\u00fcller"
    ],
    "related_topics": [
        "Viral Plaque Assay",
        "Virus quantification",
        "Infectivity"
    ],
    "citation_count": "61",
    "reference_count": "39",
    "references": [
        "2111412754",
        "2170933940",
        "1757215199",
        "2159857626",
        "2078917493",
        "1544561280",
        "1965435260",
        "2105870155",
        "3036980653",
        "2139567694"
    ]
},{
    "id": "2136039989",
    "title": "Profiles of antibody responses against severe acute respiratory syndrome coronavirus recombinant proteins and their potential use as diagnostic markers",
    "abstract": "A new coronavirus (severe acute respiratory syndrome coronavirus [SARS-CoV]) has been identified to be the etiological agent of severe acute respiratory syndrome. Given the highly contagious and acute nature of the disease, there is an urgent need for the development of diagnostic assays that can detect SARS-CoV infection. For determination of which of the viral proteins encoded by the SARS-CoV genome may be exploited as diagnostic antigens for serological assays, the viral proteins were expressed individually in mammalian and/or bacterial cells and tested for reactivity with sera from SARS-CoV-infected patients by Western blot analysis. A total of 81 sera, including 67 from convalescent patients and seven pairs from two time points of infection, were analyzed, and all showed immunoreactivity towards the nucleocapsid protein (N). Sera from some of the patients also showed immunoreactivity to U274 (59 of 81 [73%]), a protein that is unique to SARS-CoV. In addition, all of the convalescent-phase sera showed immunoreactivity to the spike (S) protein when analyzed by an immunofluorescence method utilizing mammalian cells stably expressing S. However, samples from the acute phase (2 to 9 days after the onset of illness) did not react with S, suggesting that antibodies to N may appear earlier than antibodies to S. Alternatively, this could be due to the difference in the sensitivities of the two methods. The immunoreactivities to these recombinant viral proteins are highly specific, as sera from 100 healthy donors did not react with any of them. These results suggest that recombinant N, S, and U274 proteins may be used as antigens for the development of serological assays for SARS-CoV.",
    "date": "2004",
    "authors": [
        "Yee Joo Tan",
        "Phuay Yee Goh",
        "Burtram C. Fielding",
        "Shuo Shen",
        "Chih Fong Chou",
        "Jian Lin Fu",
        "Hoe Nam Leong",
        "Yee Sin Leo",
        "Eng Eong Ooi",
        "Ai Ee Ling",
        "Seng Gee Lim",
        "Wanjin Hong"
    ],
    "related_topics": [
        "Coronavirus",
        "Serology",
        "Immunofluorescence"
    ],
    "citation_count": "188",
    "reference_count": "15",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2116586125",
        "2169198329",
        "1976741900",
        "1967669339",
        "2171291163",
        "2077489286",
        "2121810961"
    ]
},{
    "id": "2115709314",
    "title": "Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression, and Survival Analysis",
    "abstract": "Introduction * General Aspects of Fitting Regression Models * Missing Data * Multivariable Modeling Strategies * Resampling, Validating, Describing, and Simplifying the Model * S-PLUS Software * Case Study in Least Squares Fitting and Interpretation of a Linear Model * Case Study in Imputation and Data Reduction * Overview of Maximum Likelihood Estimation * Binary Logistic Regression * Logistic Model Case Study 1: Predicting Cause of Death * Logistic Model Case Study 2: Survival of Titanic Passengers * Ordinal Logistic Regression * Case Study in Ordinal Regrssion, Data Reduction, and Penalization * Models Using Nonparametic Transformations of X and Y * Introduction to Survival Analysis * Parametric Survival Models * Case Study in Parametric Survival Modeling and Model Approximation * Cox Proportional Hazards Regression Model * Case Study in Cox Regression",
    "date": "2010",
    "authors": [
        "Jr. Frank E. Harrell"
    ],
    "related_topics": [
        "Logistic regression",
        "Ordinal regression",
        "Proper linear model"
    ],
    "citation_count": "13,068",
    "reference_count": "162",
    "references": [
        "1995945562",
        "1513618424",
        "1480376833",
        "2135046866",
        "2122825543",
        "2112316706",
        "1594031697",
        "1556631438",
        "2134843796",
        "1587094587"
    ]
},{
    "id": "2136883754",
    "title": "Analysis of Survival Data",
    "abstract": "The objective of this book is to give a concise account of the analysis of survival data. The book is intended both for the applied statistician and for a wider statistical audience wanting an introduction to this field. Particular attention is paid to new theory on the relationship between survival factors and identified explanatory variables. Each chapter concludes with bibliographic notes and outline statements of further results that can be used for student exercises. (ANNOTATION)",
    "date": "1983",
    "authors": [
        "D.R. Cox",
        "D. Oakes"
    ],
    "related_topics": [
        "Statistician",
        "Population",
        "Mathematics education"
    ],
    "citation_count": "11,133",
    "reference_count": "0",
    "references": []
},{
    "id": "1966714873",
    "title": "Proportional hazards tests and diagnostics based on weighted residuals",
    "abstract": "SUMMARY Nonproportional hazards can often be expressed by extending the Cox model to include time varying coefficients; e.g., for a single covariate, the hazard function for subject i is modelled as exp { fl(t)Zi(t)}. A common example is a treatment effect that decreases with time. We show that the function /3(t) can be directly visualized by smoothing an appropriate residual plot. Also, many tests of proportional hazards, including those of Cox (1972), Gill & Schumacher (1987), Harrell (1986), Lin (1991), Moreau, O'Quigley & Mesbah (1985), Nagelkerke, Oosting & Hart (1984), O'Quigley & Pessione (1989), Schoenfeld (1980) and Wei (1984) are related to time-weighted score tests of the proportional hazards hypothesis, and can be visualized as a weighted least-squares line fitted to the residual plot.",
    "date": "1994",
    "authors": [
        "Patricia M. Grambsch",
        "Terry M. Therneau"
    ],
    "related_topics": [
        "Proportional hazards model",
        "Partial residual plot",
        "Covariate"
    ],
    "citation_count": "6,645",
    "reference_count": "24",
    "references": [
        "2797583072",
        "2796700885",
        "2995133996",
        "2057968703",
        "2319384619",
        "2063384143",
        "1977247044",
        "1502930520",
        "2170424458",
        "2335389429"
    ]
},{
    "id": "2158075347",
    "title": "Canadian Guidelines for the Initial Management of Community-Acquired Pneumonia: An Evidence-Based Update by the Canadian Infectious Diseases Society and the Canadian Thoracic Society",
    "abstract": "Lionel A Mandell MD FRCPC1, Thomas J Marrie MD FRCPC2, Ronald F Grossman MD FRCPC FACP3, Anthony W Chow MD FRCPC FACP4, Robert H Hyland MD FRCPC5, and the Canadian CAP Working Group* McMaster University, Hamilton, Ontario; Dalhousie University, Halifax, Nova Scotia; QEII Health Sciences Centre, Halifax, Nova Scotia; University of British Columbia, Vancouver, British Columbia; St Michael\u2019s Hospital, Toronto, Ontario",
    "date": "2000",
    "authors": [
        "Lionel A. Mandell",
        "Thomas J. Marrie",
        "Ronald F. Grossman",
        "Anthony W. Chow",
        "Robert H. Hyland"
    ],
    "related_topics": [
        "Antibacterial agent",
        "St. Michael",
        "Library science"
    ],
    "citation_count": "915",
    "reference_count": "220",
    "references": [
        "2320270386",
        "2202941334",
        "2336287850",
        "2037712857",
        "2112302527",
        "2339696769",
        "2132950564",
        "2027162482",
        "3143755808",
        "2917182907"
    ]
},{
    "id": "2103546861",
    "title": "A simple, fast, and accurate algorithm to estimate large phylogenies by maximum likelihood.",
    "abstract": "The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximum- likelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbcL sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/. (Algorithm; computer simulations; maximum likelihood; phylogeny; rbcL; RDPII project.) The size of homologous sequence data sets has in- creased dramatically in recent years, and many of these data sets now involve several hundreds of taxa. More- over, current probabilistic sequence evolution models (Swofford et al., 1996 ; Page and Holmes, 1998 ), notably those including rate variation among sites (Uzzell and Corbin, 1971 ; Jin and Nei, 1990 ; Yang, 1996 ), require an increasing number of calculations. Therefore, the speed of phylogeny reconstruction methods is becoming a sig- nificant requirement and good compromises between speed and accuracy must be found. The maximum likelihood (ML) approach is especially accurate for building molecular phylogenies. Felsenstein (1981) brought this framework to nucleotide-based phy- logenetic inference, and it was later also applied to amino acid sequences (Kishino et al., 1990). Several vari- ants were proposed, most notably the Bayesian meth- ods (Rannala and Yang 1996; and see below), and the discrete Fourier analysis of Hendy et al. (1994), for ex- ample. Numerous computer studies (Huelsenbeck and Hillis, 1993; Kuhner and Felsenstein, 1994; Huelsenbeck, 1995; Rosenberg and Kumar, 2001; Ranwez and Gascuel, 2002) have shown that ML programs can recover the cor- rect tree from simulated data sets more frequently than other methods can. Another important advantage of the ML approach is the ability to compare different trees and evolutionary models within a statistical framework (see Whelan et al., 2001, for a review). However, like all optimality criterion-based phylogenetic reconstruction approaches, ML is hampered by computational difficul- ties, making it impossible to obtain the optimal tree with certainty from even moderate data sets (Swofford et al., 1996). Therefore, all practical methods rely on heuristics that obtain near-optimal trees in reasonable computing time. Moreover, the computation problem is especially difficult with ML, because the tree likelihood not only depends on the tree topology but also on numerical pa- rameters, including branch lengths. Even computing the optimal values of these parameters on a single tree is not an easy task, particularly because of possible local optima (Chor et al., 2000). The usual heuristic method, implemented in the pop- ular PHYLIP (Felsenstein, 1993 ) and PAUP \u2217 (Swofford, 1999 ) packages, is based on hill climbing. It combines stepwise insertion of taxa in a growing tree and topolog- ical rearrangement. For each possible insertion position and rearrangement, the branch lengths of the resulting tree are optimized and the tree likelihood is computed. When the rearrangement improves the current tree or when the position insertion is the best among all pos- sible positions, the corresponding tree becomes the new current tree. Simple rearrangements are used during tree growing, namely \"nearest neighbor interchanges\" (see below), while more intense rearrangements can be used once all taxa have been inserted. The procedure stops when no rearrangement improves the current best tree. Despite significant decreases in computing times, no- tably in fastDNAml (Olsen et al., 1994 ), this heuristic becomes impracticable with several hundreds of taxa. This is mainly due to the two-level strategy, which sepa- rates branch lengths and tree topology optimization. In- deed, most calculations are done to optimize the branch lengths and evaluate the likelihood of trees that are finally rejected. New methods have thus been proposed. Strimmer and von Haeseler (1996) and others have assembled four- taxon (quartet) trees inferred by ML, in order to recon- struct a complete tree. However, the results of this ap- proach have not been very satisfactory to date (Ranwez and Gascuel, 2001 ). Ota and Li (2000, 2001) described",
    "date": "2003",
    "authors": [
        "St\u00e9phane Guindon",
        "Olivier Gascuel"
    ],
    "related_topics": [
        "Tree rearrangement",
        "Interval tree",
        "Range tree"
    ],
    "citation_count": "17,403",
    "reference_count": "48",
    "references": [
        "2170120409",
        "2164789250",
        "2097706568",
        "2161444534",
        "2030966943",
        "2994240441",
        "2144775551",
        "2065461553",
        "2105926960",
        "2017519756"
    ]
},{
    "id": "2046153984",
    "title": "Coronaviruses post-SARS: update on replication and pathogenesis.",
    "abstract": "Although coronaviruses were first identified nearly 60 years ago, they only received notoriety in 2003 when one of their members was identified as the aetiological agent of severe acute respiratory syndrome. Previously these viruses were known to be important agents of respiratory and enteric infections of domestic and companion animals and to cause approximately 15% of all cases of the common cold. This Review focuses on recent advances in our understanding of the mechanisms of coronavirus replication, interactions with the host immune response and disease pathogenesis. It also highlights the recent identification of numerous novel coronaviruses and the propensity of this virus family to cross species barriers.",
    "date": "2009",
    "authors": [
        "Stanley Perlman",
        "Jason Netland"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral replication",
        "Common cold"
    ],
    "citation_count": "1,340",
    "reference_count": "142",
    "references": [
        "1966238900",
        "2103503670",
        "2134061616",
        "2096145431",
        "2111412754",
        "2091671824",
        "2140338292",
        "2170933940",
        "2054076340",
        "2126707939"
    ]
},{
    "id": "1998725525",
    "title": "Incubation periods of acute respiratory viral infections: a systematic review",
    "abstract": "Summary Knowledge of the incubation period is essential in the investigation and control of infectious disease, but statements of incubation period are often poorly referenced, inconsistent, or based on limited data. In a systematic review of the literature on nine respiratory viral infections of public-health importance, we identified 436 articles with statements of incubation period and 38 with data for pooled analysis. We fitted a log-normal distribution to pooled data and found the median incubation period to be 5\u00b76 days (95% CI 4\u00b78\u20136\u00b73) for adenovirus, 3\u00b72 days (95% CI 2\u00b78\u20133\u00b77) for human coronavirus, 4\u00b70 days (95% CI 3\u00b76\u20134\u00b74) for severe acute respiratory syndrome coronavirus, 1\u00b74 days (95% CI 1\u00b73\u20131\u00b75) for influenza A, 0\u00b76 days (95% CI 0\u00b75\u20130\u00b76) for influenza B, 12\u00b75 days (95% CI 11\u00b78\u201313\u00b73) for measles, 2\u00b76 days (95% CI 2\u00b71\u20133\u00b71) for parainfluenza, 4\u00b74 days (95% CI 3\u00b79\u20134\u00b79) for respiratory syncytial virus, and 1\u00b79 days (95% CI 1\u00b74\u20132\u00b74) for rhinovirus. When using the incubation period, it is important to consider its full distribution: the right tail for quarantine policy, the central regions for likely times and sources of infection, and the full distribution for models used in pandemic planning. Our estimates combine published data to give the detail necessary for these and other applications.",
    "date": "2009",
    "authors": [
        "Justin Lessler",
        "Nicholas G Reich",
        "Ron Brookmeyer",
        "Trish M Perl",
        "Kenrad E Nelson",
        "Derek A T Cummings"
    ],
    "related_topics": [
        "Incubation period",
        "Infectious Disease Incubation Period",
        "Respiratory tract infections"
    ],
    "citation_count": "766",
    "reference_count": "74",
    "references": [
        "2100820722",
        "2125251240",
        "2156537900",
        "1990049863",
        "2162707016",
        "2146453846",
        "2140763962",
        "3140139051",
        "2800136802",
        "2086300406"
    ]
},{
    "id": "2094993149",
    "title": "Reversion of advanced Ebola virus disease in nonhuman primates with ZMapp",
    "abstract": "Without an approved vaccine or treatments, Ebola outbreak management has been limited to palliative care and barrier methods to prevent transmission. These approaches, however, have yet to end the 2014 outbreak of Ebola after its prolonged presence in West Africa. Here we show that a combination of monoclonal antibodies (ZMapp), optimized from two previous antibody cocktails, is able to rescue 100% of rhesus macaques when treatment is initiated up to 5 days post-challenge. High fever, viraemia and abnormalities in blood count and blood chemistry were evident in many animals before ZMapp intervention. Advanced disease, as indicated by elevated liver enzymes, mucosal haemorrhages and generalized petechia could be reversed, leading to full recovery. ELISA and neutralizing antibody assays indicate that ZMapp is cross-reactive with the Guinean variant of Ebola. ZMapp exceeds the efficacy of any other therapeutics described so far, and results warrant further development of this cocktail for clinical use. A new treatment, containing an optimized cocktail of three monoclonal antibodies against Ebola virus, provided full protection and disease reversal in rhesus monkeys when given under conditions in which controls succumbed by day 8; this new therapy may be a good candidate for treating Ebola virus infection in human patients. This study shows that ZMapp, an optimized cocktail of three monoclonal antibodies that has been pressed into clinical use in response to the current Ebola virus disease epidemic, was able to rescue all of 18 rhesus macaques when treatment was initiated up to five days post-infection. All three controls had died by day eight.",
    "date": "2014",
    "authors": [
        "Xiangguo Qiu",
        "Gary Wong",
        "Jonathan Audet",
        "Alexander Bello",
        "Lisa Fernando",
        "Judie B. Alimonti",
        "Hugues Fausther-Bovendo",
        "Haiyan Wei",
        "Jenna Aviles",
        "Ernie Hiatt",
        "Ashley Johnson",
        "Josh Morton",
        "Kelsi Swope",
        "Ognian Bohorov",
        "Natasha Bohorova",
        "Charles Goodman",
        "Do Kim",
        "Michael H. Pauly",
        "Jesus Velasco",
        "James Pettitt",
        "Gene G. Olinger",
        "Kevin Whaley",
        "Bianli Xu",
        "James E. Strong",
        "Larry Zeitlin",
        "Gary P. Kobinger"
    ],
    "related_topics": [
        "ZMapp",
        "Ebola virus",
        "Palliative care"
    ],
    "citation_count": "1,031",
    "reference_count": "27",
    "references": [
        "2115102869",
        "2125684318",
        "2117671399",
        "2128406623",
        "2028463307",
        "2084600650",
        "2141122594",
        "2116029690",
        "2130063921",
        "2050813818"
    ]
},{
    "id": "2152528032",
    "title": "Recombination, reservoirs, and the modular spike: mechanisms of coronavirus cross-species transmission.",
    "abstract": "Over the past 30 years, several cross-species transmission events, as well as changes in virus tropism, have mediated significant animal and human diseases. Most notable is severe acute respiratory syndrome (SARS), a lower respiratory tract disease of humans that was first reported in late 2002 in Guangdong Province, China. The disease, which quickly spread worldwide over a period of 4 months spanning late 2002 and early 2003, infected over 8,000 individuals and killed nearly 800 before it was successfully contained by aggressive public health intervention strategies. A coronavirus (SARS-CoV) was identified as the etiological agent of SARS, and initial assessments determined that the virus crossed to human hosts from zoonotic reservoirs, including bats, Himalayan palm civets (Paguma larvata), and raccoon dogs (Nyctereutes procyonoides), sold in exotic animal markets in Guangdong Province. In this review, we discuss the molecular mechanisms that govern coronavirus cross-species transmission both in vitro and in vivo, using the emergence of SARS-CoV as a model. We pay particular attention to how changes in the Spike attachment protein, both within and outside of the receptor binding domain, mediate the emergence of coronaviruses in new host populations.",
    "date": "2010",
    "authors": [
        "Rachel L. Graham",
        "Ralph S. Baric"
    ],
    "related_topics": [
        "Coronavirus",
        "Disease reservoir",
        "Cross-species transmission"
    ],
    "citation_count": "488",
    "reference_count": "161",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2116586125",
        "1966238900",
        "2169198329",
        "2103503670",
        "2134061616",
        "2046153984",
        "2141877163"
    ]
},{
    "id": "1995367098",
    "title": "A Double-Inactivated Severe Acute Respiratory Syndrome Coronavirus Vaccine Provides Incomplete Protection in Mice and Induces Increased Eosinophilic Proinflammatory Pulmonary Response upon Challenge",
    "abstract": "Severe acute respiratory syndrome coronavirus (SARS-CoV) is an important emerging virus that is highly pathogenic in aged populations and is maintained with great diversity in zoonotic reservoirs. While a variety of vaccine platforms have shown efficacy in young-animal models and against homologous viral strains, vaccine efficacy has not been thoroughly evaluated using highly pathogenic variants that replicate the acute end stage lung disease phenotypes seen during the human epidemic. Using an adjuvanted and an unadjuvanted double-inactivated SARS-CoV (DIV) vaccine, we demonstrate an eosinophilic immunopathology in aged mice comparable to that seen in mice immunized with the SARS nucleocapsid protein, and poor protection against a nonlethal heterologous challenge. In young and 1-year-old animals, we demonstrate that adjuvanted DIV vaccine provides protection against lethal disease in young animals following homologous and heterologous challenge, although enhanced immune pathology and eosinophilia are evident following heterologous challenge. In the absence of alum, DIV vaccine performed poorly in young animals challenged with lethal homologous or heterologous strains. In contrast, DIV vaccines (both adjuvanted and unadjuvanted) performed poorly in aged-animal models. Importantly, aged animals displayed increased eosinophilic immune pathology in the lungs and were not protected against significant virus replication. These data raise significant concerns regarding DIV vaccine safety and highlight the need for additional studies of the molecular mechanisms governing DIV-induced eosinophilia and vaccine failure, especially in the more vulnerable aged-animal models of human disease.",
    "date": "2011",
    "authors": [
        "Meagan Bolles",
        "Damon Deming",
        "Kristin Michelle Long",
        "Sudhakar Agnihothram",
        "Alan Whitmore",
        "Martin T Ferris",
        "William K Funkhouser",
        "Lisa Gralinski",
        "Allison Totura",
        "Mark T Heise",
        "Ralph S Baric"
    ],
    "related_topics": [
        "Vaccine efficacy",
        "Viral Vaccine",
        "Vaccine failure"
    ],
    "citation_count": "421",
    "reference_count": "67",
    "references": [
        "2129542667",
        "2103503670",
        "2163627712",
        "1990049863",
        "2140338292",
        "2054076340",
        "1990059132",
        "96734778",
        "2095069717",
        "1972591948"
    ]
},{
    "id": "2143230291",
    "title": "Identification of Diverse Alphacoronaviruses and Genomic Characterization of a Novel Severe Acute Respiratory Syndrome-Like Coronavirus from Bats in China",
    "abstract": "Although many severe acute respiratory syndrome-like coronaviruses (SARS-like CoVs) have been identified in bats in China, Europe, and Africa, most have a genetic organization significantly distinct from human/civet SARS CoVs in the receptor-binding domain (RBD), which mediates receptor binding and determines the host spectrum, resulting in their failure to cause human infections and making them unlikely progenitors of human/civet SARS CoVs. Here, a viral metagenomic analysis of 268 bat rectal swabs collected from four counties in Yunnan Province has identified hundreds of sequences relating to alpha- and betacoronaviruses. Phylogenetic analysis based on a conserved region of the RNA-dependent RNA polymerase gene revealed that alphacoronaviruses had diversities with some obvious differences from those reported previously. Full genomic analysis of a new SARS-like CoV from Baoshan (LYRa11) showed that it was 29,805 nucleotides (nt) in length with 13 open reading frames (ORFs), sharing 91% nucleotide identity with human/civet SARS CoVs and the most recently reported SARS-like CoV Rs3367, while sharing 89% with other bat SARS-like CoVs. Notably, it showed the highest sequence identity with the S gene of SARS CoVs and Rs3367, especially in the RBD region. Antigenic analysis showed that the S1 domain of LYRa11 could be efficiently recognized by SARS-convalescent human serum, indicating that LYRa11 is a novel virus antigenically close to SARS CoV. Recombination analyses indicate that LYRa11 is likely a recombinant descended from parental lineages that had evolved into a number of bat SARS-like CoVs. Importance Although many severe acute respiratory syndrome-like coronaviruses (SARS-like CoVs) have been discovered in bats worldwide, there are significant different genic structures, particularly in the S1 domain, which are responsible for host tropism determination, between bat SARS-like CoVs and human SARS CoVs, indicating that most reported bat SARS-like CoVs are not the progenitors of human SARS CoV. We have identified diverse alphacoronaviruses and a close relative (LYRa11) to SARS CoV in bats collected in Yunnan, China. Further analysis showed that alpha- and betacoronaviruses have different circulation and transmission dynamics in bat populations. Notably, full genomic sequencing and antigenic study demonstrated that LYRa11 is phylogenetically and antigenically closely related to SARS CoV. Recombination analyses indicate that LYRa11 is a recombinant from certain bat SARS-like CoVs circulating in Yunnan Province.",
    "date": "2014",
    "authors": [
        "B. He",
        "Y. Zhang",
        "L. Xu",
        "W. Yang",
        "F. Yang",
        "Y. Feng",
        "L. Xia",
        "J. Zhou",
        "W. Zhen",
        "H. Guo",
        "H. Zhang",
        "C. Tu"
    ],
    "related_topics": [
        "Coronavirus",
        "Novel virus",
        "Host tropism"
    ],
    "citation_count": "136",
    "reference_count": "54",
    "references": [
        "2152207030",
        "2132260239",
        "2104548316",
        "1993577573",
        "1966238900",
        "2169198329",
        "2103503670",
        "2134061616",
        "2140338292",
        "2141008678"
    ]
},{
    "id": "2074618762",
    "title": "Synthetic recombinant bat SARS-like coronavirus is infectious in cultured cells and in mice",
    "abstract": "Defining prospective pathways by which zoonoses evolve and emerge as human pathogens is critical for anticipating and controlling both natural and deliberate pandemics. However, predicting tenable pathways of animal-to-human movement has been hindered by challenges in identifying reservoir species, cultivating zoonotic organisms in culture, and isolating full-length genomes for cloning and genetic studies. The ability to design and recover pathogens reconstituted from synthesized cDNAs has the potential to overcome these obstacles by allowing studies of replication and pathogenesis without identification of reservoir species or cultivation of primary isolates. Here, we report the design, synthesis, and recovery of the largest synthetic replicating life form, a 29.7-kb bat severe acute respiratory syndrome (SARS)-like coronavirus (Bat-SCoV), a likely progenitor to the SARS-CoV epidemic. To test a possible route of emergence from the noncultivable Bat-SCoV to human SARS-CoV, we designed a consensus Bat-SCoV genome and replaced the Bat-SCoV Spike receptor-binding domain (RBD) with the SARS-CoV RBD (Bat-SRBD). Bat-SRBD was infectious in cell culture and in mice and was efficiently neutralized by antibodies specific for both bat and human CoV Spike proteins. Rational design, synthesis, and recovery of hypothetical recombinant viruses can be used to investigate mechanisms of transspecies movement of zoonoses and has great potential to aid in rapid public health responses to known or predicted emerging microbial threats.",
    "date": "2008",
    "authors": [
        "Michelle M. Becker",
        "Rachel Lauren Graham",
        "Eric F. Donaldson",
        "Barry Rockx",
        "Amy C Sims",
        "Timothy Patrick Sheahan",
        "Raymond J Pickles",
        "Davide Corti",
        "Robert E. Johnston",
        "Ralph S Baric",
        "Mark R. Denison"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral replication",
        "Genome"
    ],
    "citation_count": "241",
    "reference_count": "54",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2103503670",
        "2134061616",
        "2140338292",
        "1982533785",
        "1996568337",
        "2104148197",
        "2139153938"
    ]
},{
    "id": "1963580683",
    "title": "A Mouse-Adapted SARS-Coronavirus Causes Disease and Mortality in BALB/c Mice",
    "abstract": "No single animal model for severe acute respiratory syndrome (SARS) reproduces all aspects of the human disease. Young inbred mice support SARS-coronavirus (SARS-CoV) replication in the respiratory tract and are available in sufficient numbers for statistical evaluation. They are relatively inexpensive and easily accessible, but their use in SARS research is limited because they do not develop illness following infection. Older (12- to 14-mo-old) BALB/c mice develop clinical illness and pneumonitis, but they can be hard to procure, and immune senescence complicates pathogenesis studies. We adapted the SARS-CoV (Urbani strain) by serial passage in the respiratory tract of young BALB/c mice. Fifteen passages resulted in a virus (MA15) that is lethal for mice following intranasal inoculation. Lethality is preceded by rapid and high titer viral replication in lungs, viremia, and dissemination of virus to extrapulmonary sites accompanied by lymphopenia, neutrophilia, and pathological changes in the lungs. Abundant viral antigen is extensively distributed in bronchial epithelial cells and alveolar pneumocytes, and necrotic cellular debris is present in airways and alveoli, with only mild and focal pneumonitis. These observations suggest that mice infected with MA15 die from an overwhelming viral infection with extensive, virally mediated destruction of pneumocytes and ciliated epithelial cells. The MA15 virus has six coding mutations associated with adaptation and increased virulence; when introduced into a recombinant SARS-CoV, these mutations result in a highly virulent and lethal virus (rMA15), duplicating the phenotype of the biologically derived MA15 virus. Intranasal inoculation with MA15 reproduces many aspects of disease seen in severe human cases of SARS. The availability of the MA15 virus will enhance the use of the mouse model for SARS because infection with MA15 causes morbidity, mortality, and pulmonary pathology. This virus will be of value as a stringent challenge in evaluation of the efficacy of vaccines and antivirals.",
    "date": "2007",
    "authors": [
        "Anjeanette Roberts",
        "Damon Deming",
        "Christopher D. Paddock",
        "Aaron Cheng",
        "Boyd Yount",
        "Leatrice Vogel",
        "Brian D. Herman",
        "Timothy Patrick Sheahan",
        "Mark T Heise",
        "Gillian L. Genrich",
        "Sherif R. Zaki",
        "Ralph S Baric",
        "Kanta Subbarao"
    ],
    "related_topics": [
        "Serial passage",
        "Virus",
        "BALB/c"
    ],
    "citation_count": "369",
    "reference_count": "38",
    "references": [
        "2025170735",
        "2131262274",
        "2116586125",
        "2103503670",
        "1982533785",
        "2038918691",
        "2130450914",
        "96734778",
        "2171157147",
        "2171291163"
    ]
},{
    "id": "2098037373",
    "title": "Receptor recognition and cross-species infections of SARS coronavirus.",
    "abstract": "Receptor recognition is a major determinant of the host range, cross-species infections, and pathogenesis of the severe acute respiratory syndrome coronavirus (SARS-CoV). A defined receptor-binding domain (RBD) in the SARS-CoV spike protein specifically recognizes its host receptor, angiotensin-converting enzyme 2 (ACE2). This article reviews the latest knowledge about how RBDs from different SARS-CoV strains interact with ACE2 from several animal species. Detailed research on these RBD/ACE2 interactions has established important principles on host receptor adaptations, cross-species infections, and future evolution of SARS-CoV. These principles may apply to other emerging animal viruses, including the recently emerged Middle East respiratory syndrome coronavirus (MERS-CoV). This paper forms part of a series of invited articles in Antiviral Research on \u201cFrom SARS to MERS: 10 years of research on highly pathogenic human coronaviruses\u201d.",
    "date": "2013",
    "authors": [
        "Fang Li"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Middle East respiratory syndrome"
    ],
    "citation_count": "217",
    "reference_count": "72",
    "references": [
        "2166867592",
        "2104548316",
        "2025170735",
        "2131262274",
        "2119111857",
        "2112147913",
        "1966238900",
        "2169198329",
        "2103503670",
        "2134061616"
    ]
},{
    "id": "1998383538",
    "title": "An efficient method to make human monoclonal antibodies from memory B cells: potent neutralization of SARS coronavirus",
    "abstract": "Passive serotherapy can confer immediate protection against microbial infection, but methods to rapidly generate human neutralizing monoclonal antibodies are not yet available. We have developed an improved method for Epstein-Barr virus transformation of human B cells. We used this method to analyze the memory repertoire of a patient who recovered from severe acute respiratory syndrome coronavirus (SARS-CoV) infection and to isolate monoclonal antibodies specific for different viral proteins, including 35 antibodies with in vitro neutralizing activity ranging from 10(-8)M to 10(-11)M. One such antibody confers protection in vivo in a mouse model of SARS-CoV infection. These results show that it is possible to interrogate the memory repertoire of immune donors to rapidly and efficiently isolate neutralizing antibodies that have been selected in the course of natural infection.",
    "date": "2004",
    "authors": [
        "Elisabetta Traggiai",
        "Stephan Becker",
        "Kanta Subbarao",
        "Larissa Kolesnikova",
        "Yasushi Uematsu",
        "Maria Rita Gismondo",
        "Brian R Murphy",
        "Rino Rappuoli",
        "Antonio Lanzavecchia"
    ],
    "related_topics": [
        "Monoclonal antibody",
        "Coronavirus",
        "Immunization"
    ],
    "citation_count": "758",
    "reference_count": "30",
    "references": [
        "2132260239",
        "2104548316",
        "2131262274",
        "2100820722",
        "2116586125",
        "1990049863",
        "1976741900",
        "2030522563",
        "2116458521",
        "2171157147"
    ]
},{
    "id": "2405185968",
    "title": "Kinetics of Serologic Responses to MERS Coronavirus Infection in Humans, South Korea.",
    "abstract": "We investigated the kinetics of serologic responses to Middle East respiratory syndrome coronavirus (MERS-CoV) infection by using virus neutralization and MERS-CoV S1 IgG ELISA tests. In most patients, robust antibody responses developed by the third week of illness. Delayed antibody responses with the neutralization test were associated with more severe disease.",
    "date": "2015",
    "authors": [
        "Wan Beom Park",
        "Ranawaka A.P.M. Perera",
        "Pyoeng Gyun Choe",
        "Eric H.Y. Lau",
        "Seong Jin Choi",
        "June Young Chun",
        "Hong Sang Oh",
        "Kyoung-Ho Song",
        "Ji Hwan Bang",
        "Eu Suk Kim",
        "Hong Bin Kim",
        "Sang Won Park",
        "Nam Joong Kim",
        "Leo Lit Man Poon",
        "Malik Peiris",
        "Myoung-don Oh"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Middle East respiratory syndrome"
    ],
    "citation_count": "135",
    "reference_count": "9",
    "references": [
        "2108756402",
        "2087762289",
        "2135926866",
        "2115056955",
        "1488467349",
        "2318113373",
        "2009478017",
        "2172621419",
        "2065307239"
    ]
},{
    "id": "2134527559",
    "title": "Middle East Respiratory Syndrome Coronavirus Superspreading Event Involving 81 Persons, Korea 2015",
    "abstract": "Since the first imported case of Middle East respiratory syndrome coronavirus (MERS-CoV) infection was reported on May 20, 2015 in Korea, there have been 186 laboratory-confirmed cases of MERS-CoV infection with 36 fatalities. Ninety-seven percent (181/186) of the cases had exposure to the health care facilities. We are reporting a superspreading event that transmitted MERS-CoV to 81 persons at a hospital emergency room (ER) during the Korean outbreak in 2015. The index case was a 35-yr-old man who had vigorous coughing while staying at the ER for 58 hr. As in severe acute respiratory syndrome outbreaks, superspreading events can cause a large outbreak of MERS in healthcare facilities with severe consequences. All healthcare facilities should establish and implement infection prevention and control measure as well as triage policies and procedures for early detection and isolation of suspected MERS-CoV cases.",
    "date": "2015",
    "authors": [
        "Myoung Don Oh",
        "Pyoeng Gyun Choe",
        "Hong Sang Oh",
        "Wan Beom Park",
        "Sang Min Lee",
        "Jinkyeong Park",
        "Sang Kook Lee",
        "Jeong Sup Song",
        "Nam Joong Kim"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Infection control",
        "Isolation (health care)"
    ],
    "citation_count": "78",
    "reference_count": "17",
    "references": [
        "2107053896",
        "2100820722",
        "2069251911",
        "2119775949",
        "2130227690",
        "1965186841",
        "1042757214",
        "2098397474",
        "2153511427",
        "2121671559"
    ]
},{
    "id": "1947409115",
    "title": "Middle East Respiratory Syndrome Coronavirus Efficiently Infects Human Primary T Lymphocytes and Activates the Extrinsic and Intrinsic Apoptosis Pathways",
    "abstract": "Middle East respiratory syndrome (MERS) is associated with a mortality rate of >35%. We previously showed that MERS coronavirus (MERS-CoV) could infect human macrophages and dendritic cells and induce cytokine dysregulation. Here, we further investigated the interplay between human primary T cells and MERS-CoV in disease pathogenesis. Importantly, our results suggested that MERS-CoV efficiently infected T cells from the peripheral blood and from human lymphoid organs, including the spleen and the tonsil. We further demonstrated that MERS-CoV infection induced apoptosis in T cells, which involved the activation of both the extrinsic and intrinsic apoptosis pathways. Remarkably, immunostaining of spleen sections from MERS-CoV-infected common marmosets demonstrated the presence of viral nucleoprotein in their CD3(+) T cells. Overall, our results suggested that the unusual capacity of MERS-CoV to infect T cells and induce apoptosis might partly contribute to the high pathogenicity of the virus.",
    "date": "2016",
    "authors": [
        "Hin Chu",
        "Jie Zhou",
        "Bosco Ho-Yin Wong",
        "Cun Li",
        "Jasper Fuk-Woo Chan",
        "Zhong-Shan Cheng",
        "Dong Yang",
        "Dong Wang",
        "Andrew Chak-Yiu Lee",
        "Chuangen Li",
        "Man-Lung Yeung",
        "Jian-Piao Cai",
        "Ivy Hau-Yee Chan",
        "Wai-Kuen Ho",
        "Kelvin Kai-Wang To",
        "Bo-Jian Zheng",
        "Yanfeng Yao",
        "Chuan Qin",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Intrinsic apoptosis",
        "T lymphocyte",
        "Cytokine"
    ],
    "citation_count": "307",
    "reference_count": "50",
    "references": [
        "2166867592",
        "2132260239",
        "2025170735",
        "2006434809",
        "2008757142",
        "2119111857",
        "2138302361",
        "2115555188",
        "1977050884",
        "1690366459"
    ]
},{
    "id": "2017248106",
    "title": "Broad-spectrum antivirals for the emerging Middle East respiratory syndrome coronavirus.",
    "abstract": "Summary Objectives Middle East respiratory syndrome coronavirus (MERS-CoV) has emerged to cause fatal infections in patients in the Middle East and traveler-associated secondary cases in Europe and Africa. Person-to-person transmission is evident in outbreaks involving household and hospital contacts. Effective antivirals are urgently needed. Methods We used small compound-based forward chemical genetics to screen a chemical library of 1280 known drugs against influenza A virus in Biosafety Level-2 laboratory. We then assessed the anti-MERS-CoV activities of the identified compounds and of interferons, nelfinavir, and lopinavir because of their reported anti-coronavirus activities in terms of cytopathic effect inhibition, viral yield reduction, and plaque reduction assays in Biosafety Level-3 laboratory. Results Ten compounds were identified as primary hits in high-throughput screening. Only mycophenolic acid exhibited low EC 50 and high selectivity index. Additionally, ribavirin and interferons also exhibited in-vitro anti-MERS-CoV activity. The serum concentrations achievable at therapeutic doses of mycophenolic acid and interferon-\u03b21b were 60\u2013300 and 3\u20134 times higher than the concentrations at which in-vitro anti-MERS-CoV activities were demonstrated, whereas that of ribavirin was \u223c2 times lower. Combination of mycophenolic acid and interferon-\u03b21b lowered the EC 50 of each drug by 1\u20133 times. Conclusions Interferon-\u03b21b with mycophenolic acid should be considered in treatment trials of MERS.",
    "date": "2013",
    "authors": [
        "Jasper F.W. Chan",
        "Kwok Hung Chan",
        "Richard Y.T. Kao",
        "Kelvin K.W. To",
        "Bo Jian Zheng",
        "Clara P.Y. Li",
        "Patrick T.W. Li",
        "Jun Dai",
        "Florence K.Y. Mok",
        "Honglin Chen",
        "Frederick G. Hayden",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Nelfinavir"
    ],
    "citation_count": "337",
    "reference_count": "73",
    "references": [
        "2166867592",
        "2107053896",
        "2006434809",
        "2119111857",
        "2112147913",
        "2160011624",
        "2045002682",
        "2105226322",
        "2113457186",
        "2140143765"
    ]
},{
    "id": "2078121682",
    "title": "Rapid generation of a mouse model for Middle East respiratory syndrome",
    "abstract": "In this era of continued emergence of zoonotic virus infections, the rapid development of rodent models represents a critical barrier to public health preparedness, including the testing of antivirus therapy and vaccines. The Middle East respiratory syndrome coronavirus (MERS-CoV) was recently identified as the causative agent of a severe pneumonia. Given the ability of coronavirus to rapidly adapt to new hosts, a major public health concern is that MERS-CoV will further adapt to replication in humans, triggering a pandemic. No small-animal model for this infection is currently available, but studies suggest that virus entry factors can confer virus susceptibility. Here, we show that mice were sensitized to MERS-CoV infection by prior transduction with adenoviral vectors expressing the human host-cell receptor dipeptidyl peptidase 4. Mice developed a pneumonia characterized by extensive inflammatory-cell infiltration with virus clearance occurring 6\u20138 d after infection. Clinical disease and histopathological changes were more severe in the absence of type-I IFN signaling whereas the T-cell response was required for virus clearance. Using these mice, we demonstrated the efficacy of a therapeutic intervention (poly I:C) and a potential vaccine [Venezuelan equine encephalitis replicon particles expressing MERS-CoV spike protein]. We also found little protective cross-reactivity between MERS-CoV and the severe acute respiratory syndrome-CoV. Our results demonstrate that this system will be useful for MERS-CoV studies and for the rapid development of relevant animal models for emerging respiratory viral infections.",
    "date": "2014",
    "authors": [
        "Jincun Zhao",
        "Kun Li",
        "Christine Wohlford-Lenane",
        "Sudhakar S. Agnihothram",
        "Craig Fett",
        "Jingxian Zhao",
        "Michael J. Gale",
        "Ralph S. Baric",
        "Luis Enjuanes",
        "Tom Gallagher",
        "Paul B. McCray",
        "Stanley Perlman"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "385",
    "reference_count": "42",
    "references": [
        "2166867592",
        "2107053896",
        "2006434809",
        "2119111857",
        "2103503670",
        "2113457186",
        "2046153984",
        "2034462612",
        "2126707939",
        "2070597700"
    ]
},{
    "id": "2096238447",
    "title": "Convalescent plasma treatment reduced mortality in patients with severe pandemic influenza A (H1N1) 2009 virus infection",
    "abstract": "Background: Experience from treating patients with Spanish influenza and influenza A(H5N1) suggested that convalescent plasma therapy might be beneficial. However, its efficacy in patients with severe pandemic influenza A(H1N1) 2009 virus (H1N1 2009) infection remained unknown. Methods: During the period from 1 September 2009 through 30 June 2010, we conducted a prospective cohort study by recruiting patients aged \u2265 18 years with severe H1N1 2009 infection requiring intensive care. Patients were offered treatment with convalescent plasma with a neutralizing antibody titer of \u2265 1:160, harvested by apheresis from patients recovering from H1N1 2009 infection. Clinical outcome was compared with that of patients who declined plasma treatment as the untreated controls. Results: Ninety-three patients with severe H1N1 2009 infection requiring intensive care were recruited. Twenty patients (21.5%) received plasma treatment. The treatment and control groups were matched by age, sex, and disease severity scores. Mortality in the treatment group was significantly lower than in the nontreatment group (20.0% vs 54.8%; P = .01). Multivariate analysis showed that plasma treatment reduced mortality (odds ratio [OR], .20; 95% confidence interval [CI], .06-.69; P = .011), whereas complication of acute renal failure was independently associated with death (OR, 3.79; 95% CI, 1.15-12.4; P = .028). Subgroup analysis of 44 patients with serial respiratory tract viral load and cytokine level demonstrated that plasma treatment was associated with significantly lower day 3, 5, and 7 viral load, compared with the control group (P < .05). The corresponding temporal levels of interleukin 6, interleukin 10, and tumor necrosis factor \u03b1 (P < .05) were also lower in the treatment group. Conclusions: Treatment of severe H1N1 2009 infection with convalescent plasma reduced respiratory tract viral load, serum cytokine response, and mortality.",
    "date": "2011",
    "authors": [
        "Ivan Fn Hung",
        "Kelvin Kw To",
        "Cheuk-Kwong Lee",
        "Kar-Lung Lee",
        "Kenny Chan",
        "Wing-Wah Yan",
        "Raymond Liu",
        "Chi-Leung Watt",
        "Wai-Ming Chan",
        "Kang-Yiu Lai",
        "Chi-Kwan Koo",
        "Tom Buckley",
        "Fu-Loi Chow",
        "Kwan-Keung Wong",
        "Hok-Sum Chan",
        "Chi-Keung Ching",
        "Bone Sf Tang",
        "Candy Cy Lau",
        "Iris Ws Li",
        "Shao-Haei Liu",
        "Kwok-Hung Chan",
        "Che-Kit Lin",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Viral load",
        "Intensive care",
        "Influenza A virus"
    ],
    "citation_count": "591",
    "reference_count": "37",
    "references": [
        "2112166111",
        "1987783718",
        "2068592034",
        "1486394209",
        "2137673012",
        "2149729472",
        "1982137128",
        "2097158347",
        "2133701960",
        "2101172433"
    ]
},{
    "id": "2160011624",
    "title": "Middle East respiratory syndrome coronavirus neutralising serum antibodies in dromedary camels: a comparative serological study",
    "abstract": "Summary Background A new betacoronavirus\u2014Middle East respiratory syndrome coronavirus (MERS-CoV)\u2014has been identified in patients with severe acute respiratory infection. Although related viruses infect bats, molecular clock analyses have been unable to identify direct ancestors of MERS-CoV. Anecdotal exposure histories suggest that patients had been in contact with dromedary camels or goats. We investigated possible animal reservoirs of MERS-CoV by assessing specific serum antibodies in livestock. Methods We took sera from animals in the Middle East (Oman) and from elsewhere (Spain, Netherlands, Chile). Cattle (n=80), sheep (n=40), goats (n=40), dromedary camels (n=155), and various other camelid species (n=34) were tested for specific serum IgG by protein microarray using the receptor-binding S1 subunits of spike proteins of MERS-CoV, severe acute respiratory syndrome coronavirus, and human coronavirus OC43. Results were confirmed by virus neutralisation tests for MERS-CoV and bovine coronavirus. Findings 50 of 50 (100%) sera from Omani camels and 15 of 105 (14%) from Spanish camels had protein-specific antibodies against MERS-CoV spike. Sera from European sheep, goats, cattle, and other camelids had no such antibodies. MERS-CoV neutralising antibody titres varied between 1/320 and 1/2560 for the Omani camel sera and between 1/20 and 1/320 for the Spanish camel sera. There was no evidence for cross-neutralisation by bovine coronavirus antibodies. Interpretation MERS-CoV or a related virus has infected camel populations. Both titres and seroprevalences in sera from different locations in Oman suggest widespread infection. Funding European Union, European Centre For Disease Prevention and Control, Deutsche Forschungsgemeinschaft.",
    "date": "2013",
    "authors": [
        "Chantal B.E.M. Reusken",
        "Bart L. Haagmans",
        "Marcel A. M\u00fcller",
        "Carlos Gutierrez",
        "Gert Jan Godeke",
        "Benjamin Meyer",
        "Doreen Muth",
        "V. Stalin Raj",
        "Laura Smits De Vries",
        "Victor M. Corman",
        "Jan Felix Drexler",
        "Saskia L. Smits",
        "Yasmin E. El Tahir",
        "Rita De Sousa",
        "Janko van Beek",
        "Norbert Nowotny",
        "Kees van Maanen",
        "Ezequiel Hidalgo-Hermoso",
        "Berend Jan Bosch",
        "Peter Rottier",
        "Albert Osterhaus",
        "Christian Gort\u00e1zar-Schmidt",
        "Christian Drosten",
        "Marion P.G. Koopmans"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Human coronavirus OC43",
        "Camelid"
    ],
    "citation_count": "737",
    "reference_count": "36",
    "references": [
        "2107053896",
        "2119111857",
        "2045002682",
        "1852588318",
        "2140143765",
        "2140338292",
        "2130227690",
        "2066347985",
        "2100776472",
        "2105558355"
    ]
},{
    "id": "2145441153",
    "title": "Middle East respiratory syndrome coronavirus in dromedary camels: An outbreak investigation",
    "abstract": "Summary Background Middle East respiratory syndrome coronavirus (MERS-CoV) causes severe lower respiratory tract infection in people. Previous studies suggested dromedary camels were a reservoir for this virus. We tested for the presence of MERS-CoV in dromedary camels from a farm in Qatar linked to two human cases of the infection in October, 2013. Methods We took nose swabs, rectal swabs, and blood samples from all camels on the Qatari farm. We tested swabs with RT-PCR, with amplification targeting the E gene (upE), nucleocapsid ( N ) gene, and open reading frame (ORF) 1a. PCR positive samples were tested by different MERS-CoV specific PCRs and obtained sequences were used for phylogentic analysis together with sequences from the linked human cases and other human cases. We tested serum samples from the camels for IgG immunofluorescence assay, protein microarray, and virus neutralisation assay. Findings We obtained samples from 14 camels on Oct 17, 2013. We detected MERS-CoV in nose swabs from three camels by three independent RT-PCRs and sequencing. The nucleotide sequence of an ORF1a fragment (940 nucleotides) and a 4\u00b72 kb concatenated fragment were very similar to the MERS-CoV from two human cases on the same farm and a MERS-CoV isolate from Hafr-Al-Batin. Eight additional camel nose swabs were positive on one or more RT-PCRs, but could not be confirmed by sequencing. All camels had MERS-CoV spike-binding antibodies that correlated well with the presence of neutralising antibodies to MERS-CoV. Interpretation Our study provides virological confirmation of MERS-CoV in camels and suggests a recent outbreak affecting both human beings and camels. We cannot conclude whether the people on the farm were infected by the camels or vice versa, or if a third source was responsible. Funding European Union projects EMPERIE (contract number 223498), ANTIGONE (contract number 278976), and the VIRGO consortium.",
    "date": "2014",
    "authors": [
        "Bart L. Haagmans",
        "Said H.S. Al Dhahiry",
        "Chantal B.E.M. Reusken",
        "V. Stalin Raj",
        "Monica Galiano",
        "Richard Myers",
        "Gert Jan Godeke",
        "Marcel Jonges",
        "Elmoubasher Farag",
        "Ayman Diab",
        "Hazem Ghobashy",
        "Farhoud Alhajri",
        "Mohamed Al-Thani",
        "Salih A. Al-Marri",
        "Hamad E. Al Romaihi",
        "Abdullatif Al Khal",
        "Alison Bermingham",
        "Albert D.M.E. Osterhaus",
        "Mohd M. AlHajri",
        "Marion P.G. Koopmans"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "European union",
        "Outbreak"
    ],
    "citation_count": "650",
    "reference_count": "20",
    "references": [
        "1703839189",
        "2149531726",
        "2160011624",
        "2045002682",
        "1852588318",
        "2140143765",
        "2066347985",
        "2049975503",
        "3021832855",
        "2031705962"
    ]
},{
    "id": "2128886090",
    "title": "Global, regional, and national incidence and mortality for HIV, tuberculosis, and malaria during 1990???2013: a systematic analysis for the Global Burden of Disease Study 2013",
    "abstract": "Summary Background The Millennium Declaration in 2000 brought special global attention to HIV, tuberculosis, and malaria through the formulation of Millennium Development Goal (MDG) 6. The Global Burden of Disease 2013 study provides a consistent and comprehensive approach to disease estimation for between 1990 and 2013, and an opportunity to assess whether accelerated progress has occured since the Millennium Declaration. Methods To estimate incidence and mortality for HIV, we used the UNAIDS Spectrum model appropriately modified based on a systematic review of available studies of mortality with and without antiretroviral therapy (ART). For concentrated epidemics, we calibrated Spectrum models to fit vital registration data corrected for misclassification of HIV deaths. In generalised epidemics, we minimised a loss function to select epidemic curves most consistent with prevalence data and demographic data for all-cause mortality. We analysed counterfactual scenarios for HIV to assess years of life saved through prevention of mother-to-child transmission (PMTCT) and ART. For tuberculosis, we analysed vital registration and verbal autopsy data to estimate mortality using cause of death ensemble modelling. We analysed data for corrected case-notifications, expert opinions on the case-detection rate, prevalence surveys, and estimated cause-specific mortality using Bayesian meta-regression to generate consistent trends in all parameters. We analysed malaria mortality and incidence using an updated cause of death database, a systematic analysis of verbal autopsy validation studies for malaria, and recent studies (2010\u201313) of incidence, drug resistance, and coverage of insecticide-treated bednets. Findings Globally in 2013, there were 1\u00b78 million new HIV infections (95% uncertainty interval 1\u00b77 million to 2\u00b71 million), 29\u00b72 million prevalent HIV cases (28\u00b71 to 31\u00b77), and 1\u00b73 million HIV deaths (1\u00b73 to 1\u00b75). At the peak of the epidemic in 2005, HIV caused 1\u00b77 million deaths (1\u00b76 million to 1\u00b79 million). Concentrated epidemics in Latin America and eastern Europe are substantially smaller than previously estimated. Through interventions including PMTCT and ART, 19\u00b71 million life-years (16\u00b76 million to 21\u00b75 million) have been saved, 70\u00b73% (65\u00b74 to 76\u00b71) in developing countries. From 2000 to 2011, the ratio of development assistance for health for HIV to years of life saved through intervention was US$4498 in developing countries. Including in HIV-positive individuals, all-form tuberculosis incidence was 7\u00b75 million (7\u00b74 million to 7\u00b77 million), prevalence was 11\u00b79 million (11\u00b76 million to 12\u00b72 million), and number of deaths was 1\u00b74 million (1\u00b73 million to 1\u00b75 million) in 2013. In the same year and in only individuals who were HIV-negative, all-form tuberculosis incidence was 7\u00b71 million (6\u00b79 million to 7\u00b73 million), prevalence was 11\u00b72 million (10\u00b78 million to 11\u00b76 million), and number of deaths was 1\u00b73 million (1\u00b72 million to 1\u00b74 million). Annualised rates of change (ARC) for incidence, prevalence, and death became negative after 2000. Tuberculosis in HIV-negative individuals disproportionately occurs in men and boys (versus women and girls); 64\u00b70% of cases (63\u00b76 to 64\u00b73) and 64\u00b77% of deaths (60\u00b78 to 70\u00b73). Globally, malaria cases and deaths grew rapidly from 1990 reaching a peak of 232 million cases (143 million to 387 million) in 2003 and 1\u00b72 million deaths (1\u00b71 million to 1\u00b74 million) in 2004. Since 2004, child deaths from malaria in sub-Saharan Africa have decreased by 31\u00b75% (15\u00b77 to 44\u00b71). Outside of Africa, malaria mortality has been steadily decreasing since 1990. Interpretation Our estimates of the number of people living with HIV are 18\u00b77% smaller than UNAIDS's estimates in 2012. The number of people living with malaria is larger than estimated by WHO. Incidence rates for HIV, tuberculosis, and malaria have all decreased since 2000. At the global level, upward trends for malaria and HIV deaths have been reversed and declines in tuberculosis deaths have accelerated. 101 countries (74 of which are developing) still have increasing HIV incidence. Substantial progress since the Millennium Declaration is an encouraging sign of the effect of global action. Funding Bill & Melinda Gates Foundation.",
    "date": "2014",
    "authors": [
        "Christopher J.L. Murray",
        "Katrina F. Ortblad",
        "Caterina Guinovart",
        "Stephen S. Lim",
        "Timothy M. Wolock",
        "D. Allen Roberts",
        "Emily A. Dansereau",
        "Nicholas Graetz",
        "Ryan M. Barber",
        "Jonathan C. Brown",
        "Haidong Wang",
        "Herbert C. Duber",
        "Mohsen Naghavi",
        "Daniel Dicker",
        "Lalit Dandona",
        "Joshua A. Salomon",
        "Kyle R. Heuton",
        "Kyle Foreman",
        "David E. Phillips",
        "Thomas D. Fleming",
        "Abraham D. Flaxman",
        "Bryan K. Phillips",
        "Elizabeth K. Johnson",
        "Megan S. Coggeshall",
        "Foad Abd-Allah",
        "Semaw Ferede Abera",
        "Jerry P. Abraham",
        "Ibrahim Abubakar",
        "Laith J. Abu-Raddad",
        "Niveen Me Abu-Rmeileh",
        "Tom Achoki",
        "Austine Olufemi Adeyemo",
        "Ars\u00e8ne Kouablan Adou",
        "Jos\u00e9 C. Adsuar",
        "Emilie Elisabet Agardh",
        "Dickens Akena",
        "Mazin J. Al Kahbouri",
        "Deena Alasfoor",
        "Mohammed I. Albittar",
        "Gabriel Alcal\u00e1-Cerra",
        "Miguel Angel Alegretti",
        "Zewdie Aderaw Alemu",
        "Rafael Alfonso-Cristancho",
        "Samia Alhabib",
        "Raghib Ali",
        "Francois Alla",
        "Peter J. Allen",
        "Ubai Alsharif",
        "Elena Alvarez",
        "Nelson Alvis-Guzman"
    ],
    "related_topics": [
        "Verbal autopsy",
        "Global health",
        "Cost effectiveness"
    ],
    "citation_count": "1,069",
    "reference_count": "136",
    "references": [
        "2125065061",
        "2110052313",
        "2097950056",
        "2108344016",
        "2119259412",
        "2151768324",
        "2788073857",
        "2094333691",
        "2029036450",
        "2080220969"
    ]
},{
    "id": "2108756402",
    "title": "Transmission of MERS-Coronavirus in Household Contacts",
    "abstract": "BACKGROUND: Strategies to contain the Middle East respiratory syndrome coronavirus (MERS-CoV) depend on knowledge of the rate of human-to-human transmission, including subclinical infections. A lack of serologic tools has hindered targeted studies of transmission. METHODS: We studied 26 index patients with MERS-CoV infection and their 280 household contacts. The median time from the onset of symptoms in index patients to the latest blood sampling in contact patients was 17.5 days (range, 5 to 216; mean, 34.4). Probable cases of secondary transmission were identified on the basis of reactivity in two reverse-transcriptase-polymerase-chain-reaction (RT-PCR) assays with independent RNA extraction from throat swabs or reactivity on enzyme-linked immunosorbent assay against MERS-CoV S1 antigen, supported by reactivity on recombinant S-protein immunofluorescence and demonstration of neutralization of more than 50% of the infectious virus seed dose on plaque-reduction neutralization testing. RESULTS: Among the 280 household contacts of the 26 index patients, there were 12 probable cases of secondary transmission (4%; 95% confidence interval, 2 to 7). Of these cases, 7 were identified by means of RT-PCR, all in samples obtained within 14 days after the onset of symptoms in index patients, and 5 were identified by means of serologic analysis, all in samples obtained 13 days or more after symptom onset in index patients. Probable cases of secondary transmission occurred in 6 of 26 clusters (23%). Serologic results in contacts who were sampled 13 days or more after exposure were similar to overall study results for combined RT-PCR and serologic testing. CONCLUSIONS: The rate of secondary transmission among household contacts of patients with MERS-CoV infection has been approximately 5%. Our data provide insight into the rate of subclinical transmission of MERS-CoV in the home.",
    "date": "2014",
    "authors": [
        "Christian Drosten",
        "Benjamin Meyer",
        "Marcel A. M\u00fcller",
        "Victor M. Corman",
        "Malak Al-Masri",
        "Raheela Hossain",
        "Hosam Madani",
        "Andrea Sieberg",
        "Berend Jan Bosch",
        "Erik Lattwein",
        "Raafat F. Alhakeem",
        "Abdullah M. Assiri",
        "Waleed Hajomar",
        "Ali M. Albarrak",
        "Jaffar A. Al-Tawfiq",
        "Alimuddin I. Zumla",
        "Ziad A. Memish"
    ],
    "related_topics": [
        "Blood sampling",
        "Subclinical infection",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "377",
    "reference_count": "22",
    "references": [
        "2166867592",
        "2132260239",
        "2107053896",
        "1703839189",
        "2119111857",
        "2160011624",
        "1852588318",
        "2140143765",
        "1968393246",
        "2130227690"
    ]
},{
    "id": "2130227690",
    "title": "Interhuman transmissibility of Middle East respiratory syndrome coronavirus: estimation of pandemic risk",
    "abstract": "Summary Background The new Middle East respiratory syndrome coronavirus (MERS-CoV) infection shares many clinical, epidemiological, and virological similarities with that of severe acute respiratory syndrome (SARS)-CoV. We aimed to estimate virus transmissibility and the epidemic potential of MERS-CoV, and to compare the results with similar findings obtained for prepandemic SARS. Methods We retrieved data for MERS-CoV clusters from the WHO summary and subsequent reports, and published descriptions of cases, and took into account 55 of the 64 laboratory-confirmed cases of MERS-CoV reported as of June 21, 2013, excluding cases notified in the previous 2 weeks. To assess the interhuman transmissibility of MERS-CoV, we used Bayesian analysis to estimate the basic reproduction number (R 0 ) and compared it to that of prepandemic SARS. We considered two scenarios, depending on the interpretation of the MERS-CoV cluster-size data. Results With our most pessimistic scenario (scenario 2), we estimated MERS-CoV R 0 to be 0\u00b769 (95% CI 0\u00b750\u20130\u00b792); by contrast, the R 0 for prepandemic SARS-CoV was 0\u00b780 (0\u00b754\u20131\u00b713). Our optimistic scenario (scenario 1) yielded a MERS-CoV R 0 of 0\u00b760 (0\u00b742\u20130\u00b780). Because of recent implementation of effective contact tracing and isolation procedures, further MERS-CoV transmission data might no longer describe an entire cluster, but only secondary infections directly caused by the index patient. Hence, we calculated that, under scenario 2, eight or more secondary infections caused by the next index patient would translate into a 5% or higher chance that the revised MERS-CoV R 0 would exceed 1\u2014ie, that MERS-CoV might have pandemic potential. Interpretation Our analysis suggests that MERS-CoV does not yet have pandemic potential. We recommend enhanced surveillance, active contact tracing, and vigorous searches for the MERS-CoV animal hosts and transmission routes to human beings. Funding Agence Nationale de la Recherche (Labex Integrative Biology of Emerging Infectious Diseases), and the European Community's Seventh Framework Programme project PREDEMICS.",
    "date": "2013",
    "authors": [
        "Romulus Breban",
        "Julien Riou",
        "Arnaud Fontanet"
    ],
    "related_topics": [
        "Secondary infection",
        "Contact tracing",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "401",
    "reference_count": "24",
    "references": [
        "2166867592",
        "2107053896",
        "2119111857",
        "2045002682",
        "2113457186",
        "2046153984",
        "2140143765",
        "2141877163",
        "2119775949",
        "2126707939"
    ]
},{
    "id": "2115102869",
    "title": "Emergence of Zaire Ebola Virus Disease in Guinea",
    "abstract": "In March 2014, the World Health Organization was notified of an outbreak of a communicable disease characterized by fever, severe diarrhea, vomiting, and a high fatality rate in Guinea. Virologic investigation identified Zaire ebolavirus (EBOV) as the causative agent. Full-length genome sequencing and phylogenetic analysis showed that EBOV from Guinea forms a separate clade in relationship to the known EBOV strains from the Democratic Republic of Congo and Gabon. Epidemiologic investigation linked the laboratory-confirmed cases with the presumed first fatality of the outbreak in December 2013. This study demonstrates the emergence of a new EBOV strain in Guinea.",
    "date": "2014",
    "authors": [
        "Sylvain Baize",
        "Delphine Pannetier",
        "Lisa Oestereich",
        "Toni Rieger",
        "Lamine Koivogui",
        "Barr\u00e8 Soropogui",
        "Mamadou Saliou Sow",
        "Sakoba Ke\u00efta",
        "Hilde De Clerck",
        "Amanda Tiffany",
        "Gemma Dominguez",
        "Mathieu Loua",
        "Alexis Traor\u00e9",
        "Moussa Koli\u00e9",
        "Emmanuel Roland Malano",
        "Emmanuel Heleze",
        "Anne Bocquin",
        "Stephane M\u00e9ly",
        "Herv\u00e9 Raoul",
        "Val\u00e9rie Caro",
        "D\u00e1niel Cadar",
        "Martin Gabriel",
        "Meike Pahlmann",
        "Dennis Tappe",
        "Jonas Schmidt-Chanasit",
        "Benido Impouma",
        "Abdoul Karim Diallo",
        "Michel Van Herp",
        "Stephan G\u00fcnther"
    ],
    "related_topics": [
        "Zaire ebolavirus",
        "Ebola virus",
        "Ebolavirus"
    ],
    "citation_count": "1,656",
    "reference_count": "19",
    "references": [
        "2146058063",
        "2111211467",
        "1969042907",
        "2102286438",
        "1982754464",
        "2112006002",
        "2141568825",
        "2086645334",
        "2005407070",
        "2117415699"
    ]
},{
    "id": "1975375203",
    "title": "Genomic surveillance elucidates Ebola virus origin and transmission during the 2014 outbreak",
    "abstract": "In its largest outbreak, Ebola virus disease is spreading through Guinea, Liberia, Sierra Leone, and Nigeria. We sequenced 99 Ebola virus genomes from 78 patients in Sierra Leone to ~2000\u00d7 coverage. We observed a rapid accumulation of interhost and intrahost genetic variation, allowing us to characterize patterns of viral transmission over the initial weeks of the epidemic. This West African variant likely diverged from central African lineages around 2004, crossed from Guinea to Sierra Leone in May 2014, and has exhibited sustained human-to-human transmission subsequently, with no evidence of additional zoonotic sources. Because many of the mutations alter protein sequences and other biologically meaningful targets, they should be monitored for impact on diagnostics, vaccines, and therapies critical to outbreak response.",
    "date": "2014",
    "authors": [
        "Stephen K. Gire",
        "Augustine Goba",
        "Kristian G. Andersen",
        "Rachel S G Sealfon",
        "Daniel J. Park",
        "Lansana Kanneh",
        "Simbirie Jalloh",
        "Mambu Momoh",
        "Mohamed Fullah",
        "Gytis Dudas",
        "Shirlee Wohl",
        "Lina M. Moses",
        "Nathan L. Yozwiak",
        "Sarah Winnicki",
        "Christian B. Matranga",
        "Christine M. Malboeuf",
        "James Qu",
        "Adrianne D. Gladden",
        "Stephen F. Schaffner",
        "Xiao Yang",
        "Pan Pan Jiang",
        "Mahan Nekoui",
        "Andres Colubri",
        "Moinya Ruth Coomber",
        "Mbalu Fonnie",
        "Alex Moigboi",
        "Michael Gbakie",
        "Fatima K. Kamara",
        "Veronica Tucker",
        "Edwin Konuwa",
        "Sidiki Saffa",
        "Josephine Sellu",
        "Abdul Azziz Jalloh",
        "Alice Kovoma",
        "James Koninga",
        "Ibrahim Mustapha",
        "Kandeh Kargbo",
        "Momoh Foday",
        "Mohamed Yillah",
        "Franklyn Kanneh",
        "Willie Robert",
        "James L B Massally",
        "Sin\u00e9ad B. Chapman",
        "James Bochicchio",
        "Cheryl Murphy",
        "Chad Nusbaum",
        "Sarah Young",
        "Bruce W. Birren",
        "Donald S. Grant",
        "John S. Scheiffelin"
    ],
    "related_topics": [
        "Sierra leone",
        "Ebola virus",
        "ZMapp"
    ],
    "citation_count": "1,245",
    "reference_count": "43",
    "references": [
        "2132926880",
        "2146058063",
        "2130362098",
        "2115102869",
        "2106578986",
        "2094939159",
        "2102286438",
        "2117752525",
        "2009596137",
        "2124790653"
    ]
},{
    "id": "2227495319",
    "title": "Preliminary epidemiological assessment of MERS-CoV outbreak in South Korea, May to June 2015.",
    "abstract": "South Korea is experiencing the largest outbreak of Middle East respiratory syndrome coronavirus infections outside the Arabian Peninsula, with 166 laboratory-confirmed cases, including 24 deaths up to 19 June 2015. We estimated that the mean incubation period was 6.7 days and the mean serial interval 12.6 days. We found it unlikely that infectiousness precedes symptom onset. Based on currently available data, we predict an overall case fatality risk of 21% (95% credible interval: 14\u201331).",
    "date": "2015",
    "authors": [
        "Benjamin J Cowling",
        "Minah Park",
        "Vicky J Fang",
        "Peng Wu",
        "Gabriel M Leung",
        "Joseph T Wu"
    ],
    "related_topics": [
        "Case fatality rate",
        "Serial interval",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "301",
    "reference_count": "21",
    "references": [
        "2166867592",
        "2107053896",
        "2006434809",
        "2138324310",
        "2147166346",
        "1968393246",
        "2130227690",
        "1965186841",
        "2156614913",
        "1984328389"
    ]
},{
    "id": "1994871753",
    "title": "Infection with MERS-CoV Causes Lethal Pneumonia in the Common Marmoset",
    "abstract": "The availability of a robust disease model is essential for the development of countermeasures for Middle East respiratory syndrome coronavirus (MERS-CoV). While a rhesus macaque model of MERS-CoV has been established, the lack of uniform, severe disease in this model complicates the analysis of countermeasure studies. Modeling of the interaction between the MERS-CoV spike glycoprotein and its receptor dipeptidyl peptidase 4 predicted comparable interaction energies in common marmosets and humans. The suitability of the marmoset as a MERS-CoV model was tested by inoculation via combined intratracheal, intranasal, oral and ocular routes. Most of the marmosets developed a progressive severe pneumonia leading to euthanasia of some animals. Extensive lesions were evident in the lungs of all animals necropsied at different time points post inoculation. Some animals were also viremic; high viral loads were detected in the lungs of all infected animals, and total RNAseq demonstrated the induction of immune and inflammatory pathways. This is the first description of a severe, partially lethal, disease model of MERS-CoV, and as such will have a major impact on the ability to assess the efficacy of vaccines and treatment strategies as well as allowing more detailed pathogenesis studies.",
    "date": "2014",
    "authors": [
        "Darryl Falzarano",
        "Emmie de Wit",
        "Friederike Feldmann",
        "Angela L. Rasmussen",
        "Atsushi Okumura",
        "Xinxia Peng",
        "Matthew J. Thomas",
        "Neeltje van Doremalen",
        "Elaine Haddock",
        "Lee Nagy",
        "Rachel LaCasse",
        "Tingting Liu",
        "Jiang Zhu",
        "Jason S. McLellan",
        "Dana P. Scott",
        "Michael G. Katze",
        "Heinz Feldmann",
        "Vincent J. Munster"
    ],
    "related_topics": [
        "Pneumonia (non-human)",
        "Middle East respiratory syndrome coronavirus",
        "Marmoset"
    ],
    "citation_count": "198",
    "reference_count": "41",
    "references": [
        "2124985265",
        "2169456326",
        "2166867592",
        "2137015675",
        "1703839189",
        "2119111857",
        "2130116522",
        "2160011624",
        "2145441153",
        "2034462612"
    ]
},{
    "id": "1979807576",
    "title": "Progress in global surveillance and response capacity 10 years after severe acute respiratory syndrome.",
    "abstract": "Ten years have elapsed since the World Health Organization issued its first global alert for an unexplained illness named severe acute respiratory syndrome (SARS). The anniversary provides an opportunity to reflect on the international response to this new global microbial threat. While global surveillance and response capacity for public health threats have been strengthened, critical gaps remain. Of 194 World Health Organization member states that signed on to the International Health Regulations (2005), <20% had achieved compliance with the core capacities required by the deadline in June 2012. Lessons learned from the global SARS outbreak highlight the need to avoid complacency, strengthen efforts to improve global capacity to address the next pandemic using all available 21st century tools, and support research to develop new treatment options, countermeasures, and insights while striving to address the global inequities that are the root cause of many of these challenges.",
    "date": "2013",
    "authors": [
        "Christopher R. Braden",
        "Scott F. Dowell",
        "Daniel B. Jernigan",
        "James M. Hughes"
    ],
    "related_topics": [
        "Global health",
        "International Health Regulations",
        "Public health surveillance"
    ],
    "citation_count": "72",
    "reference_count": "26",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2116586125",
        "2169198329",
        "2463755683",
        "1507976894",
        "1993435091",
        "2098459942",
        "2398786667"
    ]
},{
    "id": "1942680103",
    "title": "MERS in South Korea and China: a potential outbreak threat?",
    "abstract": "",
    "date": "2015",
    "authors": [
        "Shuo Su",
        "Gary Wong",
        "Yingxia Liu",
        "George F Gao",
        "Shoujun Li",
        "Yuhai Bi"
    ],
    "related_topics": [
        "Outbreak",
        "Pandemic",
        "Global health"
    ],
    "citation_count": "89",
    "reference_count": "3",
    "references": [
        "2149508011",
        "2115555188",
        "2145566480"
    ]
},{
    "id": "2024845268",
    "title": "Replication of SARS coronavirus administered into the respiratory tract of African Green, rhesus and cynomolgus monkeys.",
    "abstract": "SARS coronavirus (SARS-CoV) administered intranasally and intratracheally to rhesus, cynomolgus and African Green monkeys (AGM) replicated in the respiratory tract but did not induce illness. The titer of serum neutralizing antibodies correlated with the level of virus replication in the respiratory tract (AGM>cynomolgus>rhesus). Moderate to high titers of SARS-CoV with associated interstitial pneumonitis were detected in the lungs of AGMs on day 2 and were resolving by day 4 post-infection. Following challenge of AGMs 2 months later, virus replication was highly restricted and there was no evidence of enhanced disease. These species will be useful for the evaluation of the immunogenicity of candidate vaccines, but the lack of apparent clinical illness in all three species, variability from animal to animal in level of viral replication, and rapid clearance of virus and pneumonitis in AGMs must be taken into account by investigators considering the use of these species in efficacy and challenge studies.",
    "date": "2004",
    "authors": [
        "Josephine McAuliffe",
        "Leatrice Vogel",
        "Anjeanette Roberts",
        "Gary Fahle",
        "Steven Fischer",
        "Wun Ju Shieh",
        "Emily Butler",
        "Sherif Zaki",
        "Marisa St. Claire",
        "Brian Murphy",
        "Kanta Subbarao"
    ],
    "related_topics": [
        "Pneumonitis",
        "Virus",
        "Viral replication"
    ],
    "citation_count": "249",
    "reference_count": "21",
    "references": [
        "2132260239",
        "2104548316",
        "2129542667",
        "2100820722",
        "2168446943",
        "1976741900",
        "2171157147",
        "2029293367",
        "2100516702",
        "2163092396"
    ]
},{
    "id": "2135540513",
    "title": "Ebola Virus Transmission in Guinea Pigs",
    "abstract": "ABSTRACT Ebola virus (EBOV) transmission is currently poorly characterized and is thought to occur primarily by direct contact with infectious material; however transmission from swine to nonhuman primates via the respiratory tract has been documented. To establish an EBOV transmission model for performing studies with statistical significance, groups of six guinea pigs (gps) were challenged intranasally (i.n.) or intraperitoneally (i.p.) with 10,000 times the 50% lethal dose (LD 50 ) of gp-adapted EBOV, and naive gps were then introduced as cage mates for contact exposure at 1 day postinfection (p.i.). The animals were monitored for survival and clinical signs of disease and quantitated for virus shedding postexposure. Changes in the duration of contact of naive gps with infected animals were evaluated for their impact on transmission efficiency. Transmission was more efficient from i.n.- than from i.p.-challenged gps, with 17% versus 83% of naive gps surviving exposure, respectively. Virus shedding was detected beginning at 3 days p.i. from both i.n.- and i.p.-challenged animals. Contact duration positively correlated with transmission efficiency, and the abrogation of direct contact between infected and naive animals through the erection of a steel mesh was effective at stopping virus spread, provided that infectious animal bedding was absent from the cages. Histopathological and immunohistochemical findings show that i.n.-infected gps display enhanced lung pathology and EBOV antigen in the trachea, which supports increased virus transmission from these animals. The results suggest that i.n.-challenged gps are more infectious to naive animals than their systemically infected counterparts and that transmission occurs through direct contact with infectious materials, including those transported through air movement over short distances. IMPORTANCE Ebola is generally thought to be spread between humans though infectious bodily fluids. However, a study has shown that Ebola can be spread from pigs to monkeys without direct contact. Further studies have been hampered, because an economical animal model for Ebola transmission is not available. To address this, we established a transmission model in guinea pigs and determined the mechanisms behind virus spread. The survival data, in addition to microscopic examination of lung and trachea sections, show that mucosal infection of guinea pigs is an efficient model for Ebola transmission. Virus spread is increased with longer contact times with an infected animal and is possible without direct contact between an infected and a naive host but can be stopped if infectious materials are absent. These results warrant consideration for the development of future strategies against Ebola transmission and for a better understanding of the parameters involved in virus spread.",
    "date": "2015",
    "authors": [
        "Gary Wong",
        "Xiangguo Qiu",
        "Jason S. Richardson",
        "Todd Cutts",
        "Brad Collignon",
        "Jason Gren",
        "Jenna Aviles",
        "Carissa Embury-Hyatt",
        "Gary P. Kobinger"
    ],
    "related_topics": [
        "Ebola virus",
        "Virus",
        "Viral shedding"
    ],
    "citation_count": "63",
    "reference_count": "21",
    "references": [
        "2102286438",
        "1982754464",
        "2116375742",
        "2167972491",
        "2161081629",
        "2081520626",
        "2104066170",
        "2080641666",
        "2086534263",
        "2089872165"
    ]
},{
    "id": "2089797630",
    "title": "Cynomolgus Macaque as an Animal Model for Severe Acute Respiratory Syndrome",
    "abstract": "Background The emergence of severe acute respiratory syndrome (SARS) in 2002 and 2003 affected global health and caused major economic disruption. Adequate animal models are required to study the underlying pathogenesis of SARS-associated coronavirus (SARS-CoV) infection and to develop effective vaccines and therapeutics. We report the first findings of measurable clinical disease in nonhuman primates (NHPs) infected with SARS-CoV. Methods and Findings In order to characterize clinically relevant parameters of SARS-CoV infection in NHPs, we infected cynomolgus macaques with SARS-CoV in three groups: Group I was infected in the nares and bronchus, group II in the nares and conjunctiva, and group III intravenously. Nonhuman primates in groups I and II developed mild to moderate symptomatic illness. All NHPs demonstrated evidence of viral replication and developed neutralizing antibodies. Chest radiographs from several animals in groups I and II revealed unifocal or multifocal pneumonia that peaked between days 8 and 10 postinfection. Clinical laboratory tests were not significantly changed. Overall, inoculation by a mucosal route produced more prominent disease than did intravenous inoculation. Half of the group I animals were infected with a recombinant infectious clone SARS-CoV derived from the SARS-CoV Urbani strain. This infectious clone produced disease indistinguishable from wild-type Urbani strain. Conclusions SARS-CoV infection of cynomolgus macaques did not reproduce the severe illness seen in the majority of adult human cases of SARS; however, our results suggest similarities to the milder syndrome of SARS-CoV infection characteristically seen in young children.",
    "date": "2006",
    "authors": [
        "James V Lawler",
        "Timothy P Endy",
        "Lisa E Hensley",
        "Aura Garrison",
        "Elizabeth A Fritz",
        "May Lesar",
        "Ralph S Baric",
        "David A Kulesh",
        "David A Norwood",
        "Leonard P Wasieloski",
        "Melanie P Ulrich",
        "Tom R Slezak",
        "Elizabeth Vitalis",
        "John W Huggins",
        "Peter B Jahrling",
        "Jason Paragas"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Macaque"
    ],
    "citation_count": "127",
    "reference_count": "50",
    "references": [
        "2129542667",
        "2103503670",
        "2134061616",
        "2163627712",
        "2168446943",
        "2167080692",
        "2070463916",
        "1976741900",
        "2130450914",
        "1972591948"
    ]
},{
    "id": "2788045019",
    "title": "The Global Virome Project",
    "abstract": "Outbreaks of novel and deadly viruses highlight global vulnerability to emerging diseases, with many having massive health and economic impacts. Our adaptive toolkit\u2014based largely on vaccines and therapeutics\u2014is often ineffective because countermeasure development can be outpaced by the speed of novel viral emergence and spread. Following each outbreak, the public health community bemoans a lack of prescience, but after decades of reacting to each event with little focus on mitigation, we remain only marginally better protected against the next epidemic. Our ability to mitigate disease emergence is undermined by our poor understanding of the diversity and ecology of viral threats, and of the drivers of their emergence. We describe a Global Virome Project (GVP) aimed to launch in 2018 that will help identify the bulk of this viral threat and provide timely data for public health interventions against future pandemics.",
    "date": "2018",
    "authors": [
        "Dennis Carroll",
        "Peter Daszak",
        "Nathan D. Wolfe",
        "George F. Gao",
        "Carlos M. Morel",
        "Subhash Morzaria",
        "Ariel Pablos-M\u00e9ndez",
        "Oyewale Tomori",
        "Jonna A. K. Mazet"
    ],
    "related_topics": [
        "Human virome",
        "Vulnerability",
        "Public health"
    ],
    "citation_count": "240",
    "reference_count": "14",
    "references": [
        "1993577573",
        "2127435093",
        "2595920264",
        "2055601403",
        "2700382303",
        "2098459942",
        "2125233222",
        "2137569894",
        "2148400637",
        "1995320511"
    ]
},{
    "id": "1783641736",
    "title": "Genetic diversity and evolutionary dynamics of Ebola virus in Sierra Leone",
    "abstract": "A novel Ebola virus (EBOV) first identified in March 2014 has infected more than 25,000 people in West Africa, resulting in more than 10,000 deaths. Preliminary analyses of genome sequences of 81 EBOV collected from March to June 2014 from Guinea and Sierra Leone suggest that the 2014 EBOV originated from an independent transmission event from its natural reservoir followed by sustained human-to-human infections. It has been reported that the EBOV genome variation might have an effect on the efficacy of sequence-based virus detection and candidate therapeutics. However, only limited viral information has been available since July 2014, when the outbreak entered a rapid growth phase. Here we describe 175 full-length EBOV genome sequences from five severely stricken districts in Sierra Leone from 28 September to 11 November 2014. We found that the 2014 EBOV has become more phylogenetically and genetically diverse from July to November 2014, characterized by the emergence of multiple novel lineages. The substitution rate for the 2014 EBOV was estimated to be 1.23 \u00d7 10(-3) substitutions per site per year (95% highest posterior density interval, 1.04 \u00d7 10(-3) to 1.41 \u00d7 10(-3) substitutions per site per year), approximating to that observed between previous EBOV outbreaks. The sharp increase in genetic diversity of the 2014 EBOV warrants extensive EBOV surveillance in Sierra Leone, Guinea and Liberia to better understand the viral evolution and transmission dynamics of the ongoing outbreak. These data will facilitate the international efforts to develop vaccines and therapeutics.",
    "date": "2015",
    "authors": [
        "Yi-Gang Tong",
        "Wei-Feng Shi",
        "Di Liu",
        "Jun Qian",
        "Long Liang",
        "Xiao-Chen Bo",
        "Jun Liu",
        "Hong-Guang Ren",
        "Hang Fan",
        "Ming Ni",
        "Yang Sun",
        "Yuan Jin",
        "Yue Teng",
        "Zhen Li",
        "David Kargbo",
        "Foday Dafae",
        "Alex Kanu",
        "Cheng-Chao Chen",
        "Zhi-Heng Lan",
        "Hui Jiang",
        "Yang Luo",
        "Hui-Jun Lu",
        "Xiao-Guang Zhang",
        "Fan Yang",
        "Yi Hu",
        "Yu-Xi Cao",
        "Yong-Qiang Deng",
        "Hao-Xiang Su",
        "Yu Sun",
        "Wen-Sen Liu",
        "Zhuang Wang",
        "Cheng-Yu Wang",
        "Zhao-Yang Bu",
        "Zhen-Dong Guo",
        "Liu-Bo Zhang",
        "Wei-Min Nie",
        "Chang-Qing Bai",
        "Chun-Hua Sun",
        "Xiao-Ping An",
        "Pei-Song Xu",
        "Xiang-Li-Lan Zhang",
        "Yong Huang",
        "Zhi-Qiang Mi",
        "Dong Yu",
        "Hong-Wu Yao",
        "Yong Feng",
        "Zhi-Ping Xia",
        "Xue-Xing Zheng",
        "Song-Tao Yang",
        "Bing Lu"
    ],
    "related_topics": [
        "Sierra leone",
        "Ebola virus",
        "Ebolavirus"
    ],
    "citation_count": "168",
    "reference_count": "16",
    "references": [
        "2160378127",
        "2161444534",
        "2110835349",
        "78967600",
        "2115102869",
        "1975375203",
        "1982754464",
        "2156358357",
        "2105811945",
        "2132982999"
    ]
},{
    "id": "1967283148",
    "title": "Bat-derived influenza-like viruses H17N10 and H18N11",
    "abstract": "Shorebirds and waterfowls are believed to be the reservoir hosts for influenza viruses, whereas swine putatively act as mixing vessels. The recent identification of two influenza-like virus genomes (designated H17N10 and H18N11) from bats has challenged this notion. A crucial question concerns the role bats might play in influenza virus ecology. Structural and functional studies of the two major surface envelope proteins, hemagglutinin (HA) and neuraminidase (NA), demonstrate that neither has canonical HA or NA functions found in influenza viruses. However, putative functional modules and domains in other encoded proteins are conserved, and the N-terminal domain of the H17N10 polymerase subunit PA has a classical structure and function. Therefore, potential genomic reassortments of such influenza-like viruses with canonical influenza viruses cannot be excluded at this point and should be assessed.",
    "date": "2014",
    "authors": [
        "Ying Wu",
        "Yan Wu",
        "Boris Tefsen",
        "Yi Shi",
        "George F. Gao"
    ],
    "related_topics": [
        "H5N1 genetic structure",
        "Antigenic drift",
        "Hemagglutinin (influenza)"
    ],
    "citation_count": "336",
    "reference_count": "67",
    "references": [
        "2312463092",
        "2106173155",
        "1523679951",
        "2130734541",
        "2069831575",
        "2159734253",
        "2102335249",
        "2160881014",
        "177909858",
        "2048172399"
    ]
},{
    "id": "2793181185",
    "title": "Genomic Insights into Zika Virus Emergence and Spread",
    "abstract": "The emergence and spread of Zika virus in the Americas continues to challenge our disease surveillance systems. Virus genome sequencing during the epidemic uncovered the timescale of Zika virus transmission and spread. Yet, we are only beginning to explore how genomics can enhance our responses to emerging viruses.",
    "date": "2018",
    "authors": [
        "Nathan D. Grubaugh",
        "Nuno R. Faria",
        "Kristian G. Andersen",
        "Oliver G. Pybus"
    ],
    "related_topics": [
        "Zika virus",
        "Genomics",
        "Virus"
    ],
    "citation_count": "58",
    "reference_count": "15",
    "references": [
        "2307185071",
        "2616925143",
        "2618268848",
        "2514298796",
        "2516104505",
        "2760364797",
        "2617274523",
        "2620298867",
        "2063289063",
        "2470441796"
    ]
},{
    "id": "2081635462",
    "title": "Influenza and the live poultry trade.",
    "abstract": "![Figure][1] CREDIT: YINGFEI LIANG Live poultry trade at local markets has long been a part of China's national identity. From small villages to big cities, the gathering and selling of different birds in this vibrant atmosphere is at the heart of the country's cuisine culture. Unfortunately, the backdrop to this tradition has changed. Last year, the H7N9 virus, a new strain of influenza A, jumped from birds to humans, causing 144 cases of human infection and 47 deaths in China. Now a second wave of this flu is coursing through the country, with 258 confirmed cases and 99 deaths as of 8 April 2014. Scientific evidence points to a connection between the conditions at these live markets and the spread of flu, suggesting that until other means are found to prevent the transmission of or effectively treat the illness, China must shut down live poultry markets to prevent further spread of the virus and a possible global pandemic. Early in 2013, the Chinese Center for Disease Control and Prevention and several prominent Chinese research groups quickly identified H7N9 as the causative agent of the emerging flu. The source of the virus was immediately traced to live poultry markets. With a call for an immediate shutdown of these markets in major cities, including Hangzhou and Shanghai (where the first H7N9 human infection cases were found), the government quickly controlled the spread of the virus. But the government deemed long-term closure to be economically unviable, and the markets reopened soon after the summer. At the beginning of the new flu season in October, the virus bounced back in the eastern Yangtze River delta region. This year, it has spread to the Canton region (Guangdong province) in China, which is alarming because live poultry markets are commonplace there. ![Figure][1] CREDIT: GUAN YUROU/IMAGINECHINA Approximately 87% of the people infected with H7N9 had close contact with live poultry or exposure to a contaminated environment such as the poultry markets, where the virus can spread quickly through birds. Poultry transportation between provinces is probably playing an important role in its spread across China. Although it is generally believed that H7N9 has not developed human-to-human transmissibility, the possibility cannot be excluded. There has been limited unsustained human-to-human transmission in several case clusters. Genomic analysis of the isolated viruses reveals that divergent strains exist and that the virus is not yet \u201cfixed\u201d in its identity and character. H7N9 has yet to adapt to humans by mixing its viral genes with those of a human-specific influenza virus. This can happen if a single host (a human or bird, for example) is infected by both an avian and a human virus. Such genomic reassortment generated the pandemic flu strains in 1918 and 2009, which killed 20 to 40 million and 250,000 people, respectively, worldwide. The risk of this occurring is precisely why the shutdown of live poultry markets is needed to avoid potential reassortments. But H7N9 is not the only problem. Two new subtypes of influenza A virus have been isolated in humans: H6N1 in Taiwan and H10N8 in mainland China. Both have a clear poultry origin and are found in live poultry markets. Six genes of H10N8 are derived from H9N2, an avian influenza virus that is common in live poultry markets but has infected humans as well. Avian H7N9 and H9N2 coexist in chickens. That means that at any time, their genomes could mix and give rise to a potentially more virulent strain that infects humans. The birds in live poultry markets are incubators for new subtypes of influenza virus, and the continuation of this culture is worrisome. It is simply not enough to implement regular birdcage disinfection measures and the killing of unsold birds every evening. Curtailing poultry transportation is even more difficult than shutting down markets. H7N9 is avirulent to poultry, so it is difficult to identify virus-carrying birds. Unless the government closes these markets, there is ample opportunity for the rise of a global and devastating pandemic. [1]: pending:yes",
    "date": "2014",
    "authors": [
        "George F. Gao"
    ],
    "related_topics": [
        "Flu season",
        "Influenza A virus",
        "Pandemic"
    ],
    "citation_count": "88",
    "reference_count": "0",
    "references": []
},{
    "id": "2473338860",
    "title": "A fatal yellow fever virus infection in China: description and lessons.",
    "abstract": "Yellow fever (YF) is a viral disease endemic to the tropical regions of Africa and South America. An outbreak of YF has been occurring in Angola, since the beginning of 2016. In March 2016, a 32-year-old Chinese man who returned from Angola was hospitalized and diagnosed with the first case of imported YF in China. Clinical observations, blood viral RNA detection, serological testing and treatments for the patient were performed daily. The virus was isolated in Vero cells, and the complete viral genome was sequenced and analyzed using the next-generation genomic sequencing platform. The patient presented with hemorrhagic fever, jaundice and oliguria at day 3 after onset, which rapidly progressed to multisystem organ failure with extremely elevated liver, pancreatic and myocardial enzymes. The patient died despite the intensive supportive treatments that were performed. A liver biopsy showed severe and multilobular necrosis. Viral RNA was detectable throughout the clinical course of the disease. Whole-genomic sequence analysis revealed that the virus belongs to the Angola71 genotype. Although the virus has been circulating in Angola for 45 years, only 14 amino-acid substitutions and no amino-acid changes were observed in the membrane and envelope proteins compared with the virus collected in 1971. The presence of this imported YF case in China indicated that with the increase in business travel among countries, YF outbreaks in Africa can lead to the international spread of the disease. The production and use of YF vaccines is, therefore, an urgent issue.",
    "date": "2016",
    "authors": [
        "Zhihai Chen",
        "Lin Liu",
        "Yanning Lv",
        "Wei Zhang",
        "Jiandong Li",
        "Yi Zhang",
        "Tian Di",
        "Shuo Zhang",
        "Jingyuan Liu",
        "Jie Li",
        "Jing Qu",
        "Wenhao Hua",
        "Chuan Li",
        "Peng Wang",
        "Quanfu Zhang",
        "Yanli Xu",
        "Rongmeng Jiang",
        "Qin Wang",
        "Lijuan Chen",
        "Shiwen Wang",
        "Xinghuo Pang",
        "Mifang Liang",
        "Xuejun Ma",
        "Xingwang Li",
        "Quanyi Wang",
        "Fujie Zhang",
        "Dexin Li"
    ],
    "related_topics": [
        "Yellow Fever Virus Infection",
        "Yellow fever",
        "Viral disease"
    ],
    "citation_count": "59",
    "reference_count": "19",
    "references": [
        "2152207030",
        "2311203695",
        "2091030812",
        "2002545308",
        "2158159015",
        "1976424397",
        "2029869358",
        "2167041942",
        "2010436800",
        "1978987834"
    ]
},{
    "id": "2782496877",
    "title": "CASCIRE surveillance network and work on avian influenza viruses.",
    "abstract": "",
    "date": "2017",
    "authors": [
        "Yuhai Bi",
        "Weifeng Shi",
        "Jianjun Chen",
        "Quanjiao Chen",
        "Zhenghai Ma",
        "Gary Wong",
        "Wenxia Tian",
        "Renfu Yin",
        "Guanghua Fu",
        "Yongchun Yang",
        "William J. Liu",
        "Chuansong Quan",
        "Qianli Wang",
        "Shenghu He",
        "Xiangdong Li",
        "Qianfeng Xia",
        "Lixin Wang",
        "Zhaohui Pan",
        "Laixing Li",
        "Hong Li",
        "Wen Xu",
        "Ying Luo",
        "Hui Zeng",
        "Lianpan Dai",
        "Haixia Xiao",
        "Kirill Sharshov",
        "Alexander Shestopalov",
        "Yi Shi",
        "Jinghua Yan",
        "Xuebing Li",
        "Yingxia Liu",
        "Fumin Lei",
        "Wenjun Liu",
        "George F. Gao"
    ],
    "related_topics": [
        "Influenza A virus subtype H5N1",
        "Work (electrical)",
        "Drug resistance"
    ],
    "citation_count": "9",
    "reference_count": "51",
    "references": [
        "2130734541",
        "2146175559",
        "2557499142",
        "2346452525",
        "2605082299",
        "1975573443",
        "1868415946",
        "2065904582",
        "2567109063",
        "2081635462"
    ]
},{
    "id": "2078917493",
    "title": "A previously undescribed coronavirus associated with respiratory disease in humans.",
    "abstract": "The etiology of acute respiratory tract illnesses is sometimes unclear due to limitations of diagnostic tests or the existence of as-yet-unidentified pathogens. Here we describe the identification and characterization of a not previously recognized coronavirus obtained from an 8-mo-old boy suffering from pneumonia. This coronavirus replicated efficiently in tertiary monkey kidney cells and Vero cells, in contrast to human coronaviruses (HCoV) 229E and OC43. The entire cDNA genome sequence of the previously undescribed coronavirus was determined, revealing that it is most closely related to porcine epidemic diarrhea virus and HCoV 229E. The maximum amino acid sequence identity between ORFs of the newly discovered coronavirus and related group 1 coronaviruses ranged from 43% to 67%. Real-time RT-PCR assays were designed to test for the prevalence of the previously undescribed coronavirus in humans. Using these tests, the virus was detected in four of 139 individuals (3%) who were suffering from respiratory illness with unknown etiology. All four patients suffered from fever, runny nose, and dry cough, and all four had underlying or additional morbidity. Our data will enable the development of diagnostic tests to study the prevalence and clinical impact of this virus in humans in more detail. Moreover, it will be important to discriminate this previously undescribed coronavirus from HCoV 229E and OC43 and the severe acute respiratory syndrome coronavirus.",
    "date": "2004",
    "authors": [
        "Ron A. M. Fouchier",
        "Nico G. Hartwig",
        "Theo M. Bestebroer",
        "Berend Niemeyer",
        "Jan C. de Jong",
        "James H. Simon",
        "Albert D. M. E. Osterhaus"
    ],
    "related_topics": [
        "Coronavirus",
        "Human coronavirus NL63",
        "Human coronavirus HKU1"
    ],
    "citation_count": "676",
    "reference_count": "24",
    "references": [
        "1483247593",
        "2132260239",
        "2104548316",
        "2025170735",
        "2100820722",
        "2116586125",
        "2169198329",
        "2170881661",
        "2111412754",
        "2168446943"
    ]
},{
    "id": "2287076968",
    "title": "Two-tube multiplex real-time reverse transcription PCR to detect six human coronaviruses",
    "abstract": "In this study, the authors developed a two-tube multiplex real-time RT-PCR assay for sensitive and specific detection of all known human coronaviruses. Its ability to monitor HKU1 replication in cultures of human airway epithelial cells, to quantitatively measure viral RNA in monkeys experimentally infected with MERS, and to detect MERS in a human patient was demonstrated. In addition, the assay was used to assess disease burden and epidemiology of coronaviruses among hospitalized patients with acute respiratory infection. The results indicate that the assay is quantitative, rapid, sensitive, specific, high-throughput, and able to detect co-infection. Finally, the assay requires significantly less sample than monoplex real-time RT-PCR.",
    "date": "2016",
    "authors": [
        "Peihua Niu",
        "Jun Shen",
        "Na Zhu",
        "Roujian Lu",
        "Wenjie Tan"
    ],
    "related_topics": [
        "Multiplex",
        "Respiratory infection",
        "Reverse transcription polymerase chain reaction"
    ],
    "citation_count": "11",
    "reference_count": "13",
    "references": [
        "2166867592",
        "2067508599",
        "2041352768",
        "2119106624",
        "2131153572",
        "1988810060",
        "1545528913",
        "2002828471",
        "1980518777",
        "2410647442"
    ]
},{
    "id": "2120839730",
    "title": "Frequent Detection of Respiratory Viruses without Symptoms: Toward Defining Clinically Relevant Cutoff Values",
    "abstract": "Highly sensitive techniques, such as PCR, have greatly improved the detection of respiratory viruses. However, the sensitivity of PCR tests also complicates clinical interpretation, as the presence of small amounts of viral targets may not necessarily have clinical relevance. We performed a prospective case-control study in asymptomatic and symptomatic young children. PCR detection of 14 respiratory viruses was performed in nasal washes, and results were quantified in copies per milliliter. A total of 141 cases and 157 controls were included. In 72% of the cases and 28% of the controls, at least one virus was identified. When stratified for age, at least one virus was identified in 47% of the controls younger than 1 year old. Rhinovirus (RV) was frequently detected in both symptomatic and asymptomatic individuals. Receiver operating characteristic analysis for quantitative rhinovirus detection showed that cutoff values for clinical relevance are feasible for RV. In contrast to rhinovirus, respiratory syncytial virus (RSV) was rarely detected in controls, suggesting that a positive RSV test result is almost always of clinical relevance, independent of viral quantity. In conclusion, our study shows that asymptomatic carriage of a respiratory virus occurs frequently in young children. However, significant differences in the amount of virus present were observed between cases and controls. This suggests that defining cutoff levels should be feasible and represents the next necessary step for diagnosing viral respiratory infections using molecular tests.",
    "date": "2011",
    "authors": [
        "Rogier R. Jansen",
        "Joanne Wieringa",
        "Sylvie M. Koekkoek",
        "Caroline E. Visser",
        "Dasja Pajkrt",
        "Richard Molenkamp",
        "Menno D. de Jong",
        "Janke Schinkel"
    ],
    "related_topics": [
        "Respiratory virus",
        "Rhinovirus",
        "Viral load"
    ],
    "citation_count": "284",
    "reference_count": "30",
    "references": [
        "2119950877",
        "2086975476",
        "2128010249",
        "2087738530",
        "2014819850",
        "2065460218",
        "2108748114",
        "1982943688",
        "1986317728",
        "1936311738"
    ]
},{
    "id": "2412526156",
    "title": "[Prevalence and seasonal distribution of respiratory viruses in patients with acute respiratory tract infections, 2002-2014].",
    "abstract": "The aim of this study was to investigate the prevalence and seasonal distribution of respiratory viruses in pediatric and adult outpatients and inpatients who were admitted to hospital with the symptoms of upper and lower respiratory tract infections, during a 12-year period. A total of 5102 clinical samples (4372 nasopharyngeal swabs, 316 bronchoalveolar lavages, 219 transtracheal aspirates, 163 nasopharyngeal aspirates, 20 sputum, 10 nasal swabs) examined in our laboratory between January 1st 2002 and July 17th 2014, were evaluated retrospectively. Of the specimens, 1107 (21.7%) were obtained from outpatients and 3995 (78.3%) from hospitalized patients. Of the patients, 2851 (55.9%) were male and 2251 (44.1%) were female, while 1233 (24.2%) were adults and 3869 (75.8%) were children (age range: 1 day - 93 years; median: 3 years). Respiratory samples were investigated for the presence of respiratory syncytial virus (RSV), influenza virus type A and B (INF-A, INF-B), adenovirus (AdV), parainfluenza viruses (PIV types 1-4), human rhinoviruses (HRV), human coronaviruses (HCoV), human metapneumovirus (HMPV) and human bocavirus (HBoV). All specimens were tested by both direct immunofluorescence antibody (DFA) and shell vial cell culture (SVCC) methods. In DFA assay the samples were initially screened by fluorescent-labeled polyclonal antibodies, and the positive ones were typed by using monoclonal antibodies (Light Diagnostics, Merck Millipore, USA). In SVCC, HEp-2, MDCK, A-549 and Vero cell lines were used for the isolation of viruses. In addition to these methods, real-time multiplex PCR methods (RealAccurate\u00ae, Respiratory RT PCR, PathoFinder, Netherlands and Seeplex\u00ae RV15 ACE Detection, Seegene, South Korea) were used for the detection of respiratory viruses in samples (n= 2104) obtained from 2007 to 2014. Respiratory viruses were detected in a total of 1705 (33.4%) patients, of them 967 (19%) were male and 738 (14.4%) were female. Three hundred and eighteen (18.6%) of the 1705 patients were infected with multiple respiratory viruses. The most frequently observed co-infections were RSV+INF-A (40/318; 12.6%), and RSV+PIV (33/318; 10.4%). The rate of positivity for the respiratory viruses in pediatric and adult groups were 35.4% (1369/3869) and 27.3% (336/1233), respectively (p< 0.000). The most frequently detected virus in pediatric group was RSV (336/1369; 24.5%), followed by influenza viruses (314/1369; 22.9%), PIV (197/1369; 14.4%), HRV (118/1369; 8.6%), AdV (75/1369; 5.5%) and the others (49/1369; 3.6%). On the other hand the most frequently detected virus in adult group was influenza viruses (181/336; 53.8%) followed by AdV (37/336; 11%), RSV (24/336; 7.1%), PIV (24/336; 7.1%), HRV (23/336; 6.8%) and the others (9/336; 2.7%). The rate of multiple virus infections in pediatric and adult groups were 7.2% (280/3869) and 3% (38/1233), respectively. Most of the coinfections (280/318; 88%) were detected in children. Respiratory viruses were detected positive in 40.2% (445/1107) of outpatients, and in 31.5% (1260/3995) of inpatients (p< 0.000). The most frequent viruses detected in pediatric outpatients and inpatients were HRV and RSV, respectively, while influenza viruses were the first in line among both adult outpatients and inpatients. During the study period, a PIV-3 outbreak (n= 96) have emerged between December 2004-April 2005, and an influenza A (H1N1)pdm09 outbreak (n= 207) between November 2009-January 2010. When the seasonal distribution was considered, the isolation rates of 1705 respiratory viruses in winter, spring, summer and autumn were 44.4%, 27%, 8.3% and 20.3%, respectively. RSV was most frequently detected from December to March, influenza viruses from November to March, HRV from December to June, and mixed infections from January to February. In conclusion, the data of our study obtained in about 12-year period indicated that the prevalence of respiratory viruses in acute respiratory infections is 33.4%, and they typically active during the months of winter and early spring in our region.",
    "date": "2015",
    "authors": [
        "Candan \u00c7i\u00e7ek",
        "Ay\u015fe Arslan",
        "Haydar Soydaner Karaku\u015f",
        "Mehmet Yalaz",
        "Eylem Ula\u015f Saz",
        "H\u00fcsn\u00fc Pulluk\u00e7u",
        "G\u00fcrsel \u00c7ok"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Human metapneumovirus",
        "Human bocavirus"
    ],
    "citation_count": "13",
    "reference_count": "0",
    "references": []
},{
    "id": "2081835188",
    "title": "Multiplex real-time PCR for detection of respiratory tract infections.",
    "abstract": "Abstract Background Broad diagnostics of respiratory infection by molecular assays has not yet won acceptance due to technical difficulties and high costs. Objectives To evaluate clinical applicability of multiplex real-time PCR. Study design An assay targeting influenza virus A (IfA) and B (IfB), parainfluenza 1-3 (PIV), human metapneumovirus (MPV), respiratory syncytial virus (RSV), rhinovirus (RV), enterovirus (EV), adenovirus (AdV), human coronaviruses (229E, OC43, NL63), M. pneumoniae and Ch. pneumoniae was developed and run daily on consecutive clinical nasopharyngeal swab samples. Results An etiology was identified in 48% of the 954 samples, with IfA in 25%, RV in 20%, MPV in 10% and M. pneumoniae in 10% of the positive. By a rational procedure costs could be reduced and the customer price set relatively low (\u20ac33 per sample). Conclusion Streamlined testing and cost limitation is achievable and probably critical for implementation of a broad molecular diagnostics of respiratory infections.",
    "date": "2007",
    "authors": [
        "Robin Brittain-Long",
        "Sandra Nord",
        "Sigvard Olofsson",
        "Johan Westin",
        "Lars Magnus Anderson",
        "Magnus Lindh"
    ],
    "related_topics": [
        "Respiratory infection",
        "Respiratory tract infections",
        "Human metapneumovirus"
    ],
    "citation_count": "244",
    "reference_count": "15",
    "references": [
        "2010585539",
        "2160004262",
        "2133680517",
        "2063850263",
        "2167019694",
        "2121782636",
        "2108295257",
        "2111498423",
        "2146280181",
        "2032398780"
    ]
},{
    "id": "2083870139",
    "title": "Comparative evaluation of six commercialized multiplex PCR kits for the diagnosis of respiratory infections.",
    "abstract": "The molecular diagnosis of respiratory infection can be performed using different commercial multiplex-based PCR kits whose performances have been previously compared individually to those of conventional techniques. This study compared the practicability and the diagnostic performances of six CE-marked kits available in 2011 on the French market, including 2 detecting viruses and atypical bacteria (from Pathofinder and Seegene companies) and 4 detecting only viruses (from Abbott, Genomica, Qiagen and Seegene companies). The respective sensitivity, specificity, accuracy and agreement of each multiplex technique were calculated by comparison to commercial duplex PCR tests (Argene/bioMerieux) used as gold standard. Eighty-eight respiratory specimens with no pathogen (n = 11), single infections (n = 33) or co-infections (n = 44) were selected to cover 9 viruses or groups of viruses and 3 atypical bacteria. All samples were extracted using the NUCLISENS\u00ae easyMAG\u2122 instrument (bioMerieux). The overall sensitivity ranged from 56.25% to 91.67% for viruses and was below 50% with both tests for bacteria. The overall specificity was excellent (>94% for all pathogens). For each tested kit, the overall agreement with the reference test was strong for viruses (kappa test >0.60) and moderate for bacteria. After the extraction step, the hands-on time varied from 50 min to 2h30 and the complete results were available in 2h30 to 9 h. The spectrum of tested agents and the technology used to reveal the PCR products as well as the laboratory organization are determinant for the selection of a kit.",
    "date": "2013",
    "authors": [
        "Sylvie Pillet",
        "Marina Lardeux",
        "Julia Dina",
        "Florence Grattard",
        "Paul Verhoeven",
        "J\u00e9r\u00f4me Le Goff",
        "Astrid Vabret",
        "Bruno Pozzetto"
    ],
    "related_topics": [
        "Respiratory infection",
        "Multiplex",
        "Multiplex polymerase chain reaction"
    ],
    "citation_count": "101",
    "reference_count": "46",
    "references": [
        "2063850263",
        "2082571397",
        "2105131328",
        "2076354126",
        "2165777597",
        "2025568079",
        "2133424486",
        "2155523942",
        "2014819850",
        "2029225660"
    ]
},{
    "id": "2131338055",
    "title": "Seeking the source of Pseudomonas aeruginosa infections in a recently opened hospital: an observational study using whole-genome sequencing",
    "abstract": "Objectives Pseudomonas aeruginosa is a common nosocomial pathogen responsible for significant morbidity and mortality internationally. Patients may become colonised or infected with P. aeruginosa after exposure to contaminated sources within the hospital environment. The aim of this study was to determine whether whole-genome sequencing (WGS) can be used to determine the source in a cohort of burns patients at high risk of P. aeruginosa acquisition. Study design An observational prospective cohort study. Setting Burns care ward and critical care ward in the UK. Participants Patients with >7% total burns by surface area were recruited into the study. Methods All patients were screened for P. aeruginosa on admission and samples taken from their immediate environment, including water. Screening patients who subsequently developed a positive P. aeruginosa microbiology result were subject to enhanced environmental surveillance. All isolates of P. aeruginosa were genome sequenced. Sequence analysis looked at similarity and relatedness between isolates. Results WGS for 141 P. aeruginosa isolates were obtained from patients, hospital water and the ward environment. Phylogenetic analysis revealed eight distinct clades, with a single clade representing the majority of environmental isolates in the burns unit. Isolates from three patients had identical genotypes compared with water isolates from the same room. There was clear clustering of water isolates by room and outlet, allowing the source of acquisitions to be unambiguously identified. Whole-genome shotgun sequencing of biofilm DNA extracted from a thermostatic mixer valve revealed this was the source of a P. aeruginosa subpopulation previously detected in water. In the remaining two cases there was no clear link to the hospital environment. Conclusions This study reveals that WGS can be used for source tracking of P. aeruginosa in a hospital setting, and that acquisitions can be traced to a specific source within a hospital ward.",
    "date": "2014",
    "authors": [
        "Joshua Quick",
        "Nicola Cumley",
        "Christopher M. Wearn",
        "Marc Niebel",
        "Chrystala Constantinidou",
        "Christopher M. Thomas",
        "Mark J. Pallen",
        "Naiem S. Moiemen",
        "Amy Bamford",
        "Beryl Oppenheim",
        "Nicholas J. Loman"
    ],
    "related_topics": [
        "Pseudomonas aeruginosa",
        "Genotype",
        "Prospective cohort study"
    ],
    "citation_count": "104",
    "reference_count": "51",
    "references": [
        "2103441770",
        "2131271579",
        "2160969485",
        "2031611770",
        "2155943701",
        "2159954944",
        "2119284644",
        "2053940732",
        "2142503351",
        "2164852757"
    ]
},{
    "id": "2097213674",
    "title": "Comparison of three multiplex PCR assays for the detection of respiratory viral infections: evaluation of xTAG respiratory virus panel fast assay, RespiFinder 19 assay and RespiFinder SMART 22 assay",
    "abstract": "A broad spectrum of pathogens is causative for respiratory tract infections, but symptoms are mostly similar. Therefore, the identification of the causative viruses and bacteria is only feasible using multiplex PCR or several monoplex PCR tests in parallel. The analytical sensitivity of three multiplex PCR assays, RespiFinder-19, RespiFinder-SMART-22 and xTAG-Respiratory-Virus-Panel-Fast-Assay (RVP), were compared to monoplex real-time PCR with quantified standardized control material. All assays include the most common respiratory pathogens. To compare the analytical sensitivity of the multiplex assays, samples were inoculated with 13 different quantified viruses in the range of 101 to 105 copies/ml. Concordant results were received for rhinovirus, whereas the RVP detected influenzavirus, RSV and hMPV more frequently in low concentrations. The RespiFinder-19 and the RespiFinder-SMART-22 showed a higher analytical sensitivity for adenoviruses and coronaviruses, whereas the RVP was incapable to detect adenovirus and coronavirus in concentrations of 104 copies/ml. The RespiFinder-19 and RespiFinder-SMART-22A did not detect influenzaviruses (104 copies/ml) and RSV (103 copies/ml). The detection of all 13 viruses in one sample was only achieved using monoplex PCR. To analyze possible competitive amplification reactions between the different viruses, samples were further inoculated with only 4 different viruses in one sample. Compared to the detection of 13 viruses in parallel, only a few differences were found. The incidence of respiratory viruses was compared in tracheal secretion (TS) samples (n\u2009=\u2009100) of mechanically ventilated patients in winter (n\u2009=\u200950) and summer (n\u2009=\u200950). In winter, respiratory viruses were detected in 32 TS samples (64%) by RespiFinder-19, whereas the detection rate with RVP was only 22%. The most frequent viruses were adenovirus (32%) and PIV-2 (20%). Multiple infections were detected in 16 TS samples (32%) by RespiFinder-19. Fewer infections were found in summer (RespiFinder-19: 20%; RVP: 6%). All positive results were verified using monoplex PCR. Multiplex PCR tests have a broad spectrum of pathogens to test at a time. Analysis of multiple inoculated samples revealed a different focus of the detected virus types by the three assays. Analysis of clinical samples showed a high concordance of detected viruses by the RespiFinder-19 compared to monoplex tests.",
    "date": "2012",
    "authors": [
        "Mareike Dabisch-Ruthe",
        "Tanja Vollmer",
        "Ortwin Adams",
        "Cornelius Knabbe",
        "Jens Dreier"
    ],
    "related_topics": [
        "Respiratory virus",
        "Multiplex",
        "Multiplex polymerase chain reaction"
    ],
    "citation_count": "66",
    "reference_count": "26",
    "references": [
        "1610919278",
        "2170881661",
        "2111412754",
        "2126556531",
        "2114191153",
        "2000837270",
        "2163742166",
        "2108295257",
        "2106066931",
        "2040499564"
    ]
},{
    "id": "2016253387",
    "title": "Epidemiology of acute respiratory infections in children in Guangzhou: a three-year study.",
    "abstract": "Acute Respiratory Infections (ARI) are some of the most common human diseases worldwide. However, they have a complex and diverse etiology, and the characteristics of the pathogens involved in respiratory infections in developing countries are not well understood. In this work, we analyzed the characteristics of 17 common respiratory pathogens in children (\u226414 years old) with ARI in Guangzhou, southern China over a 3-year period using real-time polymerase chain reaction. Pathogens were identified in 2361/4242 (55.7%) patients, and the positivity rate varied seasonally. Ten of the 17 pathogens investigated showed positivity rates of more than 5%. The most frequently detected pathogens were respiratory syncytial virus (768/2361, 32.5%), influenza A virus (428/2361, 18.1%), enterovirus (138/2361, 13.3%), Mycoplasma pneumoniae (267/2361, 11.3%) and adenovirus (213/2361, 9.0%). Co-pathogens were common and found in 503 of 2361 (21.3%) positive samples. When ranked according to frequency of occurrence, the pattern of co-pathogens was similar to that of the primary pathogens, with the exception of human bocavirus, human coronavirus and human metapneumovirus. Significant differences were found in age prevalence in 10 of the 17 pathogens (p\u22640.009): four basic patterns were observed, A: detection rates increased with age, B: detection rates declined with age, C: the detection rate showed distinct peaks or D: numbers of patients were too low to detect a trend or showed no significant difference among age groups (p>0.05). These data will be useful for planning vaccine research and control strategies and for studies predicting pathogen prevalence.",
    "date": "2014",
    "authors": [
        "Wen Kuan Liu",
        "Qian Liu",
        "De Hui Chen",
        "Huan Xi Liang",
        "Xiao Kai Chen",
        "Mei Xin Chen",
        "Shu Yan Qiu",
        "Zi Yeng Yang",
        "Rong Zhou"
    ],
    "related_topics": [
        "Human bocavirus",
        "Human metapneumovirus",
        "Mycoplasma pneumoniae"
    ],
    "citation_count": "89",
    "reference_count": "55",
    "references": [
        "2157725602",
        "1833207062",
        "1610919278",
        "2170881661",
        "2137407508",
        "2155130161",
        "2322654587",
        "2119632771",
        "2146982119",
        "2166812293"
    ]
},{
    "id": "2159773954",
    "title": "Viral Etiologies of Acute Respiratory Infections among Hospitalized Vietnamese Children in Ho Chi Minh City, 2004\u20132008",
    "abstract": "Background: The dominant viral etiologies responsible for acute respiratory infections (ARIs) are poorly understood, particularly among hospitalized children in resource-limited tropical countries where morbidity and mortality caused by ARIs are highest. Improved etiological insight is needed to improve clinical management and prevention. Objectives: We conducted a three-year prospective descriptive study of severe respiratory illness among children from 2 months to 13 years of age within the largest referral hospital for infectious diseases in southern Vietnam. Methods: Molecular detection for 15 viral species and subtypes was performed on three types of respiratory specimens (nose, throat swabs and nasopharyngeal aspirates) using a multiplex RT-PCR kit (Seeplex (TM) RV detection, Seegene) and additional monoplex real-time RT-PCRs. Results: A total of 309 children were enrolled from November 2004 to January 2008. Viruses were identified in 72% (222/309) of cases, including respiratory syncytial virus (24%), influenza virus A and B (17%), human bocavirus (16%), enterovirus (9%), human coronavirus (8%), human metapneumovirus (7%), parainfluenza virus 1-3 (6%), adenovirus (5%), and human rhinovirus A (4%). Co-infections with multiple viruses were detected in 20% (62/309) of patients. When combined, diagnostic yields in nose and throat swabs were similar to nasopharyngeal aspirates. Conclusion: Similar to other parts in the world, RSV and influenza were the predominant viral pathogens detected in Vietnamese hospitalized children. Combined nasal and throat swabs are the specimens of choice for sensitive molecular detection of a broad panel of viral agents. Further research is required to better understand the clinical significance of single versus multiple viral coinfections and to address the role of bacterial (co-) infections involved in severe respiratory illness",
    "date": "2011",
    "authors": [
        "Anh Ha Lien Do",
        "H. Rogier van Doorn",
        "My Ngoc Nghiem",
        "Juliet E. Bryant",
        "Thanh Hang thi Hoang",
        "Quang Ha Do",
        "Tan Le Van",
        "Tan Thanh Tran",
        "Bridget Wills",
        "Vinh Chau van Nguyen",
        "Minh Hien Vo",
        "Cong Khanh Vo",
        "Minh Dung Nguyen",
        "Jeremy Farrar",
        "Tinh Hien Tran",
        "Menno D. de Jong"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Human bocavirus",
        "Human metapneumovirus"
    ],
    "citation_count": "156",
    "reference_count": "35",
    "references": [
        "2166229810",
        "2065420324",
        "2150387021",
        "2137407508",
        "2166267202",
        "2114711469",
        "2131988685",
        "2105614110",
        "2034483210",
        "2133424486"
    ]
},{
    "id": "2167384912",
    "title": "Tissue distribution of ACE2 protein, the functional receptor for SARS coronavirus. A first step in understanding SARS pathogenesis",
    "abstract": "Severe acute respiratory syndrome (SARS) is an acute infectious disease that spreads mainly via the respiratory route. A distinct coronavirus (SARS-CoV) has been identified as the aetiological agent of SARS. Recently, a metallopeptidase named angiotensin-converting enzyme 2 (ACE2) has been identified as the functional receptor for SARS-CoV. Although ACE2 mRNA is known to be present in virtually all organs, its protein expression is largely unknown. Since identifying the possible route of infection has major implications for understanding the pathogenesis and future treatment strategies for SARS, the present study investigated the localization of ACE2 protein in various human organs (oral and nasal mucosa, nasopharynx, lung, stomach, small intestine, colon, skin, lymph nodes, thymus, bone marrow, spleen, liver, kidney, and brain). The most remarkable finding was the surface expression of ACE2 protein on lung alveolar epithelial cells and enterocytes of the small intestine. Furthermore, ACE2 was present in arterial and venous endothelial cells and arterial smooth muscle cells in all organs studied. In conclusion, ACE2 is abundantly present in humans in the epithelia of the lung and small intestine, which might provide possible routes of entry for the SARS-CoV. This epithelial expression, together with the presence of ACE2 in vascular endothelium, also provides a first step in understanding the pathogenesis of the main SARS disease manifestations.",
    "date": "2004",
    "authors": [
        "I Hamming",
        "W Timens",
        "M L C Bulthuis",
        "A T Lely",
        "G J Navis",
        "H van Goor"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Coronavirus",
        "Pathogenesis"
    ],
    "citation_count": "3,496",
    "reference_count": "22",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2100820722",
        "1966238900",
        "2168446943",
        "1971054351",
        "1757215199"
    ]
},{
    "id": "3027659922",
    "title": "New Insights of Emerging SARS-CoV-2: Epidemiology, Etiology, Clinical Features, Clinical Treatment, and Prevention",
    "abstract": "Since the first reports that the novel coronavirus was showing human-to-human transmission characteristics and asymptomatic cases, the number of patients with associated pneumonia has continued to rise and the epidemic has grown. It now threatens the health and lives of people across the world. The governments of many countries have attached great importance to the prevention of SARS-CoV-2, via research into the etiology and epidemiology of this newly emerged disease. Clinical signs, treatment, and prevention characteristics of the novel coronavirus pneumonia have been receiving attention worldwide, especially from medical personnel. However, owing to the different experimental methods, sample sizes, sample sources, and research perspectives of various studies, results have been inconsistent, or relate to an isolated aspect of the virus or the disease it causes. Currently, systematic summary data on the novel coronavirus are limited. This review combines experimental and clinical evidence into a systematic analysis and summary of the current progress of research into SARS-CoV-2, from multiple perspectives, with the aim of gaining a better overall understanding of the disease. Our report provides important information for current clinicians, for the prevention and treatment of COVID-19 pneumonia.",
    "date": "2020",
    "authors": [
        "Gangqiang Guo",
        "Lele Ye",
        "Kan Pan",
        "Yu Chen",
        "Dong Xing",
        "Kejing Yan",
        "Zhiyuan Chen",
        "Ning Ding",
        "Wenshu Li",
        "Hong Huang",
        "Lifang Zhang",
        "Xiaokun Li",
        "Xiangyang Xue"
    ],
    "related_topics": [
        "Disease",
        "Coronavirus",
        "Pneumonia"
    ],
    "citation_count": "75",
    "reference_count": "201",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3008028633",
        "3004280078",
        "3001195213",
        "3004318991",
        "3003465021"
    ]
},{
    "id": "3027264380",
    "title": "COVID19: A Systematic Approach to Early Identification and Healthcare Worker Protection",
    "abstract": "The COVID-19 outbreak spread rapidly throughout the globe, with worldwide infections and deaths continuing to increase dramatically. To control disease spread and protect healthcare workers, accurate information is necessary. We searched PubMed and Google Scholar for studies published from December 2019 to March 31, 2020 with the terms \"COVID-19,\" \"2019-nCoV,\" \"SARS-CoV-2,\" or \"Novel Coronavirus Pneumonia.\" The main symptoms of COVID-19 are fever (83-98.6%), cough (59.4-82%), and fatigue (38.1-69.6%). However, only 43.8% of patients have fever early in the disease course, despite still being infectious. These patients may present to clinics lacking proper precautions, leading to nosocomial transmission, and infection of workers. Potential COVID-19 cases must be identified early to initiate proper triage and distinguish them quickly from similar infections. Early identification, accurate triage, and standardized personal protection protocols can reduce the risk of cross infection. Containing disease spread will require protecting healthcare workers.",
    "date": "2020",
    "authors": [
        "Yu Zhao",
        "Chong Cui",
        "Kun Zhang",
        "Jialin Liu",
        "Jinfu Xu",
        "Eric Nisenbaum",
        "Yixiang Huang",
        "Guoyou Qin",
        "Bing Chen",
        "Michael Hoffer",
        "Susan H. Blanton",
        "Fred Telischi",
        "Joshua M. Hare",
        "Sylvia Daunert",
        "Bhavarth Shukla",
        "Savita G. Pahwa",
        "Dushyantha T. Jayaweera",
        "Paul E. Farmer",
        "Carlos del Rio",
        "Xuezhong Liu",
        "Yilai Shu"
    ],
    "related_topics": [
        "Triage",
        "Disease",
        "Outbreak"
    ],
    "citation_count": "8",
    "reference_count": "34",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3008028633",
        "3004280078",
        "3003465021",
        "3008090866",
        "3006961006",
        "3012099172"
    ]
},{
    "id": "2718090702",
    "title": "Host Factors in Coronavirus Replication.",
    "abstract": "Coronaviruses are pathogens with a serious impact on human and animal health. They mostly cause enteric or respiratory disease, which can be severe and life threatening, e.g., in the case of the zoonotic coronaviruses causing severe acute respiratory syndrome (SARS) and Middle East Respiratory Syndrome (MERS) in humans. Despite the economic and societal impact of such coronavirus infections, and the likelihood of future outbreaks of additional pathogenic coronaviruses, our options to prevent or treat coronavirus infections remain very limited. This highlights the importance of advancing our knowledge on the replication of these viruses and their interactions with the host. Compared to other +RNA viruses, coronaviruses have an exceptionally large genome and employ a complex genome expression strategy. Next to a role in basic virus replication or virus assembly, many of the coronavirus proteins expressed in the infected cell contribute to the coronavirus-host interplay. For example, by interacting with the host cell to create an optimal environment for coronavirus replication, by altering host gene expression or by counteracting the host\u2019s antiviral defenses. These coronavirus\u2013host interactions are key to viral pathogenesis and will ultimately determine the outcome of infection. Due to the complexity of the coronavirus proteome and replication cycle, our knowledge of host factors involved in coronavirus replication is still in an early stage compared to what is known for some other +RNA viruses. This review summarizes our current understanding of coronavirus\u2013host interactions at the level of the infected cell, with special attention for the assembly and function of the viral RNA-synthesising machinery and the evasion of cellular innate immune responses.",
    "date": "2017",
    "authors": [
        "Adriaan H. de Wilde",
        "Eric J. Snijder",
        "Marjolein Kikkert",
        "Martijn J. van Hemert"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral pathogenesis",
        "Middle East respiratory syndrome"
    ],
    "citation_count": "312",
    "reference_count": "258",
    "references": [
        "2166867592",
        "2132260239",
        "2104548316",
        "2025170735",
        "1973260880",
        "1993577573",
        "2119111857",
        "2112147913",
        "1966238900",
        "2195009776"
    ]
},{
    "id": "1993435091",
    "title": "Evidence of Airborne Transmission of the Severe Acute Respiratory Syndrome Virus",
    "abstract": "background There is uncertainty about the mode of transmission of the severe acute respiratory syndrome (SARS) virus. We analyzed the temporal and spatial distributions of cases in a large community outbreak of SARS in Hong Kong and examined the correlation of these data with the three-dimensional spread of a virus-laden aerosol plume that was modeled using studies of airflow dynamics. methods We determined the distribution of the initial 187 cases of SARS in the Amoy Gardens housing complex in 2003 according to the date of onset and location of residence. We then studied the association between the location (building, floor, and direction the apartment unit faced) and the probability of infection using logistic regression. The spread of the airborne, virus-laden aerosols generated by the index patient was modeled with the use of airflow-dynamics studies, including studies performed with the use of computational fluid-dynamics and multizone modeling. results The curves of the epidemic suggested a common source of the outbreak. All but 5 patients lived in seven buildings (A to G), and the index patient and more than half the other patients with SARS (99 patients) lived in building E. Residents of the floors at the middle and upper levels in building E were at a significantly higher risk than residents on lower floors; this finding is consistent with a rising plume of contaminated warm air in the air shaft generated from a middle-level apartment unit. The risks for the different units matched the virus concentrations predicted with the use of multizone modeling. The distribution of risk in buildings B, C, and D corresponded well with the three-dimensional spread of virus-laden aerosols predicted with the use of computational fluiddynamics modeling. conclusions Airborne spread of the virus appears to explain this large community outbreak of SARS, and future efforts at prevention and control must take into consideration the potential for airborne spread of this virus.",
    "date": "2004",
    "authors": [
        "Ignatius Tak Sun Yu",
        "Yuguo Li",
        "Tze Wai Wong",
        "Wilson Tam",
        "Andy T. Chan",
        "Joseph Hun Wei Lee",
        "Dennis Yiu Cheong Leung",
        "Thomas Ho"
    ],
    "related_topics": [
        "Airborne transmission",
        "Airborne disease",
        "Outbreak"
    ],
    "citation_count": "1,101",
    "reference_count": "18",
    "references": [
        "2131262274",
        "2129542667",
        "2038785086",
        "1990049863",
        "2096145431",
        "2463755683",
        "2123162799",
        "1977258390",
        "2102157604",
        "2084069113"
    ]
},{
    "id": "2792208289",
    "title": "Novel Vaccine Technologies: Essential Components of an Adequate Response to Emerging Viral Diseases",
    "abstract": "",
    "date": "2018",
    "authors": [
        "Barney S. Graham",
        "John R. Mascola",
        "Anthony S. Fauci"
    ],
    "related_topics": [
        "Viral Vaccine",
        "Plasmid",
        "MEDLINE"
    ],
    "citation_count": "69",
    "reference_count": "4",
    "references": [
        "2127435093",
        "2521436873",
        "2775374952",
        "2397894493"
    ]
},{
    "id": "3030422584",
    "title": "Potential effectiveness and safety of antiviral agents in children with coronavirus disease 2019: A rapid review and meta-analysis",
    "abstract": "Background The COVID-19 outbreak presents a new, life-threatening disease. Our aim was to assess the potential effectiveness and safety of antiviral agents for COVID-19 in children. Methods Electronic databases (MEDLINE, Embase, Web of Science, the Cochrane library, CBM, CNKI, and Wanfang Data) from their inception to March 31, 2020 were searched for randomized controlled trials (RCTs), clinical controlled trials and cohort studies of interventions with antiviral agents for children (less than 18 years of age) with COVID-19. Results A total of 23 studies with 6,008 patients were included. There was no direct evidence and all of evidence were indirect. The risks of bias in all studies were moderate to high in general. The effectiveness and safety of antiviral agents for children with COVID-19 is uncertain: For adults with COVID-19, lopinavir/ritonavir had no effect on mortality [risk ratio (RR) =0.77; 95% confidence interval (CI), 0.45 to 1.30]. Arbidol and hydroxychloroquine (HCQ) had no benefit on probability of negative PCR test (RR =1.27; 95% CI, 0.93 to 1.73; RR =0.93; 95% CI, 0.73 to 1.18) respectively. For adults with SARS, interferon was associated with reduced corticosteroid dose [weighted mean difference (WMD) = -0.14 g; 95% CI, -0.21 to -0.07] but had no effect on mortality (RR =0.72; 95% CI, 0.28 to 1.88); ribavirin did not reduce mortality (RR =0.68; 95% CI, 0.43 to 1.06) and was associated with high risk of severe adverse reactions; and oseltamivir had no effect on mortality (RR =0.87; 95% CI, 0.55 to 1.38). Ribavirin combined with interferon was also not effective in adults with MERS and associated with adverse reactions. Conclusions There is no evidence showing the effectiveness of antiviral agents for children with COVID-19, and the clinical efficacy of existing antiviral agents is still uncertain. We do not suggest clinical routine use of antivirals for COVID-19 in children, with the exception of clinical trials.",
    "date": "2020",
    "authors": [
        "Qianling Shi",
        "Qi Zhou",
        "Xia Wang",
        "Jing Liao",
        "Yang Yu",
        "Zijun Wang",
        "Shuya Lu",
        "Yanfang Ma",
        "Yangqin Xun",
        "Xufei Luo",
        "Weiguo Li",
        "Toshio Fukuoka",
        "Hyeong Sik Ahn",
        "Myeong Soo Lee",
        "Zhengxiu Luo",
        "Enmei Liu",
        "Yaolong Chen",
        "Qubei Li",
        "Kehu Yang",
        "Quanlin Guan"
    ],
    "related_topics": [
        "Randomized controlled trial",
        "Relative risk",
        "Clinical trial"
    ],
    "citation_count": "10",
    "reference_count": "45",
    "references": [
        "3001118548",
        "3001897055",
        "3003465021",
        "2156098321",
        "3004239190",
        "2098923148",
        "3005212621",
        "3010930696",
        "3000834295",
        "3012379316"
    ]
},{
    "id": "3023275846",
    "title": "Risk assessment of healthcare workers at the frontline against COVID-19",
    "abstract": "The novel coronavirus disease 2019 (COVID-19) is a global pandemic. Healthcare workers (HCWs) are on the frontline of treating patients infected with COVID-19. However, data related to its infection rate among HCWs are limited. The aim was to present evidence associated with the number of HCWs being infected with COVID-19 from most viral affected countries (Italy, China, United States, Spain, and France). Furthermore, we looked into the reasons for HCWs COVID 19 infections and strategies to overcome this problem. Early available evidence suggested that HCWs are being increasingly infected with the novel infection ranging from 15% to 18% and in some cases up to 20% of the infected population. Major factors for infection among HCWs include lack of understanding of the disease, inadequate use and availability of Personal Protective Equipment (PPE), uncertain diagnostic criteria, unavailability of diagnostic tests and psychological stress. Therefore the protection of HCWs by authorities should be prioritized through education and training, the readiness of staff, incentives, availability of PPEs, and psychological support.",
    "date": "2020",
    "authors": [
        "Saqib Ali",
        "Sara Noreen",
        "Imran Farooq",
        "Amr Bugshan",
        "Fahim Vohra"
    ],
    "related_topics": [
        "Personal protective equipment",
        "Pandemic",
        "Risk assessment"
    ],
    "citation_count": "50",
    "reference_count": "15",
    "references": [
        "3008028633",
        "3000834295",
        "3013648910",
        "3010865292",
        "3012556938",
        "3010300347",
        "3011762316",
        "3011341442",
        "2146460502",
        "3008698979"
    ]
},{
    "id": "2981657433",
    "title": "Severe Acute Respiratory Syndrome: Historical, Epidemiologic, and Clinical Features",
    "abstract": "Severe acute respiratory syndrome coronavirus (SARS-CoV), emerged from China and rapidly spread worldwide. Over 8098 people fell ill and 774 died before the epidemic ended in July 2003. Bats are likely an important reservoir for SARS-CoV. SARS-like CoVs have been detected in horseshoe bats and civet cats. The main mode of transmission of SARS-CoV is through inhalation of respiratory droplets. Faeco-oral transmission has been recorded. Strict infection control procedures with respiratory and contact precautions are essential. Fever and respiratory symptoms predominate, and diarrhea is common. Treatment involves supportive care. There are no specific antiviral treatments or vaccines available.",
    "date": "2019",
    "authors": [
        "David S.C. Hui",
        "Alimuddin Zumla"
    ],
    "related_topics": [
        "Transmission (medicine)",
        "Respiratory system",
        "Diarrhea"
    ],
    "citation_count": "322",
    "reference_count": "96",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2125251240",
        "2037454769",
        "1966238900",
        "2169198329",
        "2255243349"
    ]
},{
    "id": "2981752008",
    "title": "The Middle East Respiratory Syndrome (MERS)",
    "abstract": "The Middle East respiratory syndrome (MERS) is a novel lethal zoonotic disease of humans caused by the MERS coronavirus (MERS-CoV). Although MERS is endemic to the Middle East, travelers have exported MERS-CoV on return to their home countries. Clinical manifestations range from mild to severe acute respiratory disease and death. The elderly, immunocompromised, and those with chronic comorbid liver, lung, and hepatic conditions have a high mortality rate. There is no specific treatment. Person-to-person spread causes hospital and household outbreaks, and thus improved compliance with internationally recommended infection control protocols and rapid implementation of infection control measures are required.",
    "date": "2019",
    "authors": [
        "Esam I. Azhar",
        "David S.C. Hui",
        "Ziad A. Memish",
        "Christian Drosten",
        "Alimuddin Zumla"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus",
        "Mortality rate"
    ],
    "citation_count": "147",
    "reference_count": "55",
    "references": [
        "2166867592",
        "2107053896",
        "2138324310",
        "2769689735",
        "2108693332",
        "2565805236",
        "2149508011",
        "2791599184",
        "2255243349",
        "2160011624"
    ]
},{
    "id": "3000092258",
    "title": "Pneumonia in China: lack of information raises concerns among Hong Kong health workers",
    "abstract": "An outbreak of pneumonia of unknown cause in Wuhan, China, has prompted authorities in neighbouring Hong Kong, Macau, and Taiwan to step up border surveillance, amid fears that it could signal the emergence of a new and serious threat to public health. On 5 January local, provincial, and national health commissions reported a cluster of 59 reported cases centred around the South China Seafood Wholesale Market in Wuhan, a city of 11 million people and the capital of Hubei province. They had already ruled out known influenza viruses and the two coronaviruses known to cause severe acute respiratory illness (SARS) and Middle East respiratory syndrome. The limited information that has been released by mainland Chinese authorities is causing unease among the general population and healthcare workers in Hong Kong. The city has a strong collective memory of the SARS outbreak in 2003, which \u2026",
    "date": "2020",
    "authors": [
        "Jane Parr"
    ],
    "related_topics": [
        "China",
        "Population",
        "Public health"
    ],
    "citation_count": "26",
    "reference_count": "0",
    "references": []
},{
    "id": "3029903408",
    "title": "Knowledge, Attitudes, Impact, and Anxiety Regarding COVID-19 Infection Among the Public in China",
    "abstract": "Objectives: Sufficient knowledge and positive attitudes are crucial to the prevention of COVID-19. However, little is known about public awareness and attitudes regarding COVID-19 in China. The impact of COVID-19 on the societal well-being and anxiety levels of the public has never been documented. The aim of this study was to survey the knowledge, attitudes, impact, and anxiety levels of the people of China in relation to the COVID-19 outbreak. Method: A cross-sectional population survey using an online questionnaire was undertaken between Jan 24 and Feb 24, 2020. The study participants were residents of mainland China over the age of 18 years. The attitude items in this study measured the perceived threat of COVID-19 based on the Health Belief Model. Anxiety was measured with the State-Trait Anxiety Inventory (STAI), a self-reported questionnaire that measure both state (STAI-S), and trait anxiety (STAI-T) Results: A total of 2,446 completed responses were received. The mean and standard deviation (SD) for the total knowledge score was 20.3 (SD \u00b1 2.9) out of a possible score of 23. The social disruption and household economic impact were notable, particularly in provinces with higher cumulative confirmed cases. The majority of responses indicated a low perceived susceptibility of being infected (86.7% [95%CI 85.4-88.1]), with a fair proportion of respondents perceiving a higher severity (62.9% [95% CI 61.0-64.8]). The mean total impact score was 9.9 (SD \u00b1 3.8) out of a possible score of 15. The mean score for STAI-S was 48.7 (SD \u00b1 10.8), whereas the mean STAI-T score was 45.7 (SD \u00b1 8.5). By demographics, women reported significantly higher odds for higher levels of both STAI-S (OR = 1.67) and STAI-T (OR = 1.30) compared to men. People of a younger age were also more likely to experience higher STAI-S and STAI-T. Higher perceived susceptibility and severity and impact were strong predictors of higher levels of STAI-S and STAI-T. Conclusion: Our findings can assist in tailoring public communication to change people's knowledge and attitudes. The present study also underlined the importance of the promotion of mental health during infectious disease outbreaks to help in moderating the perceived threat, social and household economic impact, targeting the vulnerable segment of the population.",
    "date": "2020",
    "authors": [
        "Yulan Lin",
        "Zhijian Hu",
        "Haridah Alias",
        "Li Ping Wong"
    ],
    "related_topics": [
        "Anxiety",
        "Population",
        "Health belief model"
    ],
    "citation_count": "30",
    "reference_count": "21",
    "references": [
        "3008028633",
        "3004318991",
        "3008090866",
        "2999409984",
        "3004804052",
        "2101761001",
        "2498119267",
        "2077805027",
        "2001432119",
        "2079929038"
    ]
},{
    "id": "2442480670",
    "title": "Taking forward a 'ONE HEALTH' approach for turning the tide against The Middle East Respiratory Syndrome Coronavirus and other zoonotic pathogens with epidemic potential.",
    "abstract": "The appearance of novel pathogens of humans with epidemic potential and high mortality rates have threatened global health security for centuries. Over the past few decades new zoonotic infectious diseases of humans caused by pathogens arising from animal reservoirs have included West Nile virus, Yellow fever virus, Ebola virus, Nipah virus, Lassa Fever virus, Hanta virus, Dengue fever virus, Rift Valley fever virus, Crimean-Congo haemorrhagic fever virus, severe acute respiratory syndrome coronavirus, highly pathogenic avian influenza viruses, Middle East Respiratory Syndrome Coronavirus, and Zika virus. The recent Ebola Virus Disease epidemic in West Africa and the ongoing Zika Virus outbreak in South America highlight the urgent need for local, regional and international public health systems to be be more coordinated and better prepared. The One Health concept focuses on the relationship and interconnectedness between Humans, Animals and the Environment, and recognizes that the health and wellbeing of humans is intimately connected to the health of animals and their environment (and vice versa). Critical to the establishment of a One Health platform is the creation of a multidisciplinary team with a range of expertise including public health officers, physicians, veterinarians, animal husbandry specialists, agriculturalists, ecologists, vector biologists, viral phylogeneticists, and researchers to co-operate, collaborate to learn more about zoonotic spread between animals, humans and the environment and to monitor, respond to and prevent major outbreaks. We discuss the unique opportunities for Middle Eastern and African stakeholders to take leadership in building equitable and effective partnerships with all stakeholders involved in human and health systems to take forward a 'One Health' approach to control such zoonotic pathogens with epidemic potential.",
    "date": "2016",
    "authors": [
        "Alimuddin Zumla",
        "Osman Dar",
        "Richard Kock",
        "Matthew Muturi",
        "Francine Ntoumi",
        "Pontiano Kaleebu",
        "Macete Eusebio",
        "Sayoki Mfinanga",
        "Matthew Bates",
        "Peter Mwaba",
        "Rashid Ansumana",
        "Mishal Khan",
        "Abdulaziz N. Alagaili",
        "Matthew Cotten",
        "Esam I. Azhar",
        "Markus Maeurer",
        "Giuseppe Ippolito",
        "Eskild Petersen"
    ],
    "related_topics": [
        "Zika virus",
        "Ebola virus",
        "Dengue fever"
    ],
    "citation_count": "67",
    "reference_count": "33",
    "references": [
        "2166867592",
        "2138324310",
        "2565805236",
        "2149508011",
        "2145441153",
        "2119837294",
        "2167080692",
        "2217313808",
        "2268567012",
        "2003895765"
    ]
},{
    "id": "3031559976",
    "title": "Clinical and Epidemiological Characteristics of COVID-19 Patients in Chongqing China",
    "abstract": "Objectives: To study in-depth the clinical and epidemiological characteristics of pneumonia resulting from COVID-19 and provide evidence for effective public health decisions. Methods: This was a retrospective, single-center research study. Participants were enrolled from patients presenting at the Chongqing Public Health Medical Treatment Center from Jan 24 to Feb 7, 2020, and were confirmed as having COVID-19. Results: A total of 114 COVID-19 patients (99 mild, 4 severe, 11 critical) of which 56 (56/114; 49.1%) were male, 58 (58/114; 50.9%) were female with a mean age of 46.05 years. Twenty nine (29/114; 25.44%) patients suffered from chronic diseases. Neutrophils counts in 23.68% (27/114) of patients were abnormally low and abnormally high in 21.05% (24/114). Erythrocyte sedimentation rate and the C-reactive protein levels were abnormally elevated in 76.5% (62/81) and 62.9% (66/105) of patients, respectively. Creatine kinase isoenzymes (CK-MB), pro-brain natriuretic peptide (pro-BNP) and troponin levels were above the normal range in 7.10% (8/112), 66.7% (10/15), and 100% of patients, respectively. The percentage of patients in which the partial pressure of oxygen (PaO2)/fraction of inspired O2(FiO2) ratio exceeded 200 was 60%. A total of 91 (91/114; 79.82%) patients displayed severe bilateral pneumonia, 52 (52/114; 45.61%) exhibited ground-glass opacity, and pulmonary consolidation was observed in 4 (3.51%) patients. Differences in shortness of breath, insomnia, inappetence, the procalcitonin (PCT) levels, FiO2 and PaO2/FiO2 among the three groups were statistically significant (p < 0.05). Differences between the mild and severe groups was observed in neutrophil and lymphocyte counts, CD4 expression, and levels of C-reactive protein, alanine aminotransferase, aspartate aminotransferase and albumin (P < 0.05). Between the mild and critical groups, differences were observed in neutrophils, platelets, and CD4 expression (P < 0.05). A difference in C-reactive protein levels between severe and critical groups was also found (P < 0.05). Conclusions: In the majority of cases no gender differences were observed and mostly the symptoms were mild. Evidence of efficient human-to-human virus transmission was found. The elderly with comorbidities were more prone to develop into severe or critical illness. Age and comorbidity may be risk factors for poor outcome.",
    "date": "2020",
    "authors": [
        "Ao Yang",
        "Qian Qiu",
        "Xianghua Kong",
        "Yanyu Sun",
        "Tingying Chen",
        "Yujie Zuo",
        "Danfeng Yuan",
        "Wei Dai",
        "Jihong Zhou",
        "Anzhou Peng"
    ],
    "related_topics": [
        "Erythrocyte sedimentation rate",
        "Procalcitonin",
        "Pneumonia"
    ],
    "citation_count": "6",
    "reference_count": "20",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3003668884",
        "3003573988",
        "3005679569",
        "2999409984",
        "2999318660",
        "3006642361"
    ]
},{
    "id": "3023268903",
    "title": "Comparison of epidemiological variations in COVID-19 patients inside and outside of China - A meta-analysis",
    "abstract": "The objective of this study is to compare the epidemiological variations in COVID-19 patients reported in studies from inside and outside of China. We selected COVID-19 observational studies from eight countries, including, China, Italy, Australia, Canada, Korea, Taiwan, Singapore, and the USA, comprising a total of 13 studies and performed a meta-analysis for age, gender, fatality rate, and clinical symptoms of fever, cough, shortness of breath, and diarrhea. The meta-analysis shows that there are differences in symptoms and other characteristics reported by the patients of COVID-19 inside and outside China. Patients in China have a higher proportion of fever, cough, and shortness of breath as compared to patients outside of China. However, we found the opposite results for the gastrointestinal symptoms such as Diarrhea. Patients outside of China have a significantly higher proportion of Diarrhea as compared to patients within China. We also observed gender disparity among our studies, with the male population being more susceptible than the female population. Moreover, the analysis suggests that the fatality rate in China is relatively lower as compared to the fatality rate in other countries. These findings also suggest that the clinical symptoms of COVID-19 should not be generalized to fever, shortness of breath, and cough only but other symptoms such as diarrhea are also prevalent in patients with COVID-19.",
    "date": "2020",
    "authors": [
        "Ali Ahmed",
        "Areeba Ali",
        "Sana Hasan"
    ],
    "related_topics": [
        "Case fatality rate",
        "Epidemiology",
        "Diarrhea"
    ],
    "citation_count": "11",
    "reference_count": "25",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "2156098321",
        "2999409984",
        "3010338568",
        "3011559677",
        "3023787531"
    ]
},{
    "id": "3029135544",
    "title": "Fighting the Host Reaction to SARS-COv-2 in Critically Ill Patients: The Possible Contribution of Off-Label Drugs.",
    "abstract": "The severe acute respiratory syndrome coronavirus 2 (SARS-COv-2) is the etiologic agent of the 2019 coronavirus disease (COVID19). The majority of infected people presents flu like symptoms and among them 15-20% develops a severe interstitial pneumonitis (IP) that may eventually evolve in acute respiratory distress syndrome (ARDS). IP is caused by the viral glycoprotein spike (S) binding to the angiotensin converting enzyme 2 (ACE2) expressed on the surface of alveolar pneumocytes. The virus is recognized by the \"pattern recognition receptors\" (PRR) of the immune cells that release cytokines activating more immune cells that produce a large number of pro-inflammatory cytokines, tissue factors and vasoactive peptides. Affected patients might develop the \"cytokine storm syndrome,\" a fulminant and fatal hypercytokinaemia with multiorgan failure. In patients infected by SARS-COv-2 increase in T-helper 2 (TH2) cytokines (IL-4 and IL10) are reported in addition to the T-helper 1 (TH1) cytokines (IL1B, IFN\u03b3, IP10, and MCP1) previously detected in other coronavirus infections. Cytokines and other molecules involved in immune response and inflammation are conceivable therapeutic targets for IP and ARDS, improving symptoms and decreasing intensive care unit admissions. To this aim off label drugs may be used taking into consideration the window timing for immunosuppressive drugs in virus infected patients. Some off label therapeutic options and preclinical evidence drugs are herein considered.",
    "date": "2020",
    "authors": [
        "Stefania Scala",
        "Roberto Pacelli"
    ],
    "related_topics": [
        "Cytokine storm",
        "Coronavirus",
        "ARDS"
    ],
    "citation_count": "9",
    "reference_count": "72",
    "references": [
        "3001118548",
        "3009885589",
        "3008028633",
        "3012421327",
        "3005212621",
        "3011610993",
        "2999409984",
        "3012379316",
        "3006645647",
        "3008763357"
    ]
},{
    "id": "2414957595",
    "title": "[SARS--Severe Acute Respiratory syndrome].",
    "abstract": "",
    "date": "2003",
    "authors": [
        "P. Tuschy",
        "T. Welte",
        "R. Marre",
        "N. Suttorp",
        "J. Lorenz",
        "G. F\u00e4tkenheuer",
        "S. Ewig"
    ],
    "related_topics": [
        "Respiratory system",
        "Virology",
        "Medicine"
    ],
    "citation_count": "52",
    "reference_count": "0",
    "references": []
},{
    "id": "2766931063",
    "title": "MERS, SARS and other coronaviruses as causes of pneumonia",
    "abstract": "Human coronaviruses (HCoVs) have been considered to be relatively harmless respiratory pathogens in the past. However, after the outbreak of the severe acute respiratory syndrome (SARS) and emergence of the Middle East respiratory syndrome (MERS), HCoVs have received worldwide attention as important pathogens in respiratory tract infection. This review focuses on the epidemiology, pathogenesis and clinical characteristics among SARS-coronaviruses (CoV), MERS-CoV and other HCoV infections.",
    "date": "2018",
    "authors": [
        "Yudong Yin",
        "Richard G. Wunderink"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Pneumonia",
        "Respiratory tract"
    ],
    "citation_count": "685",
    "reference_count": "76",
    "references": [
        "2166867592",
        "2132260239",
        "2131262274",
        "2006434809",
        "2129542667",
        "2000714505",
        "2565805236",
        "2149508011",
        "1966238900",
        "2255243349"
    ]
},{
    "id": "1997954607",
    "title": "Molecular Evolution Analysis and Geographic Investigation of Severe Acute Respiratory Syndrome Coronavirus-Like Virus in Palm Civets at an Animal Market and on Farms",
    "abstract": "Massive numbers of palm civets were culled to remove sources for the reemergence of severe acute respiratory syndrome (SARS) in Guangdong Province, China, in January 2004, following SARS coronavirus detection in market animals. The virus was identified in all 91 palm civets and 15 raccoon dogs of animal market origin sampled prior to culling, but not in 1,107 palm civets later sampled at 25 farms, spread over 12 provinces, which were claimed to be the source of traded animals. Twenty-seven novel signature variation residues (SNVs) were identified on the spike gene and were analyzed for their phylogenetic relationships, based on 17 sequences obtained from animals in our study and from other published studies. Analysis indicated that the virus in palm civets at the live-animal market had evolved to infect humans. The evolutionary starting point was a prototype group consisting of three viral sequences of animal origin. Initially, seven SNV sites caused six amino acid changes, at positions 147, 228, 240, 479, 821, and 1080 of the spike protein, to generate low-pathogenicity viruses. One of these was linked to the first SARS patient in the 2003-2004 period. A further 14 SNVs caused 11 amino acid residue changes, at positions 360, 462, 472, 480, 487, 609, 613, 665, 743, 765, and 1163. The resulting high-pathogenicity groups were responsible for infections during the so-called early-phase epidemic of 2003. Finally, the remaining six SNVs caused four amino acid changes, at positions 227, 244, 344, and 778, which resulted in the group of viruses responsible for the global epidemic.",
    "date": "2005",
    "authors": [
        "Biao Kan",
        "Ming Wang",
        "Huaiqi Jing",
        "Huifang Xu",
        "Xiugao Jiang",
        "Meiying Yan",
        "Weili Liang",
        "Han Zheng",
        "Kanglin Wan",
        "Qiyong Liu",
        "Buyun Cui",
        "Yanmei Xu",
        "Enmin Zhang",
        "Hongxia Wang",
        "Jingrong Ye",
        "Guichang Li",
        "Machao Li",
        "Zhigang Cui",
        "Xiaobao Qi",
        "Kai Chen",
        "Lin Du",
        "Kai Gao",
        "Yu Teng Zhao",
        "Xiao Zhong Zou",
        "Yue Ju Feng",
        "Yu Fan Gao",
        "Rong Hai",
        "Dongzhen Yu",
        "Yi Guan",
        "Jianguo Xu"
    ],
    "related_topics": [
        "Coronavirus",
        "Disease reservoir",
        "Viverridae"
    ],
    "citation_count": "340",
    "reference_count": "33",
    "references": [
        "2104548316",
        "2129542667",
        "2116586125",
        "2169198329",
        "2134061616",
        "3140139051",
        "1990059132",
        "2038918691",
        "96734778",
        "1967669339"
    ]
},{
    "id": "2158887145",
    "title": "Sequence-based identification of microbial pathogens: a reconsideration of Koch's postulates.",
    "abstract": "Over 100 years ago, Robert Koch introduced his ideas about how to prove a causal relationship between a microorganism and a disease. Koch's postulates created a scientific standard for causal evidence that established the credibility of microbes as pathogens and led to the development of modern microbiology. In more recent times, Koch's postulates have evolved to accommodate a broader understanding of the host-parasite relationship as well as experimental advances. Techniques such as in situ hybridization, PCR, and representational difference analysis reveal previously uncharacterized, fastidious or uncultivated, microbial pathogens that resist the application of Koch's original postulates, but they also provide new approaches for proving disease causation. In particular, the increasing reliance on sequence-based methods for microbial identification requires a reassessment of the original postulates and the rationale that guided Koch and later revisionists. Recent investigations of Whipple's disease, human ehrlichiosis, hepatitis C, hantavirus pulmonary syndrome, and Kaposi's sarcoma illustrate some of these issues. A set of molecular guidelines for establishing disease causation with sequence-based technology is proposed, and the importance of the scientific concordance of evidence in supporting causal associations is emphasized.",
    "date": "1995",
    "authors": [
        "D N Fredericks",
        "D A Relman"
    ],
    "related_topics": [
        "Molecular Koch's postulates",
        "Koch's postulates",
        "Identification (biology)"
    ],
    "citation_count": "1,020",
    "reference_count": "109",
    "references": [
        "2032118018",
        "2050717506",
        "2131988453",
        "2006309458",
        "2032438721",
        "2066124462",
        "2047480444",
        "2320937221",
        "2005453259",
        "2039382131"
    ]
},{
    "id": "2121494157",
    "title": "Coronaviridae : a review of coronaviruses and toroviruses",
    "abstract": "From rags to riches, pauper to princess. Thus did Cinderella progress, literally overnight (well, three nights; Grimm & Grimm http://www.nationalgeographic.com/grimm/index2.html). Coronaviruses were described as being a \u201cvirology backwater\u201d, the SARS coronavirus (SARS-CoV; severe acute respiratory syndrome) likened to Cinderella, thrusting coronaviruses from the shadows to the spotlight in early 2003. Understandably, this is the view from a human disease standpoint; coronaviruses in humans are usually considered to be the cause of nothing more serious than the common cold. However, this group of viruses has long had a higher profile in the veterinary science field, most of our knowledge of coronaviruses being based on viruses of domesticated species \u2013 plus the mouse (Tab. 1). Most of the 40 000 000 000 chickens in the world annually succumb to infection by avian infectious bronchitis coronavirus (IBV), resulting in reduced production, including mortality. The death toll amongst newborn swine can be 90% when infected with porcine transmissible gastroenteritis coronavirus (TGEV). The names porcine haemagglutinating encephalomyelitis coronavirus (HEV) and porcine epidemic diarrhoea coronavirus (PEDV) tell their own story. Most of the coronaviruses replicate, at least initially, in either or both of the respiratory or enteric tracts (Tab. 1). Within a coronavirus species some variants may have a tropism for the respiratory tract, others for the enteric region, though usually causing pathology in only one of these regions. SARS-CoV might be an exception to this, it appearing to cause pathology in both tracts, although that might be strain dependent. The advent of SARS-CoV served as a reminder of an important aspect that we already knew about coronaviruses, namely that their host range is greater than was often supposed. One of the human coronaviruses, human coronavirus-OC43, is extremely similar genetically to bovine coronavirus (BCoV), suggesting that these viruses might be capable of infecting each other\u2019s recognised host. BCoV, under experimental conditions at least, infects and causes disease in turkeys. Canine enteric coronavirus (CECoV) Coronaviridae: a review of coronaviruses and toroviruses",
    "date": "2004",
    "authors": [
        "Dave Cavanagh"
    ],
    "related_topics": [
        "Coronavirus",
        "Bovine coronavirus",
        "Avian infectious bronchitis virus"
    ],
    "citation_count": "69",
    "reference_count": "257",
    "references": [
        "2025170735",
        "1966238900",
        "2134061616",
        "1976741900",
        "2159857626",
        "2127062009",
        "2171291163",
        "2097188280",
        "2029293367",
        "2988045179"
    ]
},{
    "id": "2068854215",
    "title": "Incidence and Outcomes of Acute Lung Injury",
    "abstract": "BACKGROUND Acute lung injury is a critical illness syndrome consisting of acute hypoxemic respiratory failure with bilateral pulmonary infiltrates that are not attributed to left atrial hypertension. Despite recent advances in our understanding of the mechanism and treatment of acute lung injury, its incidence and outcomes in the United States have been unclear. METHODS We conducted a prospective, population-based, cohort study in 21 hospitals in and around King County, Washington, from April 1999 through July 2000, using a validated screening protocol to identify patients who met the consensus criteria for acute lung injury. RESULTS A total of 1113 King County residents undergoing mechanical ventilation met the criteria for acute lung injury and were 15 years of age or older. On the basis of this figure, the crude incidence of acute lung injury was 78.9 per 100,000 person-years and the age-adjusted incidence was 86.2 per 100,000 person-years. The in-hospital mortality rate was 38.5 percent. The incidence of acute lung injury increased with age from 16 per 100,000 person-years for those 15 through 19 years of age to 306 per 100,000 person-years for those 75 through 84 years of age. Mortality increased with age from 24 percent for patients 15 through 19 years of age to 60 percent for patients 85 years of age or older (P<0.001). We estimate that each year in the United States there are 190,600 cases of acute lung injury, which are associated with 74,500 deaths and 3.6 million hospital days. CONCLUSIONS Acute lung injury has a substantial impact on public health, with an incidence in the United States that is considerably higher than previous reports have suggested.",
    "date": "2005",
    "authors": [
        "Gordon D. Rubenfeld",
        "Ellen Caldwell",
        "Eve Peabody",
        "Jim Weaver",
        "Diane P. Martin",
        "Margaret Neff",
        "Eric J. Stern",
        "Leonard D. Hudson"
    ],
    "related_topics": [
        "Lung injury",
        "Mortality rate",
        "Incidence (epidemiology)"
    ],
    "citation_count": "4,546",
    "reference_count": "31",
    "references": [
        "2597070792",
        "2049927822",
        "2768146862",
        "2145577370",
        "2161328469",
        "2333411966",
        "2143748013",
        "2093852073",
        "1964493140",
        "2027812057"
    ]
},{
    "id": "2328176404",
    "title": "Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach.",
    "abstract": "Methods of evaluating and comparing the performance of diagnostic tests are of increasing importance as new tests are developed and marketed. When a test is based on an observed variable that lies on a continuous or graded scale, an assessment of the overall value of the test can be made through the use of a receiver operating characteristic (ROC) curve. The curve is constructed by varying the cutpoint used to determine which values of the observed variable will be considered abnormal and then plotting the resulting sensitivities against the corresponding false positive rates. When two or more empirical curves are constructed based on tests performed on the same individuals, statistical analysis on differences between curves must take into account the correlated nature of the data. This paper presents a nonparametric approach to the analysis of areas under correlated ROC curves, by using the theory on generalized U-statistics to generate an estimated covariance matrix.",
    "date": "1988",
    "authors": [
        "Elizabeth R. DeLong",
        "David M. DeLong",
        "Daniel L. Clarke-Pearson"
    ],
    "related_topics": [
        "Receiver operating characteristic",
        "Nonparametric statistics",
        "Covariance matrix"
    ],
    "citation_count": "18,347",
    "reference_count": "12",
    "references": [
        "2157825442",
        "1968114652",
        "1515026043",
        "1990534247",
        "26510586",
        "2049172236",
        "81348628",
        "1593111636",
        "3107868771",
        "1965902853"
    ]
},{
    "id": "2326364273",
    "title": "Pulmonary-artery versus central venous catheter to guide treatment of acute lung injury.",
    "abstract": "Background The balance between the benefits and the risks of pulmonary-artery catheters (PACs) has not been established. Methods We evaluated the relationship of benefits and risks of PACs in 1000 patients with established acute lung injury in a randomized trial comparing hemodynamic management guided by a PAC with hemodynamic management guided by a central venous catheter (CVC) using an explicit management protocol. Mortality during the first 60 days before discharge home was the primary outcome. Results The groups had similar baseline characteristics. The rates of death during the first 60 days before discharge home were similar in the PAC and CVC groups (27.4 percent and 26.3 percent, respectively; P=0.69; absolute difference, 1.1 percent; 95 percent confidence interval, \u20134.4 to 6.6 percent), as were the mean (\u00b1SE) numbers of both ventilator-free days (13.2\u00b10.5 and 13.5\u00b10.5; P=0.58) and days not spent in the intensive care unit (12.0\u00b10.4 and 12.5\u00b10.5; P=0.40) to day 28. PAC-guided therapy did not impro...",
    "date": "2009",
    "authors": [
        "Lung"
    ],
    "related_topics": [
        "Lung injury",
        "Central venous catheter",
        "Intensive care unit"
    ],
    "citation_count": "762",
    "reference_count": "39",
    "references": [
        "2597070792",
        "2161328469",
        "2299836127",
        "2171467831",
        "2154390395",
        "1971267916",
        "2128252369",
        "2149134020",
        "2156967952",
        "1990483426"
    ]
},{
    "id": "1823772832",
    "title": "Has mortality from acute respiratory distress syndrome decreased over time?: A systematic review.",
    "abstract": "Rationale: It is commonly stated that mortality from acute respiratory distress syndrome (ARDS) and acute lung injury (ALI) is decreasing.Objectives: To systematically review the literature assessing ARDS mortality over time and to determine patient- and study-level factors independently associated with mortality.Methods: We searched multiple databases (MEDLINE, EMBASE, CINAHL, Cochrane CENTRAL) for prospective observational studies or randomized controlled trials (RCTs) published during the period 1984 to 2006 that enrolled 50 or more patients with ALI/ARDS and reported mortality. We pooled mortality estimates using random-effects meta-analysis and examined mortality trends before and after 1994 (when a consensus definition of ALI/ARDS was published) and factors associated with mortality using meta-regression models.Measurements and Main Results: Of 4,966 studies, 89 met inclusion criteria (53 observational, 36 RCTs). There was a total of 18,900 patients (mean age 51.6 years; 39% female). Overall pooled ...",
    "date": "2009",
    "authors": [
        "Jason Phua",
        "Joan R. Badia",
        "Neill K. J. Adhikari",
        "Jan O. Friedrich",
        "Robert A. Fowler",
        "Jeff M. Singh",
        "Damon C. Scales",
        "David R. Stather",
        "Amanda Li",
        "Andrew Jones",
        "David J. Gattas",
        "David Hallett",
        "George Tomlinson",
        "Thomas E. Stewart",
        "Niall D. Ferguson"
    ],
    "related_topics": [
        "Lung injury",
        "Respiratory distress",
        "ARDS"
    ],
    "citation_count": "963",
    "reference_count": "260",
    "references": [
        "2126930838",
        "2118858814",
        "1979423827",
        "2160691650",
        "2597070792",
        "1993397663",
        "2005775721",
        "2107328434",
        "2156267802",
        "2314787815"
    ]
},{
    "id": "1979469936",
    "title": "Tidal volume lower than 6 ml/kg enhances lung protection: role of extracorporeal carbon dioxide removal.",
    "abstract": "BACKGROUND Tidal hyperinflation may occur in patients with acute respiratory distress syndrome who are ventilated with a tidal volume (VT) of 6 ml/kg of predicted body weight develop a plateau pressure (PPLAT) of 28 < or = PPLAT < or = 30 cm H2O. The authors verified whether VT lower than 6 ml/kg may enhance lung protection and that consequent respiratory acidosis may be managed by extracorporeal carbon dioxide removal. METHODS PPLAT, lung morphology computed tomography, and pulmonary inflammatory cytokines (bronchoalveolar lavage) were assessed in 32 patients ventilated with a VT of 6 ml/kg. Data are provided as mean +/- SD or median and interquartile (25th and 75th percentile) range. In patients with 28 < or = PPLAT < or = 30 cm H2O (n = 10), VT was reduced from 6.3 +/- 0.2 to 4.2 +/- 0.3 ml/kg, and PPLAT decreased from 29.1 +/- 1.2 to 25.0 +/- 1.2 cm H2O (P < 0.001); consequent respiratory acidosis (Paco2 from 48.4 +/- 8.7 to 73.6 +/- 11.1 mmHg and pH from 7.36 +/- 0.03 to 7.20 +/- 0.02; P < 0.001) was managed by extracorporeal carbon dioxide removal. Lung function, morphology, and pulmonary inflammatory cytokines were also assessed after 72 h. RESULTS Extracorporeal assist normalized Paco2 (50.4 +/- 8.2 mmHg) and pH (7.32 +/- 0.03) and allowed use of VT lower than 6 ml/kg for 144 (84-168) h. The improvement of morphological markers of lung protection and the reduction of pulmonary cytokines concentration (P < 0.01) were observed after 72 h of ventilation with VT lower than 6 ml/kg. No patient-related complications were observed. CONCLUSIONS VT lower than 6 ml/Kg enhanced lung protection. Respiratory acidosis consequent to low VT ventilation was safely and efficiently managed by extracorporeal carbon dioxide removal.",
    "date": "2009",
    "authors": [
        "Pier Paolo Terragni",
        "Lorenzo Del Sorbo",
        "Luciana Mascia",
        "Rosario Urbino",
        "Erica L. Martin",
        "Alberto Birocco",
        "Chiara Faggiano",
        "Michael Quintel",
        "Luciano Gattinoni",
        "V Marco Ranieri"
    ],
    "related_topics": [
        "Tidal volume",
        "Respiratory acidosis",
        "Extracorporeal membrane oxygenation"
    ],
    "citation_count": "590",
    "reference_count": "41",
    "references": [
        "2597070792",
        "2161328469",
        "2128349740",
        "2333411966",
        "2154581887",
        "2317705795",
        "2113752525",
        "2168829312",
        "2121474530",
        "1967208670"
    ]
},{
    "id": "2113752525",
    "title": "Tidal hyperinflation during low tidal volume ventilation in acute respiratory distress syndrome.",
    "abstract": "Rationale: Tidal volume and plateau pressure limitation decreases mortality in acute respiratory distress syndrome. Computed tomography demonstrated a small, normally aerated compartment on the top of poorly aerated and nonaerated compartments that may be hyperinflated by tidal inflation.Objectives: We hypothesized that despite tidal volume and plateau pressure limitation, patients with a larger nonaerated compartment are exposed to tidal hyperinflation of the normally aerated compartment.Measurements and Main Results: Pulmonary computed tomography at end-expiration and end-inspiration was obtained in 30 patients ventilated with a low tidal volume (6 ml/kg predicted body weight). Cluster analysis identified 20 patients in whom tidal inflation occurred largely in the normally aerated compartment (69.9 \u00b1 6.9%; \u201cmore protected\u201d), and 10 patients in whom tidal inflation occurred largely within the hyperinflated compartments (63.0 \u00b1 12.7%; \u201cless protected\u201d). The nonaerated compartment was smaller and the norma...",
    "date": "2007",
    "authors": [
        "Pier Paolo Terragni",
        "Giulio Rosboch",
        "Andrea Tealdi",
        "Eleonora Corno",
        "Eleonora Menaldo",
        "Ottavio Davini",
        "Giovanni Gandini",
        "Peter Herrmann",
        "Luciana Mascia",
        "Michel Quintel",
        "Arthur S. Slutsky",
        "Luciano Gattinoni",
        "V. Marco Ranieri"
    ],
    "related_topics": [
        "Tidal volume",
        "Intensive care",
        "Mechanical ventilation"
    ],
    "citation_count": "800",
    "reference_count": "33",
    "references": [
        "2597070792",
        "2333411966",
        "2093852073",
        "2154581887",
        "2317705795",
        "2168829312",
        "1990202497",
        "2115303739",
        "2153339769",
        "1985671323"
    ]
},{
    "id": "2070070465",
    "title": "Epidemiology and outcome of acute lung injury in European intensive care units. Results from the ALIVE study.",
    "abstract": "Objectives To re-examine the epidemiology of acute lung injury (ALI) in European intensive care units (ICUs).",
    "date": "2004",
    "authors": [
        "Christian Brun-Buisson",
        "Cosetta Minelli",
        "Guido Bertolini",
        "Luca Brazzi",
        "Jorge Pimentel",
        "Klaus Lewandowski",
        "Julian Bion",
        "Jacques Andr\u00e9 Romand",
        "Jes\u00fas Villar",
        "Adalbj\u00f6rn Thorsteinsson",
        "Pierre Damas",
        "Apostolos Armaganidis",
        "Fran\u00e7ois Lemaire"
    ],
    "related_topics": [
        "Intensive care",
        "Lung injury",
        "Intensive care unit"
    ],
    "citation_count": "901",
    "reference_count": "44",
    "references": [
        "1973948212",
        "2597070792",
        "2107978811",
        "2161328469",
        "2128349740",
        "2093852073",
        "2140066904",
        "2043436644",
        "2136506501",
        "2083931054"
    ]
},{
    "id": "2168829312",
    "title": "Tidal Volume Reduction in Patients with Acute Lung Injury When Plateau Pressures Are Not High",
    "abstract": "Use of a volume- and pressure-limited mechanical ventilation strategy improves clinical outcomes of patients with acute lung injury and acute respiratory distress syndrome (ALI/ARDS). However, the extent to which tidal volumes and inspiratory airway pressures should be reduced to optimize clinical outcomes is a controversial topic. This article addresses the question, \u201cIs there a safe upper limit to inspiratory plateau pressure in patients with ALI/ARDS?\u201d We reviewed data from animal models with and without preexisting lung injury, studies of normal human respiratory system mechanics, and the results of five clinical trials of lung-protective mechanical ventilation strategies. We also present an original analysis of data from the largest of the five clinical trials. The available data from each of these assessments do not support the commonly held view that inspiratory plateau pressures of 30 to 35 cm H2O are safe. We could not identify a safe upper limit for plateau pressures in patients with ALI/ARDS.",
    "date": "2005",
    "authors": [
        "David N. Hager",
        "Jerry A. Krishnan",
        "Douglas L. Hayden",
        "Roy G. Brower"
    ],
    "related_topics": [
        "Lung injury",
        "Tidal volume",
        "Plateau pressure"
    ],
    "citation_count": "599",
    "reference_count": "45",
    "references": [
        "2597070792",
        "2143748013",
        "2120156715",
        "2024081693",
        "2167743972",
        "2333922183",
        "2147279870",
        "2009713463",
        "2153339769",
        "1766556848"
    ]
},{
    "id": "2074935456",
    "title": "Beyond Mortality: Future Clinical Research in Acute Lung Injury",
    "abstract": "Mortality in National Heart, Lung and Blood Institute-sponsored clinical trials of treatments for acute lung injury (ALI) has decreased dramatically during the past two decades. As a consequence, design of such trials based on a mortality outcome requires ever-increasing numbers of patients. Recognizing that advances in clinical trial design might be applicable to these trials and might allow trials with fewer patients, the National Heart, Lung and Blood Institute convened a workshop of extramural experts from several disciplines. The workshop assessed the current state of clinical research addressing ALI, identified research needs, and recommended: (1) continued performance of trials evaluating treatments of patients with ALI; (2) development of strategies to perform ALI prevention trials; (3) observational studies of patients without ALI undergoing prolonged mechanical ventilation; and (4) development of a standardized format for reporting methods, endpoints, and results of ALI trials.",
    "date": "2010",
    "authors": [
        "Roger G. Spragg",
        "Gordon R. Bernard",
        "William Checkley",
        "J. Randall Curtis",
        "Ognjen Gajic",
        "Gordon Guyatt",
        "Jesse Hall",
        "Elliott Israel",
        "Manu Jain",
        "Dale M. Needham",
        "Adrienne G. Randolph",
        "Gordon D. Rubenfeld",
        "David Schoenfeld",
        "B. Taylor Thompson",
        "Lorraine B. Ware",
        "Duncan Young",
        "Andrea L. Harabin"
    ],
    "related_topics": [
        "Lung injury",
        "Clinical study design",
        "Clinical trial"
    ],
    "citation_count": "286",
    "reference_count": "51",
    "references": [
        "2597070792",
        "2145053281",
        "2314787815",
        "2161328469",
        "2048760408",
        "2333411966",
        "1964493140",
        "2326364273",
        "1823772832",
        "2154390395"
    ]
},{
    "id": "2404280981",
    "title": "ff14SB: Improving the Accuracy of Protein Side Chain and Backbone Parameters from ff99SB",
    "abstract": "Molecular mechanics is powerful for its speed in atomistic simulations, but an accurate force field is required. The Amber ff99SB force field improved protein secondary structure balance and dynamics from earlier force fields like ff99, but weaknesses in side chain rotamer and backbone secondary structure preferences have been identified. Here, we performed a complete refit of all amino acid side chain dihedral parameters, which had been carried over from ff94. The training set of conformations included multidimensional dihedral scans designed to improve transferability of the parameters. Improvement in all amino acids was obtained as compared to ff99SB. Parameters were also generated for alternate protonation states of ionizable side chains. Average errors in relative energies of pairs of conformations were under 1.0 kcal/mol as compared to QM, reduced 35% from ff99SB. We also took the opportunity to make empirical adjustments to the protein backbone dihedral parameters as compared to ff99SB. Multiple sm...",
    "date": "2015",
    "authors": [
        "James A. Maier",
        "Carmenza Martinez",
        "Koushik Kasavajhala",
        "Lauren Wickstrom",
        "Kevin E. Hauser",
        "Carlos Simmerling"
    ],
    "related_topics": [
        "Side chain",
        "Dihedral angle",
        "Protein secondary structure"
    ],
    "citation_count": "3,819",
    "reference_count": "81",
    "references": [
        "2022950330",
        "2118233996",
        "2122199548",
        "2067174909",
        "2144288821",
        "2161605421",
        "2332712348",
        "2060872117",
        "1976499671",
        "2035266068"
    ]
},{
    "id": "2060809301",
    "title": "SWISS-MODEL: an automated protein homology-modeling server",
    "abstract": "SWISS-MODEL (http://swissmodel.expasy.org) is a server for automated comparative modeling of three-dimensional (3D) protein structures. It pioneered the field of automated modeling starting in 1993 and is the most widely-used free web-based automated modeling facility today. In 2002 the server computed 120 000 user requests for 3D protein models. SWISS-MODEL provides several levels of user interaction through its World Wide Web interface: in the 'first approach mode' only an amino acid sequence of a protein is submitted to build a 3D model. Template selection, alignment and model building are done completely automated by the server. In the 'alignment mode', the modeling process is based on a user-defined target-template alignment. Complex modeling tasks can be handled with the 'project mode' using DeepView (Swiss-PdbViewer), an integrated sequence-to-structure workbench. All models are sent back via email with a detailed modeling report. WhatCheck analyses and ANOLEA evaluations are provided optionally. The reliability of SWISS-MODEL is continuously evaluated in the EVA-CM project. The SWISS-MODEL server is under constant development to improve the successful implementation of expert knowledge into an easy-to-use server.",
    "date": "2003",
    "authors": [
        "Torsten Schwede",
        "J\u00fcrgen Kopp",
        "Nicolas Guex",
        "Manuel C. Peitsch"
    ],
    "related_topics": [
        "Application server",
        "Interface (Java)",
        "Workbench"
    ],
    "citation_count": "6,024",
    "reference_count": "32",
    "references": [
        "2158714788",
        "2055043387",
        "2015642465",
        "2148853951",
        "2065283382",
        "2108401170",
        "2114520383",
        "2088933990",
        "2014981059",
        "2150155770"
    ]
},{
    "id": "1982533785",
    "title": "Structure of SARS Coronavirus Spike Receptor-Binding Domain Complexed with Receptor",
    "abstract": "The spike protein (S) of SARS coronavirus (SARS-CoV) attaches the virus to its cellular receptor, angiotensin-converting enzyme 2 (ACE2). A defined receptor-binding domain (RBD) on S mediates this interaction. The crystal structure at 2.9 angstrom resolution of the RBD bound with the peptidase domain of human ACE2 shows that the RBD presents a gently concave surface, which cradles the N-terminal lobe of the peptidase. The atomic details at the interface between the two proteins clarify the importance of residue changes that facilitate efficient cross-species infection and human-to-human transmission. The structure of the RBD suggests ways to make truncated disulfide-stabilized RBD variants for use in the design of coronavirus vaccines.",
    "date": "2005",
    "authors": [
        "Fang Li",
        "Wenhui Li",
        "Michael Farzan",
        "Stephen C. Harrison"
    ],
    "related_topics": [
        "Coronavirus",
        "Protein structure",
        "Binding site"
    ],
    "citation_count": "1,547",
    "reference_count": "32",
    "references": [
        "2104548316",
        "2025170735",
        "2116586125",
        "1966238900",
        "2169198329",
        "2134061616",
        "1990059132",
        "2038918691",
        "2146476111",
        "96734778"
    ]
},{
    "id": "3021832855",
    "title": "Transmission and evolution of the Middle East respiratory syndrome coronavirus in Saudi Arabia: A descriptive genomic study",
    "abstract": "Methods Full genome deep sequencing was done on nucleic acid extracted directly from PCR-confi rmed clinical samples. Viral genomes were obtained from 21 MERS cases of which 13 had 100%, four 85\u201395%, and four 30\u201350% genome coverage. Phylogenetic analysis of the 21 sequences, combined with nine published MERS-CoV genomes, was done. Findings Three distinct MERS-CoV genotypes were identifi ed in Riyadh. Phylogeographic analyses suggest the MERSC oV zoonotic reservoir is geographically disperse. Selection analysis of the MERS-CoV genomes reveals the expected accumulation of genetic diversity including changes in the S protein. The genetic diversity in the Al-Hasa cluster suggests that the hospital outbreak might have had more than one virus introduction. Interpretation We present the largest number of MERS-CoV genomes (21) described so far. MERS-CoV full genome sequences provide greater detail in tracking transmission. Multiple introductions of MERS-C oV are identifi ed and suggest lower R0 values. Transmission within Saudi Arabia is consistent with either movement of an animal reservoir, animal products, or movement of infected people. Further defi nition of the exposures responsible for the sporadic",
    "date": "2012",
    "authors": [
        "Matthew Cotten",
        "Simon J. Watson",
        "Paul Kellam",
        "Abdullah A. Al-Rabeeah",
        "Hatem Q. Makhdoom",
        "Abdullah Assiri",
        "Jaffar A. Al-Tawfiq",
        "Rafat F. Alhakeem",
        "Hossam Madani",
        "Fahad A. AlRabiah",
        "Sami Al Hajjar",
        "Wafa N. Al-Nassir",
        "Ali Albarrak",
        "Hesham Flemban",
        "Hanan H. Balkhy",
        "Sarah Alsubaie",
        "Anne L. Palser",
        "Astrid Gall",
        "Rachael Bashford-Rogers",
        "Andrew Rambaut",
        "Alimuddin I. Zumla",
        "Ziad Memish"
    ],
    "related_topics": [
        "Genome",
        "Genetic diversity",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "333",
    "reference_count": "0",
    "references": []
},{
    "id": "2126080553",
    "title": "Evidence for a common evolutionary origin of coronavirus spike protein receptor-binding subunits",
    "abstract": "Among different coronavirus genera, the receptor-binding S1 subunits of their spike proteins differ in primary, secondary, and tertiary structures. This study identified shared structural topologies (connectivity of secondary structural elements) in S1 domains of different coronavirus genera. The results suggest that coronavirus S1 subunits share a common evolutionary origin but have attained diverse sequences and structures following extensive divergent evolution. The results also increase understanding of the structures and functions of coronavirus S1 domains whose tertiary structures are currently unknown.",
    "date": "2012",
    "authors": [
        "Fang Li"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral structural protein",
        "Virus genetics"
    ],
    "citation_count": "138",
    "reference_count": "11",
    "references": [
        "2046153984",
        "1982533785",
        "2169150541",
        "2155479906",
        "2143901293",
        "2137268987",
        "2124777268",
        "2012106669",
        "2165167900",
        "1971290134"
    ]
},{
    "id": "3000376083",
    "title": "Mystery virus found in Wuhan resembles bat viruses but not SARS, Chinese scientist says",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Dennis Normile"
    ],
    "related_topics": [
        "Virus",
        "Virology",
        "Biology"
    ],
    "citation_count": "5",
    "reference_count": "0",
    "references": []
},{
    "id": "2133979383",
    "title": "Infectious Diseases Society of America/American Thoracic Society Consensus Guidelines on the Management of Community-Acquired Pneumonia in Adults",
    "abstract": "Lionel A. Mandell, Richard G. Wunderink, Antonio Anzueto, John G. Bartlett, G. Douglas Campbell, Nathan C. Dean, Scott F. Dowell, Thomas M. File, Jr. Daniel M. Musher, Michael S. Niederman, Antonio Torres, and Cynthia G. Whitney McMaster University Medical School, Hamilton, Ontario, Canada; Northwestern University Feinberg School of Medicine, Chicago, Illinois; University of Texas Health Science Center and South Texas Veterans Health Care System, San Antonio, and Michael E. DeBakey Veterans Affairs Medical Center and Baylor College of Medicine, Houston, Texas; Johns Hopkins University School of Medicine, Baltimore, Maryland; Division of Pulmonary, Critical Care, and Sleep Medicine, University of Mississippi School of Medicine, Jackson; Division of Pulmonary and Critical Care Medicine, LDS Hospital, and University of Utah, Salt Lake City, Utah; Centers for Disease Control and Prevention, Atlanta, Georgia; Northeastern Ohio Universities College of Medicine, Rootstown, and Summa Health System, Akron, Ohio; State University of New York at Stony Brook, Stony Brook, and Department of Medicine, Winthrop University Hospital, Mineola, New York; and Cap de Servei de Pneumologia i Allergia Respiratoria, Institut Clinic del Torax, Hospital Clinic de Barcelona, Facultat de Medicina, Universitat de Barcelona, Institut d\u2019Investigacions Biomediques August Pi i Sunyer, CIBER CB06/06/0028, Barcelona, Spain.",
    "date": "2007",
    "authors": [
        "Lionel A. Mandell",
        "Richard G. Wunderink",
        "Antonio Anzueto",
        "John G. Bartlett",
        "G. Douglas Campbell",
        "Nathan C. Dean",
        "Scott F. Dowell",
        "Daniel M. Musher",
        "Michael S. Niederman",
        "Antonio Torres",
        "Cynthia G. Whitney",
        "Michael E. DeBakey Veterans"
    ],
    "related_topics": [
        "Veterans Affairs",
        "MEDLINE",
        "Library science"
    ],
    "citation_count": "7,169",
    "reference_count": "333",
    "references": [
        "1980717583",
        "2597070792",
        "1886211768",
        "2129542667",
        "2322121630",
        "2163814324",
        "1994307831",
        "2320270386",
        "2550507245",
        "2123324969"
    ]
},{
    "id": "2065974896",
    "title": "Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls.",
    "abstract": "Most studies have some missing data. Jonathan Sterne and colleagues describe the appropriate use and reporting of the multiple imputation approach to dealing with them",
    "date": "2009",
    "authors": [
        "Jonathan A C Sterne",
        "Ian R White",
        "John B Carlin",
        "Michael Spratt",
        "Patrick Royston",
        "Michael G Kenward",
        "Angela M Wood",
        "James R Carpenter"
    ],
    "related_topics": [
        "Missing data",
        "Research design",
        "MEDLINE"
    ],
    "citation_count": "4,724",
    "reference_count": "24",
    "references": [
        "2105625949",
        "2044758663",
        "1550443206",
        "3022423927",
        "2118502261",
        "2161375627",
        "2113559481",
        "2049977108",
        "1973907010",
        "1852065298"
    ]
},{
    "id": "2159340685",
    "title": "Clinical findings in 111 cases of influenza A (H7N9) virus infection",
    "abstract": "Background During the spring of 2013, a novel avian-origin influenza A (H7N9) virus emerged and spread among humans in China. Data were lacking on the clinical characteristics of the infections caused by this virus. Methods Using medical charts, we collected data on 111 patients with laboratory-confirmed avian-origin influenza A (H7N9) infection through May 10, 2013. Results Of the 111 patients we studied, 76.6% were admitted to an intensive care unit (ICU), and 27.0% died. The median age was 61 years, and 42.3% were 65 years of age or older; 31.5% were female. A total of 61.3% of the patients had at least one underlying medical condition. Fever and cough were the most common presenting symptoms. On admission, 108 patients (97.3%) had findings consistent with pneumonia. Bilateral ground-glass opacities and consolidation were the typical radiologic findings. Lymphocytopenia was observed in 88.3% of patients, and thrombocytopenia in 73.0%. Treatment with antiviral drugs was initiated in 108 patients (97.3%)...",
    "date": "2013",
    "authors": [
        "Hai-Nv Gao",
        "Hong-Zhou Lu",
        "Bin Cao",
        "Bin Du",
        "Hong Shang",
        "Jian-He Gan",
        "Shui-Hua Lu",
        "Yi-Da Yang",
        "Qiang Fang",
        "Yin-Zhong Shen",
        "Xiu-Ming Xi",
        "Qin Gu",
        "Xian-Mei Zhou",
        "Hong-Ping Qu",
        "Zheng Yan",
        "Fang-Ming Li",
        "Wei Zhao",
        "Zhan-Cheng Gao",
        "Guang-Fa Wang",
        "Ling-Xiang Ruan",
        "Wei-Hong Wang",
        "Jun Ye",
        "Hui-Fang Cao",
        "Xing-Wang Li",
        "Wen-Hong Zhang",
        "Xu-Chen Fang",
        "Jian He",
        "Wei-Feng Liang",
        "Juan Xie",
        "Mei Zeng",
        "Xian-Zheng Wu",
        "Jun Li",
        "Qi Xia",
        "Zhao-Chen Jin",
        "Qi Chen",
        "Chao Tang",
        "Zhi-Yong Zhang",
        "Bao-Min Hou",
        "Zhi-Xian Feng",
        "Ji-Fang Sheng",
        "Nan-Shan Zhong",
        "Lan-Juan Li"
    ],
    "related_topics": [
        "Pneumonia",
        "Intensive care unit",
        "Lymphocytopenia"
    ],
    "citation_count": "773",
    "reference_count": "17",
    "references": [
        "2106173155",
        "2105226322",
        "2058144955",
        "1523679951",
        "2162384187",
        "2187856049",
        "1971662199",
        "2318445116",
        "2088402140",
        "2009145867"
    ]
},{
    "id": "2091139031",
    "title": "Oseltamivir for influenza in adults and children: systematic review of clinical study reports and summary of regulatory comments.",
    "abstract": "Objective To describe the potential benefits and harms of oseltamivir by reviewing all clinical study reports (or similar document when no clinical study report exists) of randomised placebo controlled trials and regulatory comments (\"regulatory information\"). Design Systematic review of regulatory information. Data sources Clinical study reports, trial registries, electronic databases, regulatory archives, and correspondence with manufacturers. Eligibility criteria for selecting studies Randomised placebo controlled trials on adults and children who had confirmed or suspected exposure to natural influenza. Main outcome measures Time to first alleviation of symptoms, influenza outcomes, complications, admissions to hospital, and adverse events in the intention to treat population. Results From the European Medicines Agency and Roche, we obtained clinical study reports for 83 trials. We included 23 trials in stage 1 (reliability and completeness screen) and 20 in stage 2 (formal analysis). In treatment trials on adults, oseltamivir reduced the time to first alleviation of symptoms by 16.8 hours (95% confidence interval 8.4 to 25.1 hours, P<0.001). There was no effect in children with asthma, but there was an effect in otherwise healthy children (mean difference 29 hours, 95% confidence interval 12 to 47 hours, P=0.001). In treatment trials there was no difference in admissions to hospital in adults (risk difference 0.15%, 95% confidence interval -0.91% to 0.78%, P=0.84) and sparse data in children and for prophylaxis. In adult treatment trials, oseltamivir reduced investigator mediated unverified pneumonia (risk difference 1.00%, 0.22% to 1.49%; number needed to treat to benefit (NNTB) 100, 95% confidence interval 67 to 451). The effect was not statistically significant in the five trials that used a more detailed diagnostic form for \"pneumonia,\" and no clinical study reports reported laboratory or diagnostic confirmation of \"pneumonia.\" The effect on unverified pneumonia in children and for prophylaxis was not significant. There was no significant reduction in risk of unverified bronchitis, otitis media, sinusitis, or any complication classified as serious or that led to study withdrawal. 14 of 20 trials prompted participants to self report all secondary illnesses to an investigator. Oseltamivir in the treatment of adults increased the risk of nausea (risk difference 3.66%, 0.90% to 7.39%; number needed to treat to harm (NNTH) 28, 95% confidence interval 14 to 112) and vomiting (4.56%, 2.39% to 7.58%; 22, 14 to 42). In treatment of children, oseltamivir induced vomiting (5.34%, 1.75% to 10.29%; 19, 10 to 57). In prophylaxis trials, oseltamivir reduced symptomatic influenza in participants by 55% (3.05%, 1.83% to 3.88%; NNTB 33, 26 to 55) and households (13.6%, 9.52% to 15.47%; NNTB 7, 6 to 11) based on one study, but there was no significant effect on.",
    "date": "2014",
    "authors": [
        "Tom Jefferson",
        "Mark Jones",
        "Peter Doshi",
        "Elizabeth A Spencer",
        "Igho Onakpoya",
        "Carl J Heneghan"
    ],
    "related_topics": [
        "Number needed to treat",
        "Absolute risk reduction",
        "Intention-to-treat analysis"
    ],
    "citation_count": "480",
    "reference_count": "21",
    "references": [
        "1598602811",
        "2101110089",
        "2104397822",
        "2093867498",
        "1998616119",
        "2102355184",
        "2048679896",
        "2044338376",
        "2149955368",
        "1979485633"
    ]
},{
    "id": "2103645914",
    "title": "Net Reclassification Improvement: Computation, Interpretation, and Controversies: A Literature Review and Clinician's Guide",
    "abstract": "The net reclassification improvement (NRI) is an increasingly popular measure for evaluating improvements in risk predictions. This article details a review of 67 publications in high-impact general clinical journals that considered the NRI. Incomplete reporting of NRI methods, incorrect calculation, and common misinterpretations were found. To aid improved applications of the NRI, the article elaborates on several aspects of the computation and interpretation in various settings. Limitations and controversies are discussed, including the effect of miscalibration of prediction models, the use of the continuous NRI and \u201cclinical NRI,\u201d and the relation with decision analytic measures. A systematic approach toward presenting NRI analysis is proposed: Detail and motivate the methods used for computation of the NRI, use clinically meaningful risk cutoffs for the category-based NRI, report both NRI components, address issues of calibration, and do not interpret the overall NRI as a percentage of the study population reclassified. Promising NRI findings need to be followed with decision analytic or formal cost-effectiveness evaluations.",
    "date": "2014",
    "authors": [
        "Maarten J G Leening",
        "Moniek M Vedder",
        "Jacqueline C M Witteman",
        "Michael J Pencina",
        "Ewout W Steyerberg"
    ],
    "related_topics": [
        "Predictive modelling",
        "Actuarial science",
        "Relation (database)"
    ],
    "citation_count": "483",
    "reference_count": "135",
    "references": [
        "2337109902",
        "2131099415",
        "2118310760",
        "2105397247",
        "3021842026",
        "2477872031",
        "2112316706",
        "2297716127",
        "2119910794",
        "2106421416"
    ]
},{
    "id": "2948483377",
    "title": "Disease severity and clinical outcomes of community-acquired pneumonia caused by non-influenza respiratory viruses in adults: a multicentre prospective registry study from the CAP-China Network.",
    "abstract": "Although broad knowledge of influenza viral pneumonia has been established, the significance of non-influenza respiratory viruses in community-acquired pneumonia (CAP) and their impact on clinical outcomes remains unclear, especially in the non-immunocompromised adult population. Hospitalised immunocompetent patients with CAP were prospectively recruited from 34 hospitals in mainland China. Respiratory viruses were detected by molecular methods. Comparisons were conducted between influenza and non-influenza viral infection groups. In total, 915 out of 2336 adult patients with viral infection were enrolled in the analysis, with influenza virus (28.4%) the most frequently detected virus, followed by respiratory syncytial virus (3.6%), adenovirus (3.3%), human coronavirus (3.0%), parainfluenza virus (2.2%), human rhinovirus (1.8%) and human metapneumovirus (1.5%). Non-influenza viral infections accounted for 27.4% of viral pneumonia. Consolidation was more frequently observed in patients with adenovirus infection. The occurrence of complications such as sepsis (40.1% versus 39.6%; p=0.890) and hypoxaemia (40.1% versus 37.2%; p=0.449) during hospitalisation in the influenza viral infection group did not differ from that of the non-influenza viral infection group. Compared with influenza virus infection, the multivariable adjusted odds ratios of CURB-65 (confusion, urea >7\u2005mmol\u00b7L\u22121, respiratory rate \u226530\u2005breaths\u00b7min\u22121, blood pressure The high incidence of complications in non-influenza viral pneumonia and similar impact of non-influenza respiratory viruses relative to influenza virus on disease severity and outcomes suggest more attention should be given to CAP caused by non-influenza respiratory viruses.",
    "date": "2019",
    "authors": [
        "Fei Zhou",
        "Yimin Wang",
        "Yingmei Liu",
        "Xuedong Liu",
        "Li Gu",
        "Xiaoju Zhang",
        "Zenghui Pu",
        "Guoru Yang",
        "Bo Liu",
        "Qingrong Nie",
        "Bing Xue",
        "Jing Feng",
        "Qiang Guo",
        "Jianhua Liu",
        "Hong Fan",
        "Jin Chen",
        "Yongxiang Zhang",
        "Zhenyang Xu",
        "Min Pang",
        "Yu Chen",
        "Xiuhong Nie",
        "Zhigang Cai",
        "Jinfu Xu",
        "Kun Peng",
        "Xiangxin Li",
        "Pingchao Xiang",
        "Zuoqing Zhang",
        "Shujuan Jiang",
        "Xin Su",
        "Jie Zhang",
        "Yanming Li",
        "Xiuhong Jin",
        "Rongmeng Jiang",
        "Jianping Dong",
        "Yuanlin Song",
        "Hong Zhou",
        "Chen Wang",
        "Bin Cao"
    ],
    "related_topics": [
        "Viral pneumonia",
        "Community-acquired pneumonia",
        "Pneumonia"
    ],
    "citation_count": "28",
    "reference_count": "68",
    "references": [
        "2280404143",
        "2133979383",
        "2000714505",
        "2892275685",
        "2133440505",
        "2114699265",
        "2605374894",
        "2809930572",
        "2141475184",
        "2606248635"
    ]
},{
    "id": "2155020492",
    "title": "Incidence and characteristics of viral community-acquired pneumonia in adults",
    "abstract": "Background: In adults, viral causes of communityacquired pneumonia (CAP) are poorly characterised. The aims of this study were to characterise the viral aetiology of CAP in adults by using an extensive array of viral diagnostic tests and to compare the characteristics of viral pneumonia with those of pneumococcal pneumonia. Methods: Adults admitted to Christchurch Hospital over a 1-year period with CAP were included in the study. Microbiological testing methods included blood and sputum cultures, urinary antigen testing for Streptococcus pneumoniae and Legionella pneumophila, antibody detection in paired sera and detection of respiratory viruses in nasopharyngeal swabs by immunofluorescence, culture and PCR. Results: Of 304 patients with CAP, a viral diagnosis was made in 88 (29%), with rhinoviruses and influenza A being the most common. Two or more pathogens were detected in 49 (16%) patients, 45 of whom had mixed viral and bacterial infections. There were no reliable clinical predictors of viral pneumonia, although several variables were independently associated with some aetiologies. The presence of myalgia was associated with pneumonia caused by any respiratory virus (OR 3.62, 95% CI 1.29 to 10.12) and influenza pneumonia (OR 190.72, 95% CI 3.68 to 9891.91). Mixed rhinovirus/pneumococcal infection was associated with severe disease. Conclusions: Virus-associated CAP is common in adults. Polymicrobial infections involving bacterial and viral pathogens are frequent and may be associated with severe pneumonia.",
    "date": "2007",
    "authors": [
        "Lance C Jennings",
        "Trevor P Anderson",
        "Kirsten A Beynon",
        "Alvin Chua",
        "Richard Tr Laing",
        "Anja M Werno",
        "Sheryl A Young",
        "Stephen T Chambers",
        "David R Murdoch"
    ],
    "related_topics": [
        "Pneumococcal pneumonia",
        "Viral pneumonia",
        "Pneumonia"
    ],
    "citation_count": "472",
    "reference_count": "40",
    "references": [
        "2320270386",
        "2123324969",
        "2102361557",
        "1523679951",
        "2167080692",
        "2142230428",
        "2107932739",
        "2154385325",
        "2054703106",
        "2262679633"
    ]
},{
    "id": "1975461687",
    "title": "A question of self-preservation: immunopathology in influenza virus infection.",
    "abstract": "Influenza A viruses that circulate normally in the human population cause a debilitating, though generally transient, illness that is sometimes fatal, particularly in the elderly. Severe complications arising from pandemic influenza or the highly pathogenic avian H5N1 viruses are often associated with rapid, massive inflammatory cell infiltration, acute respiratory distress, reactive hemophagocytosis and multiple organ involvement. Histological and pathological indicators strongly suggest a key role for an excessive host response in mediating at least some of this pathology. Here, we review the current literature on how various effector arms of the immune system can act deleteriously to initiate or exacerbate pathological damage in this viral pneumonia. Generally, the same immunological factors mediating tissue damage during the anti-influenza immune response are also critical for efficient elimination of virus, thereby posing a significant challenge in the design of harmless yet effective therapeutic strategies for tackling influenza virus.",
    "date": "2007",
    "authors": [
        "Nicole L La Gruta",
        "Katherine Kedzierska",
        "John Stambas",
        "Peter C Doherty"
    ],
    "related_topics": [
        "Influenza A virus",
        "Influenza A virus subtype H5N1",
        "Respiratory infection"
    ],
    "citation_count": "488",
    "reference_count": "98",
    "references": [
        "1523679951",
        "1996311210",
        "2172466148",
        "2072237100",
        "2122399224",
        "2052374402",
        "177909858",
        "2107937020",
        "2092073971",
        "2093983981"
    ]
},{
    "id": "2900850632",
    "title": "Respiratory Viral Infection-Induced Microbiome Alterations and Secondary Bacterial Pneumonia.",
    "abstract": "Influenza and other respiratory viral infections are the most common type of acute respiratory infection. Viral infections predispose patients to secondary bacterial infections, which often have a more severe clinical course. The mechanisms underlying post-viral bacterial infections are complex, and include multifactorial processes mediated by interactions between viruses, bacteria, and the host immune system. Studies over the past 15 years have demonstrated that unique microbial communities reside on the mucosal surfaces of the gastrointestinal tract and the respiratory tract, which have both direct and indirect effects on host defense against viral infections. In addition, antiviral immune responses induced by acute respiratory infections such as influenza are associated with changes in microbial composition and function (\"dysbiosis\") in the respiratory and gastrointestinal tract, which in turn may alter subsequent immune function against secondary bacterial infection or alter the dynamics of inter-microbial interactions, thereby enhancing the proliferation of potentially pathogenic bacterial species. In this review, we summarize the literature on the interactions between host microbial communities and host defense, and how influenza, and other acute respiratory viral infections disrupt these interactions, thereby contributing to the pathogenesis of secondary bacterial infections.",
    "date": "2018",
    "authors": [
        "Shigeo Hanada",
        "Mina Pirzadeh",
        "Kyle Y. Carver",
        "Jane C. Deng"
    ],
    "related_topics": [
        "Respiratory infection",
        "Dysbiosis",
        "Bacterial pneumonia"
    ],
    "citation_count": "169",
    "reference_count": "146",
    "references": [
        "2128769815",
        "2073332363",
        "2112166111",
        "2148958087",
        "2107369528",
        "2060185417",
        "2168691128",
        "2003342633",
        "2167944937",
        "2098533519"
    ]
},{
    "id": "2801339009",
    "title": "Middle East respiratory syndrome coronavirus: risk factors and determinants of primary, household, and nosocomial transmission",
    "abstract": "Middle East respiratory syndrome coronavirus (MERS-CoV) is a lethal zoonosis that causes death in 35\u00b77% of cases. As of Feb 28, 2018, 2182 cases of MERS-CoV infection (with 779 deaths) in 27 countries were reported to WHO worldwide, with most being reported in Saudi Arabia (1807 cases with 705 deaths). MERS-CoV features prominently in the WHO blueprint list of priority pathogens that threaten global health security. Although primary transmission of MERS-CoV to human beings is linked to exposure to dromedary camels (Camelus dromedarius), the exact mode by which MERS-CoV infection is acquired remains undefined. Up to 50% of MERS-CoV cases in Saudi Arabia have been classified as secondary, occurring from human-to-human transmission through contact with asymptomatic or symptomatic individuals infected with MERS-CoV. Hospital outbreaks of MERS-CoV are a hallmark of MERS-CoV infection. The clinical features associated with MERS-CoV infection are not MERS-specific and are similar to other respiratory tract infections. Thus, the diagnosis of MERS can easily be missed, unless the doctor or health-care worker has a high degree of clinical awareness and the patient undergoes specific testing for MERS-CoV. The largest outbreak of MERS-CoV outside the Arabian Peninsula occurred in South Korea in May, 2015, resulting in 186 cases with 38 deaths. This outbreak was caused by a traveller with undiagnosed MERS-CoV infection who became ill after returning to Seoul from a trip to the Middle East. The traveller visited several health facilities in South Korea, transmitting the virus to many other individuals long before a diagnosis was made. With 10 million pilgrims visiting Saudi Arabia each year from 182 countries, watchful surveillance by public health systems, and a high degree of clinical awareness of the possibility of MERS-CoV infection is essential. In this Review, we provide a comprehensive update and synthesis of the latest available data on the epidemiology, determinants, and risk factors of primary, household, and nosocomial transmission of MERS-CoV, and suggest measures to reduce risk of transmission.",
    "date": "2018",
    "authors": [
        "David S. Hui",
        "Esam I. Azhar",
        "Yae Jean Kim",
        "Ziad A. Memish",
        "Myoung don Oh",
        "Alimuddin Zumla"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Respiratory tract infections",
        "Epidemiology"
    ],
    "citation_count": "253",
    "reference_count": "70",
    "references": [
        "2166867592",
        "2107053896",
        "2138324310",
        "2037454769",
        "2565805236",
        "2149508011",
        "2255243349",
        "2045002682",
        "2586093485",
        "2144410942"
    ]
},{
    "id": "2217313808",
    "title": "Co-circulation of three camel coronavirus species and recombination of MERS-CoVs in Saudi Arabia",
    "abstract": "Outbreaks of Middle East respiratory syndrome (MERS) raise questions about the prevalence and evolution of the MERS coronavirus (CoV) in its animal reservoir. Our surveillance in Saudi Arabia in 2014 and 2015 showed that viruses of the MERS-CoV species and a human CoV 229E-related lineage co-circulated at high prevalence, with frequent co-infections in the upper respiratory tract of dromedary camels. viruses of the betacoronavirus 1 species, we found that dromedary camels share three CoV species with humans. Several MERS-CoV lineages were present in camels, including a recombinant lineage that has been dominant since December 2014 and that subsequently led to the human outbreaks in 2015. Camels therefore serve as an important reservoir for the maintenance and diversification of the MERS-CoVs and are the source of human infections with this virus.",
    "date": "2015",
    "authors": [
        "Jamal S. M. Sabir",
        "Tommy T.-Y. Lam",
        "Mohamed M. M. Ahmed",
        "Lifeng Li",
        "Yongyi Shen",
        "Salah E. M. Abo-Aba",
        "Muhammad I. Qureshi",
        "Mohamed Abu-Zeid",
        "Yu Zhang",
        "Mohammad A. Khiyami",
        "Njud S. Alharbi",
        "Nahid H. Hajrah",
        "Meshaal J. Sabir",
        "Mohammed H. Z. Mutwakil",
        "Saleh A. Kabli",
        "Faten A. S. Alsulaimany",
        "Abdullah Y. Obaid",
        "Boping Zhou",
        "David K. Smith",
        "Edward C. Holmes",
        "Huachen Zhu",
        "Yi Guan"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Middle East respiratory syndrome",
        "Betacoronavirus 1"
    ],
    "citation_count": "290",
    "reference_count": "42",
    "references": [
        "2166867592",
        "2148698435",
        "2111211467",
        "2130362098",
        "1703839189",
        "1519266993",
        "2112147913",
        "2094939159",
        "2149508011",
        "2160011624"
    ]
},{
    "id": "2538584349",
    "title": "Molecular Evolution of Human Coronavirus Genomes",
    "abstract": "Human coronaviruses (HCoVs), including SARS-CoV and MERS-CoV, are zoonotic pathogens that originated in wild animals. HCoVs have large genomes that encode a fixed array of structural and nonstructural components, as well as a variety of accessory proteins that differ in number and sequence even among closely related CoVs. Thus, in addition to recombination and mutation, HCoV genomes evolve through gene gains and losses. In this review we summarize recent findings on the molecular evolution of HCoV genomes, with special attention to recombination and adaptive events that generated new viral species and contributed to host shifts and to HCoV emergence. VIDEO ABSTRACT.",
    "date": "2016",
    "authors": [
        "Diego Forni",
        "Rachele Cagliani",
        "Mario Salvatore Clerici",
        "Manuela Sironi"
    ],
    "related_topics": [
        "Molecular evolution",
        "Genome",
        "Gene"
    ],
    "citation_count": "414",
    "reference_count": "90",
    "references": [
        "2141052558",
        "2146058063",
        "2111211467",
        "2306794997",
        "1993577573",
        "2110335151",
        "2152770371",
        "2112147913",
        "2298153446",
        "2105637133"
    ]
},{
    "id": "96734778",
    "title": "Molecular Evolution of the SARS Coronavirus, during the Course of the SARS Epidemic in China",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Jian Feng He",
        "Guo Wen Peng",
        "Jun Min",
        "De Wen Yu",
        "Wen Jia Liang",
        "Shu Yi Zhang",
        "Rui Heng Xu",
        "Huan Ying Zheng",
        "Xin Wei Wu",
        "Jun Xu",
        "Zhan Hui Wang",
        "Ling Fang",
        "Xin Zhang",
        "Hui Li",
        "Xin Ge Yan",
        "Jia Hai Lu",
        "Zhi Hong Hu",
        "Ji Cheng Huang",
        "Zhuo Yue Wan",
        "Jin Lin Hou",
        "Jin Yan Lin",
        "Huai Dong Song",
        "Sheng Yue Wang",
        "Xiang Jun Zhou",
        "Guo Wei Zhang",
        "Bo Wei Gu",
        "Hua Jun Zheng",
        "Xiang Lin Zhang",
        "Mei He",
        "Kui Zheng",
        "Bo Fei Wang",
        "Gang Fu",
        "Xiao Ning Wang",
        "Sai Juan Chen",
        "Zhu Chen",
        "Pei Hao",
        "Hua Tang",
        "Shuang Xi Ren",
        "Yang Zhong",
        "Zong Ming Guo",
        "Qi Liu",
        "You Gang Miao",
        "Xiang Yin Kong",
        "Wei Zhong He",
        "Yi Xue Li",
        "Chung I. Wu",
        "Guo Ping Zhao",
        "Rossa W.K. Chiu",
        "Stephen S.C. Chim",
        "Yu Kwan Tong"
    ],
    "related_topics": [
        "Molecular evolution",
        "Virology",
        "Biology"
    ],
    "citation_count": "585",
    "reference_count": "25",
    "references": [
        "2132260239",
        "2104548316",
        "2131262274",
        "2125251240",
        "2116586125",
        "2169198329",
        "2134061616",
        "2141877163",
        "2463755683",
        "1976741900"
    ]
},{
    "id": "2002481497",
    "title": "Viral shedding patterns of coronavirus in patients with probable severe acute respiratory syndrome",
    "abstract": "Severe acute respiratory syndrome (SARS) is thought to be caused by a novel coronavirus, SARS-associated coronavirus. We studied viral shedding of SARS coronavirus to improve diagnosis and infection control. Reverse-transcriptase PCR was done on 2134 specimens of different types. 355 (45%) specimens of nasopharyngeal aspirates and 150 (28%) of faeces were positive for SARS coronavirus RNA. Positive rates peaked at 6-11 days after onset of illness for nasopharyngeal aspirates (87 of 149 [58%], to 37 of 62 [60%]), and 9-14 days for faeces (15 of 22 [68%], to 26 of 37 [70%]). Overall, peak viral loads were reached at 12-14 days of illness when patients were probably in hospital care, which would explain why hospital workers were prone to infection. Low rate of viral shedding in the first few days of illness meant that early isolation measures would probably be effective.",
    "date": "2004",
    "authors": [
        "Peter K C Cheng",
        "Derek A Wong",
        "Louis K L Tong",
        "Sin-Ming Ip",
        "Angus C T Lo",
        "Chi-Shan Lau",
        "Eugene Y H Yeung",
        "Wilina W L Lim"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral shedding",
        "Viral load"
    ],
    "citation_count": "317",
    "reference_count": "3",
    "references": [
        "2025170735",
        "2129542667",
        "2100654609"
    ]
},{
    "id": "1606697907",
    "title": "Infectious Diseases of Humans: Dynamics and Control",
    "abstract": "Part 1 Microparasites: biology of host-microparasite associations the basic model - statics static aspects of eradication and control the basic model - dynamics dynamic aspects of eradication and control beyond the basic model - empirical evidence of inhomogeneous mixing age-related transmission rates genetic heterogeneity social heterogeneity and sexually transmitted diseases spatial and other kinds of heterogeneity endemic infections in developing countries indirectly transmitted microparasites. Part 2 Macroparasites: biology of host-macroparasite associations the basic model - statics the basic model - dynamics acquired immunity heterogeneity within the human community indirectly transmitted helminths experimental epidemiology parasites, genetic variability, and drug resistance the ecology and genetics of host-parasite associations.",
    "date": "1991",
    "authors": [
        "Roy M. Anderson",
        "Robert M. May"
    ],
    "related_topics": [
        "Mathematical modelling of infectious disease",
        "Macroparasite",
        "Communicable disease transmission"
    ],
    "citation_count": "14,484",
    "reference_count": "0",
    "references": []
},{
    "id": "2011756067",
    "title": "Emergency response to a smallpox attack: The case for mass vaccination",
    "abstract": "In the event of a smallpox bioterrorist attack in a large U.S. city, the interim response policy is to isolate symptomatic cases, trace and vaccinate their contacts, quarantine febrile contacts, but vaccinate more broadly if the outbreak cannot be contained by these measures. We embed this traced vaccination policy in a smallpox disease transmission model to estimate the number of cases and deaths that would result from an attack in a large urban area. Comparing the results to mass vaccination from the moment an attack is recognized, we find that mass vaccination results in both far fewer deaths and much faster epidemic eradication over a wide range of disease and intervention policy parameters, including those believed most likely, and that mass vaccination similarly outperforms the existing policy of starting with traced vaccination and switching to mass vaccination only if required.",
    "date": "2002",
    "authors": [
        "Edward H. Kaplan",
        "David L. Craft",
        "Lawrence M. Wein"
    ],
    "related_topics": [
        "Vaccination policy",
        "Vaccination",
        "Mathematical modelling of infectious disease"
    ],
    "citation_count": "507",
    "reference_count": "13",
    "references": [
        "2103828083",
        "228144990",
        "2118488619",
        "2112414534",
        "1996230967",
        "2116002746",
        "2005165325",
        "2096334666",
        "1967154456",
        "2072093685"
    ]
},{
    "id": "2318510691",
    "title": "Seasonal variation in host susceptibility and cycles of certain infectious diseases.",
    "abstract": "Seasonal cycles of infectious diseases have been variously attributed to changes in atmospheric conditions, the prevalence or virulence of the pathogen, or the behavior of the host. Some observations about seasonality are difficult to reconcile with these explanations. These include the simultaneous appearance of outbreaks across widespread geographic regions of the same latitude; the detection of pathogens in the off-season without epidemic spread; and the consistency of seasonal changes, despite wide variations in weather and human behavior. In contrast, an increase in susceptibility of the host population, perhaps linked to the annual light/dark cycle and mediated by the pattern of melatonin secretion, might account for many heretofore unexplained features of infectious disease seasonality. Ample evidence indicates that photoperiod-driven physiologic changes are typical in mammalian species, including some in humans. If such physiologic changes underlie human resistance to infectious diseases for large portions of the year and the changes can be identified and modified, the therapeutic and preventive implications may be considerable.",
    "date": "2001",
    "authors": [
        "Scott F. Dowell"
    ],
    "related_topics": [
        "Infectious disease (medical specialty)",
        "Population",
        "Outbreak"
    ],
    "citation_count": "713",
    "reference_count": "53",
    "references": [
        "3135667697",
        "2012530840",
        "2077888568",
        "1985254566",
        "2139275141",
        "2032834242",
        "1589395984",
        "2174962221",
        "2122110707",
        "2313193762"
    ]
},{
    "id": "1965399019",
    "title": "A first course in stochastic processes",
    "abstract": "Preface. Elements of Stochastic Processes. Markov Chains. The Basic Limit Theorem of Markov Chains and Applications. Classical Examples of Continuous Time Markov Chains. Renewal Processes. Martingales. Brownian Motion. Branching Processes. Stationary Processes. Review of Matrix Analysis. Index.",
    "date": "1965",
    "authors": [
        "Samuel Karlin",
        "Howard M Taylor"
    ],
    "related_topics": [
        "Examples of Markov chains",
        "Markov chain",
        "Time reversibility"
    ],
    "citation_count": "5,293",
    "reference_count": "0",
    "references": []
},{
    "id": "1979065938",
    "title": "The Time Course of the Immune Response to Experimental Coronavirus Infection of Man",
    "abstract": "After preliminary trials, the detailed changes in the concentration of specific circulating and local antibodies were followed in 15 volunteers inoculated with coronavirus 229E. Ten of them, who had significantly lower concentrations of pre-existing antibody than the rest, became infected and eight of these developed colds. A limited investigation of circulating lymphocyte populations showed some lymphocytopenia in infected volunteers. In this group, antibody concentrations started to increase 1 week after inoculation and reached a maximum about 1 week later. Thereafter antibody titres slowly declined. Although concentrations were still slightly raised 1 year later, this did not always prevent reinfection when volunteers were then challenged with the homologous virus. However, the period of virus shedding was shorter than before and none developed a cold. All of the uninfected group were infected on re-challenge although they also appeared to show some resistance to disease and in the extent of infection. These results are discussed with reference to natural infections with coronavirus and with other infections, such as rhinovirus infections.",
    "date": "1990",
    "authors": [
        "K. A. Callow",
        "H. F. Parry",
        "M. Sergeant",
        "D. A. J. Tyrrell"
    ],
    "related_topics": [
        "Coronavirus",
        "Lymphocytopenia",
        "Viral shedding"
    ],
    "citation_count": "561",
    "reference_count": "33",
    "references": [
        "1775749144",
        "2142571070",
        "2065975497",
        "2006440266",
        "2109471081",
        "2051674756",
        "1966772637",
        "2001228540",
        "2029391755",
        "2090836290"
    ]
},{
    "id": "2042499956",
    "title": "Nipah Virus Encephalitis Reemergence, Bangladesh",
    "abstract": "We retrospectively investigated two outbreaks of encephalitis in Meherpur and Naogaon, Bangladesh, which occurred in 2001 and 2003. We collected serum samples from persons who were ill, their household contacts, randomly selected residents, hospital workers, and various animals. Cases were classified as laboratory confirmed or probable. We identified 13 cases (4 confirmed, 9 probable) in Meherpur; 7 were in persons in two households. Patients were more likely than nonpatients to have close contact with other patients or have contact with a sick cow. In Naogaon, we identified 12 cases (4 confirmed, 8 probable); 7 were in persons clustered in 2 households. Two Pteropus bats had antibodies for Nipah virus. Samples from hospital workers were negative for Nipah virus antibodies. These outbreaks, the first since 1999, suggest that transmission may occur through close contact with other patients or from exposure to a common source. Surveillance and enhancement of diagnostic capacity to detect Nipah virus infection are recommended.",
    "date": "2004",
    "authors": [
        "Vincent P. Hsu",
        "Mohammed Jahangir Hossain",
        "Umesh D Parashar",
        "Mohammed Monsur Ali",
        "Thomas G Ksiazek",
        "Ivan Kuzmin",
        "Michael Niezgoda",
        "Charles Rupprecht",
        "Joseph S Bresee",
        "Robert F Breiman"
    ],
    "related_topics": [
        "Disease reservoir",
        "Encephalitis",
        "Henipavirus"
    ],
    "citation_count": "595",
    "reference_count": "14",
    "references": [
        "1973647109",
        "2152839763",
        "1984844573",
        "2128458987",
        "2075423214",
        "1981329413",
        "2100169057",
        "2169563372",
        "1968530372",
        "2150120282"
    ]
},{
    "id": "2000714505",
    "title": "Community-acquired pneumonia requiring hospitalization among U.S. adults",
    "abstract": "Background Incidence estimates of hospitalizations for community-acquired pneumonia among children in the United States that are based on prospective data collection are limited. Updated estimates of pneumonia that has been confirmed radiographically and with the use of current laboratory diagnostic tests are needed. Methods We conducted active population-based surveillance for community-acquired pneumonia requiring hospitalization among children younger than 18 years of age in three hospitals in Memphis, Nashville, and Salt Lake City. We excluded children with recent hospitalization or severe immunosuppression. Blood and respiratory specimens were systematically collected for pathogen detection with the use of multiple methods. Chest radiographs were reviewed independently by study radiologists. Results From January 2010 through June 2012, we enrolled 2638 of 3803 eligible children (69%), 2358 of whom (89%) had radiographic evidence of pneumonia. The median age of the children was 2 years (interquartile ...",
    "date": "2015",
    "authors": [
        "Sema Jain",
        "W. H. Self",
        "R. G. Wunderink",
        "S. Fakhran",
        "R. Balk",
        "A. M. Bramley",
        "C. Reed",
        "C. G. Grijalva",
        "E. J. Anderson",
        "D. M. Courtney",
        "J. D. Chappell",
        "C. Qi",
        "E. M. Hart",
        "F. Carroll",
        "Christopher Trabue",
        "H. K. Donnelly",
        "D. J. Williams",
        "Y. Zhu",
        "Sandra Arnold",
        "K. Ampofo",
        "G. W. Waterer",
        "M. Levine",
        "S. Lindstrom",
        "J. M. Winchell",
        "J. M. Katz",
        "D. Erdman",
        "E. Schneider",
        "L. A. Hicks",
        "Jonathan Mccullers",
        "A. T. Pavia",
        "K. M. Edwards",
        "L. Finelli"
    ],
    "related_topics": [
        "Pneumonia",
        "Community-acquired pneumonia",
        "Population"
    ],
    "citation_count": "2,122",
    "reference_count": "74",
    "references": [
        "2133979383",
        "2785073138",
        "2320270386",
        "2116581803",
        "2149176649",
        "1989501142",
        "2097129414",
        "2143559680",
        "2098483219",
        "2182945617"
    ]
},{
    "id": "2164777277",
    "title": "The measurement of observer agreement for categorical data",
    "abstract": "This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.",
    "date": "1977",
    "authors": [
        "J. R. Landis",
        "Gary G Koch"
    ],
    "related_topics": [
        "Categorical variable",
        "Fleiss' kappa",
        "Intra-rater reliability"
    ],
    "citation_count": "65,503",
    "reference_count": "33",
    "references": [
        "2053154970",
        "2798510847",
        "2037789405",
        "1975879668",
        "2021142183",
        "1989774929",
        "2018385240",
        "2133012565",
        "2063803293",
        "2088041869"
    ]
},{
    "id": "2102263282",
    "title": "Effectiveness of neuraminidase inhibitors in reducing mortality in patients admitted to hospital with influenza A H1N1pdm09 virus infection: a meta-analysis of individual participant data.",
    "abstract": "Summary Background Neuraminidase inhibitors were widely used during the 2009\u201310 influenza A H1N1 pandemic, but evidence for their effectiveness in reducing mortality is uncertain. We did a meta-analysis of individual participant data to investigate the association between use of neuraminidase inhibitors and mortality in patients admitted to hospital with pandemic influenza A H1N1pdm09 virus infection. Methods We assembled data for patients (all ages) admitted to hospital worldwide with laboratory confirmed or clinically diagnosed pandemic influenza A H1N1pdm09 virus infection. We identified potential data contributors from an earlier systematic review of reported studies addressing the same research question. In our systematic review, eligible studies were done between March 1, 2009 (Mexico), or April 1, 2009 (rest of the world), until the WHO declaration of the end of the pandemic (Aug 10, 2010); however, we continued to receive data up to March 14, 2011, from ongoing studies. We did a meta-analysis of individual participant data to assess the association between neuraminidase inhibitor treatment and mortality (primary outcome), adjusting for both treatment propensity and potential confounders, using generalised linear mixed modelling. We assessed the association with time to treatment using time-dependent Cox regression shared frailty modelling. Findings We included data for 29\u2008234 patients from 78 studies of patients admitted to hospital between Jan 2, 2009, and March 14, 2011. Compared with no treatment, neuraminidase inhibitor treatment (irrespective of timing) was associated with a reduction in mortality risk (adjusted odds ratio [OR] 0\u00b781; 95% CI 0\u00b770\u20130\u00b793; p=0\u00b70024). Compared with later treatment, early treatment (within 2 days of symptom onset) was associated with a reduction in mortality risk (adjusted OR 0\u00b748; 95% CI 0\u00b741\u20130\u00b756; p Interpretation We advocate early instigation of neuraminidase inhibitor treatment in adults admitted to hospital with suspected or proven influenza infection. Funding F Hoffmann-La Roche.",
    "date": "2014",
    "authors": [
        "Stella G Muthuri",
        "Sudhir Venkatesan",
        "Puja R Myles",
        "Jo Leonardi-Bee",
        "Tarig S A Al Khuwaitir",
        "Adbullah Al Mamun",
        "Ashish P Anovadiya",
        "Eduardo Azziz-Baumgartner",
        "Clarisa B\u00e1ez",
        "Matteo Bassetti",
        "Bojana Beovic",
        "Barbara Bertisch",
        "Isabelle Bonmarin",
        "Robert Booy",
        "Victor H Borja-Aburto",
        "Heinz Burgmann",
        "Bin Cao",
        "Jordi Carratala",
        "Justin T Denholm",
        "Samuel R Dominguez",
        "Pericles A D Duarte",
        "Gal Dubnov-Raz",
        "Marcela Echavarria",
        "Sergio Fanella",
        "Zhancheng Gao",
        "Patrick G\u00e9rardin",
        "Maddalena Giannella",
        "Sophie Gubbels",
        "Jethro Herberg",
        "Anjarath L Higuera Iglesias",
        "Peter H Hoger",
        "Xiaoyun Hu",
        "Quazi T Islam",
        "Mirela F Jim\u00e9nez",
        "Amr Kandeel",
        "Gerben Keijzers",
        "Hossein Khalili",
        "Marian Knight",
        "Koichiro Kudo",
        "Gabriela F. Kusznierz",
        "Ilija Kuzman",
        "Arthur M C Kwan",
        "Idriss Lahlou Amine",
        "Eduard Langenegger",
        "Kamran B Lankarani",
        "Yee-Sin Leo",
        "Rita Linko",
        "Pei Liu",
        "Faris Madanat",
        "Elga Mayo-Montero"
    ],
    "related_topics": [
        "Oseltamivir",
        "Zanamivir",
        "Neuraminidase inhibitor"
    ],
    "citation_count": "598",
    "reference_count": "31",
    "references": [
        "2120959053",
        "2104040437",
        "1971662199",
        "2139529156",
        "2048565444",
        "2165613545",
        "2112164609",
        "2009145867",
        "2127089219",
        "2171016583"
    ]
},{
    "id": "2103338644",
    "title": "A Guide to Utilization of the Microbiology Laboratory for Diagnosis of Infectious Diseases: 2013 Recommendations by the Infectious Diseases Society of America (IDSA) and the American Society for Microbiology (ASM)a",
    "abstract": "The critical role of the microbiology laboratory in infectious disease diagnosis calls for a close, positive working relationship between the physician and the microbiologists who provide enormous value to the health care team. This document, developed by both laboratory and clinical experts, provides information on which tests are valuable and in which contexts, and on tests that add little or no value for diagnostic decisions. Sections are divided into anatomic systems, including Bloodstream Infections and Infections of the Cardiovascular System, Central Nervous System Infections, Ocular Infections, Soft Tissue Infections of the Head and Neck, Upper Respiratory Infections, Lower Respiratory Tract infections, Infections of the Gastrointestinal Tract, Intraabdominal Infections, Bone and Joint Infections, Urinary Tract Infections, Genital Infections, and Skin and Soft Tissue Infections; or into etiologic agent groups, including Tickborne Infections, Viral Syndromes, and Blood and Tissue Parasite Infections. Each section contains introductory concepts, a summary of key points, and detailed tables that list suspected agents; the most reliable tests to order; the samples (and volumes) to collect in order of preference; specimen transport devices, procedures, times, and temperatures; and detailed notes on specific issues regarding the test methods, such as when tests are likely to require a specialized laboratory or have prolonged turnaround times. There is redundancy among the tables and sections, as many agents and assay choices overlap. The document is intended to serve as a reference to guide physicians in choosing tests that will aid them to diagnose infectious diseases in their patients.",
    "date": "2013",
    "authors": [
        "Ellen Jo Baron",
        "J. Michael Miller",
        "Melvin P. Weinstein",
        "Sandra S. Richter",
        "Peter H. Gilligan",
        "Richard B. Thomson",
        "Paul Bourbeau",
        "Karen C. Carroll",
        "Sue C. Kehl",
        "W. Michael Dunne",
        "Barbara Robinson-Dunn",
        "Joseph D. Schwartzman",
        "Kimberle C. Chapin",
        "James W. Snyder",
        "Betty A. Forbes",
        "Robin Patel",
        "Jon E. Rosenblatt",
        "Bobbi S. Pritt"
    ],
    "related_topics": [
        "Infectious disease (medical specialty)",
        "Respiratory tract infections",
        "Intensive care medicine"
    ],
    "citation_count": "535",
    "reference_count": "232",
    "references": [
        "2133979383",
        "2123134253",
        "2917733958",
        "1833207062",
        "2616251258",
        "2101233913",
        "2102648994",
        "2133866452",
        "2109779439",
        "2158939557"
    ]
},{
    "id": "2752904261",
    "title": "Evaluation of NxTAG Respiratory Pathogen Panel and Comparison with xTAG Respiratory Viral Panel Fast v2 and Film Array Respiratory Panel for Detecting Respiratory Pathogens in Nasopharyngeal Aspirates and Swine/Avian-Origin Influenza A Subtypes in Culture Isolates.",
    "abstract": "This study evaluated a new multiplex kit, Luminex NxTAG Respiratory Pathogen Panel, for respiratory pathogens and compared it with xTAG RVP Fast v2 and FilmArray Respiratory Panel using nasopharyngeal aspirate specimens and culture isolates of different swine/avian-origin influenza A subtypes (H2N2, H5N1, H7N9, H5N6, and H9N2). NxTAG RPP gave sensitivity of 95.2%, specificity of 99.6%, PPV of 93.5%, and NPV of 99.7%. NxTAG RPP, xTAG RVP, and FilmArray RP had highly concordant performance among each other for the detection of respiratory pathogens. The mean analytic sensitivity (TCID50/ml) of NxTAG RPP, xTAG RVP, and FilmArray RP for detection of swine/avian-origin influenza A subtype isolates was 0.7, 41.8, and 0.8, respectively. All three multiplex assays correctly typed and genotyped the influenza viruses, except for NxTAG RRP that could not distinguish H3N2 from H3N2v. Further investigation should be performed if H3N2v is suspected to be the cause of disease. Sensitive and specific laboratory diagnosis of all influenza A viruses subtypes is especially essential in certain epidemic regions, such as Southeast Asia. The results of this study should help clinical laboratory professionals to be aware of the different performances of commercially available molecular multiplex RT-PCR assays that are commonly adopted in many clinical diagnostic laboratories.",
    "date": "2017",
    "authors": [
        "K. H. Chan",
        "K. K. W. To",
        "P. T. W. Li",
        "T. L. Wong",
        "R. Zhang",
        "K. K. H. Chik",
        "G. Chan",
        "C. C. Y. Yip",
        "H. L. Chen",
        "I. F. N. Hung",
        "J. F. W. Chan",
        "K. Y. Yuen"
    ],
    "related_topics": [
        "Respiratory Pathogen Panel",
        "Influenza A virus subtype H5N1",
        "Multiplex"
    ],
    "citation_count": "8",
    "reference_count": "29",
    "references": [
        "2105226322",
        "2170933940",
        "2163738297",
        "2119632771",
        "2552113437",
        "2060421888",
        "2082571397",
        "2153401879",
        "2025568079",
        "2325250956"
    ]
},{
    "id": "2605374894",
    "title": "Routine molecular point-of-care testing for respiratory viruses in adults presenting to hospital with acute respiratory illness (ResPOC): a pragmatic, open-label, randomised controlled trial",
    "abstract": "Summary Background Respiratory virus infection is a common cause of hospitalisation in adults. Rapid point-of-care testing (POCT) for respiratory viruses might improve clinical care by reducing unnecessary antibiotic use, shortening length of hospital stay, improving influenza detection and treatment, and rationalising isolation facility use; however, insufficient evidence exists to support its use over standard clinical care. We aimed to assess the effect of routine POCT on a broad range of clinical outcomes including antibiotic use. Methods In this pragmatic, parallel-group, open-label, randomised controlled trial, we enrolled adults (aged \u226518 years) within 24 h of presenting to the emergency department or acute medical unit of a large UK hospital with acute respiratory illness or fever higher than 37\u00b75\u00b0C (\u22647 days duration), or both, over two winter seasons. Patients were randomly assigned (1:1), via an internet-based allocation sequence with random permuted blocks, to have a molecular POC test for respiratory viruses or routine clinical care. The primary outcome was the proportion of patients who received antibiotics while hospitalised (up to 30 days). Secondary outcomes included duration of antibiotics, proportion of patients receiving single doses or brief courses of antibiotics, length of stay, antiviral use, isolation facility use, and safety. Analysis was by modified intention to treat, excluding patients who declined intervention or were withdrawn for protocol violations. This study is registered with ISRCTN, number 90211642, and has been completed. Findings Between Jan 15, 2015, and April 30, 2015, and between Oct 1, 2015, and April 30, 2016, we enrolled 720 patients (362 assigned to POCT and 358 to routine care). Six patients withdrew or had protocol violations. 301 (84%) of 360 patients in the POCT group received antibiotics compared with 294 (83%) of 354 controls (difference 0\u00b76%, 95% CI \u22124\u00b79 to 6\u00b70; p=0\u00b784). Mean duration of antibiotics did not differ between groups (7\u00b72 days [SD 5\u00b71] in the POCT group vs 7\u00b77 days [4\u00b79] in the control group; difference \u22120\u00b74, 95% CI \u22121\u00b72 to 0\u00b74; p=0\u00b732). 50 (17%) of 301 patients treated with antibiotics in the POCT group received single doses or brief courses of antibiotics ( vs 88 [25%] of 354 patients in the control group; \u22123\u00b75%, \u22129\u00b77 to 2\u00b77; p=0\u00b729). Interpretation Routine use of molecular POCT for respiratory viruses did not reduce the proportion of patients treated with antibiotics. However, the primary outcome measure failed to capture differences in antibiotic use because many patients were started on antibiotics before the results of POCT could be made available. Although POCT was not associated with a reduction in the duration of antibiotics overall, more patients in the POCT group received single doses or brief courses of antibiotics than did patients in the control group. POCT was also associated with a reduced length of stay and improved influenza detection and antiviral use, and appeared to be safe. Funding University of Southampton.",
    "date": "2017",
    "authors": [
        "Nathan J Brendish",
        "Ahalya K Malachira",
        "Lawrence Armstrong",
        "Rebecca Houghton",
        "Sandra Aitken",
        "Esther Nyimbili",
        "Sean Ewings",
        "Patrick J Lillie",
        "Tristan W Clark"
    ],
    "related_topics": [
        "Emergency department",
        "Randomized controlled trial",
        "Intention-to-treat analysis"
    ],
    "citation_count": "207",
    "reference_count": "24",
    "references": [
        "2168630917",
        "2000714505",
        "2102263282",
        "1998407364",
        "2736324050",
        "2045855653",
        "2082571397",
        "2141068176",
        "2286875509",
        "2114204860"
    ]
},{
    "id": "2101172433",
    "title": "Delayed Clearance of Viral Load and Marked Cytokine Activation in Severe Cases of Pandemic H1N1 2009 Influenza Virus Infection",
    "abstract": "Background Infections caused by the pandemic H1N1 2009 influenza virus range from mild upper respiratory tract syndromes to fatal diseases. However, studies comparing virological and immunological profile of different clinical severity are lacking. Methods We conducted a retrospective cohort study of 74 patients with pandemic H1N1 infection, including 23 patients who either developed acute respiratory distress syndrome (ARDS) or died (ARDS-death group), 14 patients with desaturation requiring oxygen supplementation and who survived without ARDS (survived-without-ARDS group), and 37 patients with mild disease without desaturation (mild-disease group). We compared their pattern of clinical disease, viral load, and immunological profile. Results Patients with severe disease were older, more likely to be obese or having underlying diseases, and had lower respiratory tract symptoms, especially dyspnea at presentation. The ARDS-death group had a slower decline in nasopharyngeal viral loads, had higher plasma levels of proinflammatory cytokines and chemokines, and were more likely to have bacterial coinfections (30.4%), myocarditis (21.7%), or viremia (13.0%) than patients in the survived-without-ARDS or the mild-disease groups. Reactive hemophagocytosis, thrombotic phenomena, lymphoid atrophy, diffuse alveolar damage, and multiorgan dysfunction similar to fatal avian influenza A H5N1 infection were found at postmortem examinations. Conclusions The slower control of viral load and immunodysregulation in severe cases mandate the search for more effective antiviral and immunomodulatory regimens to stop the excessive cytokine activation resulting in ARDS and death.",
    "date": "2010",
    "authors": [
        "Kelvin K. W. To",
        "Ivan F. N. Hung",
        "Iris W. S. Li",
        "Kar-Lung Lee",
        "Chi-Kwan Koo",
        "Wing-Wa Yan",
        "Raymond Liu",
        "Ka-Ying Ho",
        "Kwok-Hong Chu",
        "Chi-Leung Watt",
        "Wei-Kwang Luk",
        "Kang-Yiu Lai",
        "Fu-Loi Chow",
        "Thomas Mok",
        "Tom Buckley",
        "Jasper F. W. Chan",
        "Samson S. Y. Wong",
        "Bojian Zheng",
        "Honglin Chen",
        "Candy C. Y. Lau",
        "Herman Tse",
        "Vincent C. C. Cheng",
        "Kwok-Hung Chan",
        "Kwok-Yung Yuen"
    ],
    "related_topics": [
        "Viral load",
        "Diffuse alveolar damage",
        "ARDS"
    ],
    "citation_count": "443",
    "reference_count": "37",
    "references": [
        "2107978811",
        "2135421762",
        "2161328469",
        "2169497667",
        "2098349861",
        "1996311210",
        "2116682907",
        "2149087734",
        "2121593344",
        "1534087491"
    ]
},{
    "id": "2623181050",
    "title": "Additional molecular testing of saliva specimens improves the detection of respiratory viruses.",
    "abstract": "Emerging infectious diseases in humans are often caused by respiratory viruses such as pandemic or avian influenza viruses and novel coronaviruses. Microbiological testing for respiratory viruses i...",
    "date": "2017",
    "authors": [
        "Kelvin Kw To",
        "Lu Lu",
        "Cyril Cy Yip",
        "Rosana Ws Poon",
        "Ami My Fung",
        "Andrew Cheng",
        "Daniel Hk Lui",
        "Deborah Ty Ho",
        "Ivan Fn Hung",
        "Kwok Hung Chan",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Respiratory virus",
        "Respiratory tract infections",
        "Influenza A virus"
    ],
    "citation_count": "76",
    "reference_count": "41",
    "references": [
        "2000445173",
        "2108693332",
        "2000714505",
        "2115555188",
        "2105226322",
        "2102263282",
        "2122256368",
        "1982137128",
        "2103338644",
        "1493636931"
    ]
},{
    "id": "2752140764",
    "title": "Diagnostic Accuracy of Novel and Traditional Rapid Tests for Influenza Infection Compared With Reverse Transcriptase Polymerase Chain Reaction: A Systematic Review and Meta-analysis",
    "abstract": "Background Rapid and accurate influenza diagnostics can improve patient care. Purpose To summarize and compare accuracy of traditional rapid influenza diagnostic tests (RIDTs), digital immunoassays (DIAs), and rapid nucleic acid amplification tests (NAATs) in children and adults with suspected influenza. Data sources 6 databases from their inception through May 2017. Study selection Studies in English, French, or Spanish comparing commercialized rapid tests (that is, providing results in Data extraction Data were extracted using a standardized form; quality was assessed using QUADAS-2 (Quality Assessment of Diagnostic Accuracy Studies 2) criteria. Data synthesis 162 studies were included (130 of RIDTs, 19 of DIAs, and 13 of NAATs). Pooled sensitivities for detecting influenza A from Bayesian bivariate random-effects models were 54.4% (95% credible interval [CrI], 48.9% to 59.8%) for RIDTs, 80.0% (CrI, 73.4% to 85.6%) for DIAs, and 91.6% (CrI, 84.9% to 95.9%) for NAATs. Those for detecting influenza B were 53.2% (CrI, 41.7% to 64.4%) for RIDTs, 76.8% (CrI, 65.4% to 85.4%) for DIAs, and 95.4% (CrI, 87.3% to 98.7%) for NAATs. Pooled specificities were uniformly high (>98%). Forty-six influenza A and 24 influenza B studies presented pediatric-specific data; 35 influenza A and 16 influenza B studies presented adult-specific data. Pooled sensitivities were higher in children by 12.1 to 31.8 percentage points, except for influenza A by rapid NAATs (2.7 percentage points). Pooled sensitivities favored industry-sponsored studies by 6.2 to 34.0 percentage points. Incomplete reporting frequently led to unclear risk of bias. Limitations Underreporting of clinical variables limited exploration of heterogeneity. Few NAAT studies reported adult-specific data, and none evaluated point-of-care testing. Many studies had unclear risk of bias. Conclusion Novel DIAs and rapid NAATs had markedly higher sensitivities for influenza A and B in both children and adults than did traditional RIDTs, with equally high specificities. Primary funding source Quebec Health Research Fund and BD Diagnostic Systems.",
    "date": "2017",
    "authors": [
        "Joanna Merckx",
        "Rehab Wali",
        "Ian Schiller",
        "Chelsea Caya",
        "Genevieve C Gore",
        "Caroline Chartrand",
        "Nandini Dendukuri",
        "Jesse Papenburg"
    ],
    "related_topics": [
        "Meta-analysis",
        "Credible interval",
        "Percentage point"
    ],
    "citation_count": "180",
    "reference_count": "146",
    "references": [
        "3022903699",
        "2161374186",
        "2107638293",
        "1606105143",
        "1975130349",
        "2325835571",
        "2152015613",
        "2090440966",
        "1998407364",
        "2150077624"
    ]
},{
    "id": "2548288333",
    "title": "Comparison between Saliva and Nasopharyngeal Swab Specimens for Detection of Respiratory Viruses by Multiplex Reverse Transcription-PCR",
    "abstract": "Nasopharyngeal swabs (NPSs) are being widely used as specimens for multiplex real-time reverse transcription (RT)-PCR for respiratory virus detection. However, it remains unclear whether NPS specimens are optimal for all viruses targeted by multiplex RT-PCR. In addition, the procedure to obtain NPS specimens causes coughing in most patients, which possibly increases the risk of nosocomial spread of viruses. In this study, paired NPS and saliva specimens were collected from 236 adult male patients with suspected acute respiratory illnesses. Specimens were tested for 16 respiratory viruses by multiplex real-time RT-PCR. Among the specimens collected from the 236 patients, at least 1 respiratory virus was detected in 183 NPS specimens (77.5%) and 180 saliva specimens (76.3%). The rates of detection of respiratory viruses were comparable for NPS and saliva specimens (P = 0.766). Nine virus species and 349 viruses were isolated, 256 from NPS specimens and 273 from saliva specimens (P = 0.1574). Adenovirus was detected more frequently in saliva samples (P < 0.0001), whereas influenza virus type A and human rhinovirus were detected more frequently in NPS specimens (P = 0.0001 and P = 0.0289, respectively). The possibility of false-positive adenovirus detection from saliva samples was excluded by direct sequencing. In conclusion, neither of the sampling methods was consistently more sensitive than the other. We suggest that these cost-effective methods for detecting respiratory viruses in mixed NPS-saliva specimens might be valuable for future studies.",
    "date": "2016",
    "authors": [
        "Young Gon Kim",
        "Seung Gyu Yun",
        "Min Young Kim",
        "Kwisung Park",
        "Chi Hyun Cho",
        "Soo Young Yoon",
        "Myung Hyun Nam",
        "Chang Kyu Lee",
        "Yun Jung Cho",
        "Chae Seung Lim"
    ],
    "related_topics": [
        "Respiratory virus",
        "Saliva",
        "Respiratory tract infections"
    ],
    "citation_count": "72",
    "reference_count": "32",
    "references": [
        "2164777277",
        "2074399085",
        "2107037784",
        "2165685167",
        "2327530675",
        "2125493623",
        "2048107714",
        "1970901618",
        "2082277543",
        "2131073664"
    ]
},{
    "id": "2311203695",
    "title": "MEGA7: Molecular Evolutionary Genetics Analysis version 7.0 for bigger datasets",
    "abstract": "We present the latest version of the Molecular Evolutionary Genetics Analysis (Mega) software, which contains many sophisticated methods and tools for phylogenomics and phylomedicine. In this major upgrade, Mega has been optimized for use on 64-bit computing systems for analyzing larger datasets. Researchers can now explore and analyze tens of thousands of sequences in Mega The new version also provides an advanced wizard for building timetrees and includes a new functionality to automatically predict gene duplication events in gene family trees. The 64-bit Mega is made available in two interfaces: graphical and command line. The graphical user interface (GUI) is a native Microsoft Windows application that can also be used on Mac OS X. The command line Mega is available as native applications for Windows, Linux, and Mac OS X. They are intended for use in high-throughput and scripted analysis. Both versions are available from www.megasoftware.net free of charge.",
    "date": "2016",
    "authors": [
        "Sudhir Kumar",
        "Glen Stecher",
        "Koichiro Tamura"
    ],
    "related_topics": [
        "Mac OS",
        "Mega-",
        "Microsoft Windows"
    ],
    "citation_count": "27,616",
    "reference_count": "12",
    "references": [
        "2152207030",
        "2034285706",
        "2097706568",
        "2121552166",
        "2107886421",
        "1519266993",
        "1992566665",
        "2144775551",
        "2103296919",
        "2117260150"
    ]
},{
    "id": "2002513358",
    "title": "Long-term expansion of epithelial organoids from human colon, adenoma, adenocarcinoma, and Barrett's epithelium.",
    "abstract": "Background & Aims We previously established long-term culture conditions under which single crypts or stem cells derived from mouse small intestine expand over long periods. The expanding crypts undergo multiple crypt fission events, simultaneously generating villus-like epithelial domains that contain all differentiated types of cells. We have adapted the culture conditions to grow similar epithelial organoids from mouse colon and human small intestine and colon. Methods Based on the mouse small intestinal culture system, we optimized the mouse and human colon culture systems. Results Addition of Wnt3A to the combination of growth factors applied to mouse colon crypts allowed them to expand indefinitely. Addition of nicotinamide, along with a small molecule inhibitor of Alk and an inhibitor of p38, were required for long-term culture of human small intestine and colon tissues. The culture system also allowed growth of mouse Apc-deficient adenomas, human colorectal cancer cells, and human metaplastic epithelia from regions of Barrett's esophagus. Conclusions We developed a technology that can be used to study infected, inflammatory, or neoplastic tissues from the human gastrointestinal tract. These tools might have applications in regenerative biology through ex vivo expansion of the intestinal epithelia. Studies of these cultures indicate that there is no inherent restriction in the replicative potential of adult stem cells (or a Hayflick limit) ex vivo.",
    "date": "2011",
    "authors": [
        "Toshiro Sato",
        "Daniel E. Stange",
        "Marc Ferrante",
        "Robert G.J. Vries",
        "Johan H. van Es",
        "Stieneke van den Brink",
        "Winan J. van Houdt",
        "Apollo Pronk",
        "Joost van Gorp",
        "Peter D. Siersema",
        "Hans Clevers"
    ],
    "related_topics": [
        "Human gastrointestinal tract",
        "Adult stem cell",
        "Stem cell"
    ],
    "citation_count": "2,020",
    "reference_count": "42",
    "references": [
        "1965157206",
        "1982603620",
        "2157010562",
        "2090562908",
        "2171996338",
        "2171977041",
        "2042082068",
        "2078591745",
        "2062004524",
        "2021370278"
    ]
},{
    "id": "2144410942",
    "title": "Viral Shedding and Antibody Response in 37 Patients With Middle East Respiratory Syndrome Coronavirus Infection.",
    "abstract": "Background The Middle East respiratory syndrome (MERS) coronavirus causes isolated cases and outbreaks of severe respiratory disease. Essential features of the natural history of disease are poorly understood. Methods We studied 37 adult patients infected with MERS coronavirus for viral load in the lower and upper respiratory tracts (LRT and URT, respectively), blood, stool, and urine. Antibodies and serum neutralizing activities were determined over the course of disease. Results One hundred ninety-nine LRT samples collected during the 3 weeks following diagnosis yielded virus RNA in 93% of tests. Average (maximum) viral loads were 5 \u00d7 10(6) (6 \u00d7 10(10)) copies/mL. Viral loads (positive detection frequencies) in 84 URT samples were 1.9 \u00d7 10(4) copies/mL (47.6%). Thirty-three percent of all 108 serum samples tested yielded viral RNA. Only 14.6% of stool and 2.4% of urine samples yielded viral RNA. All seroconversions occurred during the first 2 weeks after diagnosis, which corresponds to the second and third week after symptom onset. Immunoglobulin M detection provided no advantage in sensitivity over immunoglobulin G (IgG) detection. All surviving patients, but only slightly more than half of all fatal cases, produced IgG and neutralizing antibodies. The levels of IgG and neutralizing antibodies were weakly and inversely correlated with LRT viral loads. Presence of antibodies did not lead to the elimination of virus from LRT. Conclusions The timing and intensity of respiratory viral shedding in patients with MERS closely matches that of those with severe acute respiratory syndrome. Blood viral RNA does not seem to be infectious. Extrapulmonary loci of virus replication seem possible. Neutralizing antibodies do not suffice to clear the infection.",
    "date": "2015",
    "authors": [
        "Victor M. Corman",
        "Ali M. Albarrak",
        "Ali Senosi Omrani",
        "Mohammed M. Albarrak",
        "Mohamed Elamin Farah",
        "Malak Almasri",
        "Doreen Muth",
        "Andrea Sieberg",
        "Benjamin Meyer",
        "Abdullah M. Assiri",
        "Tabea Binger",
        "Katja Steinhagen",
        "Erik Lattwein",
        "Jaffar Al-Tawfiq",
        "Marcel A. M\u00fcller",
        "Christian Drosten",
        "Ziad A. Memish"
    ],
    "related_topics": [
        "Viral load",
        "Viral shedding",
        "Coronavirus"
    ],
    "citation_count": "333",
    "reference_count": "34",
    "references": [
        "2166867592",
        "2129542667",
        "2138324310",
        "1703839189",
        "2119111857",
        "1852588318",
        "2108756402",
        "1757215199",
        "2099941783",
        "2156273941"
    ]
},{
    "id": "1757215199",
    "title": "Enteric involvement of severe acute respiratory syndrome-associated coronavirus infection.",
    "abstract": "Background & Aims: Severe acute respiratory syndrome (SARS) is a recently emerged infection from a novel coronavirus (CoV). Apart from fever and respiratory complications, gastrointestinal symptoms are frequently observed in patients with SARS but the significance remains undetermined. Herein, we describe the clinical, pathologic, and virologic features of the intestinal involvement of this new viral infection. Methods: A retrospective analysis of the gastrointestinal symptoms and other clinical parameters of the first 138 patients with confirmed SARS admitted for a major outbreak in Hong Kong in March 2003 was performed. Intestinal specimens were obtained by colonoscopy or postmortem examination to detect the presence of coronavirus by electron microscopy, virus culture, and reverse-transcription polymerase chain reaction. Results: Among these 138 patients with SARS, 28 (20.3%) presented with watery diarrhea and up to 38.4% of patients had symptoms of diarrhea during the course of illness. Diarrhea was more frequently observed during the first week of illness. The mean number of days with diarrhea was 3.7 \u00b1 2.7, and most diarrhea was self-limiting. Intestinal biopsy specimens obtained by colonoscopy or autopsy showed minimal architectural disruption but the presence of active viral replication within both the small and large intestine. Coronavirus was also isolated by culture from these specimens, and SARS-CoV RNA can be detected in the stool of patients for more than 10 weeks after symptom onset. Conclusions: Diarrhea is a common presenting symptom of SARS. The intestinal tropism of the SARS-CoV has major implications on clinical presentation and viral transmission.",
    "date": "2003",
    "authors": [
        "Wai K Leung",
        "Ka-fai To",
        "Paul K.S Chan",
        "Henry L.Y Chan",
        "Alan K.L Wu",
        "Nelson Lee",
        "Kwok Y Yuen",
        "Joseph J.Y Sung"
    ],
    "related_topics": [
        "Coronavirus",
        "Diarrhea",
        "Viral culture"
    ],
    "citation_count": "617",
    "reference_count": "15",
    "references": [
        "2132260239",
        "2104548316",
        "2131262274",
        "2129542667",
        "2163627712",
        "1990049863",
        "1971054351",
        "1976741900",
        "2122296975",
        "1491858663"
    ]
},{
    "id": "2918873120",
    "title": "Bat Coronaviruses in China",
    "abstract": "During the past two decades, three zoonotic coronaviruses have been identified as the cause of large-scale disease outbreaks\u207bSevere Acute Respiratory Syndrome (SARS), Middle East Respiratory Syndrome (MERS), and Swine Acute Diarrhea Syndrome (SADS). SARS and MERS emerged in 2003 and 2012, respectively, and caused a worldwide pandemic that claimed thousands of human lives, while SADS struck the swine industry in 2017. They have common characteristics, such as they are all highly pathogenic to humans or livestock, their agents originated from bats, and two of them originated in China. Thus, it is highly likely that future SARS- or MERS-like coronavirus outbreaks will originate from bats, and there is an increased probability that this will occur in China. Therefore, the investigation of bat coronaviruses becomes an urgent issue for the detection of early warning signs, which in turn minimizes the impact of such future outbreaks in China. The purpose of the review is to summarize the current knowledge on viral diversity, reservoir hosts, and the geographical distributions of bat coronaviruses in China, and eventually we aim to predict virus hotspots and their cross-species transmission potential.",
    "date": "2019",
    "authors": [
        "Yi Fan",
        "Kai Zhao",
        "Zheng-Li Shi",
        "Peng Zhou"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Coronavirus",
        "Outbreak"
    ],
    "citation_count": "352",
    "reference_count": "74",
    "references": [
        "2166867592",
        "2132260239",
        "1993577573",
        "2775086803",
        "2195009776",
        "2103503670",
        "2786098272",
        "2134061616",
        "2576706040",
        "2105637133"
    ]
},{
    "id": "2158714788",
    "title": "Gapped BLAST and PSI-BLAST: a new generation of protein database search programs.",
    "abstract": "The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSIBLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.",
    "date": "1997",
    "authors": [
        "Stephen F. Altschul",
        "Thomas L. Madden",
        "Alejandro A. Sch\u00e4ffer",
        "Jinghui Zhang",
        "Zheng Zhang",
        "Webb Miller",
        "David J. Lipman"
    ],
    "related_topics": [
        "Substitution matrix",
        "Sequence database",
        "Sequence profiling tool"
    ],
    "citation_count": "79,260",
    "reference_count": "77",
    "references": [
        "2055043387",
        "2015292449",
        "2085261163",
        "2109465247",
        "2143210482",
        "1652691445",
        "2087064593",
        "1998300401",
        "2164249947",
        "2094519647"
    ]
},{
    "id": "2124985265",
    "title": "Ultrafast and memory-efficient alignment of short DNA sequences to the human genome",
    "abstract": "Bowtie is an ultrafast, memory-efficient alignment program for aligning short DNA sequence reads to large genomes. For the human genome, Burrows-Wheeler indexing allows Bowtie to align more than 25 million reads per CPU hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous Burrows-Wheeler techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source http://bowtie.cbcb.umd.edu.",
    "date": "2009",
    "authors": [
        "Ben Langmead",
        "Cole Trapnell",
        "Mihai Pop",
        "Steven L Salzberg"
    ],
    "related_topics": [
        "Integrator complex",
        "Peak calling",
        "Alignment-free sequence analysis"
    ],
    "citation_count": "18,790",
    "reference_count": "29",
    "references": [
        "2112113834",
        "2012016911",
        "2139760555",
        "2121211805",
        "2001725958",
        "2121016876",
        "2129795133",
        "2153010521",
        "1984708728",
        "2119923823"
    ]
},{
    "id": "2112113834",
    "title": "Mapping short DNA sequencing reads and calling variants using mapping quality scores",
    "abstract": "New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.",
    "date": "2008",
    "authors": [
        "Heng Li",
        "Jue Ruan",
        "Richard Durbin"
    ],
    "related_topics": [
        "Reference genome",
        "DNA sequencing theory",
        "Statistical model"
    ],
    "citation_count": "3,210",
    "reference_count": "29",
    "references": [
        "2158714788",
        "2160969485",
        "2128114769",
        "2015416439",
        "2136145671",
        "2121016876",
        "2129795133",
        "2119923823",
        "2108698786",
        "2166265186"
    ]
},{
    "id": "2136145671",
    "title": "BLAT\u2014The BLAST-Like Alignment Tool",
    "abstract": "Analyzing vertebrate genomes requires rapid mRNA/DNA and cross-species protein alignments. A new tool, BLAT, is more accurate and 500 times faster than popular existing tools for mRNA/DNA alignments and 50 times faster for protein alignments at sensitivity settings typically used when comparing vertebrate sequences. BLAT's speed stems from an index of all nonoverlapping K-mers in the genome. This index fits inside the RAM of inexpensive computers, and need only be computed once for each genome assembly. BLAT has several major stages. It uses the index to find regions in the genome likely to be homologous to the query sequence. It performs an alignment between homologous regions. It stitches together these aligned regions (often exons) into larger alignments (typically genes). Finally, BLAT revisits small internal exons possibly missed at the first stage and adjusts large gap boundaries that have canonical splice sites where feasible. This paper describes how BLAT was optimized. Effects on speed and sensitivity are explored for various K-mer sizes, mismatch schemes, and number of required index matches. BLAT is compared with other alignment programs on various test sets and then used in several genome-wide applications. http://genome.ucsc.edu hosts a web-based BLAT server for the human genome.",
    "date": "2002",
    "authors": [
        "W. James Kent"
    ],
    "related_topics": [
        "Blat",
        "Vertebrate and Genome Annotation Project",
        "Genome browser"
    ],
    "citation_count": "8,847",
    "reference_count": "20",
    "references": [
        "2158714788",
        "2055043387",
        "2168909179",
        "2015292449",
        "2055666215",
        "2142619120",
        "2949977409",
        "2087064593",
        "2137986897",
        "2140244239"
    ]
},{
    "id": "2132341951",
    "title": "Real-Time DNA Sequencing from Single Polymerase Molecules",
    "abstract": "We present single-molecule, real-time sequencing data obtained from a DNA polymerase performing uninterrupted template-directed synthesis using four distinguishable fluorescently labeled deoxyribonucleoside triphosphates (dNTPs). We detected the temporal order of their enzymatic incorporation into a growing DNA strand with zero-mode waveguide nanostructure arrays, which provide optical observation volume confinement and enable parallel, simultaneous detection of thousands of single-molecule sequencing reactions. Conjugation of fluorophores to the terminal phosphate moiety of the dNTPs allows continuous observation of DNA synthesis over thousands of bases without steric hindrance. The data report directly on polymerase dynamics, revealing distinct polymerization states and pause sites corresponding to DNA secondary structure. Sequence data were aligned with the known reference sequence to assay biophysical parameters of polymerization for each template position. Consensus sequences were generated from the single-molecule reads at 15-fold coverage, showing a median accuracy of 99.3%, with no systematic error beyond fluorophore-dependent error rates.",
    "date": "2009",
    "authors": [
        "John Eid",
        "Adrian Fehr",
        "Jeremy Gray",
        "Khai Luong",
        "John Lyle",
        "Geoff Otto",
        "Paul Peluso",
        "David Rank",
        "Primo Baybayan",
        "Brad Bettman",
        "Arkadiusz Bibillo",
        "Keith Bjornson",
        "Bidhan Chaudhuri",
        "Frederick Christians",
        "Ronald Cicero",
        "Sonya Clark",
        "Ravindra Dalal",
        "Alex deWinter",
        "John Dixon",
        "Mathieu Foquet",
        "Alfred Gaertner",
        "Paul Hardenbol",
        "Cheryl Heiner",
        "Kevin Hester",
        "David Holden",
        "Gregory Kearns",
        "Xiangxu Kong",
        "Ronald Kuse",
        "Yves Lacroix",
        "Steven Lin",
        "Paul Lundquist",
        "Congcong Ma",
        "Patrick Marks",
        "Mark Maxham",
        "Devon Murphy",
        "Insil Park",
        "Thang Pham",
        "Michael Phillips",
        "Joy Roy",
        "Robert Sebra",
        "Gene Shen",
        "Jon Sorenson",
        "Austin Tomaney",
        "Kevin Travers",
        "Mark Trulson",
        "John Vieceli",
        "Jeffrey Wegener",
        "Dawn Wu",
        "Alicia Yang",
        "Denis Zaccarin"
    ],
    "related_topics": [
        "Sequencing by hybridization",
        "Single molecule real time sequencing",
        "DNA clamp"
    ],
    "citation_count": "3,589",
    "reference_count": "76",
    "references": [
        "2128114769",
        "2103903744",
        "2138270253",
        "1990061958",
        "2105776281",
        "1989568035",
        "2107233609",
        "1990601349",
        "2013221974",
        "1982538875"
    ]
},{
    "id": "2055666215",
    "title": "A greedy algorithm for aligning DNA sequences.",
    "abstract": "For aligning DNA sequences that differ only by sequencing errors, or by equivalent errors from other sources, a greedy algorithm can be much faster than traditional dynamic programming approaches and yet produce an alignment that is guaranteed to be theoretically optimal. We introduce a new greedy alignment algorithm with particularly good performance and show that it computes the same alignment as does a certain dynamic programming algorithm, while executing over 10 times faster on appropriate data. An implementation of this algorithm is currently used in a program that assembles the UniGene database at the National Center for Biotechnology Information.",
    "date": "2000",
    "authors": [
        "Zheng Zhang",
        "Scott Schwartz",
        "Lukas Wagner",
        "Webb Miller"
    ],
    "related_topics": [
        "Greedy algorithm",
        "Needleman\u2013Wunsch algorithm",
        "Greedy randomized adaptive search procedure"
    ],
    "citation_count": "4,773",
    "reference_count": "30",
    "references": [
        "2158714788",
        "2055043387",
        "2096525273",
        "2121016876",
        "2158023121",
        "2061008984",
        "2152331922",
        "2137986897",
        "2041902006",
        "1978283952"
    ]
},{
    "id": "2142619120",
    "title": "SSAHA: A Fast Search Method for Large DNA Databases",
    "abstract": "We describe an algorithm, SSAHA (Sequence Search and Alignment by Hashing Algorithm), for performing fast searches on databases containing multiple gigabases of DNA. Sequences in the database are preprocessed by breaking them into consecutive k-tuples of k contiguous bases and then using a hash table to store the position of each occurrence of each k-tuple. Searching for a query sequence in the database is done by obtaining from the hash table the \"hits\" for each k-tuple in the query sequence and then performing a sort on the results. We discuss the effect of the tuple length k on the search speed, memory usage, and sensitivity of the algorithm and present the results of computational experiments which show that SSAHA can be three to four orders of magnitude faster than BLAST or FASTA, while requiring less memory than suffix tree methods. The SSAHA algorithm is used for high-throughput single nucleotide polymorphism (SNP) detection and very large scale sequence assembly. Also, it provides Web-based sequence search facilities for Ensembl projects.",
    "date": "2001",
    "authors": [
        "Zemin Ning",
        "Anthony J. Cox",
        "James C. Mullikin"
    ],
    "related_topics": [
        "Hash table",
        "Hash function",
        "Suffix tree"
    ],
    "citation_count": "1,210",
    "reference_count": "17",
    "references": [
        "2158714788",
        "2055043387",
        "2168909179",
        "2015292449",
        "1990061958",
        "2061008984",
        "2112814753",
        "2055666215",
        "2752853835",
        "2087064593"
    ]
},{
    "id": "2111211467",
    "title": "New Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0",
    "abstract": "PhyML is a phylogeny software based on the maximum-likelihood principle. Early PhyML versions used a fast algorithm performing nearest neighbor interchanges to improve a reasonable starting tree topology. Since the original publication (Guindon S., Gascuel O. 2003. A simple, fast and accurate algorithm to estimate large phylogenies by maximum likelihood. Syst. Biol. 52:696-704), PhyML has been widely used (>2500 citations in ISI Web of Science) because of its simplicity and a fair compromise between accuracy and speed. In the meantime, research around PhyML has continued, and this article describes the new algorithms and methods implemented in the program. First, we introduce a new algorithm to search the tree space with user-defined intensity using subtree pruning and regrafting topological moves. The parsimony criterion is used here to filter out the least promising topology modifications with respect to the likelihood function. The analysis of a large collection of real nucleotide and amino acid data sets of various sizes demonstrates the good performance of this method. Second, we describe a new test to assess the support of the data for internal branches of a phylogeny. This approach extends the recently proposed approximate likelihood-ratio test and relies on a nonparametric, Shimodaira-Hasegawa-like procedure. A detailed analysis of real alignments sheds light on the links between this new approach and the more classical nonparametric bootstrap method. Overall, our tests show that the last version (3.0) of PhyML is fast, accurate, stable, and ready to use. A Web server and binary files are available from http://www.atgc-montpellier.fr/phyml/.",
    "date": "2010",
    "authors": [
        "St\u00e9phane Guindon",
        "Jean-Fran\u00e7ois Dufayard",
        "Vincent Lefort",
        "Maria Anisimova",
        "Wim Hordijk",
        "Olivier Gascuel"
    ],
    "related_topics": [
        "Likelihood function",
        "Tree (data structure)",
        "Pruning (decision trees)"
    ],
    "citation_count": "12,540",
    "reference_count": "39",
    "references": [
        "2146058063",
        "2168696662",
        "2103546861",
        "2031611770",
        "2127847431",
        "2030966943",
        "2103088017",
        "2098448352",
        "2105926960",
        "2163627198"
    ]
},{
    "id": "2168696662",
    "title": "RAxML-VI-HPC: maximum likelihood-based phylogenetic analyses with thousands of taxa and mixed models",
    "abstract": "Summary: RAxML-VI-HPC (randomized axelerated maximum likelihood for high performance computing) is a sequential and parallel program for inference of large phylogenies with maximum likelihood (ML). Low-level technical optimizations, a modification of the search algorithm, and the use of the GTR+CAT approximation as replacement for GTR+\u0393 yield a program that is between 2.7 and 52 times faster than the previous version of RAxML. A large-scale performance comparison with GARLI, PHYML, IQPNNI and MrBayes on real data containing 1000 up to 6722 taxa shows that RAxML requires at least 5.6 times less main memory and yields better trees in similar times than the best competing program (GARLI) on datasets up to 2500 taxa. On datasets \u22654000 taxa it also runs 2--3 times faster than GARLI. RAxML has been parallelized with MPI to conduct parallel multiple bootstraps and inferences on distinct starting trees. The program has been used to compute ML trees on two of the largest alignments to date containing 25\u2009057 (1463 bp) and 2182 (51\u2009089 bp) taxa, respectively. Availability: icwww.epfl.ch/~stamatak Contact: Alexandros.Stamatakis@epfl.ch Supplementary information: Supplementary data are available at Bioinformatics online.",
    "date": "2006",
    "authors": [
        "Alexandros Stamatakis"
    ],
    "related_topics": [
        "Phylogenetic tree",
        "Long branch attraction",
        "Mixed model"
    ],
    "citation_count": "15,294",
    "reference_count": "12",
    "references": [
        "2146058063",
        "2103546861",
        "1971415551",
        "2103088017",
        "2117752525",
        "2103513093",
        "2099641476",
        "2159310387",
        "3142322755",
        "2127836105"
    ]
},{
    "id": "2127847431",
    "title": "A Rapid Bootstrap Algorithm for the RAxML Web Servers",
    "abstract": "Despite recent advances achieved by application of high-performance computing methods and novel algorithmic techniques to maximum likelihood (ML)-based inference programs, the major computational bottleneck still consists in the computation of bootstrap support values. Conducting a probably insufficient number of 100 bootstrap (BS) analyses with current ML programs on large datasets-either with respect to the number of taxa or base pairs-can easily require a month of run time. Therefore, we have developed, implemented, and thoroughly tested rapid bootstrap heuristics in RAxML (Randomized Axelerated Maximum Likelihood) that are more than an order of magnitude faster than current algorithms. These new heuristics can contribute to resolving the computational bottleneck and improve current methodology in phylogenetic analyses. Computational experiments to assess the performance and relative accuracy of these heuristics were conducted on 22 diverse DNA and AA (amino acid), single gene as well as multigene, real-world alignments containing 125 up to 7764 sequences. The standard BS (SBS) and rapid BS (RBS) values drawn on the best-scoring ML tree are highly correlated and show almost identical average support values. The weighted RF (Robinson-Foulds) distance between SBS- and RBS-based consensus trees was smaller than 6% in all cases (average 4%). More importantly, RBS inferences are between 8 and 20 times faster (average 14.73) than SBS analyses with RAxML and between 18 and 495 times faster than BS analyses with competing programs, such as PHYML or GARLI. Moreover, this performance improvement increases with alignment size. Finally, we have set up two freely accessible Web servers for this significantly improved version of RAxML that provide access to the 200-CPU cluster of the Vital-IT unit at the Swiss Institute of Bioinformatics and the 128-CPU cluster of the CIPRES project at the San Diego Supercomputer Center. These Web servers offer the possibility to conduct large-scale phylogenetic inferences to a large part of the community that does not have access to, or the expertise to use, high-performance computing resources.",
    "date": "2008",
    "authors": [
        "Alexandros Stamatakis",
        "Paul Hoover",
        "Jacques Rougemont"
    ],
    "related_topics": [
        "Heuristics",
        "Bottleneck",
        "Supercomputer"
    ],
    "citation_count": "6,877",
    "reference_count": "44",
    "references": [
        "2146058063",
        "2168696662",
        "2164789250",
        "2103546861",
        "2748384280",
        "1988925586",
        "2030966943",
        "2103088017",
        "2117752525",
        "2098448352"
    ]
},{
    "id": "1794270752",
    "title": "Ultrafast approximation for phylogenetic bootstrap",
    "abstract": "Nonparametric bootstrap has been a widely used tool in phylogenetic analysis to assess the clade support of phylogenetic trees. However, with the rapidly growing amount of data, this task remains a computational bottleneck. Recently, approximation methods such as the RAxML rapid bootstrap (RBS) and the Shimodaira-Hasegawa-like approximate likelihood ratio test have been introduced to speed up the bootstrap. Here, we suggest an ultrafast bootstrap approximation approach (UFBoot) to compute the support of phylogenetic groups in maximum likelihood (ML) based trees. To achieve this, we combine the resampling estimated log-likelihood method with a simple but effective collection scheme of candidate trees. We also propose a stopping rule that assesses the convergence of branch support values to automatically determine when to stop collecting candidate trees. UFBoot achieves a median speed up of 3.1 (range: 0.66-33.3) to 10.2 (range: 1.32-41.4) compared with RAxML RBS for real DNA and amino acid alignments, respectively. Moreover, our extensive simulations show that UFBoot is robust against moderate model violations and the support values obtained appear to be relatively unbiased compared with the conservative standard bootstrap. This provides a more direct interpretation of the bootstrap support. We offer an efficient and easy-to-use software (available at http://www.cibiv.at/software/iqtree) to perform the UFBoot analysis with ML tree inference.",
    "date": "2014",
    "authors": [
        "Bui Quang Minh",
        "Minh Anh Thi Nguyen",
        "Arndt von Haeseler"
    ],
    "related_topics": [
        "Resampling",
        "Likelihood-ratio test",
        "Tree (graph theory)"
    ],
    "citation_count": "1,488",
    "reference_count": "0",
    "references": []
},{
    "id": "2068187483",
    "title": "Performance, accuracy, and Web server for evolutionary placement of short sequence reads under maximum likelihood.",
    "abstract": "We present an evolutionary placement algorithm (EPA) and a Web server for the rapid assignment of sequence fragments (short reads) to edges of a given phylogenetic tree under the maximum-likelihood model. The accuracy of the algorithm is evaluated on several real-world data sets and compared with placement by pair-wise sequence comparison, using edit distances and BLAST. We introduce a slow and accurate as well as a fast and less accurate placement algorithm. For the slow algorithm, we develop additional heuristic techniques that yield almost the same run times as the fast version with only a small loss of accuracy. When those additional heuristics are employed, the run time of the more accurate algorithm is comparable with that of a simple BLAST search for data sets with a high number of short query sequences. Moreover, the accuracy of the EPA is significantly higher, in particular when the sample of taxa in the reference topology is sparse or inadequate. Our algorithm, which has been integrated into RAxML, therefore provides an equally fast but more accurate alternative to BLAST for tree-based inference of the evolutionary origin and composition of short sequence reads. We are also actively developing a Web server that offers a freely available service for computing read placements on trees using the EPA.",
    "date": "2011",
    "authors": [
        "Simon A. Berger",
        "Denis Krompass",
        "Alexandros Stamatakis"
    ],
    "related_topics": [
        "Heuristic (computer science)",
        "Tree (data structure)",
        "Web server"
    ],
    "citation_count": "420",
    "reference_count": "44",
    "references": [
        "2158714788",
        "2132926880",
        "2168696662",
        "2149573313",
        "2127847431",
        "2155806125",
        "2170024099",
        "1971415551",
        "2030966943",
        "2107903949"
    ]
},{
    "id": "2151736966",
    "title": "How many bootstrap replicates are necessary",
    "abstract": "Phylogenetic bootstrapping (BS) is a standard technique for inferring confidence values on phylogenetic trees that is based on reconstructing many trees from minor variations of the input data, trees called replicates. BS is used with all phylogenetic reconstruction approaches, but we focus here on one of the most popular, maximum likelihood (ML). Because ML inference is so computationally demanding, it has proved too expensive to date to assess the impact of the number of replicates used in BS on the relative accuracy of the support values. For the same reason, a rather small number (typically 100) of BS replicates are computed in real-world studies. Stamatakis et al. recently introduced a BS algorithm that is 1 to 2 orders of magnitude faster than previous techniques, while yielding qualitatively comparable support values, making an experimental study possible. In this article, we propose stopping criteria--that is, thresholds computed at runtime to determine when enough replicates have been generated--and we report on the first large-scale experimental study to assess the effect of the number of replicates on the quality of support values, including the performance of our proposed criteria. We run our tests on 17 diverse real-world DNA--single-gene as well as multi-gene--datasets, which include 125-2,554 taxa. We find that our stopping criteria typically stop computations after 100-500 replicates (although the most conservative criterion may continue for several thousand replicates) while producing support values that correlate at better than 99.5% with the reference values on the best ML trees. Significantly, we also find that the stopping criteria can recommend very different numbers of replicates for different datasets of comparable sizes. Our results are thus twofold: (i) they give the first experimental assessment of the effect of the number of BS replicates on the quality of support values returned through BS, and (ii) they validate our proposals for stopping criteria. Practitioners will no longer have to enter a guess nor worry about the quality of support values; moreover, with most counts of replicates in the 100-500 range, robust BS under ML inference becomes computationally practical for most datasets. The complete test suite is available at http://lcbb.epfl.ch/BS.tar.bz2, and BS with our stopping criteria is included in the latest release of RAxML v7.2.5, available at http://wwwkramer.in.tum.de/exelixis/software.html.",
    "date": "2010",
    "authors": [
        "Nicholas D Pattengale",
        "Masoud Alipour",
        "Olaf R P Bininda-Emonds",
        "Bernard M E Moret",
        "Alexandros Stamatakis"
    ],
    "related_topics": [
        "Bootstrapping (electronics)",
        "Small number",
        "Range (statistics)"
    ],
    "citation_count": "1,112",
    "reference_count": "26",
    "references": [
        "2146058063",
        "2168696662",
        "2103546861",
        "2148534890",
        "2102424972",
        "2151736966",
        "2060425093",
        "1987005168",
        "3122058213",
        "2108911240"
    ]
},{
    "id": "2122082385",
    "title": "A Likelihood Approach to Estimating Phylogeny from Discrete Morphological Character Data",
    "abstract": "Evolutionary biologists have adopted simplelikelihood models for purposes of estimating ancestral states and evaluating character independence on specieed phylogenies; however, for pur- poses of estimating phylogenies byusing discrete morphological data, maximum parsimony remains the only option. This paper explores the possibility of using standard, well-behaved Markov models for estimating morphological phylogenies (including branch lengths) under the likelihood criterion. AnimportantmodiecationofstandardMarkovmodelsinvolvesmakingthelikelihoodconditionalon characters being variable, because constant characters are absent in morphological data sets. Without this modiecation, branch lengths are often overestimated, resulting in potentially serious biases in tree topology selection. Several new avenues of research are opened by an explicitly model-based approach to phylogenetic analysis of discrete morphological data, including combined-data likeli- hood analyses (morphologyCsequence data), likelihood ratio tests, and Bayesian analyses. (Discrete morphological character; Markov model; maximum likelihood; phylogeny.) The increased availability of nucleotide and protein sequences from a diversity of both organisms and genes has stimu- lated the development of stochastic models describing evolutionary change in molecu- lar sequences over time. Such models are not only useful for estimating molecular evolutionary parameters of interest but also important as the basis for phylogenetic inference using the method of maximum likelihood (ML) and Bayesian inference. ML provides a very general framework for esti- mation and has been extensively applied in diverse eelds of science (Casella and Berger, 1990); however, the popularity of ML in phylogenetic inference has lagged behind thatofotheroptimality criteria(suchas max- imum parsimony), primarily because of its much greater computational cost for evalu- ating any givencandidate tree.Recent devel- opments on the algorithmic aspects of ML inference as applied to phylogeny recon- struction (Olsen et al., 1994; Lewis, 1998; Salter and Pearl, 2001; Swofford, 2001) have succeeded in reducing this computational cost substantially, and ML phylogeny esti- mates involving hundreds of terminal taxa are now entering the realm of feasibility. Bayesian methods (based on a likelihood foundation) offer the prospect of obtaining meaningful nodal support measures with- out the unreasonable computational burden imposed by existing methods such as boot- strapping (Rannala and Yang, 1996; Yang and Rannala, 1997; Larget and Simon, 1999;",
    "date": "2001",
    "authors": [
        "Paul O. Lewis"
    ],
    "related_topics": [
        "Bayesian inference",
        "Maximum parsimony",
        "Bayesian probability"
    ],
    "citation_count": "2,159",
    "reference_count": "39",
    "references": [
        "2994240441",
        "2799002609",
        "2010814032",
        "2105926960",
        "2102424972",
        "2009596137",
        "2124790653",
        "1983002447",
        "2150783480",
        "2057293816"
    ]
},{
    "id": "2156921764",
    "title": "Novel Parallelization Schemes for Large-Scale Likelihood-based Phylogenetic Inference",
    "abstract": "The molecular data avalanche generated by novel wet-lab sequencing technologies allows for reconstructing phylogenies (evolutionary trees) using hundreds of complete genomes as input data. Therefore, scalable codes are required to infer trees on these data under likelihood-based models of molecular evolution. We recently introduced a checkpointable and scalable MPI-based code for this purpose called RAxML-Light and are currently using it for several real-world data analysis projects. It turned out that the scalability of RAxML-Light is nonetheless still limited because of the fork-join parallelization approach that is deployed. To this end, we introduce a novel, generally applicable, approach to computing the phylogenetic likelihood in parallel on whole-genome datasets and implement it in ExaML (Exascale Maximum Likelihood). ExaML executes up to 3.2 times faster than RAxML-Light because of the more efficient parallelization and communication scheme, while implementing exactly the same tree search algorithm. Moreover, the new parallelization approach exhibits lower code complexity and a more appropriate structure for implementing fault tolerance with respect to hardware failures.",
    "date": "2013",
    "authors": [
        "Alexandros Stamatakis",
        "Andre J. Aberer"
    ],
    "related_topics": [
        "Automatic parallelization",
        "Tree traversal",
        "Scalability"
    ],
    "citation_count": "57",
    "reference_count": "31",
    "references": [
        "2148698435",
        "2111211467",
        "2168696662",
        "1969042907",
        "2031611770",
        "2133870991",
        "2103088017",
        "2117752525",
        "2169981472",
        "2102424972"
    ]
},{
    "id": "2142678478",
    "title": "BLAST+: architecture and applications.",
    "abstract": "Sequence similarity searching is a very important bioinformatics task. While Basic Local Alignment Search Tool (BLAST) outperforms exact methods through its use of heuristics, the speed of the current BLAST software is suboptimal for very long queries or database sequences. There are also some shortcomings in the user-interface of the current command-line applications. We describe features and improvements of rewritten BLAST software and introduce new command-line applications. Long query sequences are broken into chunks for processing, in some cases leading to dramatically shorter run times. For long database sequences, it is possible to retrieve only the relevant parts of the sequence, reducing CPU time and memory usage for searches of short queries against databases of contigs or chromosomes. The program can now retrieve masking information for database sequences from the BLAST databases. A new modular software library can now access subject sequence data from arbitrary data sources. We introduce several new features, including strategy files that allow a user to save and reuse their favorite set of options. The strategy files can be uploaded to and downloaded from the NCBI BLAST web site. The new BLAST command-line applications, compared to the current BLAST tools, demonstrate substantial speed improvements for long queries as well as chromosome length database sequences. We have also improved the user interface of the command-line applications.",
    "date": "2009",
    "authors": [
        "Christiam Camacho",
        "George Coulouris",
        "Vahram Avagyan",
        "Ning Ma",
        "Jason S. Papadopoulos",
        "Kevin Bealer",
        "Thomas L. Madden"
    ],
    "related_topics": [
        "Information retrieval",
        "Computer science",
        "Theoretical computer science"
    ],
    "citation_count": "9,473",
    "reference_count": "15",
    "references": [
        "2158714788",
        "2055043387",
        "2136145671",
        "2151464048",
        "2055666215",
        "2146341019",
        "2128964206",
        "2133312664",
        "1973862547",
        "1513332069"
    ]
},{
    "id": "2149525061",
    "title": "SWISS-MODEL: modelling protein tertiary and quaternary structure using evolutionary information",
    "abstract": "Protein structure homology modelling has become a routine technique to generate 3D models for proteins when experimental structures are not available. Fully automated servers such as SWISS-MODEL with user-friendly web interfaces generate reliable models without the need for complex software packages or downloading large databases. Here, we describe the latest version of the SWISS-MODEL expert system for protein structure modelling. The SWISS-MODEL template library provides annotation of quaternary structure and essential ligands and co-factors to allow for building of complete structural models, including their oligomeric structure. The improved SWISS-MODEL pipeline makes extensive use of model quality estimation for selection of the most suitable templates and provides estimates of the expected accuracy of the resulting models. The accuracy of the models generated by SWISS-MODEL is continuously evaluated by the CAMEO system. The new web site allows users to interactively search for templates, cluster them by sequence similarity, structurally compare alternative templates and select the ones to be used for model building. In cases where multiple alternative template structures are available for a protein of interest, a user-guided template selection step allows building models in different functional states. SWISS-MODEL is available at http://swissmodel.expasy.org/.",
    "date": "2014",
    "authors": [
        "Marco Biasini",
        "Stefan Bienert",
        "Andrew Waterhouse",
        "Konstantin Arnold",
        "Gabriel Studer",
        "Tobias Schmidt",
        "Florian Kiefer",
        "Tiziano Gallo Cassarino",
        "Martino Bertoni",
        "Lorenza Bordoli",
        "Torsten Schwede"
    ],
    "related_topics": [
        "Protein structure database",
        "Structural genomics",
        "Model building"
    ],
    "citation_count": "4,319",
    "reference_count": "35",
    "references": [
        "2158714788",
        "2152301430",
        "2015642465",
        "2060259273",
        "2060809301",
        "2153187042",
        "2065283382",
        "2051210555",
        "2082667898",
        "2008708467"
    ]
},{
    "id": "2152301430",
    "title": "The SWISS-MODEL workspace: a web-based environment for protein structure homology modelling",
    "abstract": "Motivation: Homology models of proteins are of great interest for planning and analysing biological experiments when no experimental three-dimensional structures are available. Building homology models requires specialized programs and up-to-date sequence and structural databases. Integrating all required tools, programs and databases into a single web-based workspace facilitates access to homology modelling from a computer with web connection without the need of downloading and installing large program packages and databases. Results: SWISS-MODEL workspace is a web-based integrated service dedicated to protein structure homology modelling. It assists and guides the user in building protein homology models at different levels of complexity. A personal working environment is provided for each user where several modelling projects can be carried out in parallel. Protein sequence and structure databases necessary for modelling are accessible from the workspace and are updated in regular intervals. Tools for template selection, model building and structure quality evaluation can be invoked from within the workspace. Workflow and usage of the workspace are illustrated by modelling human Cyclin A1 and human Transmembrane Protease 3. Availability: The SWISS-MODEL workspace can be accessed freely at http://swissmodel.expasy.org/workspace/ Contact: Torsten.Schwede@unibas.ch Supplementary information: Supplementary data are available at Bioinformatics online.",
    "date": "2006",
    "authors": [
        "Konstantin Arnold",
        "Lorenza Bordoli",
        "J\u00fcrgen Kopp",
        "Torsten Schwede"
    ],
    "related_topics": [
        "Workspace",
        "Web application",
        "Workflow"
    ],
    "citation_count": "8,201",
    "reference_count": "56",
    "references": [
        "2158714788",
        "2096525273",
        "2141885858",
        "1986191025",
        "2161062388",
        "2015642465",
        "2060809301",
        "2153187042",
        "2008708467",
        "2022366078"
    ]
},{
    "id": "2154139219",
    "title": "UniProt: the Universal Protein knowledgebase",
    "abstract": "To provide the scientific community with a single, centralized, authoritative resource for protein sequences and functional information, the Swiss-Prot, TrEMBL and PIR protein database activities have united to form the Universal Protein Knowledgebase (UniProt) consortium. Our mission is to provide a comprehensive, fully classified, richly and accurately annotated protein sequence knowledgebase, with extensive cross-references and query interfaces. The central database will have two sections, corresponding to the familiar Swiss-Prot (fully manually curated entries) and TrEMBL (enriched with automated classification, annotation and extensive cross-references). For convenient sequence searches, UniProt also provides several non-redundant sequence databases. The UniProt NREF (UniRef) databases provide representative subsets of the knowledgebase suitable for efficient searching. The comprehensive UniProt Archive (UniParc) is updated daily from many public source databases. The UniProt databases can be accessed online (http://www.uniprot.org) or downloaded in several formats (ftp://ftp.uniprot.org/pub). The scientific community is encouraged to submit data for inclusion in UniProt.",
    "date": "2003",
    "authors": [
        "Rolf Apweiler",
        "Amos Bairoch",
        "Cathy H. Wu",
        "Winona C. Barker",
        "Brigitte Boeckmann",
        "Serenella Ferro",
        "Elisabeth Gasteiger",
        "Hongzhan Huang",
        "Rodrigo Lopez",
        "Michele Magrane",
        "Maria Jesus Martin",
        "Darren A. Natale",
        "Claire O'Donovan",
        "Nicole Redaschi",
        "Lai-Su L. Yeh"
    ],
    "related_topics": [
        "UniProt",
        "Annotation",
        "Information retrieval"
    ],
    "citation_count": "5,074",
    "reference_count": "27",
    "references": [
        "2103017472",
        "2141885858",
        "2148853951",
        "2165270659",
        "2131581981",
        "2108401170",
        "2109867978",
        "2163181687",
        "2099946731",
        "2126975650"
    ]
},{
    "id": "2015642465",
    "title": "SWISS-MODEL and the Swiss-PdbViewer: an environment for comparative protein modeling.",
    "abstract": "Comparative protein modeling is increasingly gaining interest since it is of great assistance during the rational design of mutagenesis experiments. The availability of this method, and the resulting models, has however been restricted by the availability of expensive computer hardware and software. To overcome these limitations, we have developed an environment for comparative protein modeling that consists of SWISS-MODEL, a server for automated comparative protein modeling and of the SWISS-PdbViewer, a sequence to structure workbench. The Swiss-PdbViewer not only acts as a client for SWISS-MODEL, but also provides a large selection of structure analysis and display tools. In addition, we provide the SWISS-MODEL Repository, a database containing more than 3500 automatically generated protein models. By making such tools freely available to the scientific community, we hope to increase the use of protein structures and models in the process of experiment design.",
    "date": "1996",
    "authors": [
        "Nicolas Guex",
        "Manuel C. Peitsch"
    ],
    "related_topics": [
        "Protein structure database",
        "Protein structure prediction",
        "Workbench"
    ],
    "citation_count": "12,252",
    "reference_count": "30",
    "references": [
        "2055043387",
        "2015292449",
        "2162166182",
        "1978763597",
        "2014981059",
        "2071486470",
        "1979046104",
        "1982597966",
        "2008841836",
        "1869944834"
    ]
},{
    "id": "2065283382",
    "title": "Comparative Protein Modelling by Satisfaction of Spatial Restraints",
    "abstract": "We describe a comparative protein modelling method designed to find the most probable structure for a sequence given its alignment with related structures. The three-dimensional (3D) model is obtained by optimally satisfying spatial restraints derived from the alignment and expressed as probability density functions (pdfs) for the features restrained. For example, the probabilities for main-chain conformations of a modelled residue may be restrained by its residue type, main-chain conformation of an equivalent residue in a related protein, and the local similarity between the two sequences. Several such pdfs are obtained from the correlations between structural features in 17 families of homologous proteins which have been aligned on the basis of their 3D structures. The pdfs restrain C alpha-C alpha distances, main-chain N-O distances, main-chain and side-chain dihedral angles. A smoothing procedure is used in the derivation of these relationships to minimize the problem of a sparse database. The 3D model of a protein is obtained by optimization of the molecular pdf such that the model violates the input restraints as little as possible. The molecular pdf is derived as a combination of pdfs restraining individual spatial features of the whole molecule. The optimization procedure is a variable target function method that applies the conjugate gradients algorithm to positions of all non-hydrogen atoms. The method is automated and is illustrated by the modelling of trypsin from two other serine proteinases.",
    "date": "1993",
    "authors": [
        "Andrej \u0160ali",
        "Tom L. Blundell"
    ],
    "related_topics": [
        "Loop modeling",
        "Global distance test",
        "ModBase"
    ],
    "citation_count": "13,222",
    "reference_count": "0",
    "references": []
},{
    "id": "2051210555",
    "title": "HHblits: lightning-fast iterative protein sequence searching by HMM-HMM alignment",
    "abstract": "Sequence-based protein function and structure prediction depends crucially on sequence-search sensitivity and accuracy of the resulting sequence alignments. We present an open-source, general-purpose tool that represents both query and database sequences by profile hidden Markov models (HMMs): 'HMM-HMM-based lightning-fast iterative sequence search' (HHblits; http://toolkit.genzentrum.lmu.de/hhblits/). Compared to the sequence-search tool PSI-BLAST, HHblits is faster owing to its discretized-profile prefilter, has 50-100% higher sensitivity and generates more accurate alignments.",
    "date": "2012",
    "authors": [
        "Michael Remmert",
        "Andreas Biegert",
        "Andreas Hauser",
        "Johannes S\u00f6ding"
    ],
    "related_topics": [
        "Alignment-free sequence analysis",
        "Multiple sequence alignment",
        "Hidden Markov model"
    ],
    "citation_count": "1,519",
    "reference_count": "24",
    "references": [
        "2158714788",
        "2141885858",
        "2156125289",
        "2085277871",
        "2153187042",
        "2065283382",
        "2082667898",
        "2145268834",
        "2102245393",
        "2061042699"
    ]
},{
    "id": "2159614853",
    "title": "Toward the estimation of the absolute quality of individual protein structure models",
    "abstract": "Motivation: Quality assessment of protein structures is an important part of experimental structure validation and plays a crucial role in protein structure prediction, where the predicted models may contain substantial errors. Most current scoring functions are primarily designed to rank alternative models of the same sequence supporting model selection, whereas the prediction of the absolute quality of an individual protein model has received little attention in the field. However, reliable absolute quality estimates are crucial to assess the suitability of a model for specific biomedical applications. Results: In this work, we present a new absolute measure for the quality of protein models, which provides an estimate of the \u2018degree of nativeness\u2019 of the structural features observed in a model and describes the likelihood that a given model is of comparable quality to experimental structures. Model quality estimates based on the QMEAN scoring function were normalized with respect to the number of interactions. The resulting scoring function is independent of the size of the protein and may therefore be used to assess both monomers and entire oligomeric assemblies. Model quality scores for individual models are then expressed as \u2018Z-scores\u2019 in comparison to scores obtained for high-resolution crystal structures. We demonstrate the ability of the newly introduced QMEAN Z-score to detect experimentally solved protein structures containing significant errors, as well as to evaluate theoretical protein models. In a comprehensive QMEAN Z-score analysis of all experimental structures in the PDB, membrane proteins accumulate on one side of the score spectrum and thermostable proteins on the other. Proteins from the thermophilic organism Thermatoga maritima received significantly higher QMEAN Z-scores in a pairwise comparison with their homologous mesophilic counterparts, underlining the significance of the QMEAN Z-score as an estimate of protein stability. Availability: The Z-score calculation has been integrated in the QMEAN server available at: http://swissmodel.expasy.org/qmean. Contact: torsten.schwede@unibas.ch Supplementary information:Supplementary data are available at Bioinformatics online.",
    "date": "2011",
    "authors": [
        "Pascal Benkert",
        "Marco Biasini",
        "Torsten Schwede"
    ],
    "related_topics": [
        "Protein structure prediction",
        "Thermophilic organism",
        "Structure validation"
    ],
    "citation_count": "1,761",
    "reference_count": "56",
    "references": [
        "2158714788",
        "2130479394",
        "2035503835",
        "2152301430",
        "2161062388",
        "2060809301",
        "2153187042",
        "1992192767",
        "2145268834",
        "2008708467"
    ]
},{
    "id": "2106173155",
    "title": "Human Infection with a Novel Avian-Origin Influenza A (H7N9) Virus",
    "abstract": "Background Infection of poultry with influenza A subtype H7 viruses occurs worldwide, but the introduction of this subtype to humans in Asia has not been observed previously. In March 2013, three urban residents of Shanghai or Anhui, China, presented with rapidly progressing lower respiratory tract infections and were found to be infected with a novel reassortant avian-origin influenza A (H7N9) virus. Methods We obtained and analyzed clinical, epidemiologic, and virologic data from these patients. Respiratory specimens were tested for influenza and other respiratory viruses by means of real-time reverse-transcriptase\u2013polymerase-chain-reaction assays, viral culturing, and sequence analyses. Results A novel reassortant avian-origin influenza A (H7N9) virus was isolated from respiratory specimens obtained from all three patients and was identified as H7N9. Sequencing analyses revealed that all the genes from these three viruses were of avian origin, with six internal genes from avian influenza A (H9N2) virus...",
    "date": "2013",
    "authors": [
        "Rongbao Gao",
        "Bin Cao",
        "Yunwen Hu",
        "Zijian Feng",
        "Dayan Wang",
        "Wanfu Hu",
        "Jian Chen",
        "Zhijun Jie",
        "Haibo Qiu",
        "Ke Xu",
        "Xuewei Xu",
        "Hongzhou Lu",
        "Wenfei Zhu",
        "Zhancheng Gao",
        "Nijuan Xiang",
        "Yinzhong Shen",
        "Zebao He",
        "Yong Gu",
        "Zhiyong Zhang",
        "Yi Yang",
        "Xiang Zhao",
        "Lei Zhou",
        "Xiaodan Li",
        "Shumei Zou",
        "Ye Zhang",
        "Xiyan Li",
        "Lei Yang",
        "Junfeng Guo",
        "Jie Dong",
        "Qun Li",
        "Libo Dong",
        "Yun Zhu",
        "Tian Bai",
        "Shiwen Wang",
        "Pei Hao",
        "Weizhong Yang",
        "Yanping Zhang",
        "Jun Han",
        "Hongjie Yu",
        "Dexin Li",
        "George F. Gao",
        "Guizhen Wu",
        "Yu Wang",
        "Zhenghong Yuan",
        "Yuelong Shu",
        "Y. Hu"
    ],
    "related_topics": [
        "Avian Influenza A Virus",
        "Influenza A virus subtype H5N1",
        "H5N1 genetic structure"
    ],
    "citation_count": "2,684",
    "reference_count": "23",
    "references": [
        "2158112812",
        "2112170460",
        "2116682907",
        "2111323042",
        "2024970913",
        "2102335249",
        "2122385379",
        "2145825913",
        "2131155472",
        "1997343899"
    ]
},{
    "id": "2259815689",
    "title": "Real-time, portable genome sequencing for Ebola surveillance",
    "abstract": "The Ebola virus disease epidemic in West Africa is the largest on record, responsible for over 28,599 cases and more than 11,299 deaths. Genome sequencing in viral outbreaks is desirable to characterize the infectious agent and determine its evolutionary rate. Genome sequencing also allows the identification of signatures of host adaptation, identification and monitoring of diagnostic targets, and characterization of responses to vaccines and treatments. The Ebola virus (EBOV) genome substitution rate in the Makona strain has been estimated at between 0.87\u2009\u00d7\u200910(-3) and 1.42\u2009\u00d7\u200910(-3) mutations per site per year. This is equivalent to 16-27 mutations in each genome, meaning that sequences diverge rapidly enough to identify distinct sub-lineages during a prolonged epidemic. Genome sequencing provides a high-resolution view of pathogen evolution and is increasingly sought after for outbreak surveillance. Sequence data may be used to guide control measures, but only if the results are generated quickly enough to inform interventions. Genomic surveillance during the epidemic has been sporadic owing to a lack of local sequencing capacity coupled with practical difficulties transporting samples to remote sequencing facilities. To address this problem, here we devise a genomic surveillance system that utilizes a novel nanopore DNA sequencing instrument. In April 2015 this system was transported in standard airline luggage to Guinea and used for real-time genomic surveillance of the ongoing epidemic. We present sequence data and analysis of 142 EBOV samples collected during the period March to October 2015. We were able to generate results less than 24 h after receiving an Ebola-positive sample, with the sequencing process taking as little as 15-60 min. We show that real-time genomic surveillance is possible in resource-limited settings and can be established rapidly to monitor outbreaks.",
    "date": "2016",
    "authors": [
        "Joshua Quick",
        "Nicholas J. Loman",
        "Sophie Duraffour",
        "Jared T. Simpson",
        "Ettore Severi",
        "Lauren Cowley",
        "Joseph Akoi Bore",
        "Raymond Koundouno",
        "Gytis Dudas",
        "Amy Mikhail",
        "Nobila Ou\u00e9draogo",
        "Babak Afrough",
        "Amadou Bah",
        "Jonathan H.J. Baum",
        "Beate Becker-Ziaja",
        "Jan Peter Boettcher",
        "Mar Cabeza-Cabrerizo",
        "\u00c1lvaro Camino-S\u00e1nchez",
        "Lisa L. Carter",
        "Juliane Doerrbecker",
        "Theresa Enkirch",
        "Isabel Garci\u00e1-Dorival",
        "Nicole Hetzelt",
        "Julia Hinzmann",
        "Tobias Holm",
        "Liana Eleni Kafetzopoulou",
        "Michel Koropogui",
        "Abigael Kosgey",
        "Eeva Kuisma",
        "Christopher H. Logue",
        "Antonio Mazzarelli",
        "Sarah Meisel",
        "Marc Mertens",
        "Janine Michel",
        "Didier Ngabo",
        "Katja Nitzsche",
        "Elisa Pallasch",
        "Livia Victoria Patrono",
        "Jasmine Portmann",
        "Johanna Gabriella Repits",
        "Natasha Y. Rickett",
        "Andreas Sachse",
        "Katrin Singethan",
        "In\u00eas Vitoriano",
        "Rahel L. Yemanaberhan",
        "Elsa G. Zekeng",
        "Trina Racine",
        "Alexander Bello",
        "Amadou Alpha Sall",
        "Ousmane Faye"
    ],
    "related_topics": [
        "Ebola virus",
        "DNA sequencing",
        "Nanopore sequencing"
    ],
    "citation_count": "939",
    "reference_count": "32",
    "references": [
        "2141052558",
        "2132926880",
        "2110835349",
        "2095680943",
        "2031611770",
        "1975375203",
        "2107282968",
        "2094939159",
        "2114850508",
        "1596062789"
    ]
},{
    "id": "2587970647",
    "title": "Data, disease and diplomacy: GISAID's innovative contribution to global health",
    "abstract": "The international sharing of virus data is critical for protecting populations against le-thal infectious disease outbreaks. Scientists must rapidly share information to assessthe nature of the threat and develop new medical countermeasures. Governmentsneed the data to trace the extent of the outbreak, initiate public health responses,and coordinate access to medicines and vaccines. Recent outbreaks suggest, however,that the sharing of such data cannot be taken for granted \u2013 making the timely inter-national exchange of virus data a vital global challenge. This article undertakes the\ufb01rst analysis of the Global Initiative on Sharing All In\ufb02uenza Data as an innovativepolicy effort to promote the international sharing of genetic and associated in\ufb02uenzavirus data. Based on more than 20 semi-structured interviews conducted with key in-formants in the international community, coupled with analysis of a wide range ofprimary and secondary sources, the article \ufb01nds that the Global Initiative on SharingAll In\ufb02uenza Data contributes to global health in at least \ufb01ve ways: (1) collating themost complete repository of high-quality in\ufb02uenza data in the world; (2) facilitatingthe rapid sharing of potentially pandemic virus information during recent outbreaks;(3) supporting the World Health Organization\u2019s biannual seasonal \ufb02u vaccine strainselection process; (4) developing informal mechanisms for con\ufb02ict resolution aroundthe sharing of virus data; and (5) building greater trust with several countries key toglobal pandemic preparedness.",
    "date": "2017",
    "authors": [
        "Stefan Elbe",
        "Gemma Buckland-Merrett"
    ],
    "related_topics": [
        "Global health",
        "Data sharing",
        "Pandemic"
    ],
    "citation_count": "820",
    "reference_count": "9",
    "references": [
        "2063651055",
        "1817385113",
        "2033459705",
        "2027869475",
        "2401355551",
        "2011591589",
        "2037107806",
        "1964597506",
        "2417090165"
    ]
},{
    "id": "2063651055",
    "title": "Data sharing: Make outbreak research open access",
    "abstract": "",
    "date": "2015",
    "authors": [
        "Nathan L. Yozwiak",
        "Stephen F. Schaffner",
        "Pardis C. Sabeti"
    ],
    "related_topics": [
        "Sierra leone",
        "Data sharing",
        "The Internet"
    ],
    "citation_count": "142",
    "reference_count": "6",
    "references": [
        "2115102869",
        "1975375203",
        "1699155395",
        "2027869475",
        "1977004946",
        "1989456404"
    ]
},{
    "id": "2222043208",
    "title": "Developing Global Norms for Sharing Data and Results during Public Health Emergencies",
    "abstract": "Vasee Moorthy and colleagues describe the outcomes of a recent, WHO-led meeting on sharing research data and results during public health emergencies.",
    "date": "2016",
    "authors": [
        "Kayvon Modjarrad",
        "Vasee S. Moorthy",
        "Piers Millett",
        "Pierre-St\u00e9phane Gsell",
        "Cathy Roth",
        "Marie-Paule Kieny"
    ],
    "related_topics": [
        "Public health",
        "Global health",
        "MEDLINE"
    ],
    "citation_count": "107",
    "reference_count": "8",
    "references": [
        "2344740792",
        "2063651055",
        "2343314930",
        "2152076520",
        "3123411076",
        "1996092618",
        "2155802193",
        "1989456404"
    ]
},{
    "id": "2532120756",
    "title": "Role for migratory wild birds in the global spread of avian influenza H5N8",
    "abstract": "Avian influenza viruses affect both poultry production and public health. A subtype H5N8 (clade 2.3.4.4) virus, following an outbreak in poultry in South Korea in January 2014, rapidly spread worldwide in 2014-2015. Our analysis of H5N8 viral sequences, epidemiological investigations, waterfowl migration, and poultry trade showed that long-distance migratory birds can play a major role in the global spread of avian influenza viruses. Further, we found that the hemagglutinin of clade 2.3.4.4 virus was remarkably promiscuous, creating reassortants with multiple neuraminidase subtypes. Improving our understanding of the circumpolar circulation of avian influenza viruses in migratory waterfowl will help to provide early warning of threats from avian influenza to poultry, and potentially human, health.",
    "date": "2016",
    "authors": [
        "Samantha J. Lycett",
        "Rogier Bodewes",
        "Anne Pohlmann",
        "Jill Banks",
        "Kriszti\u00e1n B\u00e1nyai",
        "Maciej F. Boni",
        "Ruth Bouwstra",
        "Lu Lu"
    ],
    "related_topics": [
        "Influenza A virus subtype H5N1",
        "H5N1 genetic structure",
        "Neuraminidase"
    ],
    "citation_count": "202",
    "reference_count": "25",
    "references": [
        "2130362098",
        "2088267428",
        "2152226780",
        "2139166200",
        "2091956821",
        "1987052745",
        "2098232873",
        "2054365466",
        "1976852215",
        "2030895743"
    ]
},{
    "id": "2557499142",
    "title": "Genesis, Evolution and Prevalence of H5N6 Avian Influenza Viruses in China",
    "abstract": "Summary Constant surveillance of live poultry markets (LPMs) is currently the best way to predict and identify emerging avian influenza viruses (AIVs) that pose a potential threat to public health. Through surveillance of LPMs from 16 provinces and municipalities in China during 2014\u20132016, we identified 3,174 AIV-positive samples and isolated and sequenced 1,135 AIVs covering 31 subtypes. Our analysis shows that H5N6 has replaced H5N1 as one of the dominant AIV subtypes in southern China, especially in ducks. Phylogenetic analysis reveals that H5N6 arose from reassortments of H5 and H6N6 viruses, with the hemagglutinin and neuraminidase combinations being strongly lineage specific. H5N6 viruses constitute at least 34 distinct genotypes derived from various evolutionary pathways. Notably, genotype G1.2 virus, with internal genes from the chicken H9N2/H7N9 gene pool, was responsible for at least five human H5N6 infections. Our findings highlight H5N6 AIVs as potential threats to public health and agriculture.",
    "date": "2016",
    "authors": [
        "Yuhai Bi",
        "Quanjiao Chen",
        "Qianli Wang",
        "Jianjun Chen",
        "Tao Jin",
        "Gary Wong",
        "Chuansong Quan",
        "Jun Liu",
        "Jun Wu",
        "Renfu Yin",
        "Lihua Zhao",
        "Mingxin Li",
        "Zhuang Ding",
        "Rongrong Zou",
        "Wen Xu",
        "Hong Li",
        "Huijun Wang",
        "Kegong Tian",
        "Guanghua Fu",
        "Yu Huang",
        "Alexander Shestopalov",
        "Shoujun Li",
        "Bing Xu",
        "Hongjie Yu",
        "Tingrong Luo",
        "Lin Lu",
        "Xun Xu",
        "Yang Luo",
        "Yingxia Liu",
        "Weifeng Shi",
        "Di Liu",
        "George Fu Gao"
    ],
    "related_topics": [
        "Influenza A virus subtype H5N1",
        "Hemagglutinin (influenza)",
        "Genotype"
    ],
    "citation_count": "174",
    "reference_count": "64",
    "references": [
        "2103441770",
        "2108234281",
        "2141052558",
        "2132926880",
        "1909499787",
        "2097341408",
        "2158112812",
        "2152226780",
        "2130734541",
        "2024970913"
    ]
},{
    "id": "2104424333",
    "title": "Synthetic Generation of Influenza Vaccine Viruses for Rapid Response to Pandemics",
    "abstract": "During the 2009 H1N1 influenza pandemic, vaccines for the virus became available in large quantities only after human infections peaked. To accelerate vaccine availability for future pandemics, we developed a synthetic approach that very rapidly generated vaccine viruses from sequence data. Beginning with hemagglutinin (HA) and neuraminidase (NA) gene sequences, we combined an enzymatic, cell-free gene assembly technique with enzymatic error correction to allow rapid, accurate gene synthesis. We then used these synthetic HA and NA genes to transfect Madin-Darby canine kidney (MDCK) cells that were qualified for vaccine manufacture with viral RNA expression constructs encoding HA and NA and plasmid DNAs encoding viral backbone genes. Viruses for use in vaccines were rescued from these MDCK cells. We performed this rescue with improved vaccine virus backbones, increasing the yield of the essential vaccine antigen, HA. Generation of synthetic vaccine seeds, together with more efficient vaccine release assays, would accelerate responses to influenza pandemics through a system of instantaneous electronic data exchange followed by real-time, geographically dispersed vaccine production.",
    "date": "2013",
    "authors": [
        "Philip R Dormitzer",
        "Pirada Suphaphiphat",
        "Daniel G Gibson",
        "David E Wentworth",
        "Timothy B Stockwell",
        "Mikkel A Algire",
        "Nina Alperovich",
        "Mario Barro",
        "David M Brown",
        "Stewart Craig",
        "Brian M Dattilo",
        "Evgeniya A Denisova",
        "Ivna De Souza",
        "Markus Eickmann",
        "Vivien G Dugan",
        "Annette Ferrari",
        "Raul C Gomila",
        "Liqun Han",
        "Casey Judge",
        "Sarthak Mane",
        "Mikhail Matrosovich",
        "Chuck Merryman",
        "Giuseppe Palladino",
        "Gene A Palmer",
        "Terika Spencer",
        "Thomas Strecker",
        "Heidi Trusheim",
        "Jennifer Uhlendorff",
        "Yingxia Wen",
        "Anthony C Yee",
        "Jayshree Zaveri",
        "Bin Zhou",
        "Stephan Becker",
        "Armen Donabedian",
        "Peter W Mason",
        "John I Glass",
        "Rino Rappuoli",
        "J Craig Venter"
    ],
    "related_topics": [
        "Synthetic vaccine",
        "Influenza A virus",
        "Influenza vaccine"
    ],
    "citation_count": "172",
    "reference_count": "23",
    "references": [
        "1971439989",
        "2157725602",
        "56574006",
        "2091527885",
        "2158073495",
        "2006218290",
        "2085980948",
        "2099549544",
        "2010866755",
        "40163005"
    ]
},{
    "id": "2033459705",
    "title": "Virus Sharing, Genetic Sequencing, and Global Health Security",
    "abstract": "This Perspective focuses on the future of the Pandemic Influenza Preparedness (PIP) Framework, which was initially established to promote the fair sharing of public health\u2013related pandemic influenza samples between countries. We examine the changes that need to be made to address the growing likelihood that genetic sequence data might be shared instead of physical virus samples, as well as the need to expand the PIP framework\u2019s scope and to improve its fairness.",
    "date": "2014",
    "authors": [
        "Lawrence O. Gostin",
        "Alexandra Phelan",
        "Michael A. Stoto",
        "John D. Kraemer",
        "K. Srinath Reddy"
    ],
    "related_topics": [
        "Preparedness",
        "Scope (project management)",
        "Global health"
    ],
    "citation_count": "17",
    "reference_count": "5",
    "references": [
        "149663004",
        "2104424333",
        "1970627059",
        "2401355551",
        "2191227849"
    ]
},{
    "id": "2096039130",
    "title": "Rapidly produced SAM \u00ae vaccine against H7N9 influenza is immunogenic in mice",
    "abstract": "The timing of vaccine availability is essential for an effective response to pandemic influenza. In 2009, vaccine became available after the disease peak, and this has motivated the development of next generation vaccine technologies for more rapid responses. The SAM(\u00ae) vaccine platform, now in pre-clinical development, is based on a synthetic, self-amplifying mRNA, delivered by a synthetic lipid nanoparticle (LNP). When used to express seasonal influenza hemagglutinin (HA), a SAM vaccine elicited potent immune responses, comparable to those elicited by a licensed influenza subunit vaccine preparation. When the sequences coding for the HA and neuraminidase (NA) genes from the H7N9 influenza outbreak in China were posted on a web-based data sharing system, the combination of rapid and accurate cell-free gene synthesis and SAM vaccine technology allowed the generation of a vaccine candidate in 8 days. Two weeks after the first immunization, mice had measurable hemagglutinin inhibition (HI) and neutralizing antibody titers against the new virus. Two weeks after the second immunization, all mice had HI titers considered protective. If the SAM vaccine platform proves safe, potent, well tolerated and effective in humans, fully synthetic vaccine technologies could provide unparalleled speed of response to stem the initial wave of influenza outbreaks, allowing first availability of a vaccine candidate days after the discovery of a new virus.",
    "date": "2013",
    "authors": [
        "Armin Hekele",
        "Sylvie Bertholet",
        "Jacob Archer",
        "Daniel G Gibson",
        "Giuseppe Palladino",
        "Luis A Brito",
        "Gillis R Otten",
        "Michela Brazzoli",
        "Scilla Buccato",
        "Alessandra Bonci",
        "Daniele Casini",
        "Domenico Maione",
        "Zhi-Qing Qi",
        "John E Gill",
        "Nicky C Caiazza",
        "Jun Urano",
        "Bolyn Hubby",
        "George F Gao",
        "Yuelong Shu",
        "Ennio De Gregorio",
        "Christian W Mandl",
        "Peter W Mason",
        "Ethan C Settembre",
        "Jeffrey B Ulmer",
        "J Craig Venter",
        "Philip R Dormitzer",
        "Rino Rappuoli",
        "Andrew J Geall"
    ],
    "related_topics": [
        "Duck embryo vaccine",
        "Synthetic vaccine",
        "Neuraminidase"
    ],
    "citation_count": "142",
    "reference_count": "31",
    "references": [
        "2106173155",
        "2105226322",
        "2068353535",
        "2104823480",
        "2051665875",
        "2006218290",
        "2100538295",
        "2104424333",
        "2054298563",
        "2086919915"
    ]
},{
    "id": "3004026249",
    "title": "Pattern of early human-to-human transmission of Wuhan 2019 novel coronavirus (2019-nCoV), December 2019 to January 2020.",
    "abstract": "Since December 2019, China has been experiencing a large outbreak of a novel coronavirus (2019-nCoV) which can cause respiratory disease and severe pneumonia. We estimated the basic reproduction number R0 of 2019-nCoV to be around 2.2 (90% high density interval: 1.4\u20133.8), indicating the potential for sustained human-to-human transmission. Transmission characteristics appear to be of similar magnitude to severe acute respiratory syndrome-related coronavirus (SARS-CoV) and pandemic influenza, indicating a risk of global spread.",
    "date": "2020",
    "authors": [
        "Julien Riou",
        "Christian L. Althaus"
    ],
    "related_topics": [
        "Coronavirus",
        "Outbreak",
        "Pneumonia"
    ],
    "citation_count": "1,047",
    "reference_count": "9",
    "references": [
        "3001118548",
        "3002539152",
        "2107053896",
        "2069251911",
        "2130227690",
        "1042757214",
        "2134527559",
        "2169080737",
        "2129156702"
    ]
},{
    "id": "2999612210",
    "title": "Pneumonia of unknown aetiology in Wuhan, China: potential for international spread via commercial air travel.",
    "abstract": "There is currently an outbreak of pneumonia of unknown aetiology in Wuhan, China. Although there are still several unanswered questions about this infection, we evaluate the potential for international dissemination of this disease via commercial air travel should the outbreak continue.",
    "date": "2020",
    "authors": [
        "Isaac I Bogoch",
        "Alexander Watts",
        "Andrea Thomas-Bachli",
        "Carmen Huber",
        "Moritz U G Kraemer",
        "Kamran Khan"
    ],
    "related_topics": [
        "Outbreak",
        "Pneumonia (non-human)",
        "China"
    ],
    "citation_count": "576",
    "reference_count": "3",
    "references": [
        "2100820722",
        "2556073860",
        "2883030708"
    ]
},{
    "id": "3026046290",
    "title": "Report 2: Estimating the potential total number of novel Coronavirus cases in Wuhan City, China",
    "abstract": "",
    "date": "2020",
    "authors": [
        "N Imai",
        "I Dorigatti",
        "A Cori",
        "C Donnelly",
        "S Riley",
        "N Ferguson"
    ],
    "related_topics": [
        "Coronavirus",
        "China",
        "Medicine"
    ],
    "citation_count": "156",
    "reference_count": "0",
    "references": []
},{
    "id": "1990049863",
    "title": "Epidemiological determinants of spread of causal agent of severe acute respiratory syndrome in Hong Kong",
    "abstract": "Summary Background Health authorities worldwide, especially in the Asia Pacific region, are seeking effective public-health interventions in the continuing epidemic of severe acute respiratory syndrome (SARS). We assessed the epidemiology of SARS in Hong Kong. Methods We included 1425 cases reported up to April 28, 2003. An integrated database was constructed from several sources containing information on epidemiological, demographic, and clinical variables. We estimated the key epidemiological distributions: infection to onset, onset to admission, admission to death, and admission to discharge. We measured associations between the estimated case fatality rate and patients\u2019 age and the time from onset to admission. Findings After the initial phase of exponential growth, the rate of confirmed cases fell to less than 20 per day by April 28. Public-health interventions included encouragement to report to hospital rapidly after the onset of clinical symptoms, contact tracing for confirmed and suspected cases, and quarantining, monitoring, and restricting the travel of contacts. The mean incubation period of the disease is estimated to be 6\u00b74 days (95% CI 5\u00b72\u20107\u00b77). The mean time from onset of clinical symptoms to admission to hospital varied between 3 and 5 days, with longer times earlier in the epidemic. The estimated case fatality rate was 13\u00b72% (9\u00b78\u201016\u00b78) for patients younger than 60 years and 43\u00b73% (35\u00b72\u201052\u00b74) for patients aged 60 years or older",
    "date": "2003",
    "authors": [
        "Christl A Donnelly",
        "Azra C Ghani",
        "Gabriel M Leung",
        "Anthony J Hedley",
        "Christophe Fraser",
        "Steven Riley",
        "Laith J Abu-Raddad",
        "Lai-Ming Ho",
        "Thuan-Quoc Thach",
        "Patsy Chau",
        "King-Pan Chan",
        "Tai-Hing Lam",
        "Lai-Yin Tse",
        "Thomas Tsang",
        "Shao-Haei Liu",
        "James H B Kong",
        "Edith M C Lau",
        "Neil M Ferguson",
        "Roy M Anderson"
    ],
    "related_topics": [
        "Case fatality rate",
        "Severe acute respiratory syndrome",
        "Epidemiology"
    ],
    "citation_count": "1,161",
    "reference_count": "2",
    "references": [
        "2025170735",
        "2125251240"
    ]
},{
    "id": "2117002055",
    "title": "How generation intervals shape the relationship between growth rates and reproductive numbers.",
    "abstract": "Mathematical models of transmission have become invaluable management tools in planning for the control of emerging infectious diseases. A key variable in such models is the reproductive number R. For new emerging infectious diseases, the value of the reproductive number can only be inferred indirectly from the observed exponential epidemic growth rate r. Such inference is ambiguous as several different equations exist that relate the reproductive number to the growth rate, and it is unclear which of these equations might apply to a new infection. Here, we show that these different equations differ only with respect to their assumed shape of the generation interval distribution. Therefore, the shape of the generation interval distribution determines which equation is appropriate for inferring the reproductive number from the observed growth rate. We show that by assuming all generation intervals to be equal to the mean, we obtain an upper bound to the range of possible values that the reproductive number may attain for a given growth rate. Furthermore, we show that by taking the generation interval distribution equal to the observed distribution, it is possible to obtain an empirical estimate of the reproductive number.",
    "date": "2007",
    "authors": [
        "J Wallinga",
        "M Lipsitch"
    ],
    "related_topics": [
        "Serial interval",
        "Growth rate",
        "Upper and lower bounds"
    ],
    "citation_count": "940",
    "reference_count": "26",
    "references": [
        "2147166346",
        "2156537900",
        "2065069831",
        "1606697907",
        "1497099219",
        "2102187991",
        "2037844075",
        "2101110089",
        "3140139051",
        "1984841045"
    ]
},{
    "id": "3002747665",
    "title": "Modelling the epidemic trend of the 2019 novel coronavirus outbreak in China",
    "abstract": "We present a timely evaluation of the Chinese 2019-nCov epidemic in its initial phase, where 2019-nCov demonstrates comparable transmissibility but lower fatality rates than SARS and MERS. A quick diagnosis that leads to case isolation and integrated interventions will have a major impact on its future trend. Nevertheless, as China is facing its Spring Festival travel rush and the epidemic has spread beyond its borders, further investigation on its potential spatiotemporal transmission pattern and novel intervention strategies are warranted.",
    "date": "2020",
    "authors": [
        "Mingwang Shen",
        "Zhihang Peng",
        "Yanni Xiao",
        "Lei Zhang"
    ],
    "related_topics": [
        "Outbreak",
        "China",
        "Transmission (mechanics)"
    ],
    "citation_count": "132",
    "reference_count": "2",
    "references": [
        "1976036024",
        "2053293344"
    ]
},{
    "id": "2102187991",
    "title": "Different Epidemic Curves for Severe Acute Respiratory Syndrome Reveal Similar Impacts of Control Measures",
    "abstract": "Severe acute respiratory syndrome (SARS) has been the first severe contagious disease to emerge in the 21st century. The available epidemic curves for SARS show marked differences between the affected regions with respect to the total number of cases and epidemic duration, even for those regions in which outbreaks started almost simultaneously and similar control measures were implemented at the same time. The authors developed a likelihood-based estimation procedure that infers the temporal pattern of effective reproduction numbers from an observed epidemic curve. Precise estimates for the effective reproduction numbers were obtained by applying this estimation procedure to available data for SARS outbreaks that occurred in Hong Kong, Vietnam, Singapore, and Canada in 2003. The effective reproduction numbers revealed that epidemics in the various affected regions were characterized by markedly similar disease transmission potentials and similar levels of effectiveness of control measures. In controlling SARS outbreaks, timely alerts have been essential: Delaying the institution of control measures by 1 week would have nearly tripled the epidemic size and would have increased the expected epidemic duration by 4 weeks.",
    "date": "2004",
    "authors": [
        "Jacco Wallinga",
        "Peter Teunis"
    ],
    "related_topics": [
        "Serial interval",
        "Outbreak",
        "Estimation"
    ],
    "citation_count": "966",
    "reference_count": "17",
    "references": [
        "2049633694",
        "2100820722",
        "2125251240",
        "2147166346",
        "1606697907",
        "1990049863",
        "2096145431",
        "2104595316",
        "1976741900",
        "2009678335"
    ]
},{
    "id": "2582743722",
    "title": "R: A language and environment for statistical computing.",
    "abstract": "",
    "date": "2013",
    "authors": [
        "R Core Team"
    ],
    "related_topics": [
        "R Programming Language",
        "Computational statistics",
        "Reef shark"
    ],
    "citation_count": "223,621",
    "reference_count": "0",
    "references": []
},{
    "id": "3001343166",
    "title": "Early Transmissibility Assessment of a Novel Coronavirus in Wuhan, China",
    "abstract": "Between December 1, 2019 and January 26, 2020, nearly 3000 cases of respiratory illness caused by a novel coronavirus originating in Wuhan, China have been reported In this short analysis, we combine publicly available cumulative case data from the ongoing outbreak with phenomenological modeling methods to conduct an early transmissibility assessment Our model suggests that the basic reproduction number associated with the outbreak (at time of writing) may range from 2 0 to 3 1 Though these estimates are preliminary and subject to change, they are consistent with previous findings regarding the transmissibility of the related SARS-Coronavirus and indicate the possibility of epidemic potential",
    "date": "2020",
    "authors": [
        "Maimuna S Majumder",
        "Kenneth D Mandl"
    ],
    "related_topics": [
        "Transmissibility (vibration)",
        "Basic reproduction number",
        "Outbreak"
    ],
    "citation_count": "164",
    "reference_count": "4",
    "references": [
        "3002108456",
        "3004318991",
        "2803393870",
        "2293555343"
    ]
},{
    "id": "2140763962",
    "title": "Factors that make an infectious disease outbreak controllable",
    "abstract": "The aim of this study is to identify general properties of emerging infectious agents that determine the likely success of two simple public health measures in controlling outbreaks, namely (i) isolating symptomatic individuals and (ii) tracing and quarantining their contacts. Because these measures depend on the recognition of specific disease symptoms, we investigate the relative timing of infectiousness and the appearance of symptoms by using a mathematical model. We show that the success of these control measures is determined as much by the proportion of transmission occurring prior to the onset of overt clinical symptoms (or via asymptomatic infection) as the inherent transmissibility of the etiological agent (measured by the reproductive number R0). From published studies, we estimate these quantities for two moderately transmissible viruses, severe acute respiratory syndrome coronavirus and HIV, and for two highly transmissible viruses, smallpox and pandemic influenza. We conclude that severe acute respiratory syndrome and smallpox are easier to control using these simple public health measures. Direct estimation of the proportion of asymptomatic and presymptomatic infections is achievable by contact tracing and should be a priority during an outbreak of a novel infectious agent.",
    "date": "2004",
    "authors": [
        "Christophe Fraser",
        "Steven Riley",
        "Roy M. Anderson",
        "Neil M. Ferguson"
    ],
    "related_topics": [
        "Infectious disease (medical specialty)",
        "Outbreak",
        "Disease"
    ],
    "citation_count": "1,008",
    "reference_count": "16",
    "references": [
        "2104548316",
        "2131262274",
        "2129542667",
        "2147166346",
        "1606697907",
        "1990049863",
        "2096145431",
        "2011756067",
        "2099810380",
        "1964326221"
    ]
},{
    "id": "2009435671",
    "title": "Model selection and multimodel inference : a practical information-theoretic approach",
    "abstract": "The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling. Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems. The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues. This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.",
    "date": "2003",
    "authors": [
        "Kenneth P. Burnham",
        "David R. Anderson"
    ],
    "related_topics": [
        "Akaike information criterion",
        "Statistical inference",
        "Model selection"
    ],
    "citation_count": "35,603",
    "reference_count": "0",
    "references": []
},{
    "id": "2146272590",
    "title": "Two\u2010sided confidence intervals for the single proportion: comparison of seven methods",
    "abstract": "Simple interval estimate methods for proportions exhibit poor coverage and can produce evidently inappropriate intervals. Criteria appropriate to the evaluation of various proposed methods include: closeness of the achieved coverage probability to its nominal value; whether intervals are located too close to or too distant from the middle of the scale; expected interval width; avoidance of aberrations such as limits outside [0,1] or zero width intervals; and ease of use, whether by tables, software or formulae. Seven methods for the single proportion are evaluated on 96,000 parameter space points. Intervals based on tail areas and the simpler score methods are recommended for use. In each case, methods are available that aim to align either the minimum or the mean coverage with the nominal 1 -alpha.",
    "date": "1998",
    "authors": [
        "Robert G. Newcombe"
    ],
    "related_topics": [
        "Coverage probability",
        "Confidence interval",
        "Interval estimation"
    ],
    "citation_count": "5,445",
    "reference_count": "27",
    "references": [
        "2118202495",
        "2797597138",
        "2313581450",
        "2096913021",
        "2110093215",
        "2122633654",
        "1967573895",
        "2977721658",
        "2144661279",
        "3028131295"
    ]
},{
    "id": "1965499304",
    "title": "Modelling disease outbreaks in realistic urban social networks.",
    "abstract": "Here we present a highly resolved agent-based simulation tool (EpiSims), which combines realistic estimates of population mobility,based on census and land-use data, with parameterized models for simulating the progress of a disease within a host and of transmission between hosts10. The simulation generates a largescale,dynamic contact graph that replaces the differential equations of the classic approach. EpiSims is based on the Transportation Analysis and Simulation System (TRANSIMS) developed at Los Alamos National Laboratory, which produces estimates of social networks based on the assumption that the transportation infrastructure constrains people\u2019s choices about where and when to perform activities11. TRANSIMS creates a synthetic population endowed with demographics such as age and income, consistent with joint distributions in census data. It then estimates positions and activities of all travellers on a second-by-second basis. For more information on TRANSIMS and its availability, see Supplementary Information. The resulting social network is the best extant estimate of the physical contact patterns among large groups of people\u2014alternative methodologies are limited to physical contacts among hundreds of people or non-physical contacts (such as e-mail or citations) among large groups.",
    "date": "2004",
    "authors": [
        "Stephen Eubank",
        "Hasan Guclu",
        "V S Anil Kumar",
        "Madhav V Marathe",
        "Aravind Srinivasan",
        "Zolt\u00e1n Toroczkai",
        "Nan Wang"
    ],
    "related_topics": [
        "Transims",
        "Geographic mobility",
        "Computational epidemiology"
    ],
    "citation_count": "2,130",
    "reference_count": "26",
    "references": [
        "2112090702",
        "2124637492",
        "2065769502",
        "2040956707",
        "2018045523",
        "2070207525",
        "2025550035",
        "2011756067",
        "2055620707",
        "2026552514"
    ]
},{
    "id": "2124853344",
    "title": "A population-dynamic model for evaluating the potential spread of drug-resistant influenza virus infections during community-based use of antivirals",
    "abstract": "A mathematical model of influenza transmission dynamics is used to simulate the impact of neuraminidase inhibitor therapy on infection rates and transmission of drug-resistant viral strains. The model incorporates population age structure, seasonal transmission, immunity and inclusion of elderly nursing home residents or non-residents. Key parameter values are estimated from epidemiological, clinical and experimental data. The analysis examines the factors determining the population spread of antiviral resistance, and predicts no significant transmission of neuraminidase inhibitor resistant virus. This conclusion is robust even at high therapy levels and under conservative assumptions regarding the likely frequency of transmission of resistant virus. The predicted incidence of resistance following protracted usage reflects primary drug resistance, currently estimated as approximately 2% for neuraminidase inhibitor therapy. It is also shown that until high levels of therapy are attained, early treatment of symptomatic cases is more efficient (per unit of drug) at preventing infections than prophylactic therapy.",
    "date": "2003",
    "authors": [
        "Neil M. Ferguson",
        "Susan Mallett",
        "Helen Jackson",
        "Noel Roberts",
        "Penelope Ward"
    ],
    "related_topics": [
        "Zanamivir",
        "Neuraminidase inhibitor",
        "Oseltamivir"
    ],
    "citation_count": "137",
    "reference_count": "53",
    "references": [
        "1886211768",
        "2004554957",
        "2159850238",
        "2081797984",
        "1988729025",
        "2072658090",
        "2122034291",
        "1974668319",
        "2093413494",
        "2116396562"
    ]
},{
    "id": "2157725602",
    "title": "Pandemic Potential of a Strain of Influenza A (H1N1) : Early Findings",
    "abstract": "A novel influenza A (H1N1) virus has spread rapidly across the globe. Judging its pandemic potential is difficult with limited data, but nevertheless essential to inform appropriate health responses. By analyzing the outbreak in Mexico, early data on international spread, and viral genetic diversity, we make an early assessment of transmissibility and severity. Our estimates suggest that 23,000 (range 6000 to 32,000) individuals had been infected in Mexico by late April, giving an estimated case fatality ratio (CFR) of 0.4% (range: 0.3 to 1.8%) based on confirmed and suspected deaths reported to that time. In a community outbreak in the small community of La Gloria, Veracruz, no deaths were attributed to infection, giving an upper 95% bound on CFR of 0.6%. Thus, although substantial uncertainty remains, clinical severity appears less than that seen in the 1918 influenza pandemic but comparable with that seen in the 1957 pandemic. Clinical attack rates in children in La Gloria were twice that in adults ( /=15 years: 29%). Three different epidemiological analyses gave basic reproduction number (R0) estimates in the range of 1.4 to 1.6, whereas a genetic analysis gave a central estimate of 1.2. This range of values is consistent with 14 to 73 generations of human-to-human transmission having occurred in Mexico to late April. Transmissibility is therefore substantially higher than that of seasonal flu, and comparable with lower estimates of R0 obtained from previous influenza pandemics.",
    "date": "2009",
    "authors": [
        "Christophe Fraser",
        "Christl A. Donnelly",
        "Simon Cauchemez",
        "William P. Hanage",
        "Maria D. Van Kerkhove",
        "T. D\u00e9irdre Hollingsworth",
        "Jamie Griffin",
        "Rebecca F. Baggaley",
        "Helen E. Jenkins",
        "Emily J. Lyons",
        "Thibaut Jombart",
        "Wes R. Hinsley",
        "Nicholas C. Grassly",
        "Francois Balloux",
        "Azra C. Ghani",
        "Neil M. Ferguson",
        "Andrew Rambaut",
        "Oliver G. Pybus",
        "Hugo Lopez-Gatell",
        "Celia M. Alpuche-Aranda",
        "Ietza Bojorquez Chapela",
        "Ethel Palacios Zavala",
        "Dulce Ma. Espejo Guevara",
        "Francesco Checchi",
        "Erika Garcia",
        "Stephane Hugonnet",
        "Cathy Roth"
    ],
    "related_topics": [
        "Human mortality from H5N1",
        "Pandemic",
        "Influenza A virus"
    ],
    "citation_count": "2,286",
    "reference_count": "19",
    "references": [
        "2312463092",
        "2110835349",
        "2147166346",
        "2156537900",
        "2065069831",
        "2142240784",
        "2117002055",
        "2037844075",
        "2149087734",
        "2109088393"
    ]
},{
    "id": "2116040950",
    "title": "Active contours without edges",
    "abstract": "We propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah (1989) functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by the gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a \"mean-curvature flow\"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We give a numerical algorithm using finite differences. Finally, we present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.",
    "date": "2001",
    "authors": [
        "T.F. Chan",
        "L.A. Vese"
    ],
    "related_topics": [
        "Active contour model",
        "Image segmentation",
        "Level set method"
    ],
    "citation_count": "12,960",
    "reference_count": "26",
    "references": [
        "2104095591",
        "2103559027",
        "2145803225",
        "1991113069",
        "2134820502",
        "2149184914",
        "2045545335",
        "2114487471",
        "1593038947",
        "2144133758"
    ]
},{
    "id": "2145023731",
    "title": "A Computational Approach to Edge Detection",
    "abstract": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.",
    "date": "1986",
    "authors": [
        "John Canny"
    ],
    "related_topics": [
        "Canny edge detector",
        "Edge detection",
        "Deriche edge detector"
    ],
    "citation_count": "38,103",
    "reference_count": "13",
    "references": [
        "2003370853",
        "1995756857",
        "1968245656",
        "2130355536",
        "2002882922",
        "2007057443",
        "1533832053",
        "1555351000",
        "128364430",
        "2016396776"
    ]
},{
    "id": "2752885492",
    "title": "Introduction to Algorithms",
    "abstract": "From the Publisher: The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. In its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. As in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. Each chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning.",
    "date": "1989",
    "authors": [
        "Thomas T. Cormen",
        "Charles E. Leiserson",
        "Ronald L. Rivest"
    ],
    "related_topics": [
        "Probabilistic analysis of algorithms",
        "Pseudocode",
        "Computer programming"
    ],
    "citation_count": "59,608",
    "reference_count": "0",
    "references": []
},{
    "id": "1964443764",
    "title": "Mean shift analysis and applications",
    "abstract": "A nonparametric estimator of density gradient, the mean shift, is employed in the joint, spatial-range (value) domain of gray level and color images for discontinuity preserving filtering and image segmentation. Properties of the mean shift are reviewed and its convergence on lattices is proven. The proposed filtering method associates with each pixel in the image the closest local mode in the density distribution of the joint domain. Segmentation into a piecewise constant structure requires only one more step, fusion of the regions associated with nearby modes. The proposed technique has two parameters controlling the resolution in the spatial and range domains. Since convergence is guaranteed, the technique does not require the intervention of the user to stop the filtering at the desired image quality. Several examples, for gray and color images, show the versatility of the method and compare favorably with results described in the literature for the same images.",
    "date": "1999",
    "authors": [
        "D. Comaniciu",
        "P. Meer"
    ],
    "related_topics": [
        "Image segmentation",
        "Range segmentation",
        "Mean-shift"
    ],
    "citation_count": "1,536",
    "reference_count": "16",
    "references": [
        "2099244020",
        "2150134853",
        "2129905273",
        "2022686119",
        "2098152234",
        "204885769",
        "2167077256",
        "2121836097",
        "2132126381",
        "2109562068"
    ]
},{
    "id": "2137560895",
    "title": "Complexity and Approximation: Combinatorial Optimization Problems and Their Approximability Properties",
    "abstract": "This book documents the state of the art in combinatorial optimization, presenting approximate solutions of virtually all relevant classes of NP-hard optimization problems. The wealth of problems, algorithms, results, and techniques make it an indispensible source of reference for professionals. The text smoothly integrates numerous illustrations, examples, and exercises.",
    "date": "1999",
    "authors": [
        "Giorgio Ausiello",
        "Pierluigi Crescenzi",
        "Giorgio Gambosi",
        "Viggo Kann",
        "Alberto Marchetti-Spaccamela",
        "Marco Protasi"
    ],
    "related_topics": [
        "Optimization problem",
        "Combinatorial optimization",
        "L-reduction"
    ],
    "citation_count": "2,361",
    "reference_count": "0",
    "references": []
},{
    "id": "2167077256",
    "title": "Robust analysis of feature spaces: color image segmentation",
    "abstract": "A general technique for the recovery of significant image features is presented. The technique is based on the mean shift algorithm, a simple nonparametric procedure for estimating density gradients. Drawbacks of the current methods (including robust clustering) are avoided. Feature space of any nature can be processed, and as an example, color image segmentation is discussed. The segmentation is completely autonomous, only its class is chosen by the user. Thus, the same program can produce a high quality edge image, or provide, by extracting all the significant colors, a preprocessor for content-based query systems. A 512/spl times/512 color image is analyzed in less than 10 seconds on a standard workstation. Gray level images are handled as color images having only the lightness coordinate.",
    "date": "1997",
    "authors": [
        "D. Comaniciu",
        "P. Meer"
    ],
    "related_topics": [
        "Image segmentation",
        "Color image",
        "Color histogram"
    ],
    "citation_count": "1,140",
    "reference_count": "10",
    "references": [
        "1971784203",
        "2160066518",
        "2022686119",
        "2129249398",
        "2008297189",
        "2098152234",
        "2051826135",
        "2171124048",
        "1974684941",
        "31292679"
    ]
},{
    "id": "2132603077",
    "title": "An optimal graph theoretic approach to data clustering: theory and its application to image segmentation",
    "abstract": "A novel graph theoretic approach for data clustering is presented and its application to the image segmentation problem is demonstrated. The data to be clustered are represented by an undirected adjacency graph G with arc capacities assigned to reflect the similarity between the linked vertices. Clustering is achieved by removing arcs of G to form mutually exclusive subgraphs such that the largest inter-subgraph maximum flow is minimized. For graphs of moderate size ( approximately 2000 vertices), the optimal solution is obtained through partitioning a flow and cut equivalent tree of G, which can be efficiently constructed using the Gomory-Hu algorithm (1961). However for larger graphs this approach is impractical. New theorems for subgraph condensation are derived and are then used to develop a fast algorithm which hierarchically constructs and partitions a partially equivalent tree of much reduced size. This algorithm results in an optimal solution equivalent to that obtained by partitioning the complete equivalent tree and is able to handle very large graphs with several hundred thousand vertices. The new clustering algorithm is applied to the image segmentation problem. The segmentation is achieved by effectively searching for closed contours of edge elements (equivalent to minimum cuts in G), which consist mostly of strong edges, while rejecting contours containing isolated strong edges. This method is able to accurately locate region boundaries and at the same time guarantees the formation of closed edge contours. >",
    "date": "1993",
    "authors": [
        "Z. Wu",
        "R. Leahy"
    ],
    "related_topics": [
        "Branch-decomposition",
        "Neighbourhood (graph theory)",
        "Graph theory"
    ],
    "citation_count": "1,705",
    "reference_count": "22",
    "references": [
        "1997063559",
        "1971784203",
        "3017143921",
        "2003370853",
        "1970800786",
        "1964119857",
        "2279353332",
        "1972969203",
        "2109567578",
        "1978627835"
    ]
},{
    "id": "1640070940",
    "title": "A Factorization Approach to Grouping",
    "abstract": "The foreground group in a scene may be \u2018discovered\u2019 and computed as a factorized approximation to the pairwise affinity of the elements in the scene. A pointwise approximation of the pairwise affinity information may in fact be interpreted as a \u2018saliency\u2019 index, and the foreground of the scene may be obtained by thresholding it. An algorithm called \u2018affinity factorization\u2019 is thus obtained which may be used for grouping.",
    "date": "1998",
    "authors": [
        "Pietro Perona",
        "William T. Freeman"
    ],
    "related_topics": [
        "Pointwise",
        "Thresholding",
        "Factorization"
    ],
    "citation_count": "394",
    "reference_count": "8",
    "references": [
        "2121947440",
        "2004485838",
        "2129104643",
        "2128197592",
        "2139868924",
        "2004618785",
        "2917264013",
        "1568513553"
    ]
},{
    "id": "2109562068",
    "title": "Image segmentation using local variation",
    "abstract": "We present a new graph-theoretic approach to the problem of image segmentation. Our method uses local criteria and yet produces results that reflect global properties of the image. We develop a framework that provides specific definitions of what it means for an image to be under- or over-segmented. We then present an efficient algorithm for computing a segmentation that is neither under- nor over-segmented according to these definitions. Our segmentation criterion is based on intensity differences between neighboring pixels. An important characteristic of the approach is that it is able to preserve detail in low-variability regions while ignoring detail in high-variability regions, which we illustrate with several examples on both real and synthetic images.",
    "date": "1998",
    "authors": [
        "P.F. Felzenszwalb",
        "D.P. Huttenlocher"
    ],
    "related_topics": [
        "Scale-space segmentation",
        "Segmentation-based object categorization",
        "Image segmentation"
    ],
    "citation_count": "326",
    "reference_count": "9",
    "references": [
        "2121947440",
        "2752885492",
        "1997063559",
        "1971784203",
        "2167077256",
        "2132603077",
        "1972969203",
        "2003004389",
        "1748744376"
    ]
},{
    "id": "1977545325",
    "title": "Network Flows: Theory, Algorithms, and Applications",
    "abstract": "A comprehensive introduction to network flows that brings together the classic and the contemporary aspects of the field, and provides an integrative view of theory, algorithms, and applications. presents in-depth, self-contained treatments of shortest path, maximum flow, and minimum cost flow problems, including descriptions of polynomial-time algorithms for these core models. emphasizes powerful algorithmic strategies and analysis tools such as data scaling, geometric improvement arguments, and potential function arguments. provides an easy-to-understand descriptions of several important data structures, including d-heaps, Fibonacci heaps, and dynamic trees. devotes a special chapter to conducting empirical testing of algorithms. features over 150 applications of network flows to a variety of engineering, management, and scientific domains. contains extensive reference notes and illustrations.",
    "date": "1992",
    "authors": [
        "Ravindra K. Ahuja",
        "Thomas L. Magnanti",
        "James B. Orlin"
    ],
    "related_topics": [
        "Flow network",
        "Minimum-cost flow problem",
        "Push\u2013relabel maximum flow algorithm"
    ],
    "citation_count": "12,862",
    "reference_count": "0",
    "references": []
},{
    "id": "2113137767",
    "title": "An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision",
    "abstract": "Minimum cut/maximum flow algorithms on graphs have emerged as an increasingly useful tool for exactor approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push -relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes.",
    "date": "2004",
    "authors": [
        "Y. Boykov",
        "V. Kolmogorov"
    ],
    "related_topics": [
        "Analysis of parallel algorithms",
        "Graph cuts in computer vision",
        "Probabilistic analysis of algorithms"
    ],
    "citation_count": "6,394",
    "reference_count": "39",
    "references": [
        "2104974755",
        "2143516773",
        "2169551590",
        "2093834886",
        "2101309634",
        "2998023265",
        "2077786999",
        "2340149117",
        "2121781154",
        "1781337833"
    ]
},{
    "id": "2620619910",
    "title": "Determining optical flow",
    "abstract": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantified rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image.",
    "date": "1992",
    "authors": [
        "Berthold K. P. Horn",
        "Brian G. Schunck"
    ],
    "related_topics": [
        "Optical flow",
        "Image processing",
        "Quantization (image processing)"
    ],
    "citation_count": "32,966",
    "reference_count": "16",
    "references": [
        "2611560603",
        "1994552597",
        "2032075694",
        "2074798463",
        "2025943913",
        "2060968961",
        "2015157402",
        "2131729179",
        "2052670720",
        "2150464846"
    ]
},{
    "id": "2121781154",
    "title": "Computing visual correspondence with occlusions using graph cuts",
    "abstract": "Several new algorithms for visual correspondence based on graph cuts have recently been developed. While these methods give very strong results in practice, they do not handle occlusions properly. Specifically, they treat the two input images asymmetrically, and they do not ensure that a pixel corresponds to at most one pixel in the other image. In this paper, we present a new method which properly addresses occlusions, while preserving the advantages of graph cut algorithms. We give experimental results for stereo as well as motion, which demonstrate that our method performs well both at detecting occlusions and computing disparities.",
    "date": "2001",
    "authors": [
        "V. Kolmogorov",
        "R. Zabih"
    ],
    "related_topics": [
        "Cut",
        "Pixel",
        "Computational geometry"
    ],
    "citation_count": "1,616",
    "reference_count": "23",
    "references": [
        "2104974755",
        "2143516773",
        "1997063559",
        "1977545325",
        "2113137767",
        "2096139825",
        "2117430149",
        "1531060698",
        "79315950",
        "2137017911"
    ]
},{
    "id": "2913192828",
    "title": "Visual Reconstruction",
    "abstract": "",
    "date": "1987",
    "authors": [
        "Andrew Blake",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Computer vision",
        "Computer science",
        "Artificial intelligence"
    ],
    "citation_count": "2,993",
    "reference_count": "0",
    "references": []
},{
    "id": "1554544485",
    "title": "On the statistical analysis of dirty pictures",
    "abstract": "may 7th, 1986, Professor A. F. M. Smith in the Chair] SUMMARY A continuous two-dimensional region is partitioned into a fine rectangular array of sites or \"pixels\", each pixel having a particular \"colour\" belonging to a prescribed finite set. The true colouring of the region is unknown but, associated with each pixel, there is a possibly multivariate record which conveys imperfect information about its colour according to a known statistical model. The aim is to reconstruct the true scene, with the additional knowledge that pixels close together tend to have the same or similar colours. In this paper, it is assumed that the local characteristics of the true scene can be represented by a nondegenerate Markov random field. Such information can be combined with the records by Bayes' theorem and the true scene can be estimated according to standard criteria. However, the computational burden is enormous and the reconstruction may reflect undesirable largescale properties of the random field. Thus, a simple, iterative method of reconstruction is proposed, which does not depend on these large-scale characteristics. The method is illustrated by computer simulations in which the original scene is not directly related to the assumed random field. Some complications, including parameter estimation, are discussed. Potential applications are mentioned briefly.",
    "date": "1986",
    "authors": [
        "Julian Besag"
    ],
    "related_topics": [
        "Random field",
        "Markov random field",
        "Hidden Markov random field"
    ],
    "citation_count": "6,251",
    "reference_count": "64",
    "references": [
        "2581275558",
        "1997063559",
        "2033482494",
        "1587362683",
        "2138309709",
        "1979622972",
        "2065301447",
        "2107792892",
        "1967374611",
        "2086699924"
    ]
},{
    "id": "1649464328",
    "title": "A maximum-flow formulation of the N-camera stereo correspondence problem",
    "abstract": "This paper describes a new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem. Once solved, the minimum-cut associated to the maximum-flow yields a disparity surface for the whole image at once. This global approach to stereo analysis provides a more accurate and coherent depth map than the traditional line-by-line stereo. Moreover, the optimality of the depth surface is guaranteed and can be shown to be a generalization of the dynamic programming approach that is widely used in standard stereo. Results show improved depth estimation as well as better handling of depth discontinuities. While the worst case running time is O(n/sup 2/d/sup 2/log(nd)), the observed average running time is O(n/sup 1.2/ d/sup 1.3/) for an image size of n pixels and depth resolution d.",
    "date": "1998",
    "authors": [
        "S. Roy",
        "I.J. Cox"
    ],
    "related_topics": [
        "Depth map",
        "Correspondence problem",
        "Image resolution"
    ],
    "citation_count": "816",
    "reference_count": "7",
    "references": [
        "2037819914",
        "2162569595",
        "1977948323",
        "1986557010",
        "1713915947",
        "2104276752",
        "1578567413"
    ]
},{
    "id": "1991113069",
    "title": "Fronts propagating with curvature-dependent speed: algorithms based on Hamilton-Jacobi formulations",
    "abstract": "Abstract We devise new numerical algorithms, called PSC algorithms, for following fronts propagating with curvature-dependent speed. The speed may be an arbitrary function of curvature, and the front also can be passively advected by an underlying flow. These algorithms approximate the equations of motion, which resemble Hamilton-Jacobi equations with parabolic right-hand sides, by using techniques from hyperbolic conservation laws. Non-oscillatory schemes of various orders of accuracy are used to solve the equations, providing methods that accurately capture the formation of sharp gradients and cusps in the moving fronts. The algorithms handle topological merging and breaking naturally, work in any number of space dimensions, and do not require that the moving surface be written as a function. The methods can be also used for more general Hamilton-Jacobi-type problems. We demonstrate our algorithms by computing the solution to a variety of surface motion problems.",
    "date": "1988",
    "authors": [
        "Stanley Osher",
        "James A. Sethian"
    ],
    "related_topics": [
        "Equations of motion",
        "Curvature",
        "Hamilton\u2013Jacobi equation"
    ],
    "citation_count": "17,823",
    "reference_count": "31",
    "references": [
        "1973481688",
        "2054662916",
        "3010292040",
        "1553761880",
        "1491650242",
        "1498500832",
        "2080477605",
        "2006134838",
        "2147963686",
        "1967575591"
    ]
},{
    "id": "1564419782",
    "title": "Computer and Robot Vision",
    "abstract": "From the Publisher: This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems.",
    "date": "1991",
    "authors": [
        "Robert M. Haralock",
        "Linda G. Shapiro"
    ],
    "related_topics": [
        "Machine vision",
        "Image processing",
        "Photogrammetry"
    ],
    "citation_count": "6,775",
    "reference_count": "0",
    "references": []
},{
    "id": "2098152234",
    "title": "Region competition: unifying snakes, region growing, and Bayes/MDL for multiband image segmentation",
    "abstract": "We present a novel statistical and variational approach to image segmentation based on a new algorithm, named region competition. This algorithm is derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle. The algorithm is guaranteed to converge to a local minimum and combines aspects of snakes/balloons and region growing. The classic snakes/balloons and region growing algorithms can be directly derived from our approach. We provide theoretical analysis of region competition including accuracy of boundary location, criteria for initial conditions, and the relationship to edge detection using filters. It is straightforward to generalize the algorithm to multiband segmentation and we demonstrate it on gray level images, color images and texture images. The novel color model allows us to eliminate intensity gradients and shadows, thereby obtaining segmentation based on the albedos of objects. It also helps detect highlight regions.",
    "date": "1996",
    "authors": [
        "Song Chun Zhu",
        "A. Yuille"
    ],
    "related_topics": [
        "Region growing",
        "Image segmentation",
        "Segmentation"
    ],
    "citation_count": "3,066",
    "reference_count": "41",
    "references": [
        "2145023731",
        "2104095591",
        "1997063559",
        "2112440119",
        "1770825568",
        "2114487471",
        "2096579040",
        "2086921140",
        "2913192828",
        "1533169541"
    ]
},{
    "id": "2086921140",
    "title": "On active contour models and balloons",
    "abstract": "Abstract The use of energy-minimizing curves, known as \u201csnakes,\u201d to extract features of interest in images has been introduced by Kass, Witkin & Terzopoulos (Int. J. Comput. Vision 1, 1987, 321\u2013331). We present a model of deformation which solves some of the problems encountered with the original method. The external forces that push the curve to the edges are modified to give more stable results. The original snake, when it is not close enough to contours, is not attracted by them and straightens to a line. Our model makes the curve behave like a balloon which is inflated by an additional force. The initial curve need no longer be close to the solution to converge. The curve passes over weak edges and is stopped only if the edge is strong. We give examples of extracting a ventricle in medical images. We have also made a first step toward 3D object reconstruction, by tracking the extracted contour on a series of successive cross sections.",
    "date": "1991",
    "authors": [
        "Laurent D. Cohen"
    ],
    "related_topics": [
        "Active contour model",
        "Line (geometry)",
        "Vector flow"
    ],
    "citation_count": "3,545",
    "reference_count": "11",
    "references": [
        "2145023731",
        "2104095591",
        "2125848778",
        "2069562432",
        "2007153649",
        "2043647324",
        "2134781380",
        "2103580031",
        "1607751055",
        "52422579"
    ]
},{
    "id": "2096139825",
    "title": "Markov random fields with efficient approximations",
    "abstract": "Markov Random Fields (MRFs) can be used for a wide variety of vision problems. In this paper we focus on MRFs with two-valued clique potentials, which form a generalized Potts model. We show that the maximum a posteriori estimate of such an MRF can be obtained by solving a multiway minimum cut problem on a graph. We develop efficient algorithms for computing good approximations to the minimum multiway, cut. The visual correspondence problem can be formulated as an MRF in our framework; this yields quite promising results on real data with ground truth. We also apply our techniques to MRFs with linear clique potentials.",
    "date": "1998",
    "authors": [
        "Y. Boykov",
        "O. Veksler",
        "R. Zabih"
    ],
    "related_topics": [
        "Minimum cut",
        "Graph cuts in computer vision",
        "Clique"
    ],
    "citation_count": "719",
    "reference_count": "12",
    "references": [
        "1997063559",
        "2913192828",
        "1649464328",
        "1507028917",
        "2037819914",
        "79315950",
        "2153980837",
        "2069702698",
        "2007579152",
        "1741851583"
    ]
},{
    "id": "1987983010",
    "title": "Interactive segmentation with Intelligent Scissors",
    "abstract": "Abstract We present a new, interactive tool called Intelligent Scissors which we use for image segmentation. Fully automated segmentation is an unsolved problem, while manual tracing is inaccurate and laboriously unacceptable. However, Intelligent Scissors allow objects within digital images to be extracted quickly and accurately using simple gesture motions with a mouse. When the gestured mouse position comes in proximity to an object edge, a live-wire boundary \u201csnaps\u201d to, and wraps around the object of interest. Live-wire boundary detection formulates boundary detection as an optimal path search in a weighted graph. Optimal graph searching provides mathematically piece-wise optimal boundaries while greatly reducing sensitivity to local noise or other intervening structures. Robustness is further enhanced with on-the-fly training which causes the boundary to adhere to the specific type of edge currently being followed, rather than simply the strongest edge in the neighborhood. Boundary cooling automatically freezes unchanging segments and automates input of additional seed points. Cooling also allows the user to be much more free with the gesture path, thereby increasing the efficiency and finesse with which boundaries can be extracted.",
    "date": "1998",
    "authors": [
        "Eric N. Mortensen",
        "William A. Barrett"
    ],
    "related_topics": [
        "Image segmentation",
        "Segmentation",
        "Robustness (computer science)"
    ],
    "citation_count": "873",
    "reference_count": "25",
    "references": [
        "2104095591",
        "2003370853",
        "2152475379",
        "2121009299",
        "2494779131",
        "2131910503",
        "2083277843",
        "1569930776",
        "2136706845",
        "2169528473"
    ]
},{
    "id": "2038276547",
    "title": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions",
    "abstract": "In this article, we give an overview of efficient algorithms for the approximate and exact nearest neighbor problem. The goal is to preprocess a dataset of objects (e.g., images) so that later, given a new query object, one can quickly return the dataset object that is most similar to the query. The problem is of significant interest in a wide variety of areas.",
    "date": "2007",
    "authors": [
        "Alexandr Andoni",
        "Piotr Indyk"
    ],
    "related_topics": [
        "Nearest neighbor search",
        "Best bin first",
        "Locality-sensitive hashing"
    ],
    "citation_count": "4,726",
    "reference_count": "50",
    "references": [
        "2147717514",
        "301824129",
        "2162006472",
        "2038276547",
        "1502916507",
        "2012833704",
        "2152565070",
        "1985123706",
        "1497953515",
        "1995990042"
    ]
},{
    "id": "1567512734",
    "title": "Bayesian learning for neural networks",
    "abstract": "From the Publisher: Artificial \"neural networks\" are now widely used as flexible models for regression classification applications, but questions remain regarding what these models mean, and how they can safely be used when training data is limited. Bayesian Learning for Neural Networks shows that Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional neural network learning methods. Insight into the nature of these complex Bayesian models is provided by a theoretical investigation of the priors over functions that underlie them. Use of these models in practice is made possible using Markov chain Monte Carlo techniques. Both the theoretical and computational aspects of this work are of wider statistical interest, as they contribute to a better understanding of how Bayesian methods can be applied to complex problems. Presupposing only the basic knowledge of probability and statistics, this book should be of interest to many researchers in statistics, engineering, and artificial intelligence. Software for Unix systems that implements the methods described is freely available over the Internet.",
    "date": "1994",
    "authors": [
        "Geoffrey Hinton",
        "Radford M. Neal"
    ],
    "related_topics": [
        "Variable-order Bayesian network",
        "Graphical model",
        "Types of artificial neural networks"
    ],
    "citation_count": "4,609",
    "reference_count": "0",
    "references": []
},{
    "id": "137106866",
    "title": "CUDAMat: a CUDA-based matrix class for Python",
    "abstract": "CUDAMat is an open source software package that provides a CUDA-based matrix class for Python. The primary goal of CUDAMat is to make it easy to implement algorithms that are easily expressed in terms of dense matrix operations on a GPU. At present, the feature set of CUDAMat is biased towards providing functionality useful for implementing standard machine learning algorithms, however, it is general enough to be useful in other elds. We have used CUDAMat to implement several common machine learning algorithms on GPUs oering speedups of up to 50x over numpy and MATLAB implementations.",
    "date": "2008",
    "authors": [
        "Volodymyr Mnih"
    ],
    "related_topics": [
        "NumPy",
        "CUDA",
        "Python (programming language)"
    ],
    "citation_count": "71",
    "reference_count": "1",
    "references": [
        "2120432001"
    ]
},{
    "id": "1983334819",
    "title": "Modeling pixel means and covariances using factorized third-order boltzmann machines",
    "abstract": "Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset.",
    "date": "2010",
    "authors": [
        "Marc'Aurelio Ranzato",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Generative model",
        "Covariance matrix",
        "Covariance"
    ],
    "citation_count": "319",
    "reference_count": "34",
    "references": [
        "2151103935",
        "2161969291",
        "2136922672",
        "3118608800",
        "2100495367",
        "2546302380",
        "2116064496",
        "2025768430",
        "2110798204",
        "2130325614"
    ]
},{
    "id": "2161000554",
    "title": "Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images",
    "abstract": "Deep belief nets have been successful in modeling handwritten characters, but it has proved more difficult to apply them to real images. The problem lies in the restricted Boltzmann machine (RBM) which is used as a module for learning deep belief nets one layer at a time. The Gaussian-Binary RBMs that have been used to model real-valued data are not a good way to model the covariance structure of natural images. We propose a factored 3-way RBM that uses the states of its hidden units to represent abnormalities in the local covariance structure of an image. This provides a probabilistic framework for the widely used simple/complex cell architecture. Our model learns binary features that work very well for object recognition on the \u201ctiny images\u201d data set. Even better features are obtained by then using standard binary RBM\u2019s to learn a deeper model.",
    "date": "2010",
    "authors": [
        "Marc'Aurelio Ranzato",
        "Alex Krizhevsky",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Restricted Boltzmann machine",
        "Boltzmann machine",
        "Real image"
    ],
    "citation_count": "282",
    "reference_count": "37",
    "references": [
        "2151103935",
        "2136922672",
        "3118608800",
        "2310919327",
        "2100495367",
        "2116064496",
        "1548802052",
        "2130325614",
        "2145607950",
        "1566135517"
    ]
},{
    "id": "2161893161",
    "title": "3D Object Recognition with Deep Belief Nets",
    "abstract": "We introduce a new type of top-level model for Deep Belief Nets and evaluate it on a 3D object recognition task. The top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients. Performance is evaluated on the NORB database (normalized-uniform version), which contains stereo-pair images of objects under different lighting conditions and viewpoints. Our model achieves 6.5% error on the test set, which is close to the best published result for NORB (5.9%) using a convolutional neural net that has built-in knowledge of translation invariance. It substantially outperforms shallow models such as SVMs (11.6%). DBNs are especially suited for semi-supervised learning, and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database. With the extra unlabeled data (and the same amount of labeled data as before), our model achieves 5.2% error.",
    "date": "2009",
    "authors": [
        "Vinod Nair",
        "Geoffrey E. Hinton"
    ],
    "related_topics": [
        "Boltzmann machine",
        "Discriminative model",
        "Artificial neural network"
    ],
    "citation_count": "408",
    "reference_count": "21",
    "references": [
        "2136922672",
        "2148603752",
        "2310919327",
        "2100495367",
        "2116064496",
        "2025768430",
        "2110798204",
        "2130325614",
        "2134557905",
        "1994197834"
    ]
},{
    "id": "2131700150",
    "title": "Speech Recognition Using Augmented Conditional Random Fields",
    "abstract": "Acoustic modeling based on hidden Markov models (HMMs) is employed by state-of-the-art stochastic speech recognition systems. Although HMMs are a natural choice to warp the time axis and model the temporal phenomena in the speech signal, their conditional independence properties limit their ability to model spectral phenomena well. In this paper, a new acoustic modeling paradigm based on augmented conditional random fields (ACRFs) is investigated and developed. This paradigm addresses some limitations of HMMs while maintaining many of the aspects which have made them successful. In particular, the acoustic modeling problem is reformulated in a data driven, sparse, augmented space to increase discrimination. Acoustic context modeling is explicitly integrated to handle the sequential phenomena of the speech signal. We present an efficient framework for estimating these models that ensures scalability and generality. In the TIMIT phone recognition task, a phone error rate of 23.0% was recorded on the full test set, a significant improvement over comparable HMM-based systems.",
    "date": "2009",
    "authors": [
        "Y. Hifny",
        "S. Renals"
    ],
    "related_topics": [
        "Speech processing",
        "Hidden Markov model",
        "Conditional random field"
    ],
    "citation_count": "104",
    "reference_count": "75",
    "references": [
        "2148603752",
        "2124776405",
        "3029645440",
        "1554663460",
        "1480376833",
        "2147880316",
        "2125838338",
        "2087347434",
        "2049633694",
        "1508165687"
    ]
},{
    "id": "2011891945",
    "title": "A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry",
    "abstract": "Abstract This paper proposes a robust approach to image matching by exploiting the only available geometric constraint, namely, the epipolar constraint. The images are uncalibrated, namely the motion between them and the camera parameters are not known. Thus, the images can be taken by different cameras or a single camera at different time instants. If we make an exhaustive search for the epipolar geometry, the complexity is prohibitively high. The idea underlying our approach is to use classical techniques (correlation and relaxation methods in our particular implementation) to find an initial set of matches, and then use a robust technique\u2014the Least Median of Squares (LMedS)\u2014to discard false matches in this set. The epipolar geometry can then be accurately estimated using a meaningful image criterion. More matches are eventually found, as in stereo matching, by using the recovered epipolar geometry. A large number of experiments have been carried out, and very good results have been obtained. Regarding the relaxation technique, we define a new measure of matching support, which allows a higher tolerance to deformation with respect to rigid transformations in the image plane and a smaller contribution for distant matches than for nearby ones. A new strategy for updating matches is developed, which only selects those matches having both high matching support and low matching ambiguity. The update strategy is different from the classical \u201cwinner-take-all\u201d, which is easily stuck at a local minimum, and also from \u201closer-take-nothing\u201d, which is usually very slow. The proposed algorithm has been widely tested and works remarkably well in a scene with many repetitive patterns.",
    "date": "1995",
    "authors": [
        "Zhengyou Zhang",
        "Rachid Deriche",
        "Olivier Faugeras",
        "Quang-Tuan Luong"
    ],
    "related_topics": [
        "Epipolar geometry",
        "Fundamental matrix (computer vision)",
        "Image processing"
    ],
    "citation_count": "2,182",
    "reference_count": "50",
    "references": [
        "2111308925",
        "2129249398",
        "2740373864",
        "1598123022",
        "2065592949",
        "2164934677",
        "2090949637",
        "1602748186",
        "2144746551",
        "2025934818"
    ]
},{
    "id": "22745672",
    "title": "Generalizing the hough transform to detect arbitrary shapes",
    "abstract": "Abstract The Hough transform is a method for detecting curves by exploiting the duality between points on a curve and parameters of that curve. The initial work showed how to detect both analytic curves (1,2) and non-analytic curves, (3) but these methods were restricted to binary edge images. This work was generalized to the detection of some analytic curves in grey level images, specifically lines, (4) circles (5) and parabolas. (6) The line detection case is the best known of these and has been ingeniously exploited in several applications. (7,8,9) We show how the boundaries of an arbitrary non-analytic shape can be used to construct a mapping between image space and Hough transform space. Such a mapping can be exploited to detect instances of that particular shape in an image. Furthermore, variations in the shape such as rotations, scale changes or figure ground reversals correspond to straightforward transformations of this mapping. However, the most remarkable property is that such mappings can be composed to build mappings for complex shapes from the mappings of simpler component shapes. This makes the generalized Hough transform a kind of universal transform which can be used to find arbitrarily complex shapes.",
    "date": "1986",
    "authors": [
        "D. H. Ballard"
    ],
    "related_topics": [
        "Generalised Hough transform",
        "Randomized Hough transform",
        "Hough transform"
    ],
    "citation_count": "6,456",
    "reference_count": "17",
    "references": [
        "1994552597",
        "2069853858",
        "2089269779",
        "2104241941",
        "1992434120",
        "1485035304",
        "1967572126",
        "38255799",
        "2080231183",
        "1967767463"
    ]
},{
    "id": "2096077837",
    "title": "Shape indexing using approximate nearest-neighbour search in high-dimensional spaces",
    "abstract": "Shape indexing is a way of making rapid associations between features detected in an image and object models that could have produced them. When model databases are large, the use of high-dimensional features is critical, due to the improved level of discrimination they can provide. Unfortunately, finding the nearest neighbour to a query point rapidly becomes inefficient as the dimensionality of the feature space increases. Past indexing methods have used hash tables for hypothesis recovery, but only in low-dimensional situations. In this paper we show that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical. This Best Bin First, or BBF search is an approximate algorithm which finds the nearest neighbour for a large fraction of the queries, and a very close neighbour in the remaining cases. The technique has been integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds.",
    "date": "1997",
    "authors": [
        "J.S. Beis",
        "D.G. Lowe"
    ],
    "related_topics": [
        "Best bin first",
        "Search engine indexing",
        "Feature vector"
    ],
    "citation_count": "1,506",
    "reference_count": "20",
    "references": [
        "2096600681",
        "2154204736",
        "2024668293",
        "2033834476",
        "1513966746",
        "2154186675",
        "2090398718",
        "2159709546",
        "2167982013",
        "2148220292"
    ]
},{
    "id": "2096600681",
    "title": "Fitting parameterized three-dimensional models to images",
    "abstract": "Model-based recognition and motion tracking depend upon the ability to solve for projection and model parameters that will best fit a 3-D model to matching 2-D image features. The author extends current methods of parameter solving to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation, variable dimensions, or surface deformations. Numerical stabilization methods are developed that take account of inherent inaccuracies in the image measurements and allow useful solutions to be determined even when there are fewer matches than unknown parameters. The Levenberg-Marquardt method is used to always ensure convergence of the solution. These techniques allow model-based vision to be used for a much wider class of problems than was possible with previous methods. Their application is demonstrated for tracking the motion of curved, parameterized objects. >",
    "date": "1991",
    "authors": [
        "D.G. Lowe"
    ],
    "related_topics": [
        "Image processing",
        "Match moving",
        "Parameterized complexity"
    ],
    "citation_count": "1,354",
    "reference_count": "30",
    "references": [
        "2085261163",
        "2003370853",
        "2131806657",
        "2075665712",
        "1531060698",
        "2149846618",
        "2986444355",
        "1532977286",
        "1981154266",
        "1513966746"
    ]
},{
    "id": "2131806657",
    "title": "Three-dimensional object recognition from single two-dimensional images",
    "abstract": "Abstract A computer vision system has been implemented that can recognize three-dimensional objects from unknown viewpoints in single gray-scale images. Unlike most other approaches, the recognition is accomplished without any attempt to reconstruct depth information bottom-up from the visual input. Instead, three other mechanisms are used that can bridge the gap between the two-dimensional image and knowledge of three-dimensional objects. First, a process of perceptual organization is used to form groupings and structures in the image that are likely to be invariant over a wide range of viewpoints. Second, a probabilistic ranking method is used to reduce the size of the search space during model-based matching. Finally, a process of spatial correspondence brings the projections of three-dimensional models into direct correspondence with the image by solving for unknown viewpoint and model parameters. A high level of robustness in the presence of occlusion and missing data can be achieved through full application of a viewpoint consistency constraint. It is argued that similar mechanisms and constraints form the basis for recognition in human vision.",
    "date": "1987",
    "authors": [
        "D G Lowe"
    ],
    "related_topics": [
        "Cognitive neuroscience of visual object recognition",
        "Probabilistic logic",
        "Invariant (mathematics)"
    ],
    "citation_count": "1,982",
    "reference_count": "30",
    "references": [
        "2085261163",
        "1933657216",
        "2003370853",
        "1532977286",
        "1513966746",
        "2337770697",
        "2125756925",
        "2130355536",
        "2037732452",
        "2943272530"
    ]
},{
    "id": "2042243448",
    "title": "Scale-Space Theory : A Basic Tool for Analysing Structures at Different Scales",
    "abstract": "An inherent property of objects in the world is that they only exist as meaningful entities over certain ranges of scale. If one aims at describing the structure of unknown real-world signals, then ...",
    "date": "1993",
    "authors": [
        "Tony Lindeberg"
    ],
    "related_topics": [
        "Scale (ratio)",
        "Scale space",
        "Property (philosophy)"
    ],
    "citation_count": "1,915",
    "reference_count": "97",
    "references": [
        "2132984323",
        "2145023731",
        "2150134853",
        "2004217976",
        "2120062331",
        "2103504761",
        "2109863423",
        "2003370853",
        "2112328181",
        "2166982406"
    ]
},{
    "id": "1553558465",
    "title": "Object Recognition Using Multidimensional Receptive Field Histograms",
    "abstract": "This paper presents a technique to determine the identity of objects in a scene using histograms of the responses of a vector of local linear neighborhood operators (receptive fields). This technique can be used to determine the most probable objects in a scene, independent of the object's position, image-plane orientation and scale. In this paper we describe the mathematical foundations of the technique and present the results of experiments which compare robustness and recognition rates for different local neighborhood operators and histogram similarity measurements.",
    "date": "1996",
    "authors": [
        "Bernt Schiele",
        "James L. Crowley"
    ],
    "related_topics": [
        "Color histogram",
        "Cognitive neuroscience of visual object recognition",
        "Histogram"
    ],
    "citation_count": "421",
    "reference_count": "10",
    "references": [
        "2170120409",
        "2914885528",
        "2102796633",
        "1991605728",
        "2160835070",
        "2135884851",
        "2131656657",
        "168814958",
        "1603917934",
        "2018013893"
    ]
},{
    "id": "2119747362",
    "title": "Indexing based on scale invariant interest points",
    "abstract": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images.",
    "date": "2001",
    "authors": [
        "K. Mikolajczyk",
        "C. Schmid"
    ],
    "related_topics": [
        "Harris affine region detector",
        "Scale-space axioms",
        "Scale space"
    ],
    "citation_count": "1,790",
    "reference_count": "14",
    "references": [
        "2124386111",
        "2124087378",
        "2109200236",
        "2165497495",
        "1991605728",
        "2109863423",
        "2132332894",
        "2143753158",
        "134171312",
        "1494702534"
    ]
},{
    "id": "2109200236",
    "title": "Feature Detection with Automatic Scale Selection",
    "abstract": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure. Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation. In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments.",
    "date": "1998",
    "authors": [
        "Tony Lindeberg"
    ],
    "related_topics": [
        "Scale space",
        "Scale-space axioms",
        "Edge detection"
    ],
    "citation_count": "3,607",
    "reference_count": "54",
    "references": [
        "2152328854",
        "2004217976",
        "2120062331",
        "2109863423",
        "2112328181",
        "2022735534",
        "1970269179",
        "1495971627",
        "2167034998",
        "2978983090"
    ]
},{
    "id": "1505641881",
    "title": "Evaluation of Interest Point Detectors",
    "abstract": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well.",
    "date": "2000",
    "authors": [
        "Cordelia Schmid",
        "Roger Mohr",
        "Christian Bauckhage"
    ],
    "related_topics": [
        "Interest point detection",
        "Hessian affine region detector",
        "Detector"
    ],
    "citation_count": "2,407",
    "reference_count": "46",
    "references": [
        "2145023731",
        "2130103520",
        "2111308925",
        "2099046646",
        "2011891945",
        "3040777582",
        "1667165204",
        "2069562432",
        "2124592837",
        "2114785422"
    ]
},{
    "id": "2005433550",
    "title": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions",
    "abstract": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions.",
    "date": "1999",
    "authors": [
        "Tinne Tuytelaars",
        "Luc J. Van Gool"
    ],
    "related_topics": [
        "Invariant (mathematics)",
        "Robustness (computer science)",
        "Hessian affine region detector"
    ],
    "citation_count": "764",
    "reference_count": "11",
    "references": [
        "2124386111",
        "2085261163",
        "2145713909",
        "134171312",
        "1494702534",
        "2059871232",
        "2152739884",
        "2065695189",
        "1519278729",
        "1499458212"
    ]
},{
    "id": "2124260943",
    "title": "Watersheds in digital spaces: an efficient algorithm based on immersion simulations",
    "abstract": "A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced. A review of watersheds and related motion is first presented, and the major methods to determine watersheds are discussed. The algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using of queue of pixel. It is described in detail provided in a pseudo C language. The accuracy of this algorithm is proven to be superior to that of the existing implementations, and it is shown that its adaptation to any kind of digital grid and its generalization to n-dimensional images (and even to graphs) are straightforward. The algorithm is reported to be faster than any other watershed algorithm. Applications of this algorithm with regard to picture segmentation are presented for magnetic resonance (MR) imagery and for digital elevation models. An example of 3-D watershed is also provided. >",
    "date": "1991",
    "authors": [
        "L. Vincent",
        "P. Soille"
    ],
    "related_topics": [
        "Image segmentation",
        "Digital image",
        "Pixel"
    ],
    "citation_count": "8,205",
    "reference_count": "31",
    "references": [
        "2145023731",
        "2164741953",
        "2799004609",
        "2069537876",
        "3100816363",
        "1593939129",
        "2913706141",
        "1973965874",
        "2008746426",
        "1779461070"
    ]
},{
    "id": "1541642243",
    "title": "Multi-view Matching for Unordered Image Sets, or How Do I Organize My Holiday Snaps?",
    "abstract": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate.",
    "date": "2002",
    "authors": [
        "Frederik Schaffalitzky",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Template matching",
        "Real image",
        "Orientation (computer vision)"
    ],
    "citation_count": "916",
    "reference_count": "27",
    "references": [
        "2033819227",
        "1676552347",
        "2124087378",
        "2119747362",
        "2165497495",
        "2124313187",
        "2118877769",
        "2011891945",
        "2005433550",
        "1970269179"
    ]
},{
    "id": "2132332894",
    "title": "Matching images with different resolutions",
    "abstract": "In this paper we address the problem of matching two images with two different resolutions: a high-resolution image and a low-resolution one. On the premise that changes in resolution act as a smoothing equivalent to changes in scale, a scale-space representation of the high-resolution image is produced. Hence the one-to-one classical image matching paradigm becomes one-to-many because the low-resolution image is compared with all the scale-space representations of the high-resolution one. Key to the success of such a process is the proper representation of the features to be matched in scale-space. We show how to extract interest points at variable scales and we devise a method allowing the comparison of two images at two different resolutions. The method comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low-resolution image region, and an image matching strategy based on the robust estimation of this geometric model. Extensive experiments show that our matching method can be used for scale changes up to a factor 6.",
    "date": "2000",
    "authors": [
        "Y. Dufournaud",
        "C. Schmid",
        "R. Horaud"
    ],
    "related_topics": [
        "Template matching",
        "Image processing",
        "Image resolution"
    ],
    "citation_count": "284",
    "reference_count": "19",
    "references": [
        "2124386111",
        "2124087378",
        "2109200236",
        "2111308925",
        "2085261163",
        "2112328181",
        "2022735534",
        "2143753158",
        "1984757472",
        "1773272891"
    ]
},{
    "id": "2143753158",
    "title": "Wide baseline stereo matching",
    "abstract": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic.",
    "date": "1998",
    "authors": [
        "P. Pritchett",
        "A. Zisserman"
    ],
    "related_topics": [
        "Epipolar geometry",
        "Fundamental matrix (computer vision)",
        "Stereo camera"
    ],
    "citation_count": "413",
    "reference_count": "18",
    "references": [
        "2111308925",
        "2085261163",
        "2011891945",
        "2978983090",
        "1549739843",
        "1528423721",
        "2170026011",
        "2200154090",
        "2074163268",
        "1848858524"
    ]
},{
    "id": "1991605728",
    "title": "The design and use of steerable filters",
    "abstract": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters. >",
    "date": "1991",
    "authors": [
        "W.T. Freeman",
        "E.H. Adelson"
    ],
    "related_topics": [
        "Steerable filter",
        "Prototype filter",
        "Adaptive filter"
    ],
    "citation_count": "4,380",
    "reference_count": "41",
    "references": [
        "2132984323",
        "2145023731",
        "2103504761",
        "1627054999",
        "2096684483",
        "2103384342",
        "2171181782",
        "2139797453",
        "2108992228",
        "2058719583"
    ]
},{
    "id": "2112328181",
    "title": "Scale-space theory in computer vision",
    "abstract": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ...",
    "date": "1993",
    "authors": [
        "Tony Lindeberg"
    ],
    "related_topics": [
        "Information and Computer Science",
        "Scale-space axioms",
        "Vision science"
    ],
    "citation_count": "2,949",
    "reference_count": "0",
    "references": []
},{
    "id": "1970269179",
    "title": "Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure'",
    "abstract": "This article describes a method for reducing the shape distortions due to scale-space smoothing that arise in the computation of 3-D shape cues using operators (derivatives) defined from scale-space representation. More precisely, we are concerned with a general class of methods for deriving 3-D shape cues from a 2-D image data based on the estimation of locally linearized deformations of brightness patterns. This class constitutes a common framework for describing several problems in computer vision (such as shape-from-texture, shape-from disparity-gradients, and motion estimation) and for expressing different algorithms in terms of similar types of visual front-end-operations. It is explained how surface orientation estimates will be biased due to the use of rotationally symmetric smoothing in the image domain. These effects can be reduced by extending the linear scale-space concept into an affine Gaussian scalespace representation and by performing affine shape adaptation of the smoothing kernels. This improves the accuracy of the surface orientation estimates, since the image descriptors, on which the methods are based, will be relative invariant under affine transformations, and the error thus confined to the higher-order terms in the locally linearized perspective transformation. A straightforward algorithm is presented for performing shape adaptation in practice. Experiments on real and synthetic images with known orientation demonstrate that in the presence of moderately high noise levels the accuracy is improved by typically one order of magnitude.",
    "date": "1997",
    "authors": [
        "Tony Lindeberg",
        "Jonas G\u00e5rding"
    ],
    "related_topics": [
        "Affine shape adaptation",
        "Harris affine region detector",
        "Affine transformation"
    ],
    "citation_count": "393",
    "reference_count": "63",
    "references": [
        "2150134853",
        "2109200236",
        "1991113069",
        "2109863423",
        "2112328181",
        "1938714998",
        "2022735534",
        "1495971627",
        "2065164181",
        "2022133743"
    ]
},{
    "id": "2022735534",
    "title": "The structure of images",
    "abstract": "In practice the relevant details of images exist only over a restricted range of scale. Hence it is important to study the dependence of image structure on the level of resolution. It seems clear enough that visual perception treats images on several levels of resolution simultaneously and that this fact must be important for the study of perception. However, no applicable mathematically formulated theory to deal with such problems appers to exist. In this paper it is shown that any image can be embedded in a one-parameter family of derived images (with resolution as the parameter) in essentially only one unique way if the constraint that no spurious detail should be generated when the resolution is diminished, is applied. The structure of this family is governed by the well known diffusion equation (a parabolic, linear, partial differential equation of the second order). As such the structure fits into existing theories that treat the front end of the visual system as a continuous tack of homogeneous layer, characterized by iterated local processing schemes. When resolution is decreased the images becomes less articulated because the extrem (\u201clight and dark blobs\u201d) disappear one after the other. This erosion of structure is a simple process that is similar in every case. As a result any image can be described as a juxtaposed and nested set of light and dark blobs, wherein each blod has a limited range of resolution in which it manifests itself. The structure of the family of derived images permits a derivation of the sampling density required to sample the image at multiple scales of resolution. The natural scale along the resolution axis (leading to an informationally uniform sampling density) is logarithmic, thus the structure is apt for the description of size invariances.",
    "date": "1983",
    "authors": [
        "Jan J. Koenderink"
    ],
    "related_topics": [
        "Scale space",
        "Scale-space axioms",
        "Erosion (morphology)"
    ],
    "citation_count": "3,743",
    "reference_count": "15",
    "references": [
        "2109863423",
        "2003370853",
        "1587069887",
        "2036259465",
        "2078377537",
        "2019222286",
        "2117900366",
        "2025203539",
        "2069918285",
        "2032159165"
    ]
},{
    "id": "2160835070",
    "title": "Color constant color indexing",
    "abstract": "Objects can be recognized on the basis of their color alone by color indexing, a technique developed by Swain-Ballard (1991) which involves matching color-space histograms. Color indexing fails, however, when the incident illumination varies either spatially or spectrally. Although this limitation might be overcome by preprocessing with a color constancy algorithm, we instead propose histogramming color ratios. Since the ratios of color RGB triples from neighboring locations are relatively insensitive to changes in the incident illumination, this circumvents the need for color constancy preprocessing. Results of tests with the new color-constant-color-indexing algorithm on synthetic and real images show that it works very well even when the illumination varies spatially in its intensity and color. >",
    "date": "1995",
    "authors": [
        "B.V. Funt",
        "G.D. Finlayson"
    ],
    "related_topics": [
        "Color constancy",
        "RGB color model",
        "Color space"
    ],
    "citation_count": "954",
    "reference_count": "13",
    "references": [
        "2914885528",
        "3021212382",
        "1989811281",
        "2051826135",
        "2164847484",
        "1997604630",
        "1994794884",
        "1994500434",
        "2109242101",
        "123950313"
    ]
},{
    "id": "1639227073",
    "title": "Obstacle avoidance and navigation in the real world by a seeing robot rover",
    "abstract": "Abstract : The Stanford AI Lab cart is a card-table sized mobile robot controlled remotely through a radio link, and equipped with a TV camera and transmitter. A computer has been programmed to drive the cart through cluttered indoor and outdoor spaces, gaining its knowledge of the world entirely from images broadcast by the onboard TV system. The cart uses several kinds of stereo to locate objects around it in 3D and to deduce its own motion. It plans an obstacle avoiding path to a desired destination on the basis of a model built with this information. The plan changes as the cart perceives new obstacles on its journey. The system is reliable for short runs, but slow. The cart moves one meter every ten to fifteen minutes, in lurches. After rolling a meter it stops, takes some pictures and thinks about them for a long time. Then it plans a new path, executes a little of it, and pauses again. The program has successfully driven the cart through several 20 meter indoor courses (each taking about five hours) complex enough to necessitate three or four avoiding swerves. A less successful outdoor run, in which the cart skirted two obstacles but collided with a third, was also done. Harsh lighting (very bright surfaces next to very dark shadows) giving poor pictures and movement of shadows during the cart's creeping progress were major reasons for the poorer outdoor performance. The action portions of these runs were filmed by computer controlled cameras. (Author)",
    "date": "1979",
    "authors": [
        "Hans Peter Moravec"
    ],
    "related_topics": [
        "Obstacle avoidance",
        "Mobile robot",
        "Obstacle"
    ],
    "citation_count": "1,094",
    "reference_count": "0",
    "references": []
},{
    "id": "1756736144",
    "title": "Finding Edges and Lines in Images",
    "abstract": "Abstract : The problem of detecting intensity changes in images is canonical in vision. Edge detection operators are typically designed to optimally estimate first or second derivative over some (usually small) support. Other criteria such as output signal to noise ratio or bandwidth have also been been argued for. This thesis is an attempt to formulate a set of edge detection criteria that capture as directly as possible the desirable properties of an edge operator. Variational techniques are used to find a solution over the space of all linear shift invariant operators. The first criterion is that the detector have low probability of error i.e. failing to mark edges or falsely marking non-edges. The second is that the marked points should b The third criterion is that there should be low probability of more than one response to a single edge. The technique is used to find optimal operators for step edges and for extended impulse profiles (ridges or valleys in two dimensions). The extension of the one dimensional operators to two dimensions is then discussed. The result is a set of operators of varying width, length and orientation. The problem of combining these outputs into a single description is discussed, and a set of heuristics for the integration are given. (Author)",
    "date": "1983",
    "authors": [
        "John Canny"
    ],
    "related_topics": [
        "Edge detection",
        "Image processing",
        "Second derivative"
    ],
    "citation_count": "1,374",
    "reference_count": "0",
    "references": []
},{
    "id": "2063599328",
    "title": "3D positional integration from image sequences",
    "abstract": "Abstract An explicit three-dimensional (3D) representation is constructed from feature points extracted from a sequence of images taken by a moving camera. The points are tracked through the sequence, and their 3D locations are accurately determined by use of Kalman filters. The egomotion of the camera is also determined.",
    "date": "1988",
    "authors": [
        "C. G. Harris",
        "J. M. Pike"
    ],
    "related_topics": [
        "Feature (computer vision)",
        "Kalman filter",
        "Sequence"
    ],
    "citation_count": "220",
    "reference_count": "2",
    "references": [
        "2020554914",
        "1988027882"
    ]
},{
    "id": "2048192053",
    "title": "Surface reconstruction from outdoor image sequences",
    "abstract": "Abstract This paper describes the results of a study aimed at inferring the surface structure of outdoor scenes from video data acquired by a vehicle-mounted TV camera. The method is based on a decomposition of each frame of the video sequence into a dense set of feature points. Through the application of a structure-from-motion algorithm, the 3D locations of the time-consistent features are estimated and sequentially updated as each new frame is processed. The resultant point-based 3D representation has been found to be reliable, accurate and rich enough to enable the surface structure of the viewed scene to be reconstructed. Examples of the surfaces extracted by this \u2018bottom-up\u2019 approach from a 12 second video sequence are presented here. The implications of these results for autonomous vehicle navigation are discussed.",
    "date": "1989",
    "authors": [
        "Debra Charnley",
        "Rod Blissett"
    ],
    "related_topics": [
        "Frame (networking)",
        "Professional video camera",
        "Feature (computer vision)"
    ],
    "citation_count": "33",
    "reference_count": "13",
    "references": [
        "2111308925",
        "2069239883",
        "1502820991",
        "2063599328",
        "2039106392",
        "2155054718",
        "2166967166",
        "2020554914",
        "2160982455",
        "1999940778"
    ]
},{
    "id": "2039106392",
    "title": "3D wire-frame integration from image sequences",
    "abstract": "Abstract When integrating visual features into 3D for a structure from motion algorithm, the connectivity and relationships of features are an important adjunct to any quantitative 3D geometry. This paper describes a general purpose vision system which aims to perceive and refine this topology in conjunction with geometry, using edges, vertices and isolated corners extracted from a sequence of monocular images of an unconstrained scene. Rules which tackle the practical difficulties of imperfect image processing and obscuration features are defined. Results are shown for a rotating view of a polyhedral object and for an outdoor scene viewed from a moving vehicle.",
    "date": "1989",
    "authors": [
        "Mike Stephens",
        "Chris Harris"
    ],
    "related_topics": [
        "Structure from motion",
        "Image processing",
        "Machine vision"
    ],
    "citation_count": "17",
    "reference_count": "7",
    "references": [
        "2111308925",
        "2063599328",
        "2048192053",
        "2331801068",
        "2020554914",
        "2116453783",
        "2065537272"
    ]
},{
    "id": "2997169974",
    "title": "Rotationally invariant image operators",
    "abstract": "",
    "date": "1977",
    "authors": [
        "Paul Beaudet"
    ],
    "related_topics": [
        "Invariant (mathematics)",
        "Pure mathematics",
        "Computer science"
    ],
    "citation_count": "486",
    "reference_count": "0",
    "references": []
},{
    "id": "2130103520",
    "title": "Good features to track",
    "abstract": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments. >",
    "date": "1994",
    "authors": [
        "Jianbo Shi",
        "Tomasi"
    ],
    "related_topics": [
        "Feature (computer vision)",
        "Feature extraction",
        "Feature selection"
    ],
    "citation_count": "10,887",
    "reference_count": "16",
    "references": [
        "2118877769",
        "1639227073",
        "2130657708",
        "2134572726",
        "2069035105",
        "1970393892",
        "2068914842",
        "2075747175",
        "2076774318",
        "2101230393"
    ]
},{
    "id": "2085261163",
    "title": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography",
    "abstract": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing",
    "date": "1981",
    "authors": [
        "Martin A. Fischler",
        "Robert C. Bolles"
    ],
    "related_topics": [
        "RANSAC",
        "Smoothing",
        "Image processing"
    ],
    "citation_count": "29,351",
    "reference_count": "5",
    "references": [
        "3017143921",
        "2168938315",
        "2056515188",
        "2170081783",
        "1550820742"
    ]
},{
    "id": "3022352042",
    "title": "Three-Dimensional Computer Vision",
    "abstract": "",
    "date": "1993",
    "authors": [
        "Olivier Faugeras"
    ],
    "related_topics": [
        "Computer vision",
        "Computer science",
        "Artificial intelligence"
    ],
    "citation_count": "1,826",
    "reference_count": "0",
    "references": []
},{
    "id": "1549739843",
    "title": "3D Model Acquisition from Extended Image Sequences",
    "abstract": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models. The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework. The matching techniques are both robust (detecting and discarding mismatches) and fully automatic.",
    "date": "1996",
    "authors": [
        "Paul A. Beardsley",
        "Philip H. S. Torr",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Trifocal tensor",
        "Feature detection (computer vision)",
        "Fundamental matrix (computer vision)"
    ],
    "citation_count": "628",
    "reference_count": "22",
    "references": [
        "2145023731",
        "2111308925",
        "2085261163",
        "2129249398",
        "2138835141",
        "1482517735",
        "1530454533",
        "1602748186",
        "1630235098",
        "1517576992"
    ]
},{
    "id": "1958762911",
    "title": "A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry",
    "abstract": "Many object classes, including human faces, can be modeled as a set of characteristic parts arranged in a variable spatial configuration. We introduce a simplified model of a deformable object class and derive the optimal detector for this model. However, the optimal detector is not realizable except under special circumstances (independent part positions). A cousin of the optimal detector is developed which uses \u201csoft\u201d part detectors with a probabilistic description of the spatial arrangement of the parts. Spatial arrangements are modeled probabilistically using shape statistics to achieve invariance to translation, rotation, and scaling. Improved recognition performance over methods based on \u201chard\u201d part detectors is demonstrated for the problem of face detection in cluttered scenes.",
    "date": "1998",
    "authors": [
        "Michael C. Burl",
        "Markus Weber",
        "Pietro Perona"
    ],
    "related_topics": [
        "Face detection",
        "Detector",
        "Probabilistic logic"
    ],
    "citation_count": "399",
    "reference_count": "26",
    "references": [
        "2138451337",
        "2217896605",
        "2159686933",
        "2123977795",
        "3017143921",
        "2113341759",
        "2095757522",
        "2135463994",
        "2053197265",
        "1530454533"
    ]
},{
    "id": "2124722975",
    "title": "A computational model for visual selection",
    "abstract": "We propose a computational model for detecting and localizing instances from an object class in static gray-level images. We divide detection into visual selection and final classification, concentrating on the former: drastically reducing the number of candidate regions that require further, usually more intensive, processing, but with a minimum of computation and missed detections. Bottom-up processing is based on local groupings of edge fragments constrained by loose geometrical relationships. They have no a priori semantic or geometric interpretation. The role of training is to select special groupings that are moderately likely at certain places on the object but rare in the background. We show that the statistics in both populations are stable. The candidate regions are those that contain global arrangements of several local groupings. Whereas our model was not conceived to explain brain functions, it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse ...",
    "date": "1999",
    "authors": [
        "Yali Amit",
        "Donald Geman"
    ],
    "related_topics": [
        "Pattern recognition (psychology)",
        "Stability (learning theory)",
        "Selection (linguistics)"
    ],
    "citation_count": "247",
    "reference_count": "24",
    "references": [
        "2217896605",
        "2159686933",
        "2120240539",
        "2029740044",
        "1513966746",
        "2122672396",
        "2119664956",
        "2125756925",
        "1677489248",
        "2097099483"
    ]
},{
    "id": "2117138270",
    "title": "Recognition of planar object classes",
    "abstract": "We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes.",
    "date": "1996",
    "authors": [
        "M.C. Burl",
        "P. Perona"
    ],
    "related_topics": [
        "3D single-object recognition",
        "Haar-like features",
        "Object detection"
    ],
    "citation_count": "166",
    "reference_count": "24",
    "references": [
        "2138451337",
        "2123977795",
        "3017143921",
        "2113341759",
        "2095757522",
        "2125713050",
        "2722851397",
        "2125791971",
        "2090196588",
        "1964156667"
    ]
},{
    "id": "2125791971",
    "title": "Finding faces in cluttered scenes using random labeled graph matching",
    "abstract": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally. >",
    "date": "1995",
    "authors": [
        "T.K. Leung",
        "M.C. Burl",
        "P. Perona"
    ],
    "related_topics": [
        "Facial recognition system",
        "Face (geometry)",
        "Feature extraction"
    ],
    "citation_count": "609",
    "reference_count": "17",
    "references": [
        "2138451337",
        "3017143921",
        "2113341759",
        "2135346934",
        "2084844503",
        "2293807537",
        "2014102379",
        "2090196588",
        "1964156667",
        "8853611"
    ]
},{
    "id": "2029727948",
    "title": "Recognizing surfaces using three-dimensional textons",
    "abstract": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions.",
    "date": "1999",
    "authors": [
        "T. Leung",
        "J. Malik"
    ],
    "related_topics": [
        "Texton",
        "Image texture",
        "Texture (geology)"
    ],
    "citation_count": "286",
    "reference_count": "20",
    "references": [
        "2170120409",
        "2130416410",
        "1997063559",
        "1634005169",
        "3017143921",
        "1490632837",
        "2000123870",
        "1506013575",
        "2115738369",
        "1528775006"
    ]
},{
    "id": "1628541567",
    "title": "Face Recognition Using Active Appearance Models",
    "abstract": "We present a new framework for interpreting face images and image sequences using an Active Appearance Model (AAM). The AAM contains a statistical, photo-realistic model of the shape and grey-level appearance of faces. This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation. We use the AAM as a basis for face recognition, obtain good results for difficult images. We show how the AAM framework allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence. The AAM approach makes optimal use of the evidence from either a single image or image sequence. Since we derive a complete description of a given image our method can be used as the basis for a range of face image interpretation tasks.",
    "date": "1998",
    "authors": [
        "Gareth J. Edwards",
        "Timothy F. Cootes",
        "Christopher J. Taylor"
    ],
    "related_topics": [
        "Active appearance model",
        "Facial recognition system",
        "Gesture recognition"
    ],
    "citation_count": "463",
    "reference_count": "17",
    "references": [
        "2138451337",
        "2152826865",
        "2038952578",
        "2095757522",
        "2129150631",
        "2612719923",
        "2124243699",
        "1969341260",
        "1567738032",
        "2090929998"
    ]
},{
    "id": "2160484851",
    "title": "Managing Gigabytes: Compressing and Indexing Documents and Images",
    "abstract": "PREFACE 1. OVERVIEW 2. TEXT COMPRESSION 3. INDEXING 4. QUERYING 5. INDEX CONSTRUCTION 6. IMAGE COMPRESSION 7. TEXTUAL IMAGES 8. MIXED TEXT AND IMAGES 9. IMPLEMENTATION 10. THE INFORMATION EXPLOSION A. GUIDE TO THE MG SYSTEM B. GUIDE TO THE NZDL REFERENCES INDEX",
    "date": "1999",
    "authors": [
        "I.H. Witten",
        "A. Moffat",
        "T.C. Bell"
    ],
    "related_topics": [
        "Index (publishing)",
        "Image compression",
        "Search engine indexing"
    ],
    "citation_count": "3,907",
    "reference_count": "1",
    "references": [
        "2130350995"
    ]
},{
    "id": "3145128584",
    "title": "Introduction to Algorithms",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Adhi Harmoko S",
        "M.Komp",
        "Joseph Marie Jacquard",
        "Konrad Zuse",
        "Eniac"
    ],
    "related_topics": [
        "Internal sort",
        "Introsort",
        "Insertion sort"
    ],
    "citation_count": "60,162",
    "reference_count": "0",
    "references": []
},{
    "id": "1510073064",
    "title": "Kernel Methods for Pattern Analysis",
    "abstract": "Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) and look for general types of relations (e.g. rankings, classifications, regressions, clusters). The application areas range from neural networks and pattern recognition to machine learning and data mining. This book, developed from lectures and tutorials, fulfils two major roles: firstly it provides practitioners with a large toolkit of algorithms, kernels and solutions ready to use for standard pattern discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly it provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so.",
    "date": "2003",
    "authors": [
        "John Shawe-Taylor",
        "Nello Cristianini"
    ],
    "related_topics": [
        "String kernel",
        "Multiple kernel learning",
        "Tree kernel"
    ],
    "citation_count": "8,363",
    "reference_count": "25",
    "references": [
        "2148603752",
        "3124955340",
        "1601740268",
        "1975846642",
        "1542886316",
        "2579923771",
        "2139338362",
        "2099579348",
        "2106491486",
        "1520252399"
    ]
},{
    "id": "2427881153",
    "title": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions",
    "abstract": "Consider a set of S of n data points in real d-dimensional space, Rd, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess S into a data structure, so that given any query point q\u2208 Rd, is the closest point of S to q can be reported quickly. Given any positive real \u03f5, data point p is a (1 +\u03f5)-approximate nearest neighbor of q if its distance from q is within a factor of (1 + \u03f5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a set of n points in Rd in O(dn log n) time and O(dn) space, so that given a query point q \u2208 Rd, and \u03f5 > 0, a (1 + \u03f5)-approximate nearest neighbor of q can be computed in O(cd, \u03f5 log n) time, where cd,\u03f5\u2264d \u23081 + 6d/\u03f5\u2309d is a factor depending only on dimension and \u03f5. In general, we show that given an integer k \u2265 1, (1 + \u03f5)-approximations to the k nearest neighbors of q can be computed in additional O(kd log n) time.",
    "date": "1998",
    "authors": [
        "Sunil Arya",
        "David M. Mount",
        "Nathan S. Netanyahu",
        "Ruth Silverman",
        "Angela Y. Wu"
    ],
    "related_topics": [
        "Fixed-radius near neighbors",
        "Nearest neighbor graph",
        "Nearest neighbor search"
    ],
    "citation_count": "3,608",
    "reference_count": "61",
    "references": [
        "2752885492",
        "2147152072",
        "2147717514",
        "1634005169",
        "2160066518",
        "2149906774",
        "3017143921",
        "2074429597",
        "2238624099",
        "2046144220"
    ]
},{
    "id": "2520931985",
    "title": "When is nearest neighbor meaningful",
    "abstract": "We explore the effect of dimensionality on the nearest neighbor problem. We show that under a broad set of conditions (much broader than independent and identically distributed dimensions), as dimensionality increases, the distance to the nearest data point approaches the distance to the farthest data point. To provide a practical perspective, we present empirical results on both real and synthetic data sets that demonstrate that this effect can occur for as few as 10-15 dimensions. These results should not be interpreted to mean that high-dimensional indexing is never meaningful; we illustrate this point by identifying some high-dimensional workloads for which this effect does not occur. However, our results do emphasize that the methodology used almost universally in the database literature to evaluate high-dimensional indexing techniques is flawed, and should be modified. In particular, most such techniques proposed in the literature are not evaluated versus simple linear scan, and are evaluated over workloads for which nearest neighbor is not meaningful. Often, even the reported experiments, when analyzed carefully, show that linear scan would outperform the techniques being proposed on the workloads studied in high (10-15) dimensionality!.",
    "date": "1998",
    "authors": [
        "K. Beyer",
        "J. Goldstein",
        "R. Ramakrishnan",
        "U. Shaft"
    ],
    "related_topics": [
        "Curse of dimensionality",
        "k-nearest neighbors algorithm",
        "Independent and identically distributed random variables"
    ],
    "citation_count": "3,252",
    "reference_count": "0",
    "references": []
},{
    "id": "2165533158",
    "title": "On the Surprising Behavior of Distance Metrics in High Dimensional Spaces",
    "abstract": "In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.",
    "date": "2001",
    "authors": [
        "Charu C. Aggarwal",
        "Alexander Hinneburg",
        "Daniel A. Keim"
    ],
    "related_topics": [
        "Euclidean distance",
        "Nearest neighbor search",
        "Metric (mathematics)"
    ],
    "citation_count": "1,895",
    "reference_count": "10",
    "references": [
        "2118269922",
        "1541459201",
        "2520931985",
        "2145725688",
        "1595303882",
        "2104128006",
        "2133542527",
        "2000830496",
        "2109424811",
        "1969357402"
    ]
},{
    "id": "2045533739",
    "title": "Stable distributions, pseudorandom generators, embeddings, and data stream computation",
    "abstract": "In this article, we show several results obtained by combining the use of stable distributions with pseudorandom generators for bounded space. In particular:---We show that, for any p \u2208 (0, 2], one can maintain (using only O(log n/e2) words of storage) a sketchC(q) of a point q \u2208 lnp under dynamic updates of its coordinates. The sketch has the property that, given C(q) and C(s), one can estimate Vq \u2212 sVp up to a factor of (1 p e) with large probability. This solves the main open problem of Feigenbaum et al. [1999].---We show that the aforementioned sketching approach directly translates into an approximate algorithm that, for a fixed linear mapping A, and given x \u2208 \u211cn and y \u2208 \u211cm, estimates VAx \u2212 yVp in O(n p m) time, for any p \u2208 (0, 2]. This generalizes an earlier algorithm of Wasserman and Blum [1997] which worked for the case p = 2.---We obtain another sketch function C\u2032 which probabilistically embeds ln1 into a normed spacelm1. The embedding guarantees that, if we set m = log(1/\u03b4)O(1/e), then for any pair of points q, s \u2208 ln1, the distance between q and s does not increase by more than (1 p e) with constant probability, and it does not decrease by more than (1 \u2212 e) with probability 1 \u2212 \u03b4. This is the only known dimensionality reduction theorem for the l1 norm. In fact, stronger theorems of this type (i.e., that guarantee very low probability of expansion as well as of contraction) cannot exist [Brinkman and Charikar 2003].---We give an explicit embedding of ln2 into lnO(log n)1 with distortion (1 p 1/n\u0398(1)).",
    "date": "2006",
    "authors": [
        "Piotr Indyk"
    ],
    "related_topics": [
        "Bounded function",
        "Embedding",
        "Open problem"
    ],
    "citation_count": "1,114",
    "reference_count": "44",
    "references": [
        "2147717514",
        "2162006472",
        "2152565070",
        "1965972569",
        "2080745194",
        "2004110412",
        "2047424291",
        "2176446742",
        "2048779798",
        "1761167196"
    ]
},{
    "id": "2169351022",
    "title": "An optimal algorithm for approximate nearest neighbor searching",
    "abstract": "",
    "date": "1994",
    "authors": [
        "Sunil Arya",
        "David M. Mount",
        "Nathan S. Netanyahu",
        "Ruth Silverman",
        "Angela Wu"
    ],
    "related_topics": [
        "Best bin first",
        "Nearest neighbor graph",
        "Nearest neighbor search"
    ],
    "citation_count": "949",
    "reference_count": "17",
    "references": [
        "2074429597",
        "2071866949",
        "2024668293",
        "2054011861",
        "2090398718",
        "2147647517",
        "2061845601",
        "1998512964",
        "2024766881",
        "2053418598"
    ]
},{
    "id": "2109034006",
    "title": "Efficient large-scale sequence comparison by locality-sensitive hashing.",
    "abstract": "Motivation: Comparison of multimegabase genomic DNA sequences is a popular technique for finding and annotating conserved genome features. Performing such comparisons entails finding many short local alignments between sequences up to tens of megabases in length. To process such long sequences efficiently, existing algorithms find alignments by expanding around short runs of matching bases with no substitutions or other differences. Unfortunately, exact matches that are short enough to occur often in significant alignments also occur frequently by chance in the background sequence. Thus, these algorithms must trade off between efficiency and sensitivity to features without long exact matches. Results: We introduce a new algorithm, LSH-ALL-PAIRS, to find ungapped local alignments in genomic sequence with up to a specified fraction of substitutions. The length and substitution rate of these alignments can be chosen so that they appear frequently in significant similarities yet still remain rare in the background sequence. The algorithm finds ungapped alignments efficiently using a randomized search technique, locality-sensitive hashing. We have found LSH-ALL-PAIRS to be both efficient and sensitive for finding local similarities with as little as 63% identity in mammalian genomic sequences up to tens of megabases in length Availability: Contact the author at the address below.",
    "date": "2001",
    "authors": [
        "Jeremy Buhler"
    ],
    "related_topics": [
        "Locality-sensitive hashing",
        "Sequence (medicine)",
        "Sequence alignment"
    ],
    "citation_count": "321",
    "reference_count": "21",
    "references": [
        "2158714788",
        "2147717514",
        "2295428206",
        "1502916507",
        "2610179052",
        "2949977409",
        "2094519647",
        "2152331922",
        "2614575602",
        "1964918240"
    ]
},{
    "id": "2048779798",
    "title": "Finding interesting associations without support pruning",
    "abstract": "Association-rule mining has heretofore relied on the condition of high support to do its work efficiently. In particular, the well-known a priori algorithm is only effective when the only rules of interest are relationships that occur very frequently. However, there are a number of applications, such as data mining, identification of similar Web documents, clustering, and collaborative filtering, where the rules of interest have comparatively few instances in the data. In these cases, we must look for highly correlated items, or possibly even causal relationships between infrequent items. We develop a family of algorithms for solving this problem, employing a combination of random sampling and hashing techniques. We provide analysis of the algorithms developed and conduct experiments on real and synthetic data to obtain a comparative performance analysis.",
    "date": "2000",
    "authors": [
        "E. Cohen",
        "M. Datar",
        "S. Fujiwara",
        "A. Gionis",
        "P. Indyk",
        "R. Motwani",
        "J.D. Ullman",
        "C. Yang"
    ],
    "related_topics": [
        "Cluster analysis",
        "Locality-sensitive hashing",
        "Association rule learning"
    ],
    "citation_count": "763",
    "reference_count": "19",
    "references": [
        "1484413656",
        "2166559705",
        "1506285740",
        "2147717514",
        "1966553486",
        "2295428206",
        "2341865734",
        "1502916507",
        "3017143921",
        "1996510517"
    ]
},{
    "id": "1595303882",
    "title": "What Is the Nearest Neighbor in High Dimensional Spaces",
    "abstract": "Nearest neighbor search in high dimensional spaces is an interesting and important problem which is relevant for a wide variety of novel database applications. As recent results show, however, the problem is a very di cult one, not only with regards to the performance issue but also to the quality issue. In this paper, we discuss the quality issue and identify a new generalized notion of nearest neighbor search as the relevant problem in high dimensional space. In contrast to previous approaches, our new notion of nearest neighbor search does not treat all dimensions equally but uses a quality criterion to select relevant dimensions (projections) with respect to the given query. As an example for a useful quality criterion, we rate how well the data is clustered around the query point within the selected projection. We then propose an e cient and e ective algorithm to solve the generalized nearest neighbor problem. Our experiments based on a number of real and synthetic data sets show that our new approach provides new insights into the nature of nearest neighbor search on high",
    "date": "2000",
    "authors": [
        "Alexander Hinneburg",
        "Charu C. Aggarwal",
        "Daniel A. Keim"
    ],
    "related_topics": [
        "Nearest neighbor search",
        "Best bin first",
        "k-nearest neighbors algorithm"
    ],
    "citation_count": "751",
    "reference_count": "18",
    "references": [
        "2055043387",
        "1833785989",
        "2118269922",
        "2238624099",
        "1541459201",
        "1975830550",
        "2065811242",
        "2106642566",
        "2010595692",
        "2112210867"
    ]
},{
    "id": "2135463994",
    "title": "Application of the Karhunen-Loeve procedure for the characterization of human faces",
    "abstract": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >",
    "date": "1989",
    "authors": [
        "M. Kirby",
        "L. Sirovich"
    ],
    "related_topics": [
        "Eigenface",
        "Covariance matrix",
        "Basis (linear algebra)"
    ],
    "citation_count": "3,915",
    "reference_count": "19",
    "references": [
        "1770825568",
        "2130259898",
        "1633869374",
        "147723833",
        "2798461040",
        "1507699566",
        "1509349128",
        "1535031115",
        "2051366222",
        "2565264375"
    ]
},{
    "id": "2125848778",
    "title": "Feature extraction from faces using deformable templates",
    "abstract": "A method for detecting and describing the features of faces using deformable templates is described. The feature of interest, an eye for example, is described by a parameterized template. An energy function is defined which links edges, peaks, and valleys in the image intensity to corresponding properties of the template. The template then interacts dynamically with the image, by altering its parameter values to minimize the energy function, thereby deforming itself to find the best fit. The final parameter values can be used as descriptors for the features. This method is demonstrated by showing deformable templates detecting eyes and mouths in real images. >",
    "date": "1989",
    "authors": [
        "A.L. Yuille",
        "D.S. Cohen",
        "P.W. Hallinan"
    ],
    "related_topics": [
        "Feature (computer vision)",
        "Feature extraction",
        "Real image"
    ],
    "citation_count": "2,713",
    "reference_count": "20",
    "references": [
        "2104095591",
        "2164741953",
        "2740373864",
        "2082206048",
        "2051719061",
        "1574225613",
        "2107198582",
        "2045798786",
        "1481387016",
        "1977699267"
    ]
},{
    "id": "2055712799",
    "title": "Smart sensing within a pyramid vision machine",
    "abstract": "A machine is designed, based on a pyramid architecture, that supports smart sensing and related highly efficient processing. Key elements of the design are (a) hierarchical data structures for image representation, (b) fine-to-coarse algorithms for the fast generation of image measures, (c) coarse-to-fine search strategies that rapidly locate objects or events within a scene, and (d) high-level control mechanisms that guide data gathering even as visual information is being interpreted. This system, known as the Pyramid Vision Machine, achieves high performance at modest cost. Design considerations and several applications are described. >",
    "date": "1988",
    "authors": [
        "P.J. Burt"
    ],
    "related_topics": [
        "Pyramid (image processing)",
        "Systems architecture",
        "Data structure"
    ],
    "citation_count": "430",
    "reference_count": "18",
    "references": [
        "2103504761",
        "2003370853",
        "2978983090",
        "2153709524",
        "2067398582",
        "2074163268",
        "2033266778",
        "1964415410",
        "1834283795",
        "2075554361"
    ]
},{
    "id": "2125999363",
    "title": "Categorization of faces using unsupervised feature extraction",
    "abstract": "The proposal of G. Cottrell et al. (1987) that their image compression network might be used to extract image features for pattern recognition automatically, is tested by training a neural network to compress 64 face images, spanning 11 subjects, and 13 nonface images. Features extracted in this manner (the output of the hidden units) are given as input to a one-layer network trained to distinguish faces from nonfaces and to attach a name and sex to the face images. The network successfully recognizes new images of familiar faces, categorizes novel images as to their `faceness' and, to a great extent, gender, and exhibits continued accuracy over a considerable range of partial or shifted input",
    "date": "1990",
    "authors": [
        "M.K. Fleming",
        "G.W. Cottrell"
    ],
    "related_topics": [
        "Feature extraction",
        "Feature (computer vision)",
        "Pattern recognition (psychology)"
    ],
    "citation_count": "211",
    "reference_count": "6",
    "references": [
        "1498436455",
        "3121926921",
        "2006852055",
        "2565808444",
        "2169718527",
        "2045817341"
    ]
},{
    "id": "1509703770",
    "title": "Parallel Models of Associative Memory",
    "abstract": "Contents: G.E. Hinton, J.A. Anderson, Introduction to the Updated Edition. D.E. Rumelhart, D.A. Norman, Introduction. J.A. Anderson, G.E. Hinton, Models of Information Processing in the Brain. J.A. Feldman, A Connectionist Model of Visual Memory. D. Willshaw, Holography, Associative Memory, and Inductive Generalization. T. Kohonen, E. Oja, P. Lehtio, Storage and Processing of Information in Distributed Associative Memory Systems. S.E. Fahlman, Representing Implicit Knowledge. G.E. Hinton, Implementing Semantic Networks in Parallel Hardware. T.J. Sejnowski, Skeleton Filters in the Brain. J.A. Anderson, M.C. Mozer, Categorization and Selective Neurons. S. Geman, Notes on a Self-Organizing Machine. R. Ratcliff, Parallel-Processing Mechanisms and Processing of Organized Information in Human Memory.",
    "date": "1988",
    "authors": [
        "Geoffrey E. Hinton",
        "James A. Anderson"
    ],
    "related_topics": [
        "Content-addressable memory",
        "Visual memory",
        "Connectionism"
    ],
    "citation_count": "1,364",
    "reference_count": "0",
    "references": []
},{
    "id": "1526492552",
    "title": "Stimulus-selective properties of inferior temporal neurons in the macaque",
    "abstract": "Previous studies have reported that some neurons in the inferior temporal (IT) cortex respond selectively to highly specific complex objects. In the present study, we conducted the first systematic survey of the responses of IT neurons to both simple stimuli, such as edges and bars, and highly complex stimuli, such as models of flowers, snakes, hands, and faces. If a neuron responded to any of these stimuli, we attempted to isolate the critical stimulus features underlying the response. We found that many of the responsive neurons responded well to virtually every stimulus tested. The remaining, stimulus-selective cells were often selective along the dimensions of shape, color, or texture of a stimulus, and this selectivity was maintained throughout a large receptive field. Although most IT neurons do not appear to be \u201cdetectors\u201d for complex objects, we did find a separate population of cells that responded selectively to faces. The responses of these cells were dependent on the configuration of specific face features, and their selectivity was maintained over changes in stimulus size and position. A particularly high incidence of such cells was found deep in the superior temporal sulcus. These results indicate that there may be specialized mechanisms for the analysis of faces in IT cortex.",
    "date": "1984",
    "authors": [
        "R Desimone",
        "TD Albright",
        "CG Gross",
        "C Bruce"
    ],
    "related_topics": [
        "Receptive field",
        "Temporal cortex",
        "Stimulus (physiology)"
    ],
    "citation_count": "1,805",
    "reference_count": "0",
    "references": []
},{
    "id": "1507699566",
    "title": "Practical Face Recognition and Verification with Wisard",
    "abstract": "WISARD (Wilkie, Aleksander, and Stonham\u2019s Recognition Device) is a general purpose pattern recognition machine with a special semi-parallel structure unlike that of conventional single instruction single data computers. The machine is self-adapting. It does not require programming where an explict set of rules, defining the operations to be performed on the data, have to be supplied. The behaviour of the system is established by a learning process whereby a representative set of patterns from the class of data to be recognised, is input to the machine. A wide range of pattern recognition problems can be solved with this approach, they include industrial inspection, speech recognition, medical pattern recognition and artificial vision.",
    "date": "1985",
    "authors": [
        "T. J. Stonham"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Pattern recognition (psychology)",
        "Face Recognition Grand Challenge"
    ],
    "citation_count": "122",
    "reference_count": "0",
    "references": []
},{
    "id": "2032361618",
    "title": "Automatic extraction of face-features",
    "abstract": "Abstract We describe software whose ultimate aim is to make measurements from a grey-scale image of a face. Cognitive psychologists have investigated human face recognition: we combine these insights with pattern recognition methods for computer face recognition. An application for our programs is in mug-shot retrieval; a subject sees a face, and is subsequently asked to guide a search for it from a large face database by providing a number of judgemental ratings. As each face is added to the database, 37 measurements of size and shape have to be made. Our software is designed to automate much of this. We describe algorithms used for extracting facial features such as head outline, location of eyes, eyebrows and mouth from a grey-scale image of the face. The methods involve first obtaining curves from edge detectors, and then combining and inducing them as necessary. Our approach is in part a multiresolution one; knowledge of appropriate positions of features at a given resolution is used to guide searches at finer resolutions. The results so far are encouraging; some measurements can be made accurately with a high probability of success, while failure, when it occurs, is recognised as such.",
    "date": "1987",
    "authors": [
        "I. Craw",
        "H. Elis",
        "J. R. Lishman"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face detection",
        "Facial recognition system"
    ],
    "citation_count": "386",
    "reference_count": "8",
    "references": [
        "143884444",
        "2027406879",
        "2020839919",
        "2575521957",
        "1985246210",
        "32941422",
        "34639563",
        "2050908357"
    ]
},{
    "id": "1986450498",
    "title": "Visual neurones responsive to faces",
    "abstract": "Abstract Populations of visual neurones have been discovered in one area of the temporal association cortex that respond to different aspects of facial information. The responses of these cells have many of the properties hypothesized for \u2018gnostic units' and provide insight into the final stages of visual processing leading to recognition of an object as a face and more specifically the identity of the face.",
    "date": "1986",
    "authors": [
        "David I. Perrett",
        "Amanda J. Mistlin",
        "Andrew J. Chitty"
    ],
    "related_topics": [
        "Visual processing",
        "Face perception",
        "Temporal lobe"
    ],
    "citation_count": "600",
    "reference_count": "29",
    "references": [
        "1597739853",
        "1990309597",
        "2139314678",
        "2117731089",
        "2005151061",
        "1763512962",
        "1539686131",
        "2084338988",
        "3142790270",
        "2050271480"
    ]
},{
    "id": "2119781527",
    "title": "High-quality video view interpolation using a layered representation",
    "abstract": "The ability to interactively control viewpoint while watching a video is an exciting application of image-based rendering. The goal of our work is to render dynamic scenes with interactive viewpoint control using a relatively small number of video cameras. In this paper, we show how high-quality video-based rendering of dynamic scenes can be accomplished using multiple synchronized video streams combined with novel image-based modeling and rendering algorithms. Once these video streams have been processed, we can synthesize any intermediate view between cameras at any time, with the potential for space-time manipulation.In our approach, we first use a novel color segmentation-based stereo algorithm to generate high-quality photoconsistent correspondences across all camera views. Mattes for areas near depth discontinuities are then automatically extracted to reduce artifacts during view synthesis. Finally, a novel temporal two-layer compressed representation that handles matting is developed for rendering at interactive rates.",
    "date": "2004",
    "authors": [
        "C. Lawrence Zitnick",
        "Sing Bing Kang",
        "Matthew Uyttendaele",
        "Simon Winder",
        "Richard Szeliski"
    ],
    "related_topics": [
        "Video post-processing",
        "Rendering (computer graphics)",
        "Image-based modeling and rendering"
    ],
    "citation_count": "1,808",
    "reference_count": "37",
    "references": [
        "2167667767",
        "2104974755",
        "2150134853",
        "2063366997",
        "2294985758",
        "2103917701",
        "1971719398",
        "2028687412",
        "2238402354",
        "2142540472"
    ]
},{
    "id": "2063366997",
    "title": "Light field rendering",
    "abstract": "A number of techniques have been proposed for flying through scenes by redisplaying previously rendered or digitized views. Techniques have also been proposed for interpolating between views by warping input images, using depth information or correspondences between multiple images. In this paper, we describe a simple and robust method for generating new views from arbitrary camera positions without depth information or feature matching, simply by combining and resampling the available images. The key to this technique lies in interpreting the input images as 2D slices of a 4D function the light field. This function completely characterizes the flow of light through unobstructed space in a static scene with fixed illumination. We describe a sampled representation for light fields that allows for both efficient creation and display of inward and outward looking views. We hav e created light fields from large arrays of both rendered and digitized images. The latter are acquired using a video camera mounted on a computer-controlled gantry. Once a light field has been created, new views may be constructed in real time by extracting slices in appropriate directions. Since the success of the method depends on having a high sample rate, we describe a compression system that is able to compress the light fields we have generated by more than a factor of 100:1 with very little loss of fidelity. We also address the issues of antialiasing during creation, and resampling during slice extraction. CR Categories: I.3.2 [Computer Graphics]: Picture/Image Generation \u2014 Digitizing and scanning, Viewing algorithms; I.4.2 [Computer Graphics]: Compression \u2014 Approximate methods Additional keywords: image-based rendering, light field, holographic stereogram, vector quantization, epipolar analysis",
    "date": "1996",
    "authors": [
        "Marc Levoy",
        "Pat Hanrahan"
    ],
    "related_topics": [
        "Image-based modeling and rendering",
        "Light-field camera",
        "Rendering (computer graphics)"
    ],
    "citation_count": "5,203",
    "reference_count": "23",
    "references": [
        "1634005169",
        "2294985758",
        "2062737404",
        "2111169574",
        "2098362450",
        "2107745473",
        "2105557003",
        "2064586097",
        "2295329974",
        "2115728367"
    ]
},{
    "id": "2149706766",
    "title": "Induction of Decision Trees",
    "abstract": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.",
    "date": "1986",
    "authors": [
        "J. R. Quinlan"
    ],
    "related_topics": [
        "Intelligent decision support system",
        "Influence diagram",
        "Decision engineering"
    ],
    "citation_count": "25,147",
    "reference_count": "24",
    "references": [
        "2159047538",
        "1527883571",
        "3021257214",
        "2067642555",
        "1488252886",
        "2026319679",
        "1693339475",
        "2894813436",
        "1483128843",
        "18968369"
    ]
},{
    "id": "2115689562",
    "title": "Human and machine recognition of faces: a survey",
    "abstract": "The goal of this paper is to present a critical survey of existing literature on human and machine recognition of faces. Machine recognition of faces has several applications, ranging from static matching of controlled photographs as in mug shots matching and credit card verification to surveillance video images. Such applications have different constraints in terms of complexity of processing requirements and thus present a wide range of different technical challenges. Over the last 20 years researchers in psychophysics, neural sciences and engineering, image processing analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. Ongoing research activities have been given a renewed emphasis over the last five years. Existing techniques and systems have been tested on different sets of images of varying complexities. But very little synergism exists between studies in psychophysics and the engineering literature. Most importantly, there exists no evaluation or benchmarking studies using large databases with the image quality that arises in commercial and law enforcement applications In this paper, we first present different applications of face recognition in commercial and law enforcement sectors. This is followed by a brief overview of the literature on face recognition in the psychophysics community. We then present a detailed overview of move than 20 years of research done in the engineering community. Techniques for segmentation/location of the face, feature extraction and recognition are reviewed. Global transform and feature based methods using statistical, structural and neural classifiers are summarized. >",
    "date": "1995",
    "authors": [
        "R. Chellappa",
        "C.L. Wilson",
        "S. Sirohey"
    ],
    "related_topics": [
        "Face Recognition Grand Challenge",
        "Feature extraction",
        "Eigenface"
    ],
    "citation_count": "4,255",
    "reference_count": "189",
    "references": [
        "2145023731",
        "1997063559",
        "2100115174",
        "2028310195",
        "2098693229",
        "3003662786",
        "1991848143",
        "2098947662",
        "2113341759",
        "2620619910"
    ]
},{
    "id": "2113341759",
    "title": "Face recognition: features versus templates",
    "abstract": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >",
    "date": "1993",
    "authors": [
        "R. Brunelli",
        "T. Poggio"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "3D single-object recognition",
        "Template matching"
    ],
    "citation_count": "4,180",
    "reference_count": "28",
    "references": [
        "2138451337",
        "1770825568",
        "2143956139",
        "2135463994",
        "2135346934",
        "2055712799",
        "1548502347",
        "2086479969",
        "2090196588",
        "2032361618"
    ]
},{
    "id": "2159173611",
    "title": "Probabilistic visual learning for object detection",
    "abstract": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands. >",
    "date": "1995",
    "authors": [
        "B. Moghaddam",
        "A. Pentland"
    ],
    "related_topics": [
        "Unsupervised learning",
        "Object detection",
        "Density estimation"
    ],
    "citation_count": "549",
    "reference_count": "12",
    "references": [
        "2138451337",
        "2148694408",
        "2049633694",
        "2159686933",
        "2098947662",
        "2138313032",
        "1981367467",
        "1973436000",
        "2798461040",
        "2157418942"
    ]
},{
    "id": "2120954940",
    "title": "Face recognition by elastic bunch graph matching",
    "abstract": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from the preceding one (Lades et al., 1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small get of sample image graphs.",
    "date": "1997",
    "authors": [
        "L. Wiskott",
        "J.-M. Fellous",
        "N. Kuiger",
        "C. von der Malsburg"
    ],
    "related_topics": [
        "Matching (graph theory)",
        "Graph theory",
        "Gabor wavelet"
    ],
    "citation_count": "4,980",
    "reference_count": "43",
    "references": [
        "2138451337",
        "2145889472",
        "2115689562",
        "1997011019",
        "2128716185",
        "2095757522",
        "2135463994",
        "2137234026",
        "2130259898",
        "2103384342"
    ]
},{
    "id": "1997011019",
    "title": "The FERET database and evaluation procedure for face-recognition algorithms",
    "abstract": "Abstract The Face Recognition Technology (FERET) program database is a large database of facial images, divided into development and sequestered portions. The development portion is made available to researchers, and the sequestered portion is reserved for testing facerecognition algorithms. The FERET evaluation procedure is an independently administered test of face-recognition algorithms. The test was designed to: (1) allow a direct comparison between different algorithms, (2) identify the most promising approaches, (3) assess the state of the art in face recognition, (4) identify future directions of research, and (5) advance the state of the art in face recognition.",
    "date": "1998",
    "authors": [
        "P.Jonathon Phillips",
        "Harry Wechsler",
        "Jeffery Huang",
        "Patrick J. Rauss"
    ],
    "related_topics": [
        "FERET database",
        "Facial recognition system",
        "Pattern recognition"
    ],
    "citation_count": "2,869",
    "reference_count": "25",
    "references": [
        "2138451337",
        "2098947662",
        "2095757522",
        "2118774738",
        "2067807322",
        "1973436000",
        "1557981788",
        "2147510700",
        "2132234724",
        "1533329149"
    ]
},{
    "id": "2131273085",
    "title": "Discriminant analysis for recognition of human face images",
    "abstract": "In this paper the discriminatory power of various human facial features is studied and a new scheme for Automatic Face Recognition (AFR) is proposed. Using Linear Discriminant Analysis (LDA) of different aspects of human faces in spatial domain, we first evaluate the significance of visual information in different parts/features of the face for identifying the human subject. The LDA of faces also provides us with a small set of features that carry the most relevant information for classification purposes. The features are obtained through eigenvector analysis of scatter matrices with the objective of maximizing between-class and minimizing within-class variations. The result is an efficient projection-based feature extraction and classification scheme for AFR. Soft decisions made based on each of the projections are combined, using probabilistic or evidential approaches to multisource data analysis. For medium-sized databases of human faces, good classification accuracy is achieved using very low-dimensional feature vectors.",
    "date": "1997",
    "authors": [
        "Kamran Etemad",
        "Rama Chellappa"
    ],
    "related_topics": [
        "Linear discriminant analysis",
        "Feature vector",
        "Feature extraction"
    ],
    "citation_count": "1,468",
    "reference_count": "39",
    "references": [
        "2132984323",
        "2098914003",
        "2159686933",
        "2098693229",
        "2115689562",
        "2156447271",
        "2098947662",
        "2113341759",
        "2095757522",
        "2135463994"
    ]
},{
    "id": "1761337995",
    "title": "Discriminant analysis of principal components for face recognition",
    "abstract": "In this paper we describe a face recognition method based on PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis). The method consists of two steps: first we project the face image from the original vector space to a face subspace via PCA, second we use LDA to obtain a best linear classifier. The basic idea of combining PCA and LDA is to improve the generalization capability of LDA when only few samples per class are available. Using PCA, we are able to construct a face subspace in which we apply LDA to perform classification. Using FERET dataset we demonstrate a significant improvement when principal components rather than original images are fed to the LDA classifier. The hybrid classifier using PCA and LDA provides a useful framework for other image recognition tasks as well.",
    "date": "1998",
    "authors": [
        "W. Zhao",
        "R. Chellappa",
        "A. Krishnaswamy"
    ],
    "related_topics": [
        "Linear discriminant analysis",
        "Principal component analysis",
        "Linear classifier"
    ],
    "citation_count": "893",
    "reference_count": "15",
    "references": [
        "2138451337",
        "2121647436",
        "1971784203",
        "2115689562",
        "2012352340",
        "2159173611",
        "2131273085",
        "2118774738",
        "2013737143",
        "2468714721"
    ]
},{
    "id": "2132234724",
    "title": "Bayesian face recognition using deformable intensity surfaces",
    "abstract": "We describe a novel technique for face recognition based on deformable intensity surfaces which incorporates both the shape and texture components of the 2D image. The intensity surface of the facial image is modeled as a deformable 3D mesh in (z, y, I(x, y)) space. Using an efficient technique for matching two surfaces (in terms of the analytic modes of vibration), we obtain a dense correspondence field (or 3D warp) between two images. The probability distributions of two classes of warps are then estimated from training data: interpersonal and extrapersonal variations. These densities are then used in a Bayesian framework for image matching and recognition. Experimental results with facial data from the US Army FERET database demonstrate an increased recognition rate over the previous best methods.",
    "date": "1996",
    "authors": [
        "B. Moghaddam",
        "C. Nastar",
        "A. Pentland"
    ],
    "related_topics": [
        "FERET database",
        "Facial recognition system",
        "Bayesian probability"
    ],
    "citation_count": "132",
    "reference_count": "13",
    "references": [
        "2148694408",
        "2620619910",
        "2031605731",
        "2159173611",
        "2132396702",
        "1973436000",
        "2124243699",
        "1863232835",
        "1567738032",
        "1485879728"
    ]
},{
    "id": "3094217134",
    "title": "FERET Verification Testing Protocol for Face Recognition Algorithms",
    "abstract": "",
    "date": "1998",
    "authors": [
        "P. Jonathon Phillips",
        "Syed A. Rizvi",
        "Hyeonjoon Moon"
    ],
    "related_topics": [
        "Facial recognition system",
        "Software verification",
        "Protocol (object-oriented programming)"
    ],
    "citation_count": "93",
    "reference_count": "0",
    "references": []
},{
    "id": "2689627924",
    "title": "The FERET Verification Testing Protocol for Face Recognition Algorithms | NIST",
    "abstract": "",
    "date": "1998",
    "authors": [
        "S A. Rizvi",
        "J P. Phillips",
        "H Moon"
    ],
    "related_topics": [
        "NIST",
        "Facial recognition system",
        "Software verification"
    ],
    "citation_count": "51",
    "reference_count": "0",
    "references": []
},{
    "id": "2102773363",
    "title": "Computational and performance aspects of PCA-based face-recognition algorithms.",
    "abstract": "Algorithms based on principal component analysis (PCA) form the basis of numerous studies in the psychological and algorithmic face-recognition literature. PCA is a statistical technique and its incorporation into a face-recognition algorithm requires numerous design decisions. We explicitly state the design decisions by introducing a generic modular PCA-algorithm. This allows us to investigate these decisions, including those not documented in the literature. We experimented with different implementations of each module, and evaluated the different implementations using the September 1996 FERET evaluation protocol (the de facto standard for evaluating face-recognition algorithms). We experimented with (i) changing the illumination normalization procedure; (ii) studying effects on algorithm performance of compressing images with JPEG and wavelet compression algorithms; (iii) varying the number of eigenvectors in the representation; and (iv) changing the similarity measure in the classification process. We...",
    "date": "2001",
    "authors": [
        "Hyeonjoon Moon",
        "P Jonathon Phillips"
    ],
    "related_topics": [
        "Similarity measure",
        "Facial recognition system",
        "JPEG"
    ],
    "citation_count": "660",
    "reference_count": "27",
    "references": [
        "2138451337",
        "2121647436",
        "2033419168",
        "2159686933",
        "2113341759",
        "1997011019",
        "2012352340",
        "2135463994",
        "2131273085",
        "2118774738"
    ]
},{
    "id": "2143542740",
    "title": "An evaluation of multimodal 2D+3D face biometrics",
    "abstract": "We report on the largest experimental study to date in multimodal 2D+3D face recognition, involving 198 persons in the gallery and either 198 or 670 time-lapse probe images. PCA-based methods are used separately for each modality and match scores in the separate face spaces are combined for multimodal recognition. Major conclusions are: 1) 2D and 3D have similar recognition performance when considered individually, 2) combining 2D and 3D results using a simple weighting scheme outperforms either 2D or 3D alone, 3) combining results from two or more 2D images using a similar weighting scheme also outperforms a single 2D image, and 4) combined 2D+3D outperforms the multi-image 2D result. This is the first (so far, only) work to present such an experimental control to substantiate multimodal performance improvement.",
    "date": "2005",
    "authors": [
        "K.I. Chang",
        "K.W. Bowyer",
        "P.J. Flynn"
    ],
    "related_topics": [
        "Facial recognition system",
        "Weighting",
        "Biometrics"
    ],
    "citation_count": "599",
    "reference_count": "12",
    "references": [
        "2033419168",
        "2156887092",
        "2483194642",
        "2081734071",
        "97821839",
        "2065595219",
        "2112530785",
        "1913892989",
        "2155641291",
        "2126087999"
    ]
},{
    "id": "2137385871",
    "title": "Face Recognition Vendor Test 2002: Evaluation Report",
    "abstract": "",
    "date": "2003",
    "authors": [
        "P Jonathon Phillips",
        "Patrick Grother",
        "Ross J Micheals",
        "Duane M Blackburn",
        "Elham Tabassi",
        "Mike Bone"
    ],
    "related_topics": [
        "Face Recognition Grand Challenge",
        "Facial recognition system",
        "Vendor"
    ],
    "citation_count": "315",
    "reference_count": "0",
    "references": []
},{
    "id": "2120838001",
    "title": "The statistics of natural images",
    "abstract": "Recently there has been a resurgence of interest in the properties of natural images. Their statistics are important not only in image compression but also for the study of sensory processing in biology, which can be viewed as satisfying certain \u2018design criteria\u2019. This review summarizes previous work on image statistics and presents our own data. Perhaps the most notable property of natural images is an invariance to scale. We present data to support this claim as well as evidence for a hierarchical invariance in natural scenes. These symmetries provide a powerful description of natural images as they greatly restrict the class of allowed distributions.",
    "date": "1993",
    "authors": [
        "Daniel L Ruderman"
    ],
    "related_topics": [
        "Image compression",
        "Property (programming)",
        "Natural (music)"
    ],
    "citation_count": "1,053",
    "reference_count": "82",
    "references": [
        "1997063559",
        "2100115174",
        "2058834119",
        "2180838288",
        "2103384342",
        "2144520790",
        "2167034998",
        "1667165204",
        "2131329059",
        "2098301339"
    ]
},{
    "id": "1555969862",
    "title": "The CSU Face Identification Evaluation System",
    "abstract": "The CSU Face Identification Evaluation System includes standardized image preprocessing software, four distinct face recognition algorithms, analysis tools to study algorithm performance, and Unix shell scripts to run standard experiments. All code is written in ANSII C. The four algorithms provided are principle components analysis (PCA), a.k.a eigenfaces, a combined principle components analysis and linear discriminant analysis algorithm (PCA + LDA), an intrapersonal/extrapersonal image difference classifier (IIDC), and an elastic bunch graph matching (EBGM) algorithm. The PCA + LDA, IIDC, and EBGM algorithms are based upon algorithms used in the FERET study contributed by the University of Maryland, MIT, and USC, respectively. One analysis tool generates cumulative match curves; the other generates a sample probability distribution for recognition rate at recognition rank 1, 2, etc., using Monte Carlo sampling to generate probe and gallery choices. The sample probability distributions at each rank allow standard error bars to be added to cumulative match curves. The tool also generates sample probability distributions for the paired difference of recognition rates for two algorithms. Whether one algorithm consistently outperforms another is easily tested using this distribution. The CSU Face Identification Evaluation System is available through our Web site and we hope it will be used by others to rigorously compare novel face identification algorithms to standard algorithms using a common implementation and known comparison techniques.",
    "date": "2005",
    "authors": [
        "J. Ross Beveridge",
        "David Bolme",
        "Bruce A. Draper",
        "Marcio Teixeira"
    ],
    "related_topics": [
        "Eigenface",
        "Facial recognition system",
        "Linear discriminant analysis"
    ],
    "citation_count": "155",
    "reference_count": "14",
    "references": [
        "2033419168",
        "1506281249",
        "2098693229",
        "1761337995",
        "2124925761",
        "2130972944",
        "2139085189",
        "2032239755",
        "1569473762",
        "127683480"
    ]
},{
    "id": "138943044",
    "title": "Face Recognition Vendor Test 2002 Supplemental Report | NIST",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Patrick J. Grother"
    ],
    "related_topics": [
        "Face Recognition Grand Challenge",
        "Facial recognition system",
        "NIST"
    ],
    "citation_count": "23",
    "reference_count": "8",
    "references": [
        "2155511848",
        "2137385871",
        "97107628",
        "102626146",
        "2112530785",
        "2104060706",
        "1502189209",
        "1498645202"
    ]
},{
    "id": "1998186877",
    "title": "From piecemeal to configurational representation of faces",
    "abstract": "Unlike older children and adults, children of less than about 10 years of age remember photographs of faces presented upside down almost as well as those shown upright and are easily fooled by simple disguises. The development at age 10 of the ability to encode orientation-specific configurational aspects of a face may reflect completion of certain maturational changes in the right cerebral hemisphere.",
    "date": "1977",
    "authors": [
        "Susan Carey",
        "Rhea Diamond"
    ],
    "related_topics": [
        "Facial expression",
        "Cognitive development",
        "Child development"
    ],
    "citation_count": "1,080",
    "reference_count": "12",
    "references": [
        "2139220163",
        "2046442873",
        "2056115137",
        "2044703390",
        "2329045102",
        "2022737180",
        "2031378282",
        "1990279616",
        "2009214135",
        "1976622121"
    ]
},{
    "id": "2169718527",
    "title": "Picture Processing System by Computer Complex and Recognition of Human Faces",
    "abstract": "",
    "date": "1974",
    "authors": [
        "Takeo Kanade"
    ],
    "related_topics": [
        "Human\u2013computer interaction",
        "Computer vision",
        "Computer science"
    ],
    "citation_count": "1,287",
    "reference_count": "0",
    "references": []
},{
    "id": "2209124607",
    "title": "Multiple View Geometry in Computer Vision (2nd ed)",
    "abstract": "",
    "date": "2002",
    "authors": [
        "Richard Hartley",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Trifocal tensor",
        "Computer graphics (images)",
        "Computer science"
    ],
    "citation_count": "4,428",
    "reference_count": "0",
    "references": []
},{
    "id": "2118774738",
    "title": "The FERET evaluation methodology for face-recognition algorithms",
    "abstract": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases.",
    "date": "1997",
    "authors": [
        "P.J. Phillips",
        "Hyeonjoon Moon",
        "P. Rauss",
        "S.A. Rizvi"
    ],
    "related_topics": [
        "FERET database",
        "Facial recognition system",
        "Pattern recognition"
    ],
    "citation_count": "903",
    "reference_count": "9",
    "references": [
        "2138451337",
        "2098947662",
        "2012352340",
        "2159173611",
        "2131273085",
        "2132234724",
        "1533329149",
        "1971345515",
        "3035660467"
    ]
},{
    "id": "2102760078",
    "title": "From few to many: generative models for recognition under variable pose and illumination",
    "abstract": "Image variability due to changes in pose and illumination can seriously impair object recognition. This paper presents appearance-based methods which, unlike previous appearance-based approaches, require only a small set of training images to generate a rich representation that models this variability. Specifically, from as few as three images of an object in fixed pose seen under slightly varying but unknown lighting, a surface and an albedo map are reconstructed. These are then used to generate synthetic images with large variations in pose and illumination and thus build a representation useful for object recognition. Our methods have been tested within the domain of face recognition on a subset of the Yale Face Database B containing 4050 images of 10 faces seen under variable pose and illumination. This database was specifically gathered for testing these generative methods. Their performance is shown to exceed that of popular existing methods.",
    "date": "2000",
    "authors": [
        "A.S. Georghiades",
        "P.N. Belhumeur",
        "D.J. Kriegman"
    ],
    "related_topics": [
        "3D pose estimation",
        "Pose",
        "Facial recognition system"
    ],
    "citation_count": "405",
    "reference_count": "18",
    "references": [
        "2138451337",
        "2121647436",
        "2123977795",
        "2113341759",
        "2138835141",
        "2130259898",
        "2168068730",
        "1506013575",
        "1686754659",
        "1539790409"
    ]
},{
    "id": "2120420721",
    "title": "Face identification across different poses and illuminations with a 3D morphable model",
    "abstract": "We present a novel approach for recognizing faces in images taken from different directions and under different illumination. The method is based on a 3D morphable face model that encodes shape and texture in terms of model parameters, and an algorithm that recovers these parameters from a single image of a face. For face identification, we use the shape and texture parameters of the model that are separated from imaging parameters, such as pose and illumination. In addition to the identity, the system provides a measure of confidence. We report experimental results for more than 4000 images from the publicly available CMU-PIE database.",
    "date": "2002",
    "authors": [
        "V. Blanz",
        "S. Romdhani",
        "T. Vetter"
    ],
    "related_topics": [
        "Face (geometry)",
        "Facial recognition system",
        "Morphing"
    ],
    "citation_count": "429",
    "reference_count": "13",
    "references": [
        "2156909104",
        "2124776405",
        "1989702938",
        "2123921160",
        "2237250383",
        "1564419782",
        "2102773363",
        "2083632529",
        "2166125343",
        "2152475608"
    ]
},{
    "id": "2110822444",
    "title": "Categorization by Learning and Combining Object Parts",
    "abstract": "We describe an algorithm for automatically learning discriminative components of objects with SVM classifiers. It is based on growing image parts by minimizing theoretical bounds on the error probability of an SVM. Component-based face classifiers are then combined in a second stage to yield a hierarchical SVM classifier. Experimental results in face classification show considerable robustness against rotations in depth and suggest performance at significantly better level than other face detection systems. Novel aspects of our approach are: a) an algorithm to learn component-based classification experts and their combination, b) the use of 3-D morphable models for training, and c) a maximum operation on the output of each component classifier which may be relevant for biological models of visual recognition.",
    "date": "2001",
    "authors": [
        "Bernd Heisele",
        "Thomas Serre",
        "Massimiliano Pontil",
        "Thomas Vetter",
        "Tomaso Poggio"
    ],
    "related_topics": [
        "Support vector machine",
        "Face detection",
        "Discriminative model"
    ],
    "citation_count": "188",
    "reference_count": "19",
    "references": [
        "2148603752",
        "2152473410",
        "1608462934",
        "2155511848",
        "2149194912",
        "2154376992",
        "2166713160",
        "2167828171",
        "2125791971",
        "1554705102"
    ]
},{
    "id": "2121114545",
    "title": "Component-based face detection",
    "abstract": "We present a component-based, trainable system for detecting frontal and near-frontal views of faces in still gray images. The system consists of a two-level hierarchy of Support Vector Machine (SVM) classifiers. On the first level, component classifiers independently detect components Of a face. On the second level, a single classifier checks if the geometrical configuration of the detected components in the image matches a geometrical model of a face. We propose a method for automatically learning components by using 3-D head models, This approach has the advantage that no manual interaction is required for choosing and extracting components. Experiments show that the component-based system is significantly more robust against rotations in depth than a comparable system trained on whole face patterns.",
    "date": "2001",
    "authors": [
        "B. Heiselet",
        "T. Serre",
        "M. Pontil",
        "T. Poggio"
    ],
    "related_topics": [
        "Face detection",
        "Object detection",
        "Support vector machine"
    ],
    "citation_count": "300",
    "reference_count": "15",
    "references": [
        "2148603752",
        "2217896605",
        "2152473410",
        "2155511848",
        "2113341759",
        "2137346077",
        "2154376992",
        "2166713160",
        "2125791971",
        "2147575376"
    ]
},{
    "id": "2106143125",
    "title": "Combining Models and Exemplars for Face Recognition: An Illuminating Example",
    "abstract": "We propose a model- and exemplar-based approach for face recognition. This problem has been previously tackled using either models or exemplars, with limited success. Our idea uses models to synthesize many more exemplars, which are then used in the learning stage of a face recognition system. To demonstrate this, we develop a statistical shape-fromshading model to recover face shape from a single image, and to synthesize the same face under new illumination. We then use this to build a simple and fast classifier that was not possible before because of a lack of training data.",
    "date": "2000",
    "authors": [
        "Terence Sim",
        "Takeo Kanade"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "Face detection",
        "Facial recognition system"
    ],
    "citation_count": "208",
    "reference_count": "21",
    "references": [
        "2138451337",
        "2121647436",
        "2120954940",
        "1490760466",
        "2340480757",
        "1506690472",
        "1689445748",
        "2118304946",
        "2295477204",
        "2102760078"
    ]
},{
    "id": "2141503314",
    "title": "Eigen light-fields and face recognition across pose",
    "abstract": "In many face recognition tasks, the pose of the probe and gallery images are different. In other cases, multiple gallery or probe images may be available, each captured from a different pose. We propose a face recognition algorithm which can use any number of gallery images per subject, captured at arbitrary poses, and any number of probe images, again captured at arbitrary poses. The algorithm operates by estimating the eigen light-field of the subject's head from the input gallery or probe images. Matching between the probe and gallery is then performed using the eigen light-fields. We present results on the CMU (Carnegie-Mellon University) PIE (Pose, Illumination and Expression) and the FERET (FacE REcocnition Technology) face databases.",
    "date": "2002",
    "authors": [
        "R. Gross",
        "I. Matthews",
        "S. Baker"
    ],
    "related_topics": [
        "Three-dimensional face recognition",
        "3D single-object recognition",
        "Facial recognition system"
    ],
    "citation_count": "146",
    "reference_count": "17",
    "references": [
        "2098693229",
        "2063366997",
        "2123977795",
        "2098947662",
        "1997011019",
        "2294985758",
        "2155759509",
        "2753461371",
        "2003709967",
        "2157500953"
    ]
},{
    "id": "2144855601",
    "title": "The 3D Room: Digitizing Time-Varying 3D Events by Synchronized Multiple Video Streams",
    "abstract": "",
    "date": "1997",
    "authors": [
        "Takeo Kanade",
        "Hideo Saito",
        "Sundar Vedula"
    ],
    "related_topics": [
        "Video processing",
        "Video capture",
        "Computer graphics (images)"
    ],
    "citation_count": "118",
    "reference_count": "6",
    "references": [
        "2042418341",
        "1770284412",
        "2167953651",
        "1816382305",
        "2146131512",
        "2149901450"
    ]
},{
    "id": "2119479037",
    "title": "An introduction to variable and feature selection",
    "abstract": "Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.",
    "date": "2003",
    "authors": [
        "Isabelle Guyon",
        "Andr\u00e9 Elisseeff"
    ],
    "related_topics": [
        "Feature selection",
        "Feature (computer vision)",
        "Minimum redundancy feature selection"
    ],
    "citation_count": "17,323",
    "reference_count": "47",
    "references": [
        "2148603752",
        "2109363337",
        "3023786531",
        "2157795344",
        "2143426320",
        "1594031697",
        "2087347434",
        "2017337590",
        "2103333826",
        "2167277498"
    ]
},{
    "id": "2130660124",
    "title": "Content-based image retrieval at the end of the early years",
    "abstract": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap.",
    "date": "2000",
    "authors": [
        "A.W.M. Smeulders",
        "M. Worring",
        "S. Santini",
        "A. Gupta",
        "R. Jain"
    ],
    "related_topics": [
        "Content-based image retrieval",
        "Visual Word",
        "Automatic image annotation"
    ],
    "citation_count": "8,486",
    "reference_count": "203",
    "references": [
        "2156909104",
        "2062024414",
        "2128272608",
        "2132549764",
        "2049633694",
        "2914885528",
        "2124087378",
        "2482402870",
        "2125148312",
        "2160066518"
    ]
},{
    "id": "1579271636",
    "title": "Finite Mixture Models",
    "abstract": "The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and ge...",
    "date": "2000",
    "authors": [
        "Geoffrey McLachlan",
        "David Peel"
    ],
    "related_topics": [
        "Expectation\u2013maximization algorithm",
        "Minimum message length",
        "Applied mathematics"
    ],
    "citation_count": "12,894",
    "reference_count": "0",
    "references": []
},{
    "id": "1508960934",
    "title": "Computer Vision: A Modern Approach",
    "abstract": "From the Publisher: The accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise.",
    "date": "2001",
    "authors": [
        "David A. Forsyth",
        "Jean Ponce"
    ],
    "related_topics": [
        "Image-based modeling and rendering",
        "Source code",
        "Digital library"
    ],
    "citation_count": "6,320",
    "reference_count": "0",
    "references": []
},{
    "id": "1579838312",
    "title": "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition",
    "abstract": "From the Publisher: This book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora.Methodology boxes are included in each chapter. Each chapter is built around one or more worked examples to demonstrate the main idea of the chapter. Covers the fundamental algorithms of various fields, whether originally proposed for spoken or written language to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation. Emphasis on web and other practical applications. Emphasis on scientific evaluation. Useful as a reference for professionals in any of the areas of speech and language processing.",
    "date": "1999",
    "authors": [
        "Daniel Jurafsky",
        "James H. Martin"
    ],
    "related_topics": [
        "Language technology",
        "Computational linguistics",
        "Language identification"
    ],
    "citation_count": "4,632",
    "reference_count": "2",
    "references": [
        "1574901103",
        "1994851566"
    ]
},{
    "id": "1540386283",
    "title": "Multiple-Instance Learning for Natural Scene Classification",
    "abstract": "",
    "date": "1998",
    "authors": [
        "Oded Maron",
        "Aparna Lakshmi Ratan"
    ],
    "related_topics": [
        "Instance-based learning",
        "Unsupervised learning",
        "Semi-supervised learning"
    ],
    "citation_count": "819",
    "reference_count": "0",
    "references": []
},{
    "id": "1585814348",
    "title": "End-User Searching Challenges Indexing Practices inthe Digital Newspaper Photo Archive",
    "abstract": "Previous research in conceptual indexing methods of images has furnished us with refined theoretical frameworks characterising various aspects of images that could and should be indexed using textual descriptors. The development of digital image processing technologies has bred a brigade of content-based indexing and retrieval methods available for applications. What the users need and in what kinds of environments different indexing and retrieval methods are relevant, has remained an area of less intensive research work. This article presents the results of a field study concentrating on journalists as users of a digital newspaper photo archive. The expressed photo needs, applied selection criteria and observed searching behaviours in journalists' daily work were contrasted with the indexing practices applied by the archivists. The results showed that the journalists achieved satisfactory results when trivial query terms were available, e.g. when photos of named persons were needed. Browsing was the main searching strategy applied by the journalists, but the system did not support browsing well. The access problems faced by the users in particular photo needs are discussed in detail. The paper concludes by discussing the potential approaches in developing both the concept-based and content-based indexing methods as well as the user interfaces in photo retrieval systems.",
    "date": "1999",
    "authors": [
        "Marjo Markkula",
        "Eero Sormunen"
    ],
    "related_topics": [
        "Image retrieval",
        "Search engine indexing",
        "User interface"
    ],
    "citation_count": "288",
    "reference_count": "33",
    "references": [
        "2066610120",
        "2161935199",
        "2166447979",
        "2093976457",
        "2004690028",
        "2032771350",
        "2039433449",
        "2053757624",
        "2026842155",
        "2142468277"
    ]
},{
    "id": "2135705692",
    "title": "Blobworld: image segmentation using expectation-maximization and its application to image querying",
    "abstract": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects.",
    "date": "2002",
    "authors": [
        "C. Carson",
        "S. Belongie",
        "H. Greenspan",
        "J. Malik"
    ],
    "related_topics": [
        "Image texture",
        "Image segmentation",
        "Feature detection (computer vision)"
    ],
    "citation_count": "2,010",
    "reference_count": "49",
    "references": [
        "2049633694",
        "2914885528",
        "2160066518",
        "2103414828",
        "2168175751",
        "1991605728",
        "2008297189",
        "1917380066",
        "2162630772",
        "2049694710"
    ]
},{
    "id": "2125101937",
    "title": "A metric for distributions with applications to image databases",
    "abstract": "We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving \"distribution mass\" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search.",
    "date": "1998",
    "authors": [
        "Y. Rubner",
        "C. Tomasi",
        "L.J. Guibas"
    ],
    "related_topics": [
        "Earth mover's distance",
        "Image texture",
        "Metric (mathematics)"
    ],
    "citation_count": "1,964",
    "reference_count": "18",
    "references": [
        "2914885528",
        "2125148312",
        "2093191240",
        "1969294188",
        "2138584058",
        "2059975159",
        "2152825437",
        "1988445395",
        "1526351017",
        "1608339372"
    ]
},{
    "id": "2062270497",
    "title": "Information retrieval as statistical translation",
    "abstract": "We propose a new probabilistic approach to information retrieval based upon the ideas and methods of statistical machine translation. The central ingredient in this approach is a statistical model of how a user might distill or \"translate\" a given document into a query. To assess the relevance of a document to a user's query, we estimate the probability that the query would have been generated as a translation of the document, and factor in the user's general preferences in the form of a prior distribution over documents. We propose a simple, well motivated model of the document-to-query translation process, and describe an algorithm for learning the parameters of this model in an unsupervised manner from a collection of documents. As we show, one can view this approach as a generalization and justification of the \"language modeling\" strategy recently proposed by Ponte and Croft. In a series of experiments on TREC data, a simple translation-based retrieval system performs well in comparison to conventional retrieval techniques. This prototype system only begins to tap the full potential of translation-based retrieval.",
    "date": "1999",
    "authors": [
        "Adam Berger",
        "John Lafferty"
    ],
    "related_topics": [
        "Query expansion",
        "Document retrieval",
        "Example-based machine translation"
    ],
    "citation_count": "853",
    "reference_count": "13",
    "references": [
        "2049633694",
        "2006969979",
        "1978394996",
        "2093390569",
        "1482214997",
        "2097333193",
        "2046325278",
        "2154384676",
        "2043909051",
        "36244633"
    ]
},{
    "id": "2155099190",
    "title": "The Bayesian image retrieval system, PicHunter: theory, implementation, and psychophysical experiments",
    "abstract": "Presents the theory, design principles, implementation and performance results of PicHunter, a prototype content-based image retrieval (CBIR) system. In addition, this document presents the rationale, design and results of psychophysical experiments that were conducted to address some key issues that arose during PicHunter's development. The PicHunter project makes four primary contributions to research on CBIR. First, PicHunter represents a simple instance of a general Bayesian framework which we describe for using relevance feedback to direct a search. With an explicit model of what users would do, given the target image they want, PicHunter uses Bayes's rule to predict the target they want, given their actions. This is done via a probability distribution over possible image targets, rather than by refining a query. Second, an entropy-minimizing display algorithm is described that attempts to maximize the information obtained from a user at each iteration of the search. Third, PicHunter makes use of hidden annotation rather than a possibly inaccurate/inconsistent annotation structure that the user must learn and make queries in. Finally, PicHunter introduces two experimental paradigms to quantitatively evaluate the performance of the system, and psychophysical experiments are presented that support the theoretical claims.",
    "date": "1999",
    "authors": [
        "I.J. Cox",
        "M.L. Miller",
        "T.P. Minka",
        "T.V. Papathomas",
        "P.N. Yianilos"
    ],
    "related_topics": [
        "Image retrieval",
        "Relevance feedback",
        "User interface"
    ],
    "citation_count": "1,092",
    "reference_count": "76",
    "references": [
        "2143022286",
        "2125148312",
        "2160066518",
        "2573715514",
        "2008297189",
        "1917380066",
        "2138313032",
        "2085989833",
        "1654865708",
        "2134814621"
    ]
},{
    "id": "2099251025",
    "title": "WebSeer: An Image Search Engine for the World Wide Web",
    "abstract": "Because of the size of the World Wide Web and its inherent lack of structure, finding what one is looking for can be a challenge. PC-Meters March, 1996, survey found that three of the five most visited Web sites were search engines. However, while Web pages typically contain both text and images, all the currently available search engines only index text. This paper describes WebSeer, a system for locating images on the Web. WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs.",
    "date": "1996",
    "authors": [
        "Charles Frankel",
        "Michael J Swain",
        "Vassilis Athitsos"
    ],
    "related_topics": [
        "Web page",
        "Web search engine",
        "Web crawler"
    ],
    "citation_count": "407",
    "reference_count": "13",
    "references": [
        "2217896605",
        "2159686933",
        "2160066518",
        "2125713050",
        "2102475035",
        "1986904703",
        "1971281888",
        "2102190518",
        "2110817034",
        "160408233"
    ]
},{
    "id": "2011549082",
    "title": "Content-based image indexing and searching using Daubechies' wavelets",
    "abstract": "This paper describes WBIIS (Wavelet-Based Image Indexing and Searching), a new image indexing and retrieval algorithm with partial sketch image searching capability for large image databases. The algorithm characterizes the color variations over the spatial extent of the image in a manner that provides semantically meaningful image comparisons. The indexing algorithm applies a Daubechies' wavelet transform for each of the three opponent color components. The wavelet coefficients in the lowest few frequency bands, and their variances, are stored as feature vectors. To speed up retrieval, a two-step procedure is used that first does a crude selection based on the variances, and then refines the search by performing a feature vector match between the selected images and the query. For better accuracy in searching, two-level multiresolution matching may also be used. Masks are used for partial-sketch queries. This technique performs much better in capturing coherence of image, object granularity, local color/texture, and bias avoidance than traditional color layout algorithms. WBIIS is much faster and more accurate than traditional algorithms. When tested on a database of more than 10 000 general-purpose images, the best 100 matches were found in 3.3 seconds.",
    "date": "1998",
    "authors": [
        "James Ze Wang",
        "Gio Wiederhold",
        "Oscar Firschein",
        "Sha Xin Wei"
    ],
    "related_topics": [
        "Image texture",
        "Image retrieval",
        "Binary image"
    ],
    "citation_count": "556",
    "reference_count": "17",
    "references": [
        "2062024414",
        "2098914003",
        "2914885528",
        "1489213177",
        "2093191240",
        "2740373864",
        "2021722152",
        "2068272887",
        "2066610120",
        "1606846851"
    ]
},{
    "id": "2117086609",
    "title": "Combining textual and visual cues for content-based image retrieval on the World Wide Web",
    "abstract": "A system is proposed that combines textual and visual statistics in a single index vector for content-based search of a WWW image database. Textual statistics are captured in vector form using latent semantic indexing (LSI) based on text in the containing HTML document. Visual statistics are captured in vector form using color and orientation histograms. By using an integrated approach, it becomes possible to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (visual statistics). The combined approach allows improved performance in conducting content-based search. Search performance experiments are reported for a database containing 100,000 images collected from the WWW.",
    "date": "1998",
    "authors": [
        "M. La Cascia",
        "S. Sethi",
        "S. Sclaroff"
    ],
    "related_topics": [
        "Content-based image retrieval",
        "Image retrieval",
        "Search engine indexing"
    ],
    "citation_count": "417",
    "reference_count": "48",
    "references": [
        "2147152072",
        "2914885528",
        "1956559956",
        "2160066518",
        "2123977795",
        "3017143921",
        "2098947662",
        "1991605728",
        "2008297189",
        "2072773380"
    ]
},{
    "id": "1658679052",
    "title": "Wavelets and filter banks",
    "abstract": "",
    "date": "1995",
    "authors": [
        "Gilbert Strang",
        "Truong Nguyen"
    ],
    "related_topics": [
        "Quadrature mirror filter",
        "Filter design",
        "Capacitor-input filter"
    ],
    "citation_count": "7,903",
    "reference_count": "0",
    "references": []
},{
    "id": "2093191240",
    "title": "QBIC project: querying images by content, using color, texture, and shape",
    "abstract": "In the query by image content (QBIC) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (`Give me other images that contain a tumor with a texture like this one'), photo-journalism (`Give me images that have blue at the top and red at the bottom'), and many others in art, fashion, cataloging, retailing, and industry. Key issues include derivation and computation of attributes of images and objects that provide useful query functionality, retrieval methods based on similarity as opposed to exact match, query by image example or user drawn image, the user interfaces, query refinement and navigation, high dimensional database indexing, and automatic and semi-automatic database population. We currently have a prototype system written in X/Motif and C running on an RS/6000 that allows a variety of queries, and a test database of over 1000 images and 1000 objects populated from commercially available photo clip art images. In this paper we present the main algorithms for color texture, shape and sketch query that we use, show example query results, and discuss future directions.\u00a9 (1993) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.",
    "date": "1993",
    "authors": [
        "Carlton Wayne Niblack",
        "Ron Barber",
        "Will Equitz",
        "Myron D. Flickner",
        "Eduardo H. Glasman",
        "Dragutin Petkovic",
        "Peter Yanker",
        "Christos Faloutsos",
        "Gabriel Taubin"
    ],
    "related_topics": [
        "Query optimization",
        "Query by Example",
        "Query expansion"
    ],
    "citation_count": "3,010",
    "reference_count": "14",
    "references": [
        "3017143921",
        "2151135734",
        "2118269922",
        "2074429597",
        "2149173084",
        "1576247523",
        "2147956424",
        "2061749544",
        "2094078373",
        "2110499305"
    ]
},{
    "id": "2008297189",
    "title": "Photobook: content-based manipulation of image databases",
    "abstract": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These query tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on text annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually-significant coefficients. We discuss three types of Photobook descriptions in detail: one that allows search based on appearance, one that uses 2-D shape, and a third that allows search based on textural properties. These image content descriptions can be combined with each other and with text-based descriptions to provide a sophisticated browsing and search capability. In this paper we demonstrate Photobook on databases containing images of people, video keyframes, hand tools, fish, texture swatches, and 3-D medical data.",
    "date": "1996",
    "authors": [
        "A. Pentland",
        "R. W. Picard",
        "S. Sclaroff"
    ],
    "related_topics": [
        "Image processing",
        "Image conversion",
        "Digital image"
    ],
    "citation_count": "2,016",
    "reference_count": "48",
    "references": [
        "2138451337",
        "2914885528",
        "3017143921",
        "2098947662",
        "2093191240",
        "2740373864",
        "2130259898",
        "1563527684",
        "2144573889",
        "2021751319"
    ]
},{
    "id": "2068272887",
    "title": "Fast multiresolution image querying",
    "abstract": "We present a method for searching in an image database using a query image that is similar to the intended target. The query image may be a hand-drawn sketch or a (potentially low-quality) scan of the image to be retrieved. Our searching algorithm makes use of multiresolution wavelet decompositions of the query and database images. The coefficients of these decompositions are distilled into small \u201csignatures\u201d for each image. We introduce an \u201cimage querying metric\u201d that operates on these signatures. This metric essentially compares how many significant wavelet coefficients the query has in common with potential targets. The metric includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries. The resulting algorithm is simple, requires very little storage overhead for the database of signatures, and is fast enough to be performed on a database of 20,000 images at interactive rates (on standard desktop machines) as a query is sketched. Our experiments with hundreds of queries in databases of 1000 and 20,000 images show dramatic improvement, in both speed and success rate, over using a conventional L1, L2, or color histogram norm. CR",
    "date": "1995",
    "authors": [
        "Charles E. Jacobs",
        "Adam Finkelstein",
        "David H. Salesin"
    ],
    "related_topics": [
        "Image retrieval",
        "Automatic image annotation",
        "Feature detection (computer vision)"
    ],
    "citation_count": "1,231",
    "reference_count": "32",
    "references": [
        "2341283081",
        "1490482062",
        "2086928636",
        "2093191240",
        "1975830550",
        "3141341243",
        "2107790757",
        "2094585768",
        "110443600",
        "2166087152"
    ]
},{
    "id": "2102475035",
    "title": "Chabot: retrieval from a relational database of images",
    "abstract": "Selecting from a large, expanding collection of images requires carefully chosen search criteria. We present an approach that integrates a relational database retrieval system with a color analysis technique. The Chabot project was initiated at our university to study storage and retrieval of a vast collection of digitized images. These images are from the State of California Department of Water Resources. The goal was to integrate a relational database retrieval system with content analysis techniques that would give our querying system a better method for handling images. Our simple color analysis method, if used in conjunction with other search criteria, improves our ability to retrieve images efficiently. The best result is obtained when text-based search criteria are combined with content-based criteria and when a coarse granularity is used for content analysis. >",
    "date": "1995",
    "authors": [
        "V.E. Ogle",
        "M. Stonebraker"
    ],
    "related_topics": [
        "Image retrieval",
        "Relational database",
        "Search engine indexing"
    ],
    "citation_count": "1,023",
    "reference_count": "11",
    "references": [
        "2134342348",
        "2093191240",
        "2118269922",
        "2008297189",
        "1975830550",
        "1570542661",
        "1969294188",
        "2138313032",
        "2162064942",
        "1986831546"
    ]
},{
    "id": "1530454533",
    "title": "Geometric invariance in computer vision",
    "abstract": "Part 1 Foundations: algebraic invariants - invariant theory and enumerative combinatorics of young tableaux, Shreeram S. Abhyankar, geometric interpretation of joint conic invariants, Joseph L. Mundy, et al, an experimental evaluation of projective invariants, Christopher Coelho, et al the projection of two non-coplanar conics, Stephen J. Maybank the non-existence of general-case view-invariants, J. Brian Burns, et al invariants of non-algebraic curves - noise resistant invariants of curves, Isaac Weiss, semi-differential invariants, Luc J. Van Gool, et al, projective invariants for curves in two and three dimensions, Michael H. Brill, et al, numerical evaluation of differential and semi-differential invariants, Christopher Brown, recognizing general curved objects efficiently, Andrew Zisserman, et al fitting affine invariant conics to curves, Deepak Kapur and Joseph L. Mundy, projectively invariant decomposition of planar shapes, Stefan Carlsson invariants from multiple views - invariant linear methods in photogrammetry and model-matching, Eamon B. Barrett, et al semi-differential invariants for nonplanar curves, Luc J. Van Gool, et al disambiguating stereo matches with spatio-temporal surfaces, Olivier Faugeras and Theo Papadopoulo. Part 2 Applications: transformation invariant indexing, Haim J. Wolfson and Yehezkel Lamdan affine invariants for model-based recognition, John E. Hopcroft, et al object recognition based on moment (or algebraic) invariants, Gabriel Taubin and David B. Cooper fast recognition using algebraic invariants, Charles A. Rothwell, et al toward 3D curved object recognition from image contours, Jean Ponce and David J. Kriegman relative positioning with uncalibrated cameras, Roger Mohr, et al. Appendix: projective geometry for machine vision, Joseph L. Mundy and Andrew Zisserman.",
    "date": "1992",
    "authors": [
        "Joseph L. Mundy",
        "Andrew Zisserman"
    ],
    "related_topics": [
        "Invariant theory",
        "Invariant (mathematics)",
        "Projective geometry"
    ],
    "citation_count": "1,378",
    "reference_count": "0",
    "references": []
},{
    "id": "2037732452",
    "title": "Symbolic reasoning among 3-D models and 2-D images",
    "abstract": "We describe model-based vision systems in terms of four components: models, prediction of image features, description of image features, and interpretation which relates image features to models. We describe details of modelling, prediction and interpretation in an implemented model-based vision system. Both generic object classes and specific objects are represented by volume models which are independent of viewpoint. We model complex real world object classes. Variations of size, structure and spatial relations within object classes can be modelled. New spatial reasoning techniques are described which are useful both for prediction within a vision system, and for planning within a manipulation system. We introduce new approaches to prediction and interpretation based on the propagation of symbolic constraints. Predictions are two pronged. First, prediction graphs provide a coarse filter for hypothesizing matches of objects to image feature. Second, they contain instructions on how to use measurements of image features to deduce three dimensional information about tentative object interpretations. Interpretation proceeds by merging local hypothesized matches, subject to consistent derived implications about the size, structure and spatial configuration of the hypothesized objects. Prediction, description and interpretation proceed concurrently from coarse object subpart and class interpretations of images, to fine distinctions among object subclasses and more precise three dimensional quantification of objects. We distinguish our implementations from the fundamental geometric operations required by our general image understanding scheme. We suggest directions for future research for improved algorithms and representations.",
    "date": "1980",
    "authors": [
        "Rodney Allen Brooks"
    ],
    "related_topics": [
        "Spatial relation",
        "Feature (computer vision)",
        "Object (computer science)"
    ],
    "citation_count": "1,336",
    "reference_count": "37",
    "references": [
        "2003370853",
        "2163178194",
        "2081519360",
        "2095364258",
        "2157368609",
        "1488252886",
        "2038118137",
        "1597474747",
        "39428922",
        "2095989672"
    ]
},{
    "id": "2069266228",
    "title": "Preattentive processing in vision",
    "abstract": "Visual analysis appears to be functionally divided between an early preattentive level of processing at which simple features are coded spatially in parallel and a later stage at which focused attention is required to conjoin the separate features into coherent objects. Evidence supporting this dichotomy comes from behavioral studies of visual search, from differences in the ease of texture segregation, from reports of illusory conjunctions when attention is overloaded, from subjects' ability to identify simple features correctly even when they mislocate them, and from the substantial benefit of pre-cuing the location of a relevant item when the task requires that features be conjoined but not when simple features are sufficient. Some further studies of search have revealed a striking asymmetry between several pairs of stimuli which differ in the presence or absence of a single part or property. The asymmetry depends solely on which of the pair is allocated the role of target and which is replicated to form the background items. It suggests that search for the presence of a visual primitive is automatic and parallel, whereas search for the absence of the same feature is serial and requires focused attention. The search asymmetry can be used as an additional diagnostic to help define the functional features extracted by the visual system.",
    "date": "1985",
    "authors": [
        "Anne Treisman"
    ],
    "related_topics": [
        "Visual search",
        "Illusory conjunctions",
        "Feature (computer vision)"
    ],
    "citation_count": "1,250",
    "reference_count": "18",
    "references": [
        "2149095485",
        "1597739853",
        "2117731089",
        "3021628422",
        "2077763860",
        "2064258335",
        "2093385392",
        "39428922",
        "1984512236",
        "2020459435"
    ]
},{
    "id": "2081687495",
    "title": "A Simple Rule-Based Part of Speech Tagger",
    "abstract": "Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods. In this paper, we present a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers. The rule-based tagger has many advantages over these taggers, including: a vast reduction in stored information required, the perspicuity of a small set of meaningful rules, ease of finding and implementing improvements to the tagger, and better portability from one tag set, corpus genre or language to another. Perhaps the biggest contribution of this work is in demonstrating that the stochastic method is not the only viable method for part of speech tagging. The fact that a simple rule-based tagger that automatically learns its rules can perform so well should offer encouragement for researchers to further explore rule-based tagging, searching for a better and more expressive set of rule templates and other variations on the simple but effective theme described below.",
    "date": "1992",
    "authors": [
        "Eric Brill"
    ],
    "related_topics": [
        "Brill tagger",
        "Trigram tagger",
        "Rule-based system"
    ],
    "citation_count": "2,239",
    "reference_count": "12",
    "references": [
        "2099247782",
        "2046224275",
        "1483126227",
        "2017580301",
        "2334801970",
        "1571096757",
        "2121407024",
        "2076526090",
        "2055528812",
        "1525757074"
    ]
},{
    "id": "2166447979",
    "title": "Analysis of user need in image archives",
    "abstract": "This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images.The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems.",
    "date": "1997",
    "authors": [
        "Linda H. Armitage",
        "Peter G.B. Enser"
    ],
    "related_topics": [
        "User interface",
        "Schema (psychology)",
        "World Wide Web"
    ],
    "citation_count": "337",
    "reference_count": "13",
    "references": [
        "2004690028",
        "1994609618",
        "2026842155",
        "2142468277",
        "2047772672",
        "2063319376",
        "2154045501",
        "584416852",
        "1556535778",
        "1767743992"
    ]
},{
    "id": "2004690028",
    "title": "PROGRESS IN DOCUMENTATION PICTORIAL INFORMATION RETRIEVAL",
    "abstract": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial. The paper is contextualised by the notion of a visually stimulated society, in which the ease of record creation and transmission in the visual medium is contrasted with the difficulty of gaining effective subject access to the world's stores of such records. The technological developments which, in casting the visual image in electronic form, have contributed so significantly to its availability are reviewed briefly, as a prelude to the main thrust of the paper. Concentrating on still and moving pictorial forms of the visual image, the paper dwells on issues related to the subject indexing of pictorial material and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need.",
    "date": "1995",
    "authors": [
        "Peter G. B. Enser"
    ],
    "related_topics": [
        "Cognitive models of information retrieval",
        "Information needs",
        "Subject indexing"
    ],
    "citation_count": "299",
    "reference_count": "79",
    "references": [
        "1708874574",
        "2022178031",
        "2157592119",
        "2032771350",
        "2026842155",
        "2142468277",
        "2068874033",
        "1494823886",
        "2066771327",
        "1529962656"
    ]
},{
    "id": "1972812142",
    "title": "Multimodal browsing of images in Web documents",
    "abstract": "In this paper, we describe a system for performing browsing and retrieval on a collection of web images and associated text on an HTML page. Browsing is combined with retrieval to help a user locate interesting portions of the corpus, without the need to formulate a query well matched to the corpus. Multi-modal information, in the form of text surrounding an image and some simple image features, is used in this process. Using the system, a user progressively narrows a collection to a small number of elements of interest, similar to the Scatter/Gather system developed for text browsing. We have extended the Scatter/Gather method to use multi-modal features. With the use of multiple features, some collection elements may have unknown or undefined values for some features; we present a method for incorporating these elements into the result set. This method also provides a way to handle the case when a search is narrowed to a part of the space near a boundary between two clusters. A number of examples illustrating our system are provided.",
    "date": "1999",
    "authors": [
        "Francine R. Chen",
        "Ullas Gargi",
        "Les Niles",
        "Hinrich Schuetze"
    ],
    "related_topics": [
        "Image retrieval",
        "Result set",
        "Feature (computer vision)"
    ],
    "citation_count": "29",
    "reference_count": "0",
    "references": []
},{
    "id": "1504061712",
    "title": "Computer Vision Tools for Finding Images and Video Sequences",
    "abstract": "Very large collections of images are now common. Indexing and searching such collections using indexing languages is difficult. Computer vision offers a variety of techniques for searching for pictures in large collections. Appearance methods compare images based on the overall content of the image using such criteria as similarity of color histograms, texture histograms, spatial layout, and filtered representations. Finding methods concentrate on matching subparts of images, defined in a variety of ways, in the hope of finding particular objects. These ideas are illustrated with a variety of examples from the current literature.",
    "date": "1999",
    "authors": [
        "David Alexander Forsyth"
    ],
    "related_topics": [
        "Search engine indexing",
        "Information retrieval",
        "Computer vision"
    ],
    "citation_count": "13",
    "reference_count": "41",
    "references": [
        "2217896605",
        "2914885528",
        "2160066518",
        "2091503252",
        "2008297189",
        "2125101937",
        "1524408959",
        "2125713050",
        "1587328194",
        "2154376992"
    ]
},{
    "id": "2006119904",
    "title": "Automatic resource compilation by analyzing hyperlink structure and associated text",
    "abstract": "We describe the design, prototyping and evaluation of ARC, a system for automatically compiling a list of authoritative Web resources on any (sufficiently broad) topic. The goal of ARC is to compile resource lists similar to those provided by Yahoo! or Infoseek. The fundamental difference is that these services construct lists either manually or through a combination of human and automated effort, while ARC operates fully automatically. We describe the evaluation of ARC, Yahoo!, and Infoseek resource lists by a panel of human users. This evaluation suggests that the resources found by ARC frequently fare almost as well as, and sometimes better than, lists of resources that are manually compiled or classified into a topic. We also provide examples of ARC resource lists for the reader to examine.",
    "date": "1998",
    "authors": [
        "Soumen Chakrabarti",
        "Byron Dom",
        "Prabhakar Raghavan",
        "Sridhar Rajagopalan",
        "David Gibson",
        "Jon Kleinberg"
    ],
    "related_topics": [
        "HITS algorithm",
        "Web resource",
        "Hyperlink"
    ],
    "citation_count": "1,133",
    "reference_count": "11",
    "references": [
        "3013264884",
        "2138621811",
        "2798909945",
        "2037498077",
        "2145311040",
        "2095150974",
        "2051804774",
        "2028406909",
        "2059275719",
        "2041333730"
    ]
},{
    "id": "2079672501",
    "title": "Improved algorithms for topic distillation in a hyperlinked environment",
    "abstract": "This paper addresses the problem of topic distillation on the World Wide Web, namely, given a typical user query to find quality documents related to the query topic. Connectivity analysis has been shown to be useful in identifying high quality pages within a topic specific graph of hyperlinked documents. The essence of our approach is to augment a previous connectivity analysis based algorithm with content analysis. We identify three problems with the existing approach and devise algorithms to tackle them. The results of a user evaluation are reported that show an improvement of precision at 10 documents by at least 45% over pure connectivity analysis.",
    "date": "1998",
    "authors": [
        "Krishna Bharat",
        "Monika R. Henzinger"
    ],
    "related_topics": [
        "HITS algorithm",
        "Query language",
        "Link farm"
    ],
    "citation_count": "1,291",
    "reference_count": "23",
    "references": [
        "2138621811",
        "2798909945",
        "2098162425",
        "1978394996",
        "2006119904",
        "1996764654",
        "2037498077",
        "2105276905",
        "1976232673",
        "2082751088"
    ]
},{
    "id": "1987777228",
    "title": "Finding related pages in the World Wide Web",
    "abstract": "When using traditional search engines, users have to formulate queries to describe their information need. This paper discusses a different approach to Web searching where the input to the search process is not a set of query terms, but instead is the URL of a page, and the output is a set of related Web pages. A related Web page is one that addresses the same topic as the original page. For example, www.washingtonpost.com is a page related to www.nytimes.com, since both are online newspapers. We describe two algorithms to identify related Web pages. These algorithms use only the connectivity information in the Web (i.e., the links between pages) and not the content of pages or usage information. We have implemented both algorithms and measured their runtime performance. To evaluate the effectiveness of our algorithms, we performed a user study comparing our algorithms with Netscape\u2019s \u2018What\u2019s Related\u2019 service ( http://home. netscape.com/escapes/related/). Our study showed that the precision at 10 for our two algorithms are 73% better and 51% better than that of Netscape, despite the fact that Netscape uses both content and usage pattern information in addition to connectivity information. \u00a9 1999 Published by Elsevier Science B.V. All rights reserved.",
    "date": "1999",
    "authors": [
        "Jeffrey Dean",
        "Monika R. Henzinger"
    ],
    "related_topics": [
        "Static web page",
        "Web page",
        "Web search engine"
    ],
    "citation_count": "827",
    "reference_count": "19",
    "references": [
        "3013264884",
        "2138621811",
        "2124591829",
        "2006119904",
        "2079672501",
        "2037498077",
        "2076008912",
        "2145311040",
        "1976232673",
        "2028406909"
    ]
},{
    "id": "2089199911",
    "title": "The stochastic approach for link-structure analysis (SALSA) and the TKC effect",
    "abstract": "Abstract Today, when searching for information on the World Wide Web, one usually performs a query through a term-based search engine. These engines return, as the query's result, a list of Web sites whose contents match the query. For broad topic queries, such searches often result in a huge set of retrieved documents, many of which are irrelevant to the user. However, much information is contained in the link-structure of the World Wide Web. Information such as which pages are linked to others can be used to augment search algorithms. In this context, Jon Kleinberg introduced the notion of two distinct types of Web sites: hubs and authorities . Kleinberg argued that hubs and authorities exhibit a mutually reinforcing relationship : a good hub will point to many authorities, and a good authority will be pointed at by many hubs. In light of this, he devised an algorithm aimed at finding authoritative sites. We present SALSA, a new stochastic approach for link structure analysis, which examines random walks on graphs derived from the link structure. We show that both SALSA and Kleinberg's mutual reinforcement approach employ the same meta-algorithm. We then prove that SALSA is equivalent to a weighted in-degree analysis of the link-structure of World Wide Web subgraphs, making it computationally more efficient than the mutual reinforcement approach. We compare the results of applying SALSA to the results derived through Kleinberg's approach. These comparisons reveal a topological phenomenon called the TKC effect (Tightly Knit Community) which, in certain cases, prevents the mutual reinforcement approach from identifying meaningful authorities.",
    "date": "2000",
    "authors": [
        "R. Lempel",
        "S. Moran"
    ],
    "related_topics": [
        "HITS algorithm",
        "Search algorithm",
        "Context (language use)"
    ],
    "citation_count": "741",
    "reference_count": "17",
    "references": [
        "3013264884",
        "2138621811",
        "2006119904",
        "2079672501",
        "2063392856",
        "2037498077",
        "2020423193",
        "2129620481",
        "2054119298",
        "2095150974"
    ]
},{
    "id": "2140350208",
    "title": "What is this page known for? Computing Web page reputations",
    "abstract": "Abstract The textual content of the Web enriched with the hyperlink structure surrounding it can be a useful source of information for querying and searching. This paper presents a search process where the input is the URL of a page, and the output is a ranked set of topics on which the page has a reputation. For example, if the input is www.gamelan.com, then a possible output is `Java'. We propose several algorithmic formulations of the notion of reputation using simple random walk models of Web-browsing behavior. We give preliminary test results on the effectiveness of these algorithms.",
    "date": "2000",
    "authors": [
        "Davood Rafiei",
        "Alberto O. Mendelzon"
    ],
    "related_topics": [
        "Web page",
        "HITS algorithm",
        "Hyperlink"
    ],
    "citation_count": "184",
    "reference_count": "11",
    "references": [
        "3013264884",
        "2138621811",
        "2079672501",
        "2151626491",
        "2076008912",
        "2020423193",
        "2072881690",
        "2134122907",
        "755194005",
        "2043200638"
    ]
},{
    "id": "2139212933",
    "title": "A Tutorial on Support Vector Machines for Pattern Recognition",
    "abstract": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.",
    "date": "1998",
    "authors": [
        "Christopher J. C. Burges"
    ],
    "related_topics": [
        "Margin classifier",
        "Least squares support vector machine",
        "Relevance vector machine"
    ],
    "citation_count": "30,110",
    "reference_count": "54",
    "references": [
        "2156909104",
        "2148603752",
        "1554663460",
        "2119821739",
        "2610857016",
        "2140095548",
        "2981264952",
        "2087347434",
        "2432517183",
        "740415"
    ]
},{
    "id": "2981264952",
    "title": "Numerical recipes in Pascal : the art of scientific computing",
    "abstract": "",
    "date": "1988",
    "authors": [
        "William Henry Press",
        "Brian P Flannery",
        "Saul Arno Teukolsky"
    ],
    "related_topics": [
        "Pascal (programming language)",
        "Computer science",
        "Programming language"
    ],
    "citation_count": "12,424",
    "reference_count": "0",
    "references": []
},{
    "id": "2042371054",
    "title": "Multiresolution sampling procedure for analysis and synthesis of texture images",
    "abstract": "This paper outlines a technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled. In a two-phase process, the input texture is first analyzed by measuring the joint occurrence of texture discrimination features at multiple resolutions. In the second phase, a new texture is synthesized by sampling successive spatial frequency bands from the input texture, conditioned on the similar joint occurrence of features at lower spatial frequencies. Textures synthesized with this method more successfully capture the characteristics of input textures than do previous techniques.",
    "date": "1997",
    "authors": [
        "Jeremy S. De Bonet"
    ],
    "related_topics": [
        "Texture synthesis",
        "Texture (geology)",
        "Sampling (statistics)"
    ],
    "citation_count": "908",
    "reference_count": "17",
    "references": [
        "2103504761",
        "1490632837",
        "2150920547",
        "2162703509",
        "2113834765",
        "2120420595",
        "2998496342",
        "2019299491",
        "179221956",
        "164346725"
    ]
},{
    "id": "2156273867",
    "title": "Bayesian inference in statistical analysis",
    "abstract": "Nature of Bayesian Inference Standard Normal Theory Inference Problems Bayesian Assessment of Assumptions: Effect of Non-Normality on Inferences About a Population Mean with Generalizations Bayesian Assessment of Assumptions: Comparison of Variances Random Effect Models Analysis of Cross Classification Designs Inference About Means with Information from More than One Source: One-Way Classification and Block Designs Some Aspects of Multivariate Analysis Estimation of Common Regression Coefficients Transformation of Data Tables References Indexes.",
    "date": "1973",
    "authors": [
        "George E. P. Box",
        "George C. Tiao"
    ],
    "related_topics": [
        "Frequentist inference",
        "Robust Bayesian analysis",
        "Bayesian statistics"
    ],
    "citation_count": "7,993",
    "reference_count": "0",
    "references": []
},{
    "id": "2126163471",
    "title": "Theory of probability",
    "abstract": "1. Fundamental notions 2. Direct probabilities 3. Estimation problems 4. Approximate methods and simplifications 5. Significance tests: one new parameter 6. Significance tests: various complications 7. Frequency definitions and direct methods 8. General questions",
    "date": "1938",
    "authors": [
        "Harold Jeffreys",
        "R. Bruce Lindsay"
    ],
    "related_topics": [
        "Imprecise probability",
        "Probability interpretations",
        "Direct methods"
    ],
    "citation_count": "11,560",
    "reference_count": "0",
    "references": []
},{
    "id": "1533179050",
    "title": "Statistical Methods for Research Workers",
    "abstract": "The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.",
    "date": "1924",
    "authors": [
        "Rory A. Fisher"
    ],
    "related_topics": [
        "Statistical hypothesis testing",
        "Data science",
        "Prime (order theory)"
    ],
    "citation_count": "19,278",
    "reference_count": "0",
    "references": []
},{
    "id": "2108207895",
    "title": "Understanding the Metropolis-Hastings Algorithm",
    "abstract": "Abstract We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.",
    "date": "1995",
    "authors": [
        "Siddhartha Chib",
        "Edward Greenberg"
    ],
    "related_topics": [
        "Gibbs sampling",
        "Metropolis\u2013Hastings algorithm",
        "Markov chain Monte Carlo"
    ],
    "citation_count": "5,264",
    "reference_count": "24",
    "references": [
        "2148534890",
        "2083875149",
        "1995713768",
        "2136796925",
        "2114001875",
        "2163738067",
        "2056099894",
        "2017899835",
        "2152977846",
        "2313953460"
    ]
},{
    "id": "1560013842",
    "title": "Fundamentals of speech recognition",
    "abstract": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition.",
    "date": "1992",
    "authors": [
        "Lawrence Rabiner",
        "Biing-Hwang Juang"
    ],
    "related_topics": [
        "Speech processing",
        "Audio-visual speech recognition",
        "Voice activity detection"
    ],
    "citation_count": "13,510",
    "reference_count": "0",
    "references": []
},{
    "id": "301824129",
    "title": "Introduction to Algorithms, 2nd edition.",
    "abstract": "",
    "date": "2000",
    "authors": [
        "TH Cormen",
        "CE Leiserson",
        "RL Rivest",
        "C Stein"
    ],
    "related_topics": [
        "Computer science",
        "Theoretical computer science"
    ],
    "citation_count": "6,742",
    "reference_count": "0",
    "references": []
},{
    "id": "2009570821",
    "title": "Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids",
    "abstract": "Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it is accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time presents the state of the art in this new and important field.",
    "date": "1998",
    "authors": [
        "Richard Durbin",
        "Sean Eddy",
        "Anders St\u00e6rmose Krogh",
        "Graeme Mitchison"
    ],
    "related_topics": [
        "Probabilistic logic",
        "Probabilistic method",
        "Hidden Markov model"
    ],
    "citation_count": "7,672",
    "reference_count": "0",
    "references": []
},{
    "id": "2101309634",
    "title": "What energy functions can be minimized via graph cuts",
    "abstract": "In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.",
    "date": "2003",
    "authors": [
        "V. Kolmogorov",
        "R. Zabin"
    ],
    "related_topics": [
        "Graph cuts in computer vision",
        "Null graph",
        "Graph property"
    ],
    "citation_count": "4,633",
    "reference_count": "45",
    "references": [
        "2104974755",
        "2143516773",
        "2169551590",
        "1997063559",
        "1977545325",
        "2113137767",
        "2077786999",
        "2121781154",
        "1781337833",
        "1649464328"
    ]
},{
    "id": "2134820502",
    "title": "Geodesic active contours",
    "abstract": "A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric as defined by the image content. This geodesic approach for object segmentation allows to connect classical \"snakes\" based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. >",
    "date": "1995",
    "authors": [
        "V. Caselles",
        "R. Kimmel",
        "G. Sapiro"
    ],
    "related_topics": [
        "Active contour model",
        "Geodesic",
        "Image segmentation"
    ],
    "citation_count": "5,253",
    "reference_count": "50",
    "references": [
        "2104095591",
        "1991113069",
        "2149184914",
        "2032316144",
        "1991605728",
        "2146052399",
        "2086921140",
        "2913192828",
        "2144133758",
        "1977946246"
    ]
},{
    "id": "2077786999",
    "title": "Graphcut textures: image and video synthesis using graph cuts",
    "abstract": "In this paper we introduce a new algorithm for image and video texture synthesis. In our approach, patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output. In contrast to other techniques, the size of the patch is not chosen a-priori, but instead a graph cut technique is used to determine the optimal patch region for any given offset between the input and output texture. Unlike dynamic programming, our graph cut technique for seam optimization is applicable in any dimension. We specifically explore it in 2D and 3D to perform video texture synthesis in addition to regular image synthesis. We present approximative offset search techniques that work well in conjunction with the presented patch size optimization. We show results for synthesizing regular, random, and natural images and videos. We also demonstrate how this method can be used to interactively merge different images to generate new scenes.",
    "date": "2003",
    "authors": [
        "Vivek Kwatra",
        "Arno Sch\u00f6dl",
        "Irfan Essa",
        "Greg Turk",
        "Aaron Bobick"
    ],
    "related_topics": [
        "Texture synthesis",
        "Cut",
        "Computer vision"
    ],
    "citation_count": "2,011",
    "reference_count": "28",
    "references": [
        "2143516773",
        "2116013899",
        "1999360130",
        "2127006916",
        "2232702494",
        "2042371054",
        "1490632837",
        "2068623560",
        "2083518538",
        "2295660824"
    ]
},{
    "id": "2103917701",
    "title": "A Bayesian approach to digital matting",
    "abstract": "This paper proposes a new Bayesian framework for solving the matting problem, i.e. extracting a foreground element from a background image by estimating an opacity for each pixel of the foreground element. Our approach models both the foreground and background color distributions with spatially-varying sets of Gaussians, and assumes a fractional blending of the foreground and background colors to produce the final output. It then uses a maximum-likelihood criterion to estimate the optimal opacity, foreground and background simultaneously. In addition to providing a principled approach to the matting problem, our algorithm effectively handles objects with intricate boundaries, such as hair strands and fur, and provides an improvement over existing techniques for these difficult cases.",
    "date": "2001",
    "authors": [
        "Yung-Yu Chuang",
        "B. Curless",
        "D.H. Salesin",
        "R. Szeliski"
    ],
    "related_topics": [
        "Pixel",
        "Feature extraction",
        "Bayesian probability"
    ],
    "citation_count": "1,127",
    "reference_count": "10",
    "references": [
        "2069281566",
        "2103334940",
        "1978508694",
        "2177745862",
        "2168495030",
        "1761458024",
        "2145382867",
        "2134301959",
        "2728280651",
        "2051412854"
    ]
},{
    "id": "2103334940",
    "title": "Alpha estimation in natural images",
    "abstract": "Many boundaries between objects in the world project onto curves in an image. However, boundaries involving natural objects (e.g., trees, hair, water, smoke) are often unworkable under this model because many pixels receive light from more than one object. We propose a technique for estimating alpha, the proportion in which two colors mix to produce a color at the boundary. The technique extends blue screen matting to backgrounds that have almost arbitrary color distributions, though coarse knowledge of the boundary's location is required. Results show a number of different objects moved from one image to another while maintaining naturalism.",
    "date": "2000",
    "authors": [
        "M.A. Ruzon",
        "C. Tomasi"
    ],
    "related_topics": [
        "Color quantization",
        "Color image",
        "High color"
    ],
    "citation_count": "515",
    "reference_count": "8",
    "references": [
        "1490482062",
        "1987983010",
        "1978508694",
        "1966798775",
        "2168495030",
        "2051826135",
        "2145382867",
        "2137554464"
    ]
},{
    "id": "1785730614",
    "title": "Interactive Image Segmentation Using an Adaptive GMMRF Model",
    "abstract": "The problem of interactive foreground/background segmentation in still images is of great practical importance in image editing. The state of the art in interactive segmentation is probably represented by the graph cut algorithm of Boykov and Jolly (ICCV 2001). Its underlying model uses both colour and contrast information, together with a strong prior for region coherence. Estimation is performed by solving a graph cut problem for which very efficient algorithms have recently been developed. However the model depends on parameters which must be set by hand and the aim of this work is for those constants to be learned from image data.",
    "date": "2004",
    "authors": [
        "Andrew Blake",
        "Carsten Rother",
        "Matthew A. Brown",
        "Patrick P\u00e9rez",
        "Philip H. S. Torr"
    ],
    "related_topics": [
        "Image segmentation",
        "Segmentation-based object categorization",
        "Scale-space segmentation"
    ],
    "citation_count": "789",
    "reference_count": "11",
    "references": [
        "2169551590",
        "1997063559",
        "2101309634",
        "2103917701",
        "2141376824",
        "2103334940",
        "1554544485",
        "2124189704",
        "79315950",
        "186419298"
    ]
},{
    "id": "1540007258",
    "title": "Soft Margins for AdaBoost",
    "abstract": "Recently ensemble methods like ADABOOST have been applied successfully in many problems, while seemingly defying the problems of overfitting. ADABOOST rarely overfits in the low noise regime, however, we show that it clearly does so for higher noise levels. Central to the understanding of this fact is the margin distribution. ADABOOST can be viewed as a constraint gradient descent in an error function with respect to the margin. We find that ADABOOST asymptotically achieves a hard margin distribution, i.e. the algorithm concentrates its resources on a few hard-to-learn patterns that are interestingly very similar to Support Vectors. A hard margin is clearly a sub-optimal strategy in the noisy case, and regularization, in our case a \u201cmistrust\u201d in the data, must be introduced in the algorithm to alleviate the distortions that single difficult patterns (e.g. outliers) can cause to the margin distribution. We propose several regularization methods and generalizations of the original ADABOOST algorithm to achieve a soft margin. In particular we suggest (1) regularized ADABOOSTREG where the gradient decent is done directly with respect to the soft margin and (2) regularized linear and quadratic programming (LP/QP-) ADABOOST, where the soft margin is attained by introducing slack variables. Extensive simulations demonstrate that the proposed regularized ADABOOST-type algorithms are useful and yield competitive results for noisy data.",
    "date": "2001",
    "authors": [
        "G. R\u00e4tsch",
        "T. Onoda",
        "K.-R. M\u00fcller"
    ],
    "related_topics": [
        "AdaBoost",
        "Margin (machine learning)",
        "BrownBoost"
    ],
    "citation_count": "1,540",
    "reference_count": "42",
    "references": [
        "2156909104",
        "2170120409",
        "1554663460",
        "2119821739",
        "3124955340",
        "2912934387",
        "2125055259",
        "3023786531",
        "2024046085",
        "2087347434"
    ]
},{
    "id": "1881647329",
    "title": "The Alternating Decision Tree Learning Algorithm",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Yoav Freund",
        "Llew Mason"
    ],
    "related_topics": [
        "Incremental decision tree",
        "ID3 algorithm",
        "Decision stump"
    ],
    "citation_count": "1,055",
    "reference_count": "0",
    "references": []
},{
    "id": "2141518341",
    "title": "Boosting First-Order Learning",
    "abstract": "Several empirical studies have confirmed that boosting classifier-learning systems can lead to substantial improvements in predictive accuracy. This paper reports early experimental results from applying boosting to ffoil, a first-order system that constructs definitions of functional relations. Although the evidence is less convincing than that for propositional-level learning systems, it suggests that boosting will also prove beneficial for first-order induction.",
    "date": "1996",
    "authors": [
        "J. Ross Quinlan"
    ],
    "related_topics": [
        "Boosting (machine learning)",
        "Unsupervised learning",
        "Inductive logic programming"
    ],
    "citation_count": "157",
    "reference_count": "15",
    "references": [
        "3124955340",
        "2912934387",
        "2125055259",
        "1999138184",
        "2119831128",
        "1565236324",
        "2037689320",
        "1996824494",
        "2134980541",
        "1537900672"
    ]
},{
    "id": "1481646516",
    "title": "Multirate Systems and Filter Banks",
    "abstract": "1. Introduction 2. Review of Discrete-Time Systems 3. Review of Digital Filters 4. Fundamentals of Multirate Systems 5. Maximally Decimated Filter Banks 6. Paraunitary Perfect Reconstruction Filter Banks 7. Linear Phase Perfect Reconstruction QMF Banks 8. Cosine Modulated Filter Banks 9. Finite Word Length Effects 10. Multirate Filter Bank Theory and Related Topics 11. The Wavelet Transform and Relation to Multirate Filter Banks 12. Multidimensional Multirate Systems 13. Review of Discrete-Time Multi-Input Multi-Output LTI Systems 14. Paraunitary and Lossless Systems Appendices Bibliography Index",
    "date": "1992",
    "authors": [
        "P. P. Vaidyanathan"
    ],
    "related_topics": [
        "Filter bank",
        "Filter design",
        "Quadrature mirror filter"
    ],
    "citation_count": "7,131",
    "reference_count": "0",
    "references": []
},{
    "id": "3009912996",
    "title": "SARS-CoV-2 Cell Entry Depends on ACE2 and TMPRSS2 and Is Blocked by a Clinically Proven Protease Inhibitor",
    "abstract": "The recent emergence of the novel, pathogenic SARS-coronavirus 2 (SARS-CoV-2) in China and its rapid national and international spread pose a global health emergency. Cell entry of coronaviruses depends on binding of the viral spike (S) proteins to cellular receptors and on S protein priming by host cell proteases. Unravelling which cellular factors are used by SARS-CoV-2 for entry might provide insights into viral transmission and reveal therapeutic targets. Here, we demonstrate that SARS-CoV-2 uses the SARS-CoV receptor ACE2 for entry and the serine protease TMPRSS2 for S protein priming. A TMPRSS2 inhibitor approved for clinical use blocked entry and might constitute a treatment option. Finally, we show that the sera from convalescent SARS patients cross-neutralized SARS-2-S-driven entry. Our results reveal important commonalities between SARS-CoV-2 and SARS-CoV infection and identify a potential target for antiviral intervention.",
    "date": "2020",
    "authors": [
        "Markus Hoffmann",
        "Hannah Kleine-Weber",
        "Simon Schroeder",
        "Nadine Kr\u00fcger",
        "Tanja Herrler",
        "Sandra Erichsen",
        "Tobias S. Schiergens",
        "Georg Herrler",
        "Nai Huei Wu",
        "Andreas Nitsche",
        "Marcel A. M\u00fcller",
        "Christian Drosten",
        "Stefan P\u00f6hlmann"
    ],
    "related_topics": [
        "Proteases",
        "Coronavirus",
        "Transmembrane Protease Serine 2"
    ],
    "citation_count": "8,695",
    "reference_count": "66",
    "references": [
        "3001118548",
        "3001897055",
        "3002539152",
        "3004280078",
        "3001195213",
        "3001465255",
        "2799524357",
        "3002533507",
        "2470646526",
        "1993577573"
    ]
},{
    "id": "3016535995",
    "title": "Presenting Characteristics, Comorbidities, and Outcomes Among 5700 Patients Hospitalized With COVID-19 in the New York City Area.",
    "abstract": "Importance There is limited information describing the presenting characteristics and outcomes of US patients requiring hospitalization for coronavirus disease 2019 (COVID-19). Objective To describe the clinical characteristics and outcomes of patients with COVID-19 hospitalized in a US health care system. Design, Setting, and Participants Case series of patients with COVID-19 admitted to 12 hospitals in New York City, Long Island, and Westchester County, New York, within the Northwell Health system. The study included all sequentially hospitalized patients between March 1, 2020, and April 4, 2020, inclusive of these dates. Exposures Confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection by positive result on polymerase chain reaction testing of a nasopharyngeal sample among patients requiring admission. Main Outcomes and Measures Clinical outcomes during hospitalization, such as invasive mechanical ventilation, kidney replacement therapy, and death. Demographics, baseline comorbidities, presenting vital signs, and test results were also collected. Results A total of 5700 patients were included (median age, 63 years [interquartile range {IQR}, 52-75; range, 0-107 years]; 39.7% female). The most common comorbidities were hypertension (3026; 56.6%), obesity (1737; 41.7%), and diabetes (1808; 33.8%). At triage, 30.7% of patients were febrile, 17.3% had a respiratory rate greater than 24 breaths/min, and 27.8% received supplemental oxygen. The rate of respiratory virus co-infection was 2.1%. Outcomes were assessed for 2634 patients who were discharged or had died at the study end point. During hospitalization, 373 patients (14.2%) (median age, 68 years [IQR, 56-78]; 33.5% female) were treated in the intensive care unit care, 320 (12.2%) received invasive mechanical ventilation, 81 (3.2%) were treated with kidney replacement therapy, and 553 (21%) died. As of April 4, 2020, for patients requiring mechanical ventilation (n\u2009=\u20091151, 20.2%), 38 (3.3%) were discharged alive, 282 (24.5%) died, and 831 (72.2%) remained in hospital. The median postdischarge follow-up time was 4.4 days (IQR, 2.2-9.3). A total of 45 patients (2.2%) were readmitted during the study period. The median time to readmission was 3 days (IQR, 1.0-4.5) for readmitted patients. Among the 3066 patients who remained hospitalized at the final study follow-up date (median age, 65 years [IQR, 54-75]), the median follow-up at time of censoring was 4.5 days (IQR, 2.4-8.1). Conclusions and Relevance This case series provides characteristics and early outcomes of sequentially hospitalized patients with confirmed COVID-19 in the New York City area.",
    "date": "2020",
    "authors": [
        "Safiya Richardson",
        "Jamie S. Hirsch",
        "Mangala Narasimhan",
        "James M. Crawford",
        "Thomas McGinn",
        "Karina W. Davidson",
        "Douglas P. Barnaby",
        "Lance B. Becker",
        "John D. Chelico",
        "Stuart L. Cohen",
        "Jennifer Cookingham",
        "Kevin Coppa",
        "Michael A. Diefenbach",
        "Andrew J. Dominello",
        "Joan Duer-Hefele",
        "Louise Falzon",
        "Jordan Gitlin",
        "Negin Hajizadeh",
        "Tiffany G. Harvin",
        "David A. Hirschwerk",
        "Eun Ji Kim",
        "Zachary M. Kozel",
        "Lyndonna M. Marrast",
        "Jazmin N. Mogavero",
        "Gabrielle A. Osorio",
        "Michael Qiu",
        "Theodoros P. Zanos"
    ],
    "related_topics": [
        "Interquartile range",
        "Respiratory virus",
        "Intensive care unit"
    ],
    "citation_count": "4,591",
    "reference_count": "14",
    "references": [
        "3009885589",
        "3003465021",
        "3011559677",
        "2000445173",
        "2952762910",
        "3026065783",
        "1897436286",
        "3013529907",
        "2028521865",
        "3034720935"
    ]
},{
    "id": "3012747666",
    "title": "Association of Cardiac Injury With Mortality in Hospitalized Patients With COVID-19 in Wuhan, China.",
    "abstract": "Importance Coronavirus disease 2019 (COVID-19) has resulted in considerable morbidity and mortality worldwide since December 2019. However, information on cardiac injury in patients affected by COVID-19 is limited. Objective To explore the association between cardiac injury and mortality in patients with COVID-19. Design, Setting, and Participants This cohort study was conducted from January 20, 2020, to February 10, 2020, in a single center at Renmin Hospital of Wuhan University, Wuhan, China; the final date of follow-up was February 15, 2020. All consecutive inpatients with laboratory-confirmed COVID-19 were included in this study. Main Outcomes and Measures Clinical laboratory, radiological, and treatment data were collected and analyzed. Outcomes of patients with and without cardiac injury were compared. The association between cardiac injury and mortality was analyzed. Results A total of 416 hospitalized patients with COVID-19 were included in the final analysis; the median age was 64 years (range, 21-95 years), and 211 (50.7%) were female. Common symptoms included fever (334 patients [80.3%]), cough (144 [34.6%]), and shortness of breath (117 [28.1%]). A total of 82 patients (19.7%) had cardiac injury, and compared with patients without cardiac injury, these patients were older (median [range] age, 74 [34-95] vs 60 [21-90] years;P\u2009 Conclusions and Relevance Cardiac injury is a common condition among hospitalized patients with COVID-19 in Wuhan, China, and it is associated with higher risk of in-hospital mortality.",
    "date": "2020",
    "authors": [
        "Shaobo Shi",
        "Mu Qin",
        "Bo Shen",
        "Yuli Cai",
        "Tao Liu",
        "Fan Yang",
        "Wei Gong",
        "Xu Liu",
        "Jinjun Liang",
        "Qinyan Zhao",
        "He Huang",
        "Bo Yang",
        "Congxin Huang"
    ],
    "related_topics": [
        "Heart Injury",
        "Cohort study",
        "Survival rate"
    ],
    "citation_count": "2,420",
    "reference_count": "19",
    "references": [
        "3001118548",
        "3005079553",
        "3007940623",
        "3007643904",
        "1803784511",
        "2026274122",
        "3012180666",
        "1996311210",
        "2109626958",
        "3023259384"
    ]
},{
    "id": "3016902371",
    "title": "Using social and behavioural science to support COVID-19 pandemic response.",
    "abstract": "The COVID-19 pandemic represents a massive global health crisis. Because the crisis requires large-scale behaviour change and places significant psychological burdens on individuals, insights from the social and behavioural sciences can be used to help align human behaviour with the recommendations of epidemiologists and public health experts. Here we discuss evidence from a selection of research topics relevant to pandemics, including work on navigating threats, social and cultural influences on behaviour, science communication, moral decision-making, leadership, and stress and coping. In each section, we note the nature and quality of prior research, including uncertainty and unsettled issues. We identify several insights for effective response to the COVID-19 pandemic and highlight important gaps researchers should move quickly to fill in the coming weeks and months.",
    "date": "2020",
    "authors": [
        "Jay J.Van Bavel",
        "Katherine Baicker",
        "Paulo S. Boggio",
        "Valerio Capraro",
        "Aleksandra Cichocka",
        "Mina Cikara",
        "Molly J. Crockett",
        "Alia J. Crum",
        "Karen M. Douglas",
        "James N. Druckman",
        "John Drury",
        "Oeindrila Dube",
        "Naomi Ellemers",
        "Eli J. Finkel",
        "James H. Fowler",
        "Michele Gelfand",
        "Shihui Han",
        "S. Alexander Haslam",
        "Jolanda Jetten",
        "Shinobu Kitayama",
        "Dean Mobbs",
        "Lucy E. Napper",
        "Dominic J. Packer",
        "Gordon Pennycook",
        "Ellen Peters",
        "Richard E. Petty",
        "David G. Rand",
        "Stephen D. Reicher",
        "Simone Schnall",
        "Azim Shariff",
        "Linda J. Skitka",
        "Sandra Susan Smith",
        "Cass R. Sunstein",
        "Nassim Tabri",
        "Joshua A. Tucker",
        "Sander van der Linden",
        "Paul van Lange",
        "Kim A. Weeden",
        "Michael J.A. Wohl",
        "Jamil Zaki",
        "Sean R. Zion",
        "Robb Willer"
    ],
    "related_topics": [
        "Behavioural sciences",
        "Science communication",
        "Social distance"
    ],
    "citation_count": "1,546",
    "reference_count": "229",
    "references": [
        "3009885589",
        "3006659024",
        "1481908410",
        "2582561810",
        "1968380849",
        "1954045752",
        "2081155210",
        "2167062553",
        "2123791568",
        "1686065478"
    ]
},{
    "id": "3022459584",
    "title": "Children with Covid-19 in Pediatric Emergency Departments in Italy.",
    "abstract": "Children with Covid-19 in Italy This letter describes a cohort of 100 children younger than 18 years of age with RT-PCR\u2013confirmed Covid-19 who were assessed in 17 pediatric emergency departments in...",
    "date": "2020",
    "authors": [
        "Niccol\u00f2 Parri",
        "Matteo Lenge",
        "Danilo Buonsenso"
    ],
    "related_topics": [
        "Cohort",
        "Family medicine",
        "Medicine"
    ],
    "citation_count": "365",
    "reference_count": "3",
    "references": [
        "3010819577",
        "3010951319",
        "3014361632"
    ]
},{
    "id": "2091069417",
    "title": "Perception of risk.",
    "abstract": "Studies of risk perception examine the judgements people make when they are asked to characterize and evaluate hazardous activities and technologies. This research aims to aid risk analysis and policy-making by providing a basis for understanding and anticipating public responses to hazards and improving the communication of risk information among lay people, technical experts, and decision-makers. This work assumes that those who promote and regulate health and safety need to understand how people think about and respond to risk. Without such understanding, well-intended policies may be ineffective.",
    "date": "1987",
    "authors": [
        "Paul Slovic"
    ],
    "related_topics": [
        "Risk analysis",
        "Risk perception",
        "Risk assessment"
    ],
    "citation_count": "11,246",
    "reference_count": "15",
    "references": [
        "2096452841",
        "2138502710",
        "2118439232",
        "1963536888",
        "2314752693",
        "1987813830",
        "2046535896",
        "2035086034",
        "2000368687",
        "2125989577"
    ]
},{
    "id": "3134923022",
    "title": "What are the Risks of COVID-19 Infection in Pregnant Women?",
    "abstract": "",
    "date": "2021",
    "authors": [
        "J. Qiao"
    ],
    "related_topics": [
        "Obstetrics",
        "Medicine",
        "Coronavirus disease 2019 (COVID-19)"
    ],
    "citation_count": "289",
    "reference_count": "0",
    "references": []
},{
    "id": "3003217347",
    "title": "A new coronavirus associated with human respiratory disease in China.",
    "abstract": "Emerging infectious diseases, such as severe acute respiratory syndrome (SARS) and Zika virus disease, present a major threat to public health1-3. Despite intense research efforts, how, when and where new diseases appear are still a source of considerable uncertainty. A severe respiratory disease was recently reported in Wuhan, Hubei province, China. As of 25 January 2020, at least 1,975 cases had been reported since the first patient was hospitalized on 12 December 2019. Epidemiological investigations have suggested that the outbreak was associated with a seafood market in Wuhan. Here we study a single patient who was a worker at the market and who was admitted to the Central Hospital of Wuhan on 26 December 2019 while experiencing a severe respiratory syndrome that included fever, dizziness and a cough. Metagenomic RNA sequencing4 of a sample of bronchoalveolar lavage fluid from the patient identified a new RNA virus strain from the family Coronaviridae, which is designated here 'WH-Human 1' coronavirus (and has also been referred to as '2019-nCoV'). Phylogenetic analysis of the complete viral genome (29,903 nucleotides) revealed that the virus was most closely related (89.1% nucleotide similarity) to a group of SARS-like coronaviruses (genus Betacoronavirus, subgenus Sarbecovirus) that had previously been found in bats in China5. This outbreak highlights the ongoing ability of viral spill-over from animals to cause severe disease in humans.",
    "date": "2020",
    "authors": [
        "Fan Wu",
        "Su Zhao",
        "Bin Yu",
        "Yan Mei Chen",
        "Wen Wang",
        "Zhi Gang Song",
        "Yi Hu",
        "Zhao Wu Tao",
        "Jun Hua Tian",
        "Yuan Yuan Pei",
        "Ming Li Yuan",
        "Yu Ling Zhang",
        "Fa Hui Dai",
        "Yi Liu",
        "Qi Min Wang",
        "Jiao Jiao Zheng",
        "Lin Xu",
        "Edward C. Holmes",
        "Yong Zhen Zhang"
    ],
    "related_topics": [
        "Coronavirus",
        "Betacoronavirus",
        "Outbreak"
    ],
    "citation_count": "5,704",
    "reference_count": "47",
    "references": [
        "3004280078",
        "2132632499",
        "2108234281",
        "2131271579",
        "2170551349",
        "2160378127",
        "2132926880",
        "2111211467",
        "2126419817",
        "2132260239"
    ]
},{
    "id": "3007643904",
    "title": "Cryo-EM structure of the 2019-nCoV spike in the prefusion conformation.",
    "abstract": "The outbreak of a novel coronavirus (2019-nCoV) represents a pandemic threat that has been declared a public health emergency of international concern. The CoV spike (S) glycoprotein is a key target for vaccines, therapeutic antibodies, and diagnostics. To facilitate medical countermeasure development, we determined a 3.5-angstrom-resolution cryo-electron microscopy structure of the 2019-nCoV S trimer in the prefusion conformation. The predominant state of the trimer has one of the three receptor-binding domains (RBDs) rotated up in a receptor-accessible conformation. We also provide biophysical and structural evidence that the 2019-nCoV S protein binds angiotensin-converting enzyme 2 (ACE2) with higher affinity than does severe acute respiratory syndrome (SARS)-CoV S. Additionally, we tested several published SARS-CoV RBD-specific monoclonal antibodies and found that they do not have appreciable binding to 2019-nCoV S, suggesting that antibody cross-reactivity may be limited between the two RBDs. The structure of 2019-nCoV S should enable the rapid development and evaluation of medical countermeasures to address the ongoing public health crisis.",
    "date": "2020",
    "authors": [
        "Daniel Wrapp",
        "Nianshuang Wang",
        "Kizzmekia S. Corbett",
        "Jory A. Goldsmith",
        "Ching Lin Hsieh",
        "Olubukola Abiona",
        "Barney S. Graham",
        "Jason S. McLellan"
    ],
    "related_topics": [
        "Coronavirus",
        "Protein structure",
        "Viral protein"
    ],
    "citation_count": "4,541",
    "reference_count": "42",
    "references": [
        "3001118548",
        "3002108456",
        "3003668884",
        "3002539152",
        "3004280078",
        "3004318991",
        "3003217347",
        "2144081223",
        "2132629607",
        "3004348779"
    ]
},{
    "id": "3012310845",
    "title": "Severe Outcomes Among Patients with Coronavirus Disease 2019 (COVID-19) - United States, February 12-March 16, 2020",
    "abstract": "Globally, approximately 170,000 confirmed cases of coronavirus disease 2019 (COVID-19) caused by the 2019 novel coronavirus (SARS-CoV-2) have been reported, including an estimated 7,000 deaths in approximately 150 countries (1). On March 11, 2020, the World Health Organization declared the COVID-19 outbreak a pandemic (2). Data from China have indicated that older adults, particularly those with serious underlying health conditions, are at higher risk for severe COVID-19-associated illness and death than are younger persons (3). Although the majority of reported COVID-19 cases in China were mild (81%), approximately 80% of deaths occurred among adults aged \u226560 years; only one (0.1%) death occurred in a person aged \u226419 years (3). In this report, COVID-19 cases in the United States that occurred during February 12-March 16, 2020 and severity of disease (hospitalization, admission to intensive care unit [ICU], and death) were analyzed by age group. As of March 16, a total of 4,226 COVID-19 cases in the United States had been reported to CDC, with multiple cases reported among older adults living in long-term care facilities (4). Overall, 31% of cases, 45% of hospitalizations, 53% of ICU admissions, and 80% of deaths associated with COVID-19 were among adults aged \u226565 years with the highest percentage of severe outcomes among persons aged \u226585 years. In contrast, no ICU admissions or deaths were reported among persons aged \u226419 years. Similar to reports from other countries, this finding suggests that the risk for serious disease and death from COVID-19 is higher in older age groups.",
    "date": "2020",
    "authors": [
        "Stephanie Bialek",
        "Ellen Boundy",
        "Virginia Bowen",
        "Nancy Chow",
        "Amanda Cohn",
        "Nicole Dowling",
        "Sascha Ellington",
        "Ryan Gierke",
        "Aron Hall",
        "Jessica MacNeil",
        "Priti Patel",
        "Georgina Peacock",
        "Tamara Pilishvili",
        "Hilda Razzaghi",
        "Nia Reed",
        "Matthew Ritchey",
        "Erin Sauber-Schatz"
    ],
    "related_topics": [
        "Severity of illness",
        "Outbreak",
        "Young adult"
    ],
    "citation_count": "1,623",
    "reference_count": "2",
    "references": [
        "3008818676",
        "3010860326"
    ]
},{
    "id": "3004348779",
    "title": "Receptor Recognition by the Novel Coronavirus from Wuhan: an Analysis Based on Decade-Long Structural Studies of SARS Coronavirus.",
    "abstract": "Recently, a novel coronavirus (2019-nCoV) has emerged from Wuhan, China, causing symptoms in humans similar to those caused by severe acute respiratory syndrome coronavirus (SARS-CoV). Since the SARS-CoV outbreak in 2002, extensive structural analyses have revealed key atomic-level interactions between the SARS-CoV spike protein receptor-binding domain (RBD) and its host receptor angiotensin-converting enzyme 2 (ACE2), which regulate both the cross-species and human-to-human transmissions of SARS-CoV. Here, we analyzed the potential receptor usage by 2019-nCoV, based on the rich knowledge about SARS-CoV and the newly released sequence of 2019-nCoV. First, the sequence of 2019-nCoV RBD, including its receptor-binding motif (RBM) that directly contacts ACE2, is similar to that of SARS-CoV, strongly suggesting that 2019-nCoV uses ACE2 as its receptor. Second, several critical residues in 2019-nCoV RBM (particularly Gln493) provide favorable interactions with human ACE2, consistent with 2019-nCoV's capacity for human cell infection. Third, several other critical residues in 2019-nCoV RBM (particularly Asn501) are compatible with, but not ideal for, binding human ACE2, suggesting that 2019-nCoV has acquired some capacity for human-to-human transmission. Last, while phylogenetic analysis indicates a bat origin of 2019-nCoV, 2019-nCoV also potentially recognizes ACE2 from a diversity of animal species (except mice and rats), implicating these animal species as possible intermediate hosts or animal models for 2019-nCoV infections. These analyses provide insights into the receptor usage, cell entry, host cell infectivity and animal origin of 2019-nCoV and may help epidemic surveillance and preventive measures against 2019-nCoV.IMPORTANCE The recent emergence of Wuhan coronavirus (2019-nCoV) puts the world on alert. 2019-nCoV is reminiscent of the SARS-CoV outbreak in 2002 to 2003. Our decade-long structural studies on the receptor recognition by SARS-CoV have identified key interactions between SARS-CoV spike protein and its host receptor angiotensin-converting enzyme 2 (ACE2), which regulate both the cross-species and human-to-human transmissions of SARS-CoV. One of the goals of SARS-CoV research was to build an atomic-level iterative framework of virus-receptor interactions to facilitate epidemic surveillance, predict species-specific receptor usage, and identify potential animal hosts and animal models of viruses. Based on the sequence of 2019-nCoV spike protein, we apply this predictive framework to provide novel insights into the receptor usage and likely host range of 2019-nCoV. This study provides a robust test of this reiterative framework, providing the basic, translational, and public health research communities with predictive insights that may help study and battle this novel 2019-nCoV.",
    "date": "2020",
    "authors": [
        "Yushun Wan",
        "Jian Shang",
        "Rachel Graham",
        "Ralph S. Baric",
        "Fang Li"
    ],
    "related_topics": [
        "Coronavirus",
        "Cross-species transmission",
        "Sequence alignment"
    ],
    "citation_count": "2,940",
    "reference_count": "38",
    "references": [
        "3004280078",
        "2903899730",
        "2144081223",
        "2025170735",
        "2127322768",
        "2131262274",
        "1993577573",
        "3008394341",
        "2775086803",
        "2119111857"
    ]
},{
    "id": "3035011439",
    "title": "The Epidemiological Characteristics of an Outbreak of 2019 Novel Coronavirus Diseases (COVID-19) \u2014 China, 2020",
    "abstract": "",
    "date": "2019",
    "authors": [
        "China Cdc Weekly"
    ],
    "related_topics": [
        "Outbreak",
        "Epidemiology",
        "Medicine"
    ],
    "citation_count": "1,199",
    "reference_count": "0",
    "references": []
},{
    "id": "3004896487",
    "title": "Genome Composition and Divergence of the Novel Coronavirus (2019-nCoV) Originating in China.",
    "abstract": "An in-depth annotation of the newly discovered coronavirus (2019-nCoV) genome has revealed differences between 2019-nCoV and severe acute respiratory syndrome (SARS) or SARS-like coronaviruses. A systematic comparison identified 380 amino acid substitutions between these coronaviruses, which may have caused functional and pathogenic divergence of 2019-nCoV.",
    "date": "2020",
    "authors": [
        "Aiping Wu",
        "Yousong Peng",
        "Baoying Huang",
        "Xiao Ding",
        "Xianyue Wang",
        "Peihua Niu",
        "Jing Meng",
        "Zhaozhong Zhu",
        "Zheng Zhang",
        "Jiangyuan Wang",
        "Jie Sheng",
        "Lijun Quan",
        "Zanxian Xia",
        "Wenjie Tan",
        "Genhong Cheng",
        "Taijiao Jiang"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Genome"
    ],
    "citation_count": "1,384",
    "reference_count": "14",
    "references": [
        "3001118548",
        "3001897055",
        "3004280078",
        "2903899730",
        "1993577573",
        "2909194930",
        "2513547424",
        "2134061616",
        "2406220407",
        "2158922816"
    ]
},{
    "id": "3006645647",
    "title": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and coronavirus disease-2019 (COVID-19): The epidemic and the challenges.",
    "abstract": "The emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2; previously provisionally named 2019 novel coronavirus or 2019-nCoV) disease (COVID-19) in China at the end of 2019 has caused a large global outbreak and is a major public health issue. As of 11 February 2020, data from the World Health Organization (WHO) have shown that more than 43 000 confirmed cases have been identified in 28 countries/regions, with >99% of cases being detected in China. On 30 January 2020, the WHO declared COVID-19 as the sixth public health emergency of international concern. SARS-CoV-2 is closely related to two bat-derived severe acute respiratory syndrome-like coronaviruses, bat-SL-CoVZC45 and bat-SL-CoVZXC21. It is spread by human-to-human transmission via droplets or direct contact, and infection has been estimated to have mean incubation period of 6.4 days and a basic reproduction number of 2.24-3.58. Among patients with pneumonia caused by SARS-CoV-2 (novel coronavirus pneumonia or Wuhan pneumonia), fever was the most common symptom, followed by cough. Bilateral lung involvement with ground-glass opacity was the most common finding from computed tomography images of the chest. The one case of SARS-CoV-2 pneumonia in the USA is responding well to remdesivir, which is now undergoing a clinical trial in China. Currently, controlling infection to prevent the spread of SARS-CoV-2 is the primary intervention being used. However, public health authorities should keep monitoring the situation closely, as the more we can learn about this novel virus and its associated outbreak, the better we can respond.",
    "date": "2020",
    "authors": [
        "Chih Cheng Lai",
        "Tzu Ping Shih",
        "Wen Chien Ko",
        "Hung Jen Tang",
        "Po Ren Hsueh"
    ],
    "related_topics": [
        "Pneumonia",
        "Outbreak",
        "Transmission (medicine)"
    ],
    "citation_count": "2,972",
    "reference_count": "57",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3004280078",
        "3004318991",
        "3003465021",
        "3003573988"
    ]
},{
    "id": "3011176674",
    "title": "The origin, transmission and clinical therapies on coronavirus disease 2019 (COVID-19) outbreak - an update on the status.",
    "abstract": "An acute respiratory disease, caused by a novel coronavirus (SARS-CoV-2, previously known as 2019-nCoV), the coronavirus disease 2019 (COVID-19) has spread throughout China and received worldwide attention. On 30 January 2020, World Health Organization (WHO) officially declared the COVID-19 epidemic as a public health emergency of international concern. The emergence of SARS-CoV-2, since the severe acute respiratory syndrome coronavirus (SARS-CoV) in 2002 and Middle East respiratory syndrome coronavirus (MERS-CoV) in 2012, marked the third introduction of a highly pathogenic and large-scale epidemic coronavirus into the human population in the twenty-first century. As of 1 March 2020, a total of 87,137 confirmed cases globally, 79,968 confirmed in China and 7169 outside of China, with 2977 deaths (3.4%) had been reported by WHO. Meanwhile, several independent research groups have identified that SARS-CoV-2 belongs to \u03b2-coronavirus, with highly identical genome to bat coronavirus, pointing to bat as the natural host. The novel coronavirus uses the same receptor, angiotensin-converting enzyme 2 (ACE2) as that for SARS-CoV, and mainly spreads through the respiratory tract. Importantly, increasingly evidence showed sustained human-to-human transmission, along with many exported cases across the globe. The clinical symptoms of COVID-19 patients include fever, cough, fatigue and a small population of patients appeared gastrointestinal infection symptoms. The elderly and people with underlying diseases are susceptible to infection and prone to serious outcomes, which may be associated with acute respiratory distress syndrome (ARDS) and cytokine storm. Currently, there are few specific antiviral strategies, but several potent candidates of antivirals and repurposed drugs are under urgent investigation. In this review, we summarized the latest research progress of the epidemiology, pathogenesis, and clinical characteristics of COVID-19, and discussed the current treatment and scientific advancements to combat the epidemic novel coronavirus.",
    "date": "2020",
    "authors": [
        "Yan Rong Guo",
        "Qing Dong Cao",
        "Zhong Si Hong",
        "Yuan Yang Tan",
        "Shou Deng Chen",
        "Hong Jun Jin",
        "Kai Sen Tan",
        "De Yun Wang",
        "Yan Yan"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Disease reservoir"
    ],
    "citation_count": "2,843",
    "reference_count": "107",
    "references": [
        "3001118548",
        "3001897055",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3002539152",
        "3004280078",
        "3004318991",
        "3003465021"
    ]
},{
    "id": "3009607814",
    "title": "Clinical characteristics of 24 asymptomatic infections with COVID-19 screened among close contacts in Nanjing, China.",
    "abstract": "Previous studies have showed clinical characteristics of patients with the 2019 novel coronavirus disease (COVID-19) and the evidence of person-to-person transmission. Limited data are available for asymptomatic infections. This study aims to present the clinical characteristics of 24 cases with asymptomatic infection screened from close contacts and to show the transmission potential of asymptomatic COVID-19 virus carriers. Epidemiological investigations were conducted among all close contacts of COVID-19 patients (or suspected patients) in Nanjing, Jiangsu Province, China, from Jan 28 to Feb 9, 2020, both in clinic and in community. Asymptomatic carriers were laboratory-confirmed positive for the COVID-19 virus by testing the nucleic acid of the pharyngeal swab samples. Their clinical records, laboratory assessments, and chest CT scans were reviewed. As a result, none of the 24 asymptomatic cases presented any obvious symptoms while nucleic acid screening. Five cases (20.8%) developed symptoms (fever, cough, fatigue, etc.) during hospitalization. Twelve (50.0%) cases showed typical CT images of ground-glass chest and 5 (20.8%) presented stripe shadowing in the lungs. The remaining 7 (29.2%) cases showed normal CT image and had no symptoms during hospitalization. These 7 cases were younger (median age: 14.0 years; P=0.012) than the rest. None of the 24 cases developed severe COVID-19 pneumonia or died. The median communicable period, defined as the interval from the first day of positive nucleic acid tests to the first day of continuous negative tests, was 9.5 days (up to 21 days among the 24 asymptomatic cases). Through epidemiological investigation, we observed a typical asymptomatic transmission to the cohabiting family members, which even caused severe COVID-19 pneumonia. Overall, the asymptomatic carriers identified from close contacts were prone to be mildly ill during hospitalization. However, the communicable period could be up to three weeks and the communicated patients could develop severe illness. These results highlighted the importance of close contact tracing and longitudinally surveillance via virus nucleic acid tests. Further isolation recommendation and continuous nucleic acid tests may also be recommended to the patients discharged.",
    "date": "2020",
    "authors": [
        "Zhiliang Hu",
        "Ci Song",
        "Chuanjun Xu",
        "Guangfu Jin",
        "Yaling Chen",
        "Xin Xu",
        "Hongxia Ma",
        "Wei Chen",
        "Yuan Lin",
        "Yishan Zheng",
        "Jianming Wang",
        "Zhibin Hu",
        "Yongxiang Yi",
        "Hongbing Shen"
    ],
    "related_topics": [
        "Asymptomatic",
        "Asymptomatic carrier",
        "Pneumonia"
    ],
    "citation_count": "1,135",
    "reference_count": "13",
    "references": [
        "3001118548",
        "3008827533",
        "3002108456",
        "3002539152",
        "3004318991",
        "3006961006",
        "3003573988",
        "3003951199",
        "3005995896",
        "3005347918"
    ]
},{
    "id": "3011802905",
    "title": "Epidemiology, causes, clinical manifestation and diagnosis, prevention and control of coronavirus disease (COVID-19) during the early outbreak period: a scoping review.",
    "abstract": "The coronavirus disease (COVID-19) has been identified as the cause of an outbreak of respiratory illness in Wuhan, Hubei Province, China beginning in December 2019. As of 31 January 2020, this epidemic had spread to 19 countries with 11\u2009791 confirmed cases, including 213 deaths. The World Health Organization has declared it a Public Health Emergency of International Concern. A scoping review was conducted following the methodological framework suggested by Arksey and O\u2019Malley. In this scoping review, 65 research articles published before 31 January 2020 were analyzed and discussed to better understand the epidemiology, causes, clinical diagnosis, prevention and control of this virus. The research domains, dates of publication, journal language, authors\u2019 affiliations, and methodological characteristics were included in the analysis. All the findings and statements in this review regarding the outbreak are based on published information as listed in the references. Most of the publications were written using the English language (89.2%). The largest proportion of published articles were related to causes (38.5%) and a majority (67.7%) were published by Chinese scholars. Research articles initially focused on causes, but over time there was an increase of the articles related to prevention and control. Studies thus far have shown that the virus\u2019 origination is in connection to a seafood market in Wuhan, but specific animal associations have not been confirmed. Reported symptoms include fever, cough, fatigue, pneumonia, headache, diarrhea, hemoptysis, and dyspnea. Preventive measures such as masks, hand hygiene practices, avoidance of public contact, case detection, contact tracing, and quarantines have been discussed as ways to reduce transmission. To date, no specific antiviral treatment has proven effective; hence, infected people primarily rely on symptomatic treatment and supportive care. There has been a rapid surge in research in response to the outbreak of COVID-19. During this early period, published research primarily explored the epidemiology, causes, clinical manifestation and diagnosis, as well as prevention and control of the novel coronavirus. Although these studies are relevant to control the current public emergency, more high-quality research is needed to provide valid and reliable ways to manage this kind of public health emergency in both the short- and long-term.",
    "date": "2020",
    "authors": [
        "Sasmita Poudel Adhikari",
        "Sha Meng",
        "Yu Ju Wu",
        "Yu Ping Mao",
        "Rui Xue Ye",
        "Qing Zhi Wang",
        "Chang Sun",
        "Sean Sylvia",
        "Scott Rozelle",
        "Hein Raat",
        "Huan Zhou"
    ],
    "related_topics": [
        "Epidemiology",
        "Public health",
        "Contact tracing"
    ],
    "citation_count": "1,394",
    "reference_count": "30",
    "references": [
        "3001118548",
        "3001897055",
        "3002108456",
        "3003668884",
        "3004280078",
        "2007872832",
        "3004318991",
        "2156098321",
        "3003573988",
        "2166867592"
    ]
},{
    "id": "3005798348",
    "title": "Protecting health-care workers from subclinical coronavirus infection.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "De Chang",
        "Huiwen Xu",
        "Andre Rebaza",
        "Lokesh Sharma",
        "Charles S Dela Cruz"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Betacoronavirus"
    ],
    "citation_count": "466",
    "reference_count": "2",
    "references": [
        "3002539152",
        "3004239190"
    ]
},{
    "id": "3006961006",
    "title": "SARS-CoV-2 Viral Load in Upper Respiratory Specimens of Infected Patients.",
    "abstract": "SARS-CoV-2 Viral Load in Upper Respiratory Specimens The authors report results of an analysis of nasal and throat swabs from 17 patients in Zhuhai, China, who had received a diagnosis of Covid-19....",
    "date": "2020",
    "authors": [
        "Lirong Zou",
        "Feng Ruan",
        "Mingxing Huang",
        "Lijun Liang",
        "Huitao Huang",
        "Zhongsi Hong",
        "Jianxiang Yu",
        "Min Kang",
        "Yingchao Song",
        "Jinyu Xia",
        "Qianfang Guo",
        "Tie Song",
        "Jianfeng He",
        "Hui Ling Yen",
        "Malik Peiris",
        "Jie Wu"
    ],
    "related_topics": [
        "Viral load",
        "Throat",
        "Respiratory system"
    ],
    "citation_count": "3,765",
    "reference_count": "8",
    "references": [
        "3004239190",
        "2129542667",
        "3024919756",
        "2147166346",
        "3034411794",
        "3034408674",
        "3018339046",
        "2133748753"
    ]
},{
    "id": "3008874180",
    "title": "The epidemiology and pathogenesis of coronavirus disease (COVID-19) outbreak.",
    "abstract": "Coronavirus disease (COVID-19) is caused by SARS-COV2 and represents the causative agent of a potentially fatal disease that is of great global public health concern. Based on the large number of infected people that were exposed to the wet animal market in Wuhan City, China, it is suggested that this is likely the zoonotic origin of COVID-19. Person-to-person transmission of COVID-19 infection led to the isolation of patients that were subsequently administered a variety of treatments. Extensive measures to reduce person-to-person transmission of COVID-19 have been implemented to control the current outbreak. Special attention and efforts to protect or reduce transmission should be applied in susceptible populations including children, health care providers, and elderly people. In this review, we highlights the symptoms, epidemiology, transmission, pathogenesis, phylogenetic analysis and future directions to control the spread of this fatal disease.",
    "date": "2020",
    "authors": [
        "Hussin A. Rothan",
        "Siddappa N. Byrareddy"
    ],
    "related_topics": [
        "Outbreak",
        "Transmission (medicine)",
        "Disease"
    ],
    "citation_count": "3,390",
    "reference_count": "39",
    "references": [
        "3001118548",
        "3001897055",
        "3002108456",
        "3003668884",
        "3004318991",
        "3003465021",
        "2903899730",
        "3005212621",
        "3003951199",
        "2999409984"
    ]
},{
    "id": "3010781325",
    "title": "Estimating the asymptomatic proportion of coronavirus disease 2019 (COVID-19) cases on board the Diamond Princess cruise ship, Yokohama, Japan, 2020.",
    "abstract": "On 5 February 2020, in Yokohama, Japan, a cruise ship hosting 3,711 people underwent a 2-week quarantine after a former passenger was found with COVID-19 post-disembarking. As at 20 February, 634 persons on board tested positive for the causative virus. We conducted statistical modelling to derive the delay-adjusted asymptomatic proportion of infections, along with the infections' timeline. The estimated asymptomatic proportion was 17.9% (95% credible interval (CrI): 15.5-20.2%). Most infections occurred before the quarantine start.",
    "date": "2020",
    "authors": [
        "Kenji Mizumoto",
        "Katsushi Kagaya",
        "Alexander Zarebski",
        "Gerardo Chowell"
    ],
    "related_topics": [
        "Asymptomatic",
        "Quarantine",
        "Outbreak"
    ],
    "citation_count": "1,913",
    "reference_count": "20",
    "references": [
        "3001118548",
        "3006961006",
        "3008818676",
        "3004912618",
        "3006065484",
        "3012188173",
        "3006750069",
        "3023775996",
        "3033518790",
        "3014654669"
    ]
},{
    "id": "3015792206",
    "title": "Association of Public Health Interventions With the Epidemiology of the COVID-19 Outbreak in Wuhan, China.",
    "abstract": "Importance Coronavirus disease 2019 (COVID-19) has become a pandemic, and it is unknown whether a combination of public health interventions can improve control of the outbreak. Objective To evaluate the association of public health interventions with the epidemiological features of the COVID-19 outbreak in Wuhan by 5 periods according to key events and interventions. Design, Setting, and Participants In this cohort study, individual-level data on 32\u202f583 laboratory-confirmed COVID-19 cases reported between December 8, 2019, and March 8, 2020, were extracted from the municipal Notifiable Disease Report System, including patients\u2019 age, sex, residential location, occupation, and severity classification. Exposures Nonpharmaceutical public health interventions includingcordons sanitaire, traffic restriction, social distancing, home confinement, centralized quarantine, and universal symptom survey. Main Outcomes and Measures Rates of laboratory-confirmed COVID-19 infections (defined as the number of cases per day per million people), across age, sex, and geographic locations were calculated across 5 periods: December 8 to January 9 (no intervention), January 10 to 22 (massive human movement due to the Chinese New Year holiday), January 23 to February 1 (cordons sanitaire, traffic restriction and home quarantine), February 2 to 16 (centralized quarantine and treatment), and February 17 to March 8 (universal symptom survey). The effective reproduction number of SARS-CoV-2 (an indicator of secondary transmission) was also calculated over the periods. Results Among 32 583 laboratory-confirmed COVID-19 cases, the median patient age was 56.7 years (range, 0-103; interquartile range, 43.4-66.8) and 16 817 (51.6%) were women. The daily confirmed case rate peaked in the third period and declined afterward across geographic regions and sex and age groups, except for children and adolescents, whose rate of confirmed cases continued to increase. The daily confirmed case rate over the whole period in local health care workers (130.5 per million people [95% CI, 123.9-137.2]) was higher than that in the general population (41.5 per million people [95% CI, 41.0-41.9]). The proportion of severe and critical cases decreased from 53.1% to 10.3% over the 5 periods. The severity risk increased with age: compared with those aged 20 to 39 years (proportion of severe and critical cases, 12.1%), elderly people (\u226580 years) had a higher risk of having severe or critical disease (proportion, 41.3%; risk ratio, 3.61 [95% CI, 3.31-3.95]) while younger people ( Conclusions and Relevance A series of multifaceted public health interventions was temporally associated with improved control of the COVID-19 outbreak in Wuhan, China. These findings may inform public health policy in other countries and regions.",
    "date": "2020",
    "authors": [
        "An Pan",
        "Li Liu",
        "Chaolong Wang",
        "Huan Guo",
        "Xingjie Hao",
        "Qi Wang",
        "Jiao Huang",
        "Na He",
        "Hongjie Yu",
        "Xihong Lin",
        "Sheng Wei",
        "Tangchun Wu"
    ],
    "related_topics": [
        "Epidemiology",
        "Cohort study",
        "Incidence (epidemiology)"
    ],
    "citation_count": "918",
    "reference_count": "29",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3003668884",
        "3008028633",
        "3008090866",
        "3003573988",
        "3008696669",
        "3012284084"
    ]
},{
    "id": "3012188173",
    "title": "Estimation of the asymptomatic ratio of novel coronavirus infections (COVID-19).",
    "abstract": "A total of 565 Japanese citizens were evacuated from Wuhan, China to Japan. All passengers were screened for symptoms and also undertook reverse transcription polymerase chain reaction testing, identifying 5 asymptomatic and 7 symptomatic passengers testing positive for 2019-nCoV. We show that the screening result is suggestive of the asymptomatic ratio at 41.6%.",
    "date": "2020",
    "authors": [
        "Hiroshi Nishiura",
        "Tetsuro Kobayashi",
        "Takeshi Miyama",
        "Ayako Suzuki",
        "Sung mok Jung",
        "Katsuma Hayashi",
        "Ryo Kinoshita",
        "Yichi Yang",
        "Baoyin Yuan",
        "Andrei R. Akhmetzhanov",
        "Natalie M. Linton"
    ],
    "related_topics": [
        "Asymptomatic",
        "Reverse transcription polymerase chain reaction",
        "Virology"
    ],
    "citation_count": "907",
    "reference_count": "6",
    "references": [
        "3003668884",
        "3006065484",
        "3001423274",
        "3004658686",
        "2119950877",
        "2071827900"
    ]
},{
    "id": "3009976289",
    "title": "COVID-19 and the cardiovascular system.",
    "abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infects host cells through ACE2 receptors, leading to coronavirus disease (COVID-19)-related pneumonia, while also causing acute myocardial injury and chronic damage to the cardiovascular system. Therefore, particular attention should be given to cardiovascular protection during treatment for COVID-19.",
    "date": "2020",
    "authors": [
        "Ying-Ying Zheng",
        "Yi-Tong Ma",
        "Jin-Ying Zhang",
        "Xiang Xie"
    ],
    "related_topics": [
        "Coronavirus",
        "Pneumonia",
        "Disease"
    ],
    "citation_count": "2,129",
    "reference_count": "10",
    "references": [
        "3001118548",
        "3005079553",
        "3002539152",
        "3004280078",
        "2465777822",
        "2070463916",
        "2416324255",
        "2746482698",
        "2012289331",
        "2045983943"
    ]
},{
    "id": "3009859788",
    "title": "Dysregulation of Immune Response in Patients With Coronavirus 2019 (COVID-19) in Wuhan, China.",
    "abstract": "BACKGROUND: In December 2019, coronavirus 2019 (COVID-19) emerged in Wuhan and rapidly spread throughout China. METHODS: Demographic and clinical data of all confirmed cases with COVID-19 on admission at Tongji Hospital from 10 January to 12 February 2020 were collected and analyzed. The data on laboratory examinations, including peripheral lymphocyte subsets, were analyzed and compared between patients with severe and nonsevere infection. RESULTS: Of the 452 patients with COVID-19 recruited, 286 were diagnosed as having severe infection. The median age was 58 years and 235 were male. The most common symptoms were fever, shortness of breath, expectoration, fatigue, dry cough, and myalgia. Severe cases tend to have lower lymphocyte counts, higher leukocyte counts and neutrophil-lymphocyte ratio (NLR), as well as lower percentages of monocytes, eosinophils, and basophils. Most severe cases demonstrated elevated levels of infection-related biomarkers and inflammatory cytokines. The number of T cells significantly decreased, and were more impaired in severe cases. Both helper T (Th) cells and suppressor T cells in patients with COVID-19 were below normal levels, with lower levels of Th cells in the severe group. The percentage of naive Th cells increased and memory Th cells decreased in severe cases. Patients with COVID-19 also have lower levels of regulatory T cells, which are more obviously decreased in severe cases. CONCLUSIONS: The novel coronavirus might mainly act on lymphocytes, especially T lymphocytes. Surveillance of NLR and lymphocyte subsets is helpful in the early screening of critical illness, diagnosis, and treatment of COVID-19.",
    "date": "2020",
    "authors": [
        "Chuan Qin",
        "Luoqi Zhou",
        "Ziwei Hu",
        "Shuoqi Zhang",
        "Sheng Yang",
        "Yu Tao",
        "Cuihong Xie",
        "Ke Ma",
        "Ke Shang",
        "Wei Wang",
        "Dai Shi Tian"
    ],
    "related_topics": [
        "Lymphocyte",
        "Immune system",
        "T lymphocyte"
    ],
    "citation_count": "2,754",
    "reference_count": "17",
    "references": [
        "3001118548",
        "3005079553",
        "3002108456",
        "2610356532",
        "2790127336",
        "3005929298",
        "2345375456",
        "2072853625",
        "2070463916",
        "2564152524"
    ]
},{
    "id": "2601317354",
    "title": "Proof-of-Concept Workflow for Establishing Reference Intervals of Human Urine Proteome for Monitoring Physiological and Pathological Changes",
    "abstract": "Abstract Urine as a true non-invasive sampling source holds great potential for biomarker discovery. While approximately 2000 proteins can be detected by mass spectrometry in urine from healthy people, the amount of these proteins vary considerably. A systematic evaluation of a large number of samples is needed to determine the range of the variations. Current biomarker studies often measure limited number of urine samples in the discovery phase, which makes it difficult to determine whether proteins differentially expressed between control and disease groups represent actual difference, or are just physiological variations among the individuals, leads to failures in the validation phase with the increased sample numbers. Here, we report a streamlined workflow with capacity of measuring 8 urine proteomes per day at the coverage of >1500 proteins. With this workflow, we evaluated variations in 497 urine proteomes from 167 healthy donors, establishing reference intervals (RIs) that covered urine protein variations. We demonstrated that RIs could be used to monitor physiological changes by detecting transient outlier proteins. Furthermore, we provided a RIs-based algorithm for biomarker discovery and validation to screen for diseases such as cancer. This study provided a proof-of-principle workflow for the use of urine proteome for health monitoring and disease screening.",
    "date": "2017",
    "authors": [
        "Wenchuan Leng",
        "Xiaotian Ni",
        "Changqing Sun",
        "Tianyuan Lu",
        "Anna Malovannaya",
        "Sung Yun Jung",
        "Yin Huang",
        "Yang Qiu",
        "Guannan Sun",
        "Matthew V. Holt",
        "Chen Ding",
        "Wei Sun",
        "Xuebo Men",
        "Tieliu Shi",
        "Weimin Zhu",
        "Yi Wang",
        "Fuchu He",
        "Bei Zhen",
        "Guangshun Wang",
        "Jun Qin"
    ],
    "related_topics": [
        "Biomarker discovery",
        "Biomarker (medicine)",
        "Proteome"
    ],
    "citation_count": "16",
    "reference_count": "51",
    "references": [
        "2012034410",
        "2128551987",
        "2140687262",
        "2080100938",
        "2119412782",
        "1996365670",
        "2028133290",
        "2094229819",
        "2129062330",
        "2031913105"
    ]
},{
    "id": "2946740876",
    "title": "Now is the time to test early urinary biomarkers in large-scale human samples.",
    "abstract": "",
    "date": "2019",
    "authors": [
        "Youhe Gao"
    ],
    "related_topics": [
        "Scale (ratio)",
        "Test (assessment)",
        "Medicine"
    ],
    "citation_count": "2",
    "reference_count": "17",
    "references": [
        "2017233149",
        "1845673212",
        "2787707286",
        "2108862809",
        "2757225757",
        "2923978424",
        "2763669221",
        "2952474859",
        "2091994609",
        "2160050270"
    ]
},{
    "id": "2416914730",
    "title": "American thoracic society/European respiratory society international multidisciplinary consensus classification of the idiopathic interstitial pneumonias",
    "abstract": "",
    "date": "2002",
    "authors": [
        "William D. Travis",
        "Talmadge E. King",
        "Eric D. Bateman",
        "David A. Lynch",
        "Fr\u00e9drique Capron",
        "Thomas V. Colby",
        "Jean Fran\u00e7ois Cordier",
        "Roland M. DuBois",
        "Jeffrey Galvin",
        "Philippe Grenier",
        "David M. Hansell",
        "Gary W. Hunninghake",
        "Masanori Kitaichi",
        "Nestor Luiz M\u00fcller",
        "Jeffrey L. Myers",
        "Sonoko Nagai",
        "Andrew Nicholson",
        "Ganesh Raghu",
        "Benoit Wallaert",
        "Christian G. Brambilla",
        "Kevin K. Brown",
        "Andrew L. Cherniaev",
        "Ulrich Costabel",
        "David B. Coultas",
        "Gerald S. Davis",
        "Maurits G. Demedts",
        "William W. Douglas",
        "J. Egan",
        "Anders G. Eklund",
        "Leonarda M. Fabbri",
        "Craig A. Henke",
        "Richard B. Hubbard",
        "Y. Inoue",
        "Takateru Izumi",
        "H. M. Jansen",
        "Ian Johnston",
        "Dong Soon Kim",
        "Nasreen Khalil",
        "Fiona R. Lake",
        "Giuseppe Lungarella",
        "Joseph P. Lynch",
        "Douglas W. Mapel",
        "Fernando Martinez",
        "Richard Matthay",
        "Lee S. Newman",
        "Paul W. Noble",
        "Ken Ohta",
        "Dario Olivieri",
        "Luis A. Ortiz",
        "Venerino Poletti"
    ],
    "related_topics": [
        "Respiratory bronchiolitis interstitial lung disease",
        "Non-specific interstitial pneumonia",
        "Idiopathic interstitial pneumonia"
    ],
    "citation_count": "4,192",
    "reference_count": "133",
    "references": [
        "2161328469",
        "2626588662",
        "2018809578",
        "2157693596",
        "2140923971",
        "2017898137",
        "2102838725",
        "1990383677",
        "2141785470",
        "1982444609"
    ]
},{
    "id": "2626588662",
    "title": "Idiopathic pulmonary fibrosis: Diagnosis and treatment: International Consensus Statement",
    "abstract": "",
    "date": "1999",
    "authors": [
        "Jr King",
        "U. Costabel",
        "J. F. Cordier",
        "G. A. DoPico",
        "R. M. DuBois",
        "D. Lynch",
        "J. P. Lynch",
        "J. Myers",
        "R. Panos",
        "G. Raghu",
        "D. Schwartz",
        "C. M. Smith"
    ],
    "related_topics": [
        "Idiopathic pulmonary fibrosis",
        "Idiopathic interstitial pneumonia",
        "Usual interstitial pneumonia"
    ],
    "citation_count": "3,304",
    "reference_count": "204",
    "references": [
        "2157693596",
        "2140923971",
        "2315878550",
        "2163147529",
        "2041775285",
        "2328859138",
        "2116000536",
        "2614365993",
        "2138421611",
        "2132293969"
    ]
},{
    "id": "2017898137",
    "title": "Glossary of terms for CT of the lungs: recommendations of the Nomenclature Committee of the Fleischner Society.",
    "abstract": "",
    "date": "1996",
    "authors": [
        "J. H. M. Austin",
        "N. L. M\u00fcller",
        "P. J. Friedman",
        "D. M. Hansell",
        "D. P. Naidich",
        "M. Remy-Jardin",
        "W. R. Webb",
        "E. A. Zerhouni"
    ],
    "related_topics": [
        "Glossary",
        "MEDLINE",
        "Medicine"
    ],
    "citation_count": "1,026",
    "reference_count": "0",
    "references": []
},{
    "id": "1924766221",
    "title": "High-resolution computed tomography in idiopathic pulmonary fibrosis: diagnosis and prognosis.",
    "abstract": "Rationale: High-resolution computed tomography (HRCT) is an integral aspect of the evaluation of patients with suspected idiopathic pulmonary fibrosis (IPF). However, few studies have evaluated its use in a large cohort. Objectives: To describe HRCT features in patients with mild to moderate IPF, compare diagnostic evaluations by a radiology core (three thoracic radiologists) with those by study-site radiologists, correlate baseline clinical and physiologic variables with HRCT findings, and evaluate their association with mortality. Methods: We assessed HRCT scans from patients with IPF (n = 315) enrolled in a randomized controlled study evaluating IFN-\u03b31b. Measurements and Main Results: There was concordance between study-site and core radiologists regarding the diagnosis of IPF in 86% of cases. Diffusing capacity of carbon monoxide (DLCO) was the physiologic characteristic most highly correlated with HRCT findings. Multivariate analysis identified three independent predictors of mortality: a higher exte...",
    "date": "2005",
    "authors": [
        "David A. Lynch",
        "J. David Godwin",
        "Sharon Safrin",
        "Karen M. Starko",
        "Phil Hormel",
        "Kevin K. Brown",
        "Ganesh Raghu",
        "Talmadge E. King",
        "Williamson Z. Bradford",
        "David A. Schwartz",
        "W. Richard Webb"
    ],
    "related_topics": [
        "High-resolution computed tomography",
        "Idiopathic pulmonary fibrosis",
        "Intensive care"
    ],
    "citation_count": "510",
    "reference_count": "20",
    "references": [
        "2164777277",
        "2416914730",
        "2626588662",
        "2101073067",
        "2108226118",
        "2104232168",
        "2141785470",
        "1835326614",
        "2166780351",
        "2614365993"
    ]
},{
    "id": "2121350896",
    "title": "Reversed Halo Sign on High-Resolution CT of Cryptogenic Organizing Pneumonia: Diagnostic Implications",
    "abstract": "OBJECTIVE. The aim of our study was to evaluate the usefulness of the reversed halo sign on high-resolution CT in the diagnosis of cryptogenic organizing pneumonia.MATERIALS AND METHODS. Between 1996 and 2001, we saw 31 patients with biopsy-proven cryptogenic organizing pneumonia. During the same period, we also saw 30 patients with non-cryptogenic organizing pneumonia diseases, from which cryptogenic organizing pneumonia should be differentiated: Wegener's granulomatosis (n = 14), diffuse bronchioloalveolar carcinoma (n = 10), chronic eosinophilic pneumonia (n = 5), and Churg-Strauss syndrome (n = 1). Two independent observers analyzed CT findings and recorded how frequently the so-called reversed halo sign (central ground-glass opacity and surrounding air-space consolidation of crescentic and ring shape) was seen on high-resolution CT.RESULTS. The most common patterns of parenchymal abnormalities of cryptogenic organizing pneumonia were ground-glass opacity (28/31 patients, 90%) and consolidation (27/31...",
    "date": "2003",
    "authors": [
        "Sang Jin Kim",
        "Kyung Soo Lee",
        "Young Hoon Ryu",
        "Young Cheol Yoon",
        "Kyu Ok Choe",
        "Tae Sung Kim",
        "Ki Jun Sung"
    ],
    "related_topics": [
        "Cryptogenic Organizing Pneumonia",
        "Pneumonia",
        "Halo sign"
    ],
    "citation_count": "342",
    "reference_count": "16",
    "references": [
        "2416914730",
        "1552511798",
        "2017898137",
        "2041775285",
        "2156696474",
        "2124705491",
        "1972990539",
        "1980765407",
        "2037346751",
        "1993118662"
    ]
},{
    "id": "2107051779",
    "title": "Idiopathic Interstitial Pneumonias: CT Features",
    "abstract": "Idiopathic interstitial pneumonias comprise usual interstitial pneumonia (UIP), nonspecific interstitial pneumonia (NSIP), desquamative interstitial pneumonia (DIP), respiratory bronchiolitis-associated interstitial lung disease (RB-ILD), cryptogenic organizing pneumonia (COP), acute interstitial pneumonia (AIP), and lymphoid interstitial pneumonia (LIP). Each of these entities has a typical imaging and histologic pattern, although in practice the imaging patterns may be variable. Each entity may be idiopathic or may be secondary to a recognizable cause such as collagen vascular disease or inhalational exposure. The diagnosis of idiopathic interstitial pneumonia is made by means of correlation of clinical, imaging, and pathologic features. The characteristic computed tomographic (CT) features of UIP are predominantly basal and peripheral reticular pattern with honeycombing and traction bronchiectasis. NSIP is characterized by predominantly basal ground-glass opacity and/or reticular pattern, often with traction bronchiectasis. DIP and RB-ILD are smoking-related lung diseases characterized by ground-glass opacity and centrilobular nodules. COP is characterized by patchy peripheral or peribronchovascular consolidation. AIP manifests as diffuse lung consolidation and ground-glass opacity. LIP is associated with a CT pattern of ground-glass opacity sometimes associated with perivascular cysts.",
    "date": "2005",
    "authors": [
        "David A. Lynch",
        "William D. Travis",
        "Nestor L. M\u00fcller",
        "Jeffrey R. Galvin",
        "David M. Hansell",
        "Philippe A. Grenier",
        "Talmadge E. King"
    ],
    "related_topics": [
        "Desquamative interstitial pneumonia",
        "Acute Interstitial Pneumonia",
        "Idiopathic interstitial pneumonia"
    ],
    "citation_count": "410",
    "reference_count": "55",
    "references": [
        "2416914730",
        "2626588662",
        "2157693596",
        "2140923971",
        "1990383677",
        "2104232168",
        "2141785470",
        "2052397837",
        "2041775285",
        "2328859138"
    ]
},{
    "id": "2157678780",
    "title": "Radiologic Findings Are Strongly Associated With a Pathologic Diagnosis of Usual Interstitial Pneumonia",
    "abstract": "Purpose To determine which clinical and radiologic findings are independently associated with a pathologic diagnosis of usual interstitial pneumonia (UIP). Methods We recently reported, using a prospective, multicenter study of patients suspected of having idiopathic interstitial pneumonia (IIP), that a confident diagnosis of UIP made by experienced radiologists was correct in 95% of cases. In the current article, we further analyzed data from this study. Ninety-one patients were entered into the study. Clinical, physiologic, chest radiographic, and CT features were prospectively recorded, and analyzed using univariate and multivariate logistic regression analysis to compare the patients with a histologic diagnosis of UIP with those who received other pathologic diagnoses. Results Fifty-four of 91 patients (59%) received a pathologic diagnosis of UIP. The following features recorded at the referring clinical centers were associated with a pathologic diagnosis of UIP on multivariate analysis: lower-lobe honeycombing on high-resolution CT (HRCT) [odds ratio, 11.45], radiographic findings consistent with UIP (odds ratio, 5.73), elevated ratio of FEV 1 to FVC (odds ratio, 4.8), and absence of smoking history (odds ratio, 0.19). On multivariate analysis of specific HRCT features recorded by four experienced chest radiologists, lower-lung honeycombing (odds ratio, 5.36) and upper-lung irregular lines (odds ratio, 6.28) were the only independent predictors of UIP. Using only these two factors, a diagnosis of UIP could be established with a sensitivity of 74%, a specificity of 81%, and a positive predictive value of 85%. Conclusion In patients presenting with a clinical syndrome suggestive of IIP, CT findings of lower-lung honeycombing and upper-lung irregular lines are most closely associated with a pathologic diagnosis of UIP.",
    "date": "2003",
    "authors": [
        "Gary W. Hunninghake",
        "David A. Lynch",
        "Jeffrey R. Galvin",
        "Barry H. Gross",
        "Nestor M\u00fcller",
        "David A. Schwartz",
        "Talmadge E. King",
        "Joseph P. Lynch",
        "Richard Hegele",
        "James Waldron",
        "Thomas V. Colby",
        "James C. Hogg"
    ],
    "related_topics": [
        "Usual interstitial pneumonia",
        "Honeycombing",
        "Odds ratio"
    ],
    "citation_count": "376",
    "reference_count": "25",
    "references": [
        "2626588662",
        "1968632832",
        "2157693596",
        "2140923971",
        "2046501504",
        "2141785470",
        "2018529629",
        "2137748315",
        "1538418766",
        "2138421611"
    ]
},{
    "id": "2114857071",
    "title": "\"Crazy-paving\" pattern at thin-section CT of the lungs: radiologic-pathologic overview.",
    "abstract": "The \"crazy-paving\" pattern is a common finding at thin-section computed tomography (CT) of the lungs. It consists of scattered or diffuse ground-glass attenuation with superimposed interlobular septal thickening and intralobular lines. This finding has a variety of causes, including infectious, neoplastic, idiopathic, inhalational, and sanguineous disorders. Specific disorders that can cause the crazy-paving pattern include Pneumocystis carinii pneumonia, mucinous bronchioloalveolar carcinoma, pulmonary alveolar proteinosis, sarcoidosis, nonspecific interstitial pneumonia, organizing pneumonia, exogenous lipoid pneumonia, adult respiratory distress syndrome, and pulmonary hemorrhage syndromes. Knowledge of the many causes of this pattern can be useful in preventing diagnostic errors. In addition, although the causes of this pattern are frequently indistinguishable at radiologic evaluation, differences in the location of the characteristic attenuation in the lungs, as well as the presence of additional radiologic findings, the patient's history, and the clinical presentation, can often be useful in suggesting the appropriate diagnosis.",
    "date": "2003",
    "authors": [
        "Santiago E. Rossi",
        "Jeremy J. Erasmus",
        "Mariano Volpacchio",
        "Tomas Franquet",
        "Teresa Castiglioni",
        "H. Page McAdams"
    ],
    "related_topics": [
        "Pneumonia",
        "Diffuse alveolar damage",
        "Pulmonary alveolar proteinosis"
    ],
    "citation_count": "306",
    "reference_count": "41",
    "references": [
        "1982444609",
        "3025576394",
        "2039157860",
        "1985967929",
        "1975309489",
        "2022096221",
        "2053611435",
        "1997558608",
        "2023843571",
        "2171172624"
    ]
},{
    "id": "2155323443",
    "title": "Pneumoconiosis: Comparison of Imaging and Pathologic Findings",
    "abstract": "Pneumoconiosis may be classified as either fibrotic or nonfibrotic, according to the presence or absence of fibrosis. Silicosis, coal worker pneumoconiosis, asbestosis, berylliosis, and talcosis are examples of fibrotic pneumoconiosis. Siderosis, stannosis, and baritosis are nonfibrotic forms of pneumoconiosis that result from inhalation of iron oxide, tin oxide, and barium sulfate particles, respectively. In an individual who has a history of exposure to silica or coal dust, a finding of nodular or reticulonodular lesions at chest radiography or small nodules with a perilymphatic distribution at thin-section computed tomography (CT), with or without eggshell calcifications, is suggestive of silicosis or coal worker pneumoconiosis. Magnetic resonance imaging is helpful for distinguishing between progressive massive fibrosis and lung cancer. CT and histopathologic findings in asbestosis are similar to those in idiopathic pulmonary fibrosis, but the presence of asbestos bodies in histopathologic specimens i...",
    "date": "2005",
    "authors": [
        "Semin Chong",
        "Kyung Soo Lee",
        "Myung Jin Chung",
        "Joungho Han",
        "O. Jung Kwon",
        "d Tae Sung Kim"
    ],
    "related_topics": [
        "Pneumoconiosis",
        "Progressive massive fibrosis",
        "Stannosis"
    ],
    "citation_count": "265",
    "reference_count": "66",
    "references": [
        "1562094885",
        "2105243150",
        "2063113156",
        "2112859856",
        "2104789245",
        "2075570895",
        "2046571468",
        "2138221172",
        "1998731918",
        "2002313613"
    ]
},{
    "id": "1971054351",
    "title": "Lung pathology of fatal severe acute respiratory syndrome",
    "abstract": "Summary Background Severe acute respiratory syndrome (SARS) is a novel infectious disease with global impact. A virus from the family Coronaviridae has been identified as the cause, but the pathogenesis is still unclear. Methods Post-mortem tissue samples from six patients who died from SARS in February and March, 2003, and an open lung biopsy from one of these patients were studied by histology and virology. Only one full autopsy was done. Evidence of infection with the SARS-associated coronavirus (SARS-CoV) and human metapneumovirus was sought by reverse-transcriptase PCR and serology. Pathological samples were examined by light and electron microscopy and immunohistochemistry. Findings All six patients had serological evidence of recent infection with SARS-CoV. Diffuse alveolar damage was common but not universal. Morphological changes identified were bronchial epithelial denudation, loss of cilia, and squamous metaplasia. Secondary bacterial pneumonia was present in one case. A giant-cell infiltrate was seen in four patients, with a pronounced increase in macrophages in the alveoli and the interstitium of the lung. Haemophagocytosis was present in two patients. The alveolar pneumocytes also showed cytomegaly with granular amphophilic cytoplasm. The patient for whom full autopsy was done had atrophy of the white pulp of the spleen. Electron microscopy revealed viral particles in the cytoplasm of epithelial cells corresponding to coronavirus. Interpretation SARS is associated with epithelial-cell proliferation and an increase in macrophages in the lung. The presence of haemophagocytosis supports the contention that cytokine dysregulation may account, at least partly, for the severity of the clinical disease. The case definition of SARS should acknowledge the range of lung pathology associated with this disease. Published online May 16, 2003 http://image.thelancet.com/extras/03art4347web.pdf",
    "date": "2003",
    "authors": [
        "John M Nicholls",
        "Leo L M Poon",
        "Kam C Lee",
        "Wai F Ng",
        "Sik T Lai",
        "Chung Y Leung",
        "Chung M Chu",
        "Pak K Hui",
        "Kong L Mak",
        "Wilina Lim",
        "Kin W Yan",
        "Kwok H Chan",
        "Ngai C Tsang",
        "Yi Guan",
        "Kwok Y Yuen",
        "J S Malik Peiris"
    ],
    "related_topics": [
        "Diffuse alveolar damage",
        "Severe acute respiratory syndrome",
        "Coronavirus"
    ],
    "citation_count": "1,166",
    "reference_count": "23",
    "references": [
        "2104548316",
        "2025170735",
        "2131262274",
        "2100820722",
        "2125251240",
        "2116682907",
        "2122399224",
        "2104730345",
        "2143232661",
        "1988436330"
    ]
},{
    "id": "1976741900",
    "title": "Aetiology: Koch's postulates fulfilled for SARS virus.",
    "abstract": "Severe acute respiratory syndrome (SARS) has recently emerged as a new human disease, resulting globally in 435 deaths from 6,234 probable cases (as of 3 May 2003). Here we provide proof from experimental infection of cynomolgus macaques (Macaca fascicularis) that the newly discovered SARS-associated coronavirus (SCV) is the aetiological agent of this disease. Our understanding of the aetiology of SARS will expedite the development of diagnostic tests, antiviral therapies and vaccines, and may allow a more concise case definition for this emerging disease.",
    "date": "2003",
    "authors": [
        "Ron A. M. Fouchier",
        "Thijs Kuiken",
        "Martin Schutten",
        "Geert van Amerongen",
        "Gerard J. J. van Doornum",
        "Bernadette G. van den Hoogen",
        "Malik Peiris",
        "Wilina Lim",
        "Klaus St\u00f6hr",
        "Albert D. M. E. Osterhaus"
    ],
    "related_topics": [
        "Severe acute respiratory syndrome",
        "Koch's postulates",
        "Coronavirus"
    ],
    "citation_count": "1,070",
    "reference_count": "4",
    "references": [
        "2025170735",
        "2170881661",
        "1594412726",
        "1568737385"
    ]
},{
    "id": "2119467724",
    "title": "Viral Pneumonias in Adults: Radiologic and Pathologic Findings",
    "abstract": "Numerous viruses, including influenza virus, measles virus, Hantavirus, adenovirus, herpesviruses, varicella-zoster virus, cytomegalovirus, and Epstein-Barr virus, can cause lower respiratory tract infection in adults. Viral pneumonia in adults can be classified into two clinical groups: so-called atypical pneumonia in otherwise healthy hosts and viral pneumonia in immunocompromised hosts. Influenza virus types A and B cause most cases of viral pneumonia in immunocompetent adults. Immunocompromised hosts are susceptible to pneumonias caused by cytomegalovirus, herpesviruses, measles virus, and adenovirus. The radiographic findings, which consist mainly of patchy or diffuse ground-glass opacity with or without consolidation and reticular areas of increased opacity, are variable and overlapping. Computed tomographic findings, which are also overlapping, consist of poorly defined centrilobular nodules, ground-glass attenuation with a lobular distribution, segmental consolidation, or diffuse ground-glass attenuation with thickened interlobular septa. The radiologic findings reflect the variable extents of the histopathologic features: diffuse alveolar damage (intraalveolar edema, fibrin, and variable cellular infiltrates with a hyaline membrane), intraalveolar hemorrhage, and interstitial (intrapulmonary or airway) inflammatory cell infiltration. Clinical information such as patient age, immune status, community outbreaks, symptom onset and duration, and presence of a rash remain important aids in diagnosis of viral causes.",
    "date": "2002",
    "authors": [
        "Eun A Kim",
        "Kyung Soo Lee",
        "Steven L Primack",
        "Hye Kyung Yoon",
        "Hong Sik Byun",
        "Tae Sung Kim",
        "Gee Young Suh",
        "O Jung Kwon",
        "Joungho Han"
    ],
    "related_topics": [
        "Viral pneumonia",
        "Atypical pneumonia",
        "Pneumonia"
    ],
    "citation_count": "390",
    "reference_count": "50",
    "references": [
        "2140319515",
        "2346878152",
        "1997673720",
        "2012149683",
        "2314268763",
        "2025944450",
        "1998810872",
        "2042766920",
        "1998992501",
        "2001748738"
    ]
},{
    "id": "2099918622",
    "title": "Severe acute respiratory syndrome: radiographic and CT findings.",
    "abstract": "OBJECTIVE. We review the radiographic and CT findings in the lungs of 12 patients with severe acute respiratory syndrome (SARS) in an effort to describe the most common radiologic findings for this disease.CONCLUSION. The most common radiographic findings of SARS patients at presentation are unilateral or bilateral ground-glass opacities or focal unilateral or bilateral areas of consolidation. In hospitalized SARS patients, the abnormalities tend to progress to bilateral air-space consolidation. CT may reveal parenchymal disease in patients whose radiographs show normal results.",
    "date": "2003",
    "authors": [
        "Nestor L. M\u00fcller",
        "Gaik C. Ooi",
        "Pek Lan Khong",
        "Savvas Nicolaou"
    ],
    "related_topics": [
        "Surgery",
        "Radiography",
        "Respiratory system"
    ],
    "citation_count": "130",
    "reference_count": "3",
    "references": [
        "2097858003",
        "2019141077",
        "2060289833"
    ]
},{
    "id": "2098293966",
    "title": "Crazy-paving appearance at thin-section CT: spectrum of disease and pathologic findings.",
    "abstract": "PURPOSE: To determine the spectrum of diseases associated with a fine reticular pattern superimposed on areas of ground-glass opacity (ie, \u201ccrazy-paving\u201d appearance) at thin-section computed tomography (CT) and to determine the underlying pathologic features. MATERIALS AND METHODS: In the in vivo study, the cases of 46 patients (21 male, 25 female; age range, 13\u201382 years) were retrospectively reviewed, with special attention paid to the size and extent of the reticular network. In the in vitro study, the thin-section CT findings in 20 inflated and fixed lungs were precisely correlated with the gross appearance, contact radiograph findings, stereomicroscopic views, and histologic findings. RESULTS: In the in vivo study, 15 different diseases were identified, including alveolar proteinosis, adult respiratory distress syndrome, acute interstitial pneumonia, diffuse alveolar damage superimposed on usual interstitial pneumonia, and drug-induced pneumonitis. In the in vitro study, the fine networks at pathologi...",
    "date": "1999",
    "authors": [
        "Takeshi Johkoh",
        "Harumi Itoh",
        "Nestor L. M\u00fcller",
        "Kazuya Ichikado",
        "Hironobu Nakamura",
        "Junpei Ikezoe",
        "Masanori Akira",
        "Tomofumi Nagareda"
    ],
    "related_topics": [
        "Diffuse alveolar damage",
        "Acute Interstitial Pneumonia",
        "Usual interstitial pneumonia"
    ],
    "citation_count": "294",
    "reference_count": "15",
    "references": [
        "2145920814",
        "2151075538",
        "1975309489",
        "2053611435",
        "2019141077",
        "2022390446",
        "2020151328",
        "2006280550",
        "1995657924",
        "2087456097"
    ]
},{
    "id": "2097858003",
    "title": "SARS: imaging of severe acute respiratory syndrome.",
    "abstract": "",
    "date": "2003",
    "authors": [
        "Savvas Nicolaou",
        "Nizar A. Al-Nakshabandi",
        "Nestor L. M\u00fcller"
    ],
    "related_topics": [
        "Respiratory distress",
        "Respiratory disease",
        "Artificial respiration"
    ],
    "citation_count": "79",
    "reference_count": "0",
    "references": []
},{
    "id": "2111742711",
    "title": "CT correlation with outcomes in 15 patients with acute Middle East respiratory syndrome coronavirus.",
    "abstract": "OBJECTIVE. The purpose of this article is to retrospectively analyze chest CT findings for 15 patients with Middle East respiratory syndrome coronavirus and to identify features associated with survival. MATERIALS AND METHODS. Patients were assigned to group 1 if they died (n = 9) and to group 2 if they made a full recovery (n = 6). Two reviewers scored chest radiographs and CT examinations for segmental involvement, ground-glass opacities, consolidation, and interstitial thickening. RESULTS. Eight patients had ground-glass opacity (53%), five had ground-glass and consolidation in combination (33%), five had pleural effusion (33%), and four patients had interlobular thickening (27%). Of 281 CT findings, 151 (54%) were peripheral, 68 (24%) were central, and 62 (22%) had a mixed location. The number of involved lung segments was higher in group 1. The lower lobe was more commonly involved (mean, 12.2 segments) than in the upper and middle lobes combined (mean, 6.3 segments). The mean number of lung segments...",
    "date": "2015",
    "authors": [
        "Karuna M. Das",
        "Edward Y. Lee",
        "Mushira A. Enani",
        "Suhaila E. AlJawder",
        "Rajvir Singh",
        "Salman Bashir",
        "Nizar Al-Nakshbandi",
        "Khalid AlDossari",
        "Sven G. Larsson"
    ],
    "related_topics": [
        "Pleural effusion",
        "Lung",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "137",
    "reference_count": "28",
    "references": [
        "2166867592",
        "2006434809",
        "2102634410",
        "2109520345",
        "2140143765",
        "2112136274",
        "2056155046",
        "2113438513",
        "2080286891",
        "2093815354"
    ]
},{
    "id": "3135910874",
    "title": "Focus on a 2019-novel coronavirus (SARS-CoV-2).",
    "abstract": "A new coronavirus, severe acute respiratory syndrome coronavirus 2, was first discovered in Wuhan, China, in December 2019. As of April 7, 2020, the new coronavirus has spread quickly to 184 countries and aroused the attention of the entire world. No targeted drugs have yet been available for intervention and treatment of this virus. The sharing of academic information is crucial to risk assessment and control activities in outbreak countries. In this review, we summarize the epidemiological, genetic and clinical characteristics of the virus as well as laboratory testing and treatments to understand the nature of the virus. We hope this review will be helpful to prevent viral infections in outbreak countries and regions.",
    "date": "2019",
    "authors": [
        "Ling-Pu Zhang",
        "Meixian Wang",
        "Yanping Wang",
        "Jun Zhu",
        "Nannan Zhang"
    ],
    "related_topics": [
        "Coronavirus",
        "Outbreak",
        "Virus"
    ],
    "citation_count": "9",
    "reference_count": "0",
    "references": []
},{
    "id": "3009749892",
    "title": "Novel Immunoglobulin Domain Proteins Provide Insights into Evolution and Pathogenesis Mechanisms of SARS-Related Coronaviruses",
    "abstract": "A novel coronavirus (SARS-CoV-2) is the causative agent of an emergent severe respiratory disease (COVID-19) in humans that is threatening to result in a global health crisis. By using genomic, sequence, structural and evolutionary analysis, we show that Alpha- and Beta-CoVs possess several novel families of immunoglobulin (Ig) domain proteins, including ORF8 and ORF7a from SARS-related coronaviruses and two protein groups from certain Alpha-CoVs. Among them, ORF8 is distinguished in being rapidly evolving, possessing a unique insert and a hypervariable position among SARS-CoV-2 genomes in its predicted ligand-binding groove. We also uncover many Ig proteins from several metazoan viruses which are distinct in sequence and structure but share an architecture comparable to that of CoV Ig domain proteins. Hence, we propose that deployment of Ig domain proteins is a widely-used strategy by viruses, and SARS-CoV-2 ORF8 is a potential pathogenicity factor which evolves rapidly to counter the immune response and facilitate the transmission between hosts.",
    "date": "2020",
    "authors": [
        "Yongjun Tan",
        "Theresa Schneider",
        "Matthew Leong",
        "L Aravind",
        "Dapeng Zhang"
    ],
    "related_topics": [
        "Immunoglobulin domain",
        "Coronavirus",
        "Genome"
    ],
    "citation_count": "10",
    "reference_count": "53",
    "references": [
        "3001118548",
        "3001897055",
        "3002108456",
        "3004280078",
        "2152207030",
        "2311203695",
        "2158714788",
        "2903899730",
        "2166867592",
        "2132926880"
    ]
},{
    "id": "2149661971",
    "title": "An Official American Thoracic Society/European Respiratory Society Statement: Update of the International Multidisciplinary Classification of the Idiopathic Interstitial Pneumonias",
    "abstract": "Background: In 2002 the American Thoracic Society/European Respiratory Society (ATS/ERS) classification of idiopathic interstitial pneumonias (IIPs) defined seven specific entities, and provided standardized terminology and diagnostic criteria. In addition, the historical \u201cgold standard\u201d of histologic diagnosis was replaced by a multidisciplinary approach. Since 2002 many publications have provided new information about IIPs.Purpose: The objective of this statement is to update the 2002 ATS/ERS classification of IIPs.Methods: An international multidisciplinary panel was formed and developed key questions that were addressed through a review of the literature published between 2000 and 2011.Results: Substantial progress has been made in IIPs since the previous classification. Nonspecific interstitial pneumonia is now better defined. Respiratory bronchiolitis\u2013interstitial lung disease is now commonly diagnosed without surgical biopsy. The clinical course of idiopathic pulmonary fibrosis and nonspecific inte...",
    "date": "2013",
    "authors": [
        "William D. Travis",
        "Ulrich Costabel",
        "David M. Hansell",
        "Talmadge E. King",
        "David A. Lynch",
        "Andrew G. Nicholson",
        "Christopher J. Ryerson",
        "Jay H. Ryu",
        "Mois\u00e9s Selman",
        "Athol U. Wells",
        "Jurgen Behr",
        "Demosthenes Bouros",
        "Kevin K. Brown",
        "Thomas V. Colby",
        "Harold R. Collard",
        "Carlos Robalo Cordeiro",
        "Vincent Cottin",
        "Bruno Crestani",
        "Marjolein Drent",
        "Rosalind F. Dudden",
        "Jim Egan",
        "Kevin Flaherty",
        "Cory Hogaboam",
        "Yoshikazu Inoue",
        "Takeshi Johkoh",
        "Dong Soon Kim",
        "Masanori Kitaichi",
        "James Loyd",
        "Fernando J. Martinez",
        "Jeffrey Myers",
        "Shandra Protzko",
        "Ganesh Raghu",
        "Luca Richeldi",
        "Nicola Sverzellati",
        "Jeffrey Swigris",
        "Dominique Valeyre"
    ],
    "related_topics": [
        "Non-specific interstitial pneumonia",
        "Idiopathic interstitial pneumonia",
        "Idiopathic pulmonary fibrosis"
    ],
    "citation_count": "2,410",
    "reference_count": "165",
    "references": [
        "2167383172",
        "2416914730",
        "2157869208",
        "1985846684",
        "2167189518",
        "2169324488",
        "2113777102",
        "2166267091",
        "2108406461",
        "2121910720"
    ]
},{
    "id": "2109520345",
    "title": "Clinical Course and Outcomes of Critically Ill Patients With Middle East Respiratory Syndrome Coronavirus Infection",
    "abstract": "In a study of patients hospitalized with suspected Middle East respiratory syndrome coronavirus infection, those with confirmed disease had preexisting comorbid conditions and required mechanical v...",
    "date": "2014",
    "authors": [
        "Yaseen M. Arabi",
        "Ahmed A. Arifi",
        "Hanan H. Balkhy",
        "Hani Najm",
        "Abdulaziz S. Aldawood",
        "Alaa Ghabashi",
        "Hassan Hawa",
        "Adel Alothman",
        "Abdulaziz Khaldi",
        "Basel Al Raiy"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Coronavirus",
        "Middle East respiratory syndrome"
    ],
    "citation_count": "546",
    "reference_count": "36",
    "references": [
        "2166867592",
        "2597070792",
        "2006434809",
        "2106923828",
        "1898928487",
        "2045002682",
        "2115186092",
        "2140143765",
        "2134592673",
        "2320873518"
    ]
},{
    "id": "2162112824",
    "title": "Age- and Sex-Specific Mortality Associated With the 1918\u20131919 Influenza Pandemic in Kentucky",
    "abstract": "Background.\u2003The reasons for the unusual age-specific mortality patterns of the 1918\u20131919 influenza pandemic remain unknown. Here we characterize pandemic-related mortality by single year of age in a unique statewide Kentucky data set and explore breakpoints in the age curves. Methods.\u2003Individual death certificates from Kentucky during 1911\u20131919 were abstracted by medically trained personnel. Pandemic-associated excess mortality rates were calculated by subtracting observed rates during pandemic months from rates in previous years, separately for each single year of age and by sex. Results.\u2003The age profile of excess mortality risk in fall 1918 was characterized by a maximum among infants, a minimum at ages 9\u201310 years, a maximum at ages 24\u201326 years, and a second minimum at ages 56\u201359 years. The excess mortality risk in young adults had been greatly attenuated by winter 1919. The age breakpoints of mortality risk did not differ between males and females. Conclusions.\u2003The observed mortality breakpoints in male and female cohorts born during 1859\u20131862, 1892\u20131894, and 1908\u20131909 did not coincide with known dates of historical pandemics. The atypical age mortality patterns of the 1918\u20131919 pandemic cannot be explained by military crowding, war-related factors, or prior immunity alone and likely result from a combination of unknown factors.",
    "date": "2013",
    "authors": [
        "C\u00e9cile Viboud",
        "Jana Eisenstein",
        "Ann H. Reid",
        "Thomas A. Janczewski",
        "David M. Morens",
        "Jeffery K. Taubenberger"
    ],
    "related_topics": [
        "Young adult",
        "Pandemic",
        "Demography"
    ],
    "citation_count": "85",
    "reference_count": "48",
    "references": [
        "2068592034",
        "2169497667",
        "1996311210",
        "2167944937",
        "2104148197",
        "2119611042",
        "2045934762",
        "2026783289",
        "2122096836",
        "2073234751"
    ]
},{
    "id": "2156614913",
    "title": "The Epidemiology of Severe Acute Respiratory Syndrome in the 2003 Hong Kong Epidemic: An Analysis of All 1755 Patients",
    "abstract": "This analysis of 1755 cases from the Hong Kong epidemic of severe acute respiratory syndrome (SARS) found that most patients became infected in hospitals and residential buildings. The observed pat...",
    "date": "2004",
    "authors": [
        "Gabriel M Leung",
        "Anthony J Hedley",
        "Lai-Ming Ho",
        "Patsy Chau",
        "Irene O L Wong",
        "Thuan Q Thach",
        "Azra C Ghani",
        "Christl A Donnelly",
        "Christophe Fraser",
        "Steven Riley",
        "Neil M Ferguson",
        "Roy M Anderson",
        "Thomas Tsang",
        "Pak-Yin Leung",
        "Vivian Wong",
        "Jane C K Chan",
        "Eva Tsui",
        "Su-Vui Lo",
        "Tai-Hing Lam"
    ],
    "related_topics": [
        "Epidemiology",
        "Respiratory disease",
        "Public health"
    ],
    "citation_count": "338",
    "reference_count": "30",
    "references": [
        "2131262274",
        "2129542667",
        "2147166346",
        "2118502261",
        "2134061616",
        "2163627712",
        "1990049863",
        "2141877163",
        "2096145431",
        "2140763962"
    ]
},{
    "id": "2794573360",
    "title": "Fatal swine acute diarrhoea syndrome caused by an HKU2-related coronavirus of bat origin.",
    "abstract": "Cross-species transmission of viruses from wildlife animal reservoirs poses a marked threat to human and animal health 1 . Bats have been recognized as one of the most important reservoirs for emerging viruses and the transmission of a coronavirus that originated in bats to humans via intermediate hosts was responsible for the high-impact emerging zoonosis, severe acute respiratory syndrome (SARS) 2\u201310 . Here we provide virological, epidemiological, evolutionary and experimental evidence that a novel HKU2-related bat coronavirus, swine acute diarrhoea syndrome coronavirus (SADS-CoV), is the aetiological agent that was responsible for a large-scale outbreak of fatal disease in pigs in China that has caused the death of 24,693 piglets across four farms. Notably, the outbreak began in Guangdong province in the vicinity of the origin of the SARS pandemic. Furthermore, we identified SADS-related CoVs with 96\u201398% sequence identity in 9.8% (58 out of 591) of anal swabs collected from bats in Guangdong province during 2013\u20132016, predominantly in horseshoe bats (Rhinolophus spp.) that are known reservoirs of SARS-related CoVs. We found that there were striking similarities between the SADS and SARS outbreaks in geographical, temporal, ecological and aetiological settings. This study highlights the importance of identifying coronavirus diversity and distribution in bats to mitigate future outbreaks that could threaten livestock, public health and economic growth.",
    "date": "2018",
    "authors": [
        "Peng Zhou",
        "Hang Fan",
        "Tian Lan",
        "Xing-Lou Yang",
        "Wei-Feng Shi",
        "Wei Zhang",
        "Yan Zhu",
        "Ya-Wei Zhang",
        "Qing-Mei Xie",
        "Shailendra Mani",
        "Xiao-Shuang Zheng",
        "Bei Li",
        "Jin-Man Li",
        "Hua Guo",
        "Guang-Qian Pei",
        "Xiao-Ping An",
        "Jun-Wei Chen",
        "Ling Zhou",
        "Kai-Jie Mai",
        "Zi-Xian Wu",
        "Di Li",
        "Danielle E. Anderson",
        "Li-Biao Zhang",
        "Shi-Yue Li",
        "Zhi-Qiang Mi",
        "Tong-Tong He",
        "Feng Cong",
        "Peng-Ju Guo",
        "Ren Huang",
        "Yun Luo",
        "Xiang-Ling Liu",
        "Jing Chen",
        "Yong Huang",
        "Qiang Sun",
        "Xiang-Li-Lan Zhang",
        "Yuan-Yuan Wang",
        "Shao-Zhen Xing",
        "Yan-Shan Chen",
        "Yuan Sun",
        "Juan Li",
        "Peter Daszak",
        "Lin-Fa Wang",
        "Zheng-Li Shi",
        "Yi-Gang Tong",
        "Jing-Yun Ma"
    ],
    "related_topics": [
        "Coronavirus",
        "Outbreak",
        "Zoonosis"
    ],
    "citation_count": "418",
    "reference_count": "27",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "1594700207",
        "1993577573",
        "2775086803",
        "2119111857",
        "2116586125",
        "1966238900",
        "2169198329"
    ]
},{
    "id": "2148822770",
    "title": "The Effectiveness of Convalescent Plasma and Hyperimmune Immunoglobulin for the Treatment of Severe Acute Respiratory Infections of Viral Etiology: A Systematic Review and Exploratory Meta-analysis",
    "abstract": "Background: Administration of convalescent plasma, serum, or hyperimmune immunoglobulin may be of clinical benefit for treatment of severe acute respiratory infections (SARIs) of viral etiology. We conducted a systematic review and exploratory meta-analysis to assess the overall evidence. Methods: Healthcare databases and sources of grey literature were searched in July 2013. All records were screened against the protocol eligibility criteria, using a 3-stage process. Data extraction and risk of bias assessments were undertaken. Results: We identified 32 studies of SARS coronavirus infection and severe influenza. Narrative analyses revealed consistent evidence for a reduction in mortality, especially when convalescent plasma is administered early after symptom onset. Exploratory post hoc meta-analysis showed a statistically significant reduction in the pooled odds of mortality following treatment, compared with placebo or no therapy (odds ratio, 0.25; 95% confidence interval, .14\u2013.45; I(2) = 0%). Studies were commonly of low or very low quality, lacked control groups, and at moderate or high risk of bias. Sources of clinical and methodological heterogeneity were identified. Conclusions: Convalescent plasma may reduce mortality and appears safe. This therapy should be studied within the context of a well-designed clinical trial or other formal evaluation, including for treatment of Middle East respiratory syndrome coronavirus CoV infection.",
    "date": "2014",
    "authors": [
        "John Mair-Jenkins",
        "Maria Saavedra-Campos",
        "J. Kenneth Baillie",
        "Paul Cleary",
        "Fu-Meng Khaw",
        "Wei Shen Lim",
        "Sophia Makki",
        "Kevin D. Rooney",
        "Jonathan S. Nguyen-Van-Tam",
        "Charles R. Beck",
        "Ana L. P. Mateus",
        "Simone Reuter",
        "Jinho Shin",
        "Xiaolin Xu",
        "Dmitriy Pereyaslov",
        "Irina Papieva",
        "Anders Tegnell",
        "H\u00e9l\u00e8ne Englund",
        "\u00c5sa Elfving",
        "Rebecca Cox",
        "Kristin Greve-Isdahl Mohn",
        "Yingjie Feng Jenkins"
    ],
    "related_topics": [
        "Odds ratio",
        "Respiratory tract infections",
        "Meta-analysis"
    ],
    "citation_count": "555",
    "reference_count": "44",
    "references": [
        "2007872832",
        "2156098321",
        "2612891587",
        "1598602811",
        "2468996569",
        "2054076340",
        "1973269051",
        "2096238447",
        "28510732",
        "2057439500"
    ]
},{
    "id": "2015323375",
    "title": "The radiologic manifestations of H5N1 avian influenza.",
    "abstract": "Avian influenza is caused by the H5N1 subtype of the influenza A virus. Human transmission is either directly through close contact with infected birds usually poultry or their secretions. To date 178 people throughout South East Asia have been infected with 85 deaths. Patients usually present with a rapidly progressive pneumonia that can result in respiratory failure and acute respiratory distress syndrome. The chest radiograph therefore remains the most convenient and accessible imaging modality. Studies have shown that most radiographs are abnormal at the time of presentation with multifocal consolidation the commonest radiographic finding. During the course of disease, pleural effusions and cavitation can also develop. Consolidation that involves > or = 4 zones on presentation or at day 7 after the onset of symptoms and subsequent development of acute respiratory distress syndrome are generally associated with an adverse outcome. Chest CT examinations performed during the convalescent period have demonstrated persistent ground glass attenuation and segmental consolidation. Additional features included pseudocavitation, pneumatocoele formation, lymphadenopathy, and centrilobular nodules. Overall the appearances are suggestive of mild fibrosis.",
    "date": "2006",
    "authors": [
        "Nagmi R Qureshi",
        "Tran T Hien",
        "Jeremy Farrar",
        "Fergus V Gleeson"
    ],
    "related_topics": [
        "Chest radiograph",
        "Pneumonia",
        "Respiratory failure"
    ],
    "citation_count": "78",
    "reference_count": "17",
    "references": [
        "2162384187",
        "2116682907",
        "2072237100",
        "2052374402",
        "2133197143",
        "2150047295",
        "2088402140",
        "1988436330",
        "2124122135",
        "1978266690"
    ]
},{
    "id": "2789752210",
    "title": "Comparison of patients with avian influenza A (H7N9) and influenza A (H1N1) complicated by acute respiratory distress syndrome.",
    "abstract": "The aim of this study was to compare the clinical features of patients with avian influenza A (H7N9) and influenza A (H1N1) complicated by acute respiratory distress syndrome (ARDS).The clinical data of 18 cases of H7N9 and 26 cases of H1N1 with ARDS were collected and compared in the respiratory intensive care unit (RICU) of Fuzhou Pulmonary Hospital of Fujian from March 2014 to December 2016.Patients with H7N9 had a higher acute physiology and chronic health evaluation-II score (P < .05) and lung injury score (P < .05). The rates of coexisting diabetes mellitus, hyperpyrexia, and bloody sputum production were significantly higher in the H7N9 group than in the H1N1 group (P < .05). The H7N9 group had a longer duration of viral shedding from the onset of illness (P < .05) and from the initiation of antiviral therapy (P < .05) to a negative viral test result than the H1N1 group. Patients with H7N9 had higher rates of invasive mechanical ventilation; serious complications, including alimentary tract hemorrhage, pneumothorax or septum emphysema, hospital-acquired pneumonia (HAP) and multiple organ dysfunction syndrome (MODS); and hospital mortality (P < .05). At the 6th month of follow-up, the rates of bronchiectasia, reticular opacities, fibrous stripes, and patchy opacities on chest computed tomography (CT) were significantly higher in the H7N9 group than in the H1N1 group (P < .05). Based on multiple logistic regression analysis, H7N9 influenza viral infection was associated with a higher risk of the presence of severe ARDS than H1N1 influenza viral infection (odds ratio 8.29, 95% confidence interval [CI] 1.53-44.94; P < .05).Compared to patients with H1N1, patients with H7N9 complicated by ARDS had much more severe disease. During long-term follow-up, more changes in pulmonary fibrosis were observed in patients with H7N9 than in patients with H1N1 during the convalescent stage.",
    "date": "2018",
    "authors": [
        "Hongyan Li",
        "Heng Weng",
        "Changqing Lan",
        "Hongying Zhang",
        "Xinhang Wang",
        "Jianguang Pan",
        "Lulu Chen",
        "Jinbao Huang"
    ],
    "related_topics": [
        "ARDS",
        "Pneumonia",
        "Lung injury"
    ],
    "citation_count": "15",
    "reference_count": "19",
    "references": [
        "1803784511",
        "2106173155",
        "2159340685",
        "2162080474",
        "2155876639",
        "1421343027",
        "2135365914",
        "2088582712",
        "2557566431",
        "2074704631"
    ]
},{
    "id": "1922522683",
    "title": "Initial HRCT findings of novel influenza A (H1N1) infection",
    "abstract": "Please cite this paper as: Yuan et al. (2012) Initial HRCT findings of novel influenza A (H1N1) infection. Influenza and Other Respiratory Viruses 6(601), e114\u2013e119. Objectives\u2002 The aim of our study was to describe the presentation and illustrate the imaging features of chest high-resolution computed tomography (HRCT) of patients with novel influenza A (H1N1) virus infection. Methods\u2002 Data were collected from 163 hospitalized patients between November 2009 and March 2011, who fulfilled the clinical criteria for H1N1 influenza infection and underwent HRCT examinations within 24 hours of admission. Results\u2002 Abnormal findings were observed in 40\u00b75% of the patients. The patients with positive imaging findings were significantly older than patients with normal HRCT findings (P = 0\u00b702). The most common finding was ground-glass opacity (GGO) (n = 35). Interlobular septal thickening (n = 31) and centrilobular nodules (n = 30) were the second most frequent findings. Other common findings were consolidation, reticulation, and linear shadow. The most common imaging finding for lung involvement was GGO with a patchy pattern. Pulmonary involvement of the disease may be extensive and variable, but the total volume of affected lung was mostly <1 lobe. Conclusion\u2002 The baseline HRCT may be valuable and suggestive even for non-severe H1N1 infections. When a severe case or a evolution is suspected, chest CT could be essential both for determining the precise extent of parenchymal damage and for monitoring its evolution.",
    "date": "2012",
    "authors": [
        "Ying Yuan",
        "Xiao-Feng Tao",
        "Yu-Xin Shi",
        "Shi-Yuan Liu",
        "Ji-Quan Chen"
    ],
    "related_topics": [
        "Lung",
        "Radiology",
        "Young adult"
    ],
    "citation_count": "17",
    "reference_count": "16",
    "references": [
        "2312463092",
        "2162080474",
        "2508794604",
        "2113438513",
        "1991159506",
        "1999030559",
        "2119467724",
        "2162791897",
        "2028910229",
        "1526790442"
    ]
},{
    "id": "1997020575",
    "title": "Severe acute respiratory syndrome: thin-section computed tomography features, temporal changes, and clinicoradiologic correlation during the convalescent period.",
    "abstract": "Objective: To evaluate thin-section computed tomography findings of patients with severe acute respiratory syndrome (SARS) in the convalescent period and to correlate the results with clinical parameters and lung functiontests. Methods: Ninety-nine severe acute respiratory syndrome patients with persistent changes on follow-up chest radiography were included. One hundred seventy computed tomography examinations at baseline (n = 70), 3 months (n = 56), and 6 months (n = 44) were retrospectively evaluated to determine the extent of ground-glass opacification, reticulation, and total parenchymal involvement. Patients' demographic information, clinical information during treatment, and results of lung function tests at 3 and 6 months were correlated with computed tomography findings. Results: A significant serial improvement in the extent of overall ground-glass opacification, overall reticulation, and total parenchymal involvement was observed (P < 0.01). Advanced age, previous intensive care unit admission, mechanical ventilation, alternative treatment, higher peak lactate dehydrogenase, and peak radiographic involvement during treatment showed a positive correlation with overall reticulation and total parenchymal involvement at 6 months. There was a significant negative correlation between overall reticulation and total parenchymal involvement with diffusion capacity adjusted for hemoglobin at 3 and 6 months (P < 0.01). Conclusion: Lung changes on thin-section computed tomography of severe acute respiratory syndrome patients improved with time during the convalescent period and showed a significant correlation with advanced age, parameters indicating severe illness, and diffusion capacity adjusted for hemoglobin on follow-up.",
    "date": "2004",
    "authors": [
        "Ka-tak Wong",
        "Gregory E Antonio",
        "David S C Hui",
        "Catherine Ho",
        "Po-nin Chan",
        "Wing-hung Ng",
        "Kwok-kuen Shing",
        "Alan Wu",
        "Nelson Lee",
        "Florence Yap",
        "Gavin M Joynt",
        "Joseph J Y Sung",
        "Anil T Ahuja"
    ],
    "related_topics": [
        "Pulmonary function testing",
        "Mechanical ventilation",
        "Lung"
    ],
    "citation_count": "32",
    "reference_count": "18",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2125251240",
        "2056155046",
        "2080286891",
        "2017898137",
        "2151996610"
    ]
},{
    "id": "2285897784",
    "title": "Isolation and Characterization of a Novel Bat Coronavirus Closely Related to the Direct Progenitor of Severe Acute Respiratory Syndrome Coronavirus",
    "abstract": "We report the isolation and characterization of a novel bat coronavirus which is much closer to the severe acute respiratory syndrome coronavirus (SARS-CoV) in genomic sequence than others previously reported, particularly in its S gene. Cell entry and susceptibility studies indicated that this virus can use ACE2 as a receptor and infect animal and human cell lines. Our results provide further evidence of the bat origin of the SARS-CoV and highlight the likelihood of future bat coronavirus emergence in humans.",
    "date": "2016",
    "authors": [
        "Xing-Lou Yang",
        "Ben Hu",
        "Bo Wang",
        "Mei-Niang Wang",
        "Qian Zhang",
        "Wei Zhang",
        "Li-Jun Wu",
        "Xing-Yi Ge",
        "Yun-Zhi Zhang",
        "Peter Daszak",
        "Lin-Fa Wang",
        "Zheng-Li Shi"
    ],
    "related_topics": [
        "Virus",
        "Virology",
        "Gene"
    ],
    "citation_count": "167",
    "reference_count": "14",
    "references": [
        "1993577573",
        "2195009776",
        "2103503670",
        "2134061616",
        "2140338292",
        "2126707939",
        "2101063972",
        "2255897570",
        "1990059132",
        "2126080553"
    ]
},{
    "id": "2200668708",
    "title": "Bat origin of human coronaviruses",
    "abstract": "Bats have been recognized as the natural reservoirs of a large variety of viruses. Special attention has been paid to bat coronaviruses as the two emerging coronaviruses which have caused unexpected human disease outbreaks in the 21st century, Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) and Middle East Respiratory Syndrome Coronavirus (MERS-CoV), are suggested to be originated from bats. Various species of horseshoe bats in China have been found to harbor genetically diverse SARS-like coronaviruses. Some strains are highly similar to SARS-CoV even in the spike protein and are able to use the same receptor as SARS-CoV for cell entry. On the other hand, diverse coronaviruses phylogenetically related to MERS-CoV have been discovered worldwide in a wide range of bat species, some of which can be classified to the same coronavirus species as MERS-CoV. Coronaviruses genetically related to human coronavirus 229E and NL63 have been detected in bats as well. Moreover, intermediate hosts are believed to play an important role in the transmission and emergence of these coronaviruses from bats to humans. Understanding the bat origin of human coronaviruses is helpful for the prediction and prevention of another pandemic emergence in the future.",
    "date": "2015",
    "authors": [
        "Ben Hu",
        "Xingyi Ge",
        "Lin Fa Wang",
        "Zhengli Shi"
    ],
    "related_topics": [
        "Coronavirus",
        "Human coronavirus 229E",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "332",
    "reference_count": "106",
    "references": [
        "2166867592",
        "1993577573",
        "2565805236",
        "2119111857",
        "2112147913",
        "2149508011",
        "2116586125",
        "1966238900",
        "2169198329",
        "2160011624"
    ]
},{
    "id": "2151461700",
    "title": "Duration of antibody responses after severe acute respiratory syndrome",
    "abstract": "Among 176 patients who had had severe acute respiratory syndrome (SARS), SARS-specific antibodies were maintained for an average of 2 years, and significant reduction of immunoglobulin G-positive percentage and titers occurred in the third year. Thus, SARS patients might be susceptible to reinfection >or=3 years after initial exposure.",
    "date": "2007",
    "authors": [
        "Li Ping Wu",
        "Nai Chang Wang",
        "Yi Hua Chang",
        "Xiang Yi Tian",
        "Dan Yu Na",
        "Li Yuan Zhang",
        "Lei Zheng",
        "Tao Lan",
        "Lin Fa Wang",
        "Guo Dong Liang"
    ],
    "related_topics": [
        "Respiratory system",
        "Immunoglobulin G",
        "Antibody"
    ],
    "citation_count": "310",
    "reference_count": "14",
    "references": [
        "2103503670",
        "2134061616",
        "2140338292",
        "2126707939",
        "1990059132",
        "2141787825",
        "2156368174",
        "2140734584",
        "2121643748",
        "2115484790"
    ]
},{
    "id": "2168446943",
    "title": "Newly discovered coronavirus as the primary cause of severe acute respiratory syndrome",
    "abstract": "Summary Background The worldwide outbreak of severe acute respiratory syndrome (SARS) is associated with a newly discovered coronavirus, SARS-associated coronavirus (SARSCoV). We did clinical and experimental studies to assess the role of this virus in the cause of SARS. Methods We tested clinical and postmortem samples from 436 SARS patients in six countries for infection with SARSCoV, human metapneumovirus, and other respiratory pathogens. We infected four cynomolgus macaques (Macaca fascicularis) with SARS-CoV in an attempt to replicate SARS and did necropsies on day 6 after infection. Findings SARS-CoV infection was diagnosed in 329 (75%) of 436 patients fitting the case definition of SARS; human metapneumovirus was diagnosed in 41 (12%) of 335, and other respiratory pathogens were diagnosed only sporadically. SARS-CoV was, therefore, the most likely causal agent of SARS. The four SARS-CoV-infected macaques excreted SARS-CoV from nose, mouth, and pharynx from 2 days after infection. Three of four macaques developed diffuse alveolar damage, similar to that in SARS patients, and characterised by epithelial necrosis, serosanguineous exudate, formation of hyaline membranes, type 2 pneumocyte hyperplasia, and the presence of syncytia. SARS-CoV was detected in pneumonic areas by virus isolation and RT-PCR, and was localised to alveolar epithelial cells and syncytia by immunohistochemistry and transmission electron microscopy.",
    "date": "2003",
    "authors": [
        "Thijs Kuiken",
        "Ron A M Fouchier",
        "Martin Schutten",
        "Guus F Rimmelzwaan",
        "Geert van Amerongen",
        "Debby van Riel",
        "Jon D Laman",
        "Ton de Jong",
        "Gerard van Doornum",
        "Wilina Lim",
        "Ai Ee Ling",
        "Paul K S Chan",
        "John S Tam",
        "Maria C Zambon",
        "Robin Gopal",
        "Christian Drosten",
        "Sylvie van der Werf",
        "Nicolas Escriou",
        "Jean-Claude Manuguerra",
        "Klaus St\u00f6hr",
        "J S Malik Peiris",
        "Albert D M E Osterhaus"
    ],
    "related_topics": [
        "Coronavirus",
        "Human metapneumovirus",
        "Diffuse alveolar damage"
    ],
    "citation_count": "1,094",
    "reference_count": "28",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2100820722",
        "2125251240",
        "2170881661",
        "1523998792",
        "1971054351"
    ]
},{
    "id": "2158118659",
    "title": "The clinical pathology of severe acute respiratory syndrome (SARS): a report from China.",
    "abstract": "In order to investigate the clinical pathology of severe acute respiratory syndrome (SARS), the autopsies of three patients who died from SARS in Nan Fang Hospital Guangdong, China were studied retrospectively. Routine haematoxylin and eosin (H&E) staining was used to study all of the tissues from the three cases. The lung tissue specimens were studied further with Macchiavello staining, viral inclusion body staining, reticulin staining, PAS staining, immunohistochemistry, ultrathin sectioning and staining, light microscopy, and transmission electron microscopy. The first symptom was hyperpyrexia in all three cases, followed by progressive dyspnoea and lung field shadowing. The pulmonary lesions included bilateral extensive consolidation, localized haemorrhage and necrosis, desquamative pulmonary alveolitis and bronchitis, proliferation and desquamation of alveolar epithelial cells, exudation of protein and monocytes, lymphocytes and plasma cells in alveoli, hyaline membrane formation, and viral inclusion bodies in alveolar epithelial cells. There was also massive necrosis of splenic lymphoid tissue and localized necrosis in lymph nodes. Systemic vasculitis included oedema, localized fibrinoid necrosis, and infiltration of monocytes, lymphocytes, and plasma cells into vessel walls in the heart, lung, liver, kidney, adrenal gland, and the stroma of striated muscles. Thrombosis was present in small veins. Systemic toxic changes included degeneration and necrosis of the parenchyma cells in the lung, liver, kidney, heart, and adrenal gland. Electron microscopy demonstrated clusters of viral particles, consistent with coronavirus, in lung tissue. SARS is a systemic disease that injures many organs. The lungs, immune organs, and systemic small vessels are the main targets of virus attack, so that extensive consolidation of the lung, diffuse alveolar damage with hyaline membrane formation, respiratory distress, and decreased immune function are the main causes of death.",
    "date": "2003",
    "authors": [
        "Yanqing Ding",
        "Huijun Wang",
        "Hong Shen",
        "Zhuguo Li",
        "Jian Geng",
        "Huixia Han",
        "Junjie Cai",
        "Xin Li",
        "Wei Kang",
        "Desheng Weng",
        "Yaodan Lu",
        "Dehua Wu",
        "Li He",
        "Kaitai Yao"
    ],
    "related_topics": [
        "Fibrinoid necrosis",
        "Diffuse alveolar damage",
        "Lung"
    ],
    "citation_count": "692",
    "reference_count": "6",
    "references": [
        "2104548316",
        "2100820722",
        "2125251240",
        "2463755683",
        "2027518730",
        "2143922127"
    ]
},{
    "id": "3005679569",
    "title": "Clinical characteristics and intrauterine vertical transmission potential of COVID-19 infection in nine pregnant women: a retrospective review of medical records.",
    "abstract": "Summary Background Previous studies on the pneumonia outbreak caused by the 2019 novel coronavirus disease (COVID-19) were based on information from the general population. Limited data are available for pregnant women with COVID-19 pneumonia. This study aimed to evaluate the clinical characteristics of COVID-19 in pregnancy and the intrauterine vertical transmission potential of COVID-19 infection. Methods Clinical records, laboratory results, and chest CT scans were retrospectively reviewed for nine pregnant women with laboratory-confirmed COVID-19 pneumonia (ie, with maternal throat swab samples that were positive for severe acute respiratory syndrome coronavirus 2 [SARS-CoV-2]) who were admitted to Zhongnan Hospital of Wuhan University, Wuhan, China, from Jan 20 to Jan 31, 2020. Evidence of intrauterine vertical transmission was assessed by testing for the presence of SARS-CoV-2 in amniotic fluid, cord blood, and neonatal throat swab samples. Breastmilk samples were also collected and tested from patients after the first lactation. Findings All nine patients had a caesarean section in their third trimester. Seven patients presented with a fever. Other symptoms, including cough (in four of nine patients), myalgia (in three), sore throat (in two), and malaise (in two), were also observed. Fetal distress was monitored in two cases. Five of nine patients had lymphopenia ( Interpretation The clinical characteristics of COVID-19 pneumonia in pregnant women were similar to those reported for non-pregnant adult patients who developed COVID-19 pneumonia. Findings from this small group of cases suggest that there is currently no evidence for intrauterine infection caused by vertical transmission in women who develop COVID-19 pneumonia in late pregnancy. Funding Hubei Science and Technology Plan, Wuhan University Medical Development Plan.",
    "date": "2020",
    "authors": [
        "Huijun Chen",
        "Juanjuan Guo",
        "Chen Wang",
        "Fan Luo",
        "Xuechen Yu",
        "Wei Zhang",
        "Jiafu Li",
        "Dongchi Zhao",
        "Dan Xu",
        "Qing Gong",
        "Jing Liao",
        "Huixia Yang",
        "Wei Hou",
        "Yuanzhen Zhang"
    ],
    "related_topics": [
        "Pneumonia",
        "Sore throat",
        "Fetal distress"
    ],
    "citation_count": "3,118",
    "reference_count": "13",
    "references": [
        "3001118548",
        "3001897055",
        "3003668884",
        "3004280078",
        "3001195213",
        "2470646526",
        "2135421762",
        "3103590655",
        "2947642275",
        "2041013541"
    ]
},{
    "id": "3012756997",
    "title": "Temporal profiles of viral load in posterior oropharyngeal saliva samples and serum antibody responses during infection by SARS-CoV-2: an observational cohort study.",
    "abstract": "Summary Background Coronavirus disease 2019 (COVID-19) causes severe community and nosocomial outbreaks. Comprehensive data for serial respiratory viral load and serum antibody responses from patients infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) are not yet available. Nasopharyngeal and throat swabs are usually obtained for serial viral load monitoring of respiratory infections but gathering these specimens can cause discomfort for patients and put health-care workers at risk. We aimed to ascertain the serial respiratory viral load of SARS-CoV-2 in posterior oropharyngeal (deep throat) saliva samples from patients with COVID-19, and serum antibody responses. Methods We did a cohort study at two hospitals in Hong Kong. We included patients with laboratory-confirmed COVID-19. We obtained samples of blood, urine, posterior oropharyngeal saliva, and rectal swabs. Serial viral load was ascertained by reverse transcriptase quantitative PCR (RT-qPCR). Antibody levels against the SARS-CoV-2 internal nucleoprotein (NP) and surface spike protein receptor binding domain (RBD) were measured using EIA. Whole-genome sequencing was done to identify possible mutations arising during infection. Findings Between Jan 22, 2020, and Feb 12, 2020, 30 patients were screened for inclusion, of whom 23 were included (median age 62 years [range 37\u201375]). The median viral load in posterior oropharyngeal saliva or other respiratory specimens at presentation was 5\u00b72 log10 copies per mL (IQR 4\u00b71\u20137\u00b70). Salivary viral load was highest during the first week after symptom onset and subsequently declined with time (slope \u22120\u00b715, 95% CI \u22120\u00b719 to \u22120\u00b711; R2=0\u00b771). In one patient, viral RNA was detected 25 days after symptom onset. Older age was correlated with higher viral load (Spearman's \u03c1=0\u00b748, 95% CI 0\u00b7074\u20130\u00b775; p=0\u00b7020). For 16 patients with serum samples available 14 days or longer after symptom onset, rates of seropositivity were 94% for anti-NP IgG (n=15), 88% for anti-NP IgM (n=14), 100% for anti-RBD IgG (n=16), and 94% for anti-RBD IgM (n=15). Anti-SARS-CoV-2-NP or anti-SARS-CoV-2-RBD IgG levels correlated with virus neutralisation titre (R2>0\u00b79). No genome mutations were detected on serial samples. Interpretation Posterior oropharyngeal saliva samples are a non-invasive specimen more acceptable to patients and health-care workers. Unlike severe acute respiratory syndrome, patients with COVID-19 had the highest viral load near presentation, which could account for the fast-spreading nature of this epidemic. This finding emphasises the importance of stringent infection control and early use of potent antiviral agents, alone or in combination, for high-risk individuals. Serological assay can complement RT-qPCR for diagnosis. Funding Richard and Carol Yu, May Tam Mak Mei Yin, The Shaw Foundation Hong Kong, Michael Tong, Marina Lee, Government Consultancy Service, and Sanming Project of Medicine.",
    "date": "2020",
    "authors": [
        "Kelvin Kai Wang To",
        "Owen Tak Yin Tsang",
        "Wai Shing Leung",
        "Anthony Raymond Tam",
        "Tak Chiu Wu",
        "David Christopher Lung",
        "Cyril Chik Yan Yip",
        "Jian Piao Cai",
        "Jacky Man Chun Chan",
        "Thomas Shiu Hong Chik",
        "Daphne Pui Ling Lau",
        "Chris Yau Chung Choi",
        "Lin Lei Chen",
        "Wan Mui Chan",
        "Kwok Hung Chan",
        "Jonathan Daniel Ip",
        "Anthony Chin Ki Ng",
        "Rosana Wing Shan Poon",
        "Cui Ting Luo",
        "Vincent Chi Chung Cheng",
        "Jasper Fuk Woo Chan",
        "Ivan Fan Ngai Hung",
        "Zhiwei Chen",
        "Honglin Chen",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Viral load",
        "Respiratory tract infections",
        "Saliva"
    ],
    "citation_count": "2,284",
    "reference_count": "33",
    "references": [
        "3008827533",
        "3005079553",
        "3002539152",
        "3004280078",
        "3004318991",
        "3006961006",
        "3008962515",
        "3005690553",
        "2129542667",
        "3009219040"
    ]
},{
    "id": "3009314935",
    "title": "Clinical predictors of mortality due to COVID-19 based on an analysis of data of 150 patients from Wuhan, China.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Qiurong Ruan",
        "Kun Yang",
        "Wenxia Wang",
        "Lingyu Jiang",
        "Jianxin Song"
    ],
    "related_topics": [
        "Medicine",
        "Risk assessment",
        "Demography"
    ],
    "citation_count": "3,267",
    "reference_count": "3",
    "references": [
        "3002108456",
        "3007446911",
        "2902943881"
    ]
},{
    "id": "3013985547",
    "title": "Antibody Responses to SARS-CoV-2 in Patients With Novel Coronavirus Disease 2019.",
    "abstract": "BACKGROUND: The novel coronavirus SARS-CoV-2 is a newly emerging virus. The antibody response in infected patients remains largely unknown, and the clinical value of antibody testing has not been fully demonstrated. METHODS: 173 patients with SARS-CoV-2 infection were enrolled. Their serial plasma samples (n\u00e2\u0080\u0085=\u00e2\u0080\u0085535) collected during hospitalization were tested for total antibodies (Ab), IgM, and IgG against SARS-CoV-2. The dynamics of antibodies with disease progress were analyzed. RESULTS: Among 173 patients, the seroconversion rates for Ab, IgM, and IgG were 93.1%, 82.7%, and 64.7%, respectively. The reason for the negative antibody findings in 12 patients might be due to the lack of blood samples at the later stage of illness. The median seroconversion times for Ab, IgM, and then IgG were days 11, 12, and 4, respectively. The presence of antibodies was\u00e2\u0080\u0085<40% among patients within 1 week of onset, and rapidly increased to 100.0% (Ab), 94.3% (IgM), and 79.8% (IgG) by day 15 after onset. In contrast, RNA detectability decreased from 66.7% (58/87) in samples collected before day 7 to 45.5% (25/55) during days 15-39. Combining RNA and antibody detection significantly improved the sensitivity of pathogenic diagnosis for COVID-19 (P\u00e2\u0080\u0085<\u00e2\u0080\u0085.001), even in the early phase of 1 week from onset (P\u00e2\u0080\u0085=\u00e2\u0080\u0085.007). Moreover, a higher titer of Ab was independently associated with a worse clinical classification (P\u00e2\u0080\u0085=\u00e2\u0080\u0085.006). CONCLUSIONS: Antibody detection offers vital clinical information during the course of SARS-CoV-2 infection. The findings provide strong empirical support for the routine application of serological testing in the diagnosis and management of COVID-19 patients.",
    "date": "2020",
    "authors": [
        "Juanjuan Zhao",
        "Quan Yuan",
        "Haiyan Wang",
        "Wei Liu",
        "Xuejiao Liao",
        "Yingying Su",
        "Xin Wang",
        "Jing Yuan",
        "Tingdong Li",
        "Jinxiu Li",
        "Shen Qian",
        "Congming Hong",
        "Fuxiang Wang",
        "Yingxia Liu",
        "Zhaoqin Wang",
        "Qing He",
        "Zhiyong Li",
        "Bin He",
        "Tianying Zhang",
        "Yang Fu",
        "Shengxiang Ge",
        "Lei Liu",
        "Jun Zhang",
        "Ningshao Xia",
        "Zheng Zhang"
    ],
    "related_topics": [
        "Seroconversion",
        "Immunoglobulin M",
        "Immunoglobulin G"
    ],
    "citation_count": "1,865",
    "reference_count": "11",
    "references": [
        "3001118548",
        "3008827533",
        "3005079553",
        "3002108456",
        "3002539152",
        "3006961006",
        "2129542667",
        "3005827208",
        "2915839491",
        "3006592697"
    ]
},{
    "id": "3010233963",
    "title": "The Incubation Period of Coronavirus Disease 2019 (COVID-19) From Publicly Reported Confirmed Cases: Estimation and Application.",
    "abstract": "Using news reports and press releases from provinces, regions, and countries outside Wuhan, Hubei province, China, this analysis estimates the length of the incubation period of COVID-19 and its pu...",
    "date": "2020",
    "authors": [
        "Stephen A. Lauer",
        "Kyra H. Grantz",
        "Qifang Bi",
        "Forrest K. Jones",
        "Qulu Zheng",
        "Hannah R. Meredith",
        "Andrew S. Azman",
        "Nicholas G. Reich",
        "Justin Lessler"
    ],
    "related_topics": [
        "Infectious Disease Incubation Period",
        "Incubation period",
        "Serial interval"
    ],
    "citation_count": "4,104",
    "reference_count": "25",
    "references": [
        "3001118548",
        "3001897055",
        "3003668884",
        "3002539152",
        "3004239190",
        "3008818676",
        "3035011439",
        "3004912618",
        "3006065484",
        "3045614912"
    ]
},{
    "id": "3005212621",
    "title": "Remdesivir and chloroquine effectively inhibit the recently emerged novel coronavirus (2019-nCoV) in vitro.",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Manli Wang",
        "Ruiyuan Cao",
        "Leike Zhang",
        "Xinglou Yang",
        "Jia Liu",
        "Mingyue Xu",
        "Zhengli Shi",
        "Zhihong Hu",
        "Wu Zhong",
        "Gengfu Xiao"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Chloroquine"
    ],
    "citation_count": "4,937",
    "reference_count": "10",
    "references": [
        "3001118548",
        "2725497285",
        "2991491848",
        "2255243349",
        "2292021561",
        "1971292277",
        "2095807050",
        "2074095102",
        "2018534682",
        "1979536387"
    ]
},{
    "id": "3011610993",
    "title": "Risk Factors Associated With Acute Respiratory Distress Syndrome and Death in Patients With Coronavirus Disease 2019 Pneumonia in Wuhan, China",
    "abstract": "Importance Coronavirus disease 2019 (COVID-19) is an emerging infectious disease that was first reported in Wuhan, China, and has subsequently spread worldwide. Risk factors for the clinical outcomes of COVID-19 pneumonia have not yet been well delineated. Objective To describe the clinical characteristics and outcomes in patients with COVID-19 pneumonia who developed acute respiratory distress syndrome (ARDS) or died. Design, Setting, and Participants Retrospective cohort study of 201 patients with confirmed COVID-19 pneumonia admitted to Wuhan Jinyintan Hospital in China between December 25, 2019, and January 26, 2020. The final date of follow-up was February 13, 2020. Exposures Confirmed COVID-19 pneumonia. Main Outcomes and Measures The development of ARDS and death. Epidemiological, demographic, clinical, laboratory, management, treatment, and outcome data were also collected and analyzed. Results Of 201 patients, the median age was 51 years (interquartile range, 43-60 years), and 128 (63.7%) patients were men. Eighty-four patients (41.8%) developed ARDS, and of those 84 patients, 44 (52.4%) died. In those who developed ARDS, compared with those who did not, more patients presented with dyspnea (50 of 84 [59.5%] patients and 30 of 117 [25.6%] patients, respectively [difference, 33.9%; 95% CI, 19.7%-48.1%]) and had comorbidities such as hypertension (23 of 84 [27.4%] patients and 16 of 117 [13.7%] patients, respectively [difference, 13.7%; 95% CI, 1.3%-26.1%]) and diabetes (16 of 84 [19.0%] patients and 6 of 117 [5.1%] patients, respectively [difference, 13.9%; 95% CI, 3.6%-24.2%]). In bivariate Cox regression analysis, risk factors associated with the development of ARDS and progression from ARDS to death included older age (hazard ratio [HR], 3.26; 95% CI 2.08-5.11; and HR, 6.17; 95% CI, 3.26-11.67, respectively), neutrophilia (HR, 1.14; 95% CI, 1.09-1.19; and HR, 1.08; 95% CI, 1.01-1.17, respectively), and organ and coagulation dysfunction (eg, higher lactate dehydrogenase [HR, 1.61; 95% CI, 1.44-1.79; and HR, 1.30; 95% CI, 1.11-1.52, respectively] and D-dimer [HR, 1.03; 95% CI, 1.01-1.04; and HR, 1.02; 95% CI, 1.01-1.04, respectively]). High fever (\u226539 \u00b0C) was associated with higher likelihood of ARDS development (HR, 1.77; 95% CI, 1.11-2.84) and lower likelihood of death (HR, 0.41; 95% CI, 0.21-0.82). Among patients with ARDS, treatment with methylprednisolone decreased the risk of death (HR, 0.38; 95% CI, 0.20-0.72). Conclusions and Relevance Older age was associated with greater risk of development of ARDS and death likely owing to less rigorous immune response. Although high fever was associated with the development of ARDS, it was also associated with better outcomes among patients with ARDS. Moreover, treatment with methylprednisolone may be beneficial for patients who develop ARDS.",
    "date": "2020",
    "authors": [
        "Chaomin Wu",
        "Xiaoyan Chen",
        "Yanping Cai",
        "Jia\u2019an Xia",
        "Xing Zhou",
        "Sha Xu",
        "Hanping Huang",
        "Li Zhang",
        "Xia Zhou",
        "Chunling Du",
        "Yuye Zhang",
        "Juan Song",
        "Sijiao Wang",
        "Yencheng Chao",
        "Zeyong Yang",
        "Jie Xu",
        "Xin Zhou",
        "Dechang Chen",
        "Weining Xiong",
        "Lei Xu",
        "Feng Zhou",
        "Jinjun Jiang",
        "Chunxue Bai",
        "Junhua Zheng",
        "Yuanlin Song"
    ],
    "related_topics": [
        "ARDS",
        "Interquartile range",
        "Hazard ratio"
    ],
    "citation_count": "5,200",
    "reference_count": "26",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3004280078",
        "2610356532",
        "2320270386",
        "2256430766",
        "3003430844",
        "2345375456"
    ]
},{
    "id": "2799524357",
    "title": "MEGA X: Molecular Evolutionary Genetics Analysis across Computing Platforms.",
    "abstract": "The Molecular Evolutionary Genetics Analysis (Mega) software implements many analytical methods and tools for phylogenomics and phylomedicine. Here, we report a transformation of Mega to enable cross-platform use on Microsoft Windows and Linux operating systems. Mega X does not require virtualization or emulation software and provides a uniform user experience across platforms. Mega X has additionally been upgraded to use multiple computing cores for many molecular evolutionary analyses. Mega X is available in two interfaces (graphical and command line) and can be downloaded from www.megasoftware.net free of charge.",
    "date": "2018",
    "authors": [
        "Sudhir Kumar",
        "Glen Stecher",
        "Michael Li",
        "Christina Knyaz",
        "Koichiro Tamura"
    ],
    "related_topics": [
        "Mega-",
        "Virtualization",
        "Software"
    ],
    "citation_count": "9,566",
    "reference_count": "4",
    "references": [
        "2311203695",
        "2156434383",
        "2121552166",
        "2097403532"
    ]
},{
    "id": "2789368753",
    "title": "MERS coronaviruses from camels in Africa exhibit region-dependent genetic diversity",
    "abstract": "Middle East respiratory syndrome coronavirus (MERS-CoV) causes a zoonotic respiratory disease of global public health concern, and dromedary camels are the only proven source of zoonotic infection. Although MERS-CoV infection is ubiquitous in dromedaries across Africa as well as in the Arabian Peninsula, zoonotic disease appears confined to the Arabian Peninsula. MERS-CoVs from Africa have hitherto been poorly studied. We genetically and phenotypically characterized MERS-CoV from dromedaries sampled in Morocco, Burkina Faso, Nigeria, and Ethiopia. Viruses from Africa (clade C) are phylogenetically distinct from contemporary viruses from the Arabian Peninsula (clades A and B) but remain antigenically similar in microneutralization tests. Viruses from West (Nigeria, Burkina Faso) and North (Morocco) Africa form a subclade, C1, that shares clade-defining genetic signatures including deletions in the accessory gene ORF4b. Compared with human and camel MERS-CoV from Saudi Arabia, virus isolates from Burkina Faso (BF785) and Nigeria (Nig1657) had lower virus replication competence in Calu-3 cells and in ex vivo cultures of human bronchus and lung. BF785 replicated to lower titer in lungs of human DPP4-transduced mice. A reverse genetics-derived recombinant MERS-CoV (EMC) lacking ORF4b elicited higher type I and III IFN responses than the isogenic EMC virus in Calu-3 cells. However, ORF4b deletions may not be the major determinant of the reduced replication competence of BF785 and Nig1657. Genetic and phenotypic differences in West African viruses may be relevant to zoonotic potential. There is an urgent need for studies of MERS-CoV at the animal\u2013human interface.",
    "date": "2018",
    "authors": [
        "Daniel K.W. Chu",
        "Kenrie P.Y. Hui",
        "Ranawaka A.P.M. Perera",
        "Eve Miguel",
        "Daniela Niemeyer",
        "Jincun Zhao",
        "Rudragouda Channappanavar",
        "Gytis Dudas",
        "Jamiu O. Oladipo",
        "Amadou Traor\u00e9",
        "Ouafaa Fassi-Fihri",
        "Abraham Ali",
        "Getnet Fekadu Demissie",
        "Doreen Muth",
        "Michael C.W. Chan",
        "John M. Nicholls",
        "David K. Meyerholz",
        "Sulyman A. Kuranga",
        "Gezahegne Mamo",
        "Ziqi Zhou",
        "Ray T.Y. So",
        "Maged G. Hemida",
        "Richard J. Webby",
        "Fran\u00e7ois Roger",
        "Andrew Rambaut",
        "Leo L.M. Poon",
        "Stanley Perlman",
        "Christian Drosten",
        "V\u00e9ronique Chevalier",
        "Malik Peiris"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Zoonotic Infection",
        "Coronavirus"
    ],
    "citation_count": "123",
    "reference_count": "24",
    "references": [
        "2111211467",
        "2145441153",
        "2078121682",
        "1999625084",
        "2131369206",
        "2559337285",
        "1984494056",
        "2134781640",
        "2216419812",
        "1966504197"
    ]
},{
    "id": "1998201250",
    "title": "Middle East Respiratory Syndrome (MERS) coronavirus seroprevalence in domestic livestock in Saudi Arabia, 2010 to 2013.",
    "abstract": "In Saudi Arabia, including regions of Riyadh and Al Ahsa, pseudoparticle neutralisation (ppNT) and microneutralisation (MNT) tests detected no antibodies to Middle East Respiratory Syndrome coronavirus (MERS-CoV) in sheep (n= 100), goats (n= 45), cattle (n= 50) and chickens (n= 240). Dromedary camels however, had a high prevalence of MERS-CoV antibodies. Bovine coronavirus (BCoV) infected sera from cattle had no cross-reactivity in MERS-CoV ppNT or MNT, while many dromedary camels' sera reacted to both BCoV and MERS-CoV. Some nevertheless displayed specific serologic reaction profiles to MERS-CoV. .",
    "date": "2013",
    "authors": [
        "M G Hemida",
        "R A Perera",
        "P Wang",
        "M A Alhammadi",
        "L Y Siu",
        "M Li",
        "L L Poon",
        "L Saif",
        "A Alnaeem",
        "M Peiris"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Middle East respiratory syndrome",
        "Bovine coronavirus"
    ],
    "citation_count": "253",
    "reference_count": "9",
    "references": [
        "2166867592",
        "2107053896",
        "2160011624",
        "2049975503",
        "3021832855",
        "2022439931",
        "2131369206",
        "28510732",
        "2105360462"
    ]
},{
    "id": "2954438954",
    "title": "Worldwide Reduction in MERS Cases and Deaths since 2016.",
    "abstract": "Since 2012, Middle East respiratory syndrome (MERS) coronavirus has infected 2,442 persons worldwide. Case-based data analysis suggests that since 2016, as many as 1,465 cases and 293-520 deaths might have been averted. Efforts to reduce the global MERS threat are working, but countries must maintain vigilance to prevent further infections.",
    "date": "2019",
    "authors": [
        "Christl A. Donnelly",
        "Mamun R. Malik",
        "Amgad Elkholy",
        "Simon Cauchemez",
        "Maria D. Van Kerkhove"
    ],
    "related_topics": [
        "Middle East respiratory syndrome",
        "Global health",
        "Coronavirus"
    ],
    "citation_count": "30",
    "reference_count": "8",
    "references": [
        "2107053896",
        "1965186841",
        "1947023024",
        "2239299266",
        "2892294485",
        "2945602507",
        "2287757556",
        "2910161306"
    ]
},{
    "id": "3009906937",
    "title": "The species Severe acute respiratory syndrome-related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2",
    "abstract": "",
    "date": "2020",
    "authors": [
        "Alexander E. Gorbalenya",
        "Susan C. Baker",
        "Ralph S. Baric",
        "Raoul J. de Groot",
        "Christian Drosten",
        "Anastasia A. Gulyaeva",
        "Bart L. Haagmans",
        "Chris Lauber",
        "Andrey M. Leontovich",
        "Benjamin W. Neuman",
        "Dmitry Penzar",
        "Stanley Perlman",
        "Leo L.M. Poon",
        "Dmitry V. Samborskiy",
        "Igor A. Sidorov",
        "Isabel Sola",
        "John Ziebuhr"
    ],
    "related_topics": [
        "Coronavirus",
        "Virology",
        "Respiratory system"
    ],
    "citation_count": "4,096",
    "reference_count": "50",
    "references": [
        "3001118548",
        "3001897055",
        "3003668884",
        "3004280078",
        "3004318991",
        "2166867592",
        "2111647009",
        "3006642361",
        "2132260239",
        "2104548316"
    ]
},{
    "id": "3010338568",
    "title": "Epidemiologic Features and Clinical Course of Patients Infected With SARS-CoV-2 in Singapore.",
    "abstract": "Importance Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) emerged in Wuhan, China, in December 2019 and has spread globally with sustained human-to-human transmission outside China. Objective To report the initial experience in Singapore with the epidemiologic investigation of this outbreak, clinical features, and management. Design, Setting, and Participants Descriptive case series of the first 18 patients diagnosed with polymerase chain reaction (PCR)\u2013confirmed SARS-CoV-2 infection at 4 hospitals in Singapore from January 23 to February 3, 2020; final follow-up date was February 25, 2020. Exposures Confirmed SARS-CoV-2 infection. Main Outcomes and Measures Clinical, laboratory, and radiologic data were collected, including PCR cycle threshold values from nasopharyngeal swabs and viral shedding in blood, urine, and stool. Clinical course was summarized, including requirement for supplemental oxygen and intensive care and use of empirical treatment with lopinavir-ritonavir. Results Among the 18 hospitalized patients with PCR-confirmed SARS-CoV-2 infection (median age, 47 years; 9 [50%] women), clinical presentation was an upper respiratory tract infection in 12 (67%), and viral shedding from the nasopharynx was prolonged for 7 days or longer among 15 (83%). Six individuals (33%) required supplemental oxygen; of these, 2 required intensive care. There were no deaths. Virus was detectable in the stool (4/8 [50%]) and blood (1/12 [8%]) by PCR but not in urine. Five individuals requiring supplemental oxygen were treated with lopinavir-ritonavir. For 3 of the 5 patients, fever resolved and supplemental oxygen requirement was reduced within 3 days, whereas 2 deteriorated with progressive respiratory failure. Four of the 5 patients treated with lopinavir-ritonavir developed nausea, vomiting, and/or diarrhea, and 3 developed abnormal liver function test results. Conclusions and Relevance Among the first 18 patients diagnosed with SARS-CoV-2 infection in Singapore, clinical presentation was frequently a mild respiratory tract infection. Some patients required supplemental oxygen and had variable clinical outcomes following treatment with an antiretroviral agent.",
    "date": "2020",
    "authors": [
        "Barnaby Edward Young",
        "Sean Wei Xiang Ong",
        "Shirin Kalimuddin",
        "Jenny G. Low",
        "Seow Yen Tan",
        "Jiashen Loh",
        "Oon Tek Ng",
        "Kalisvar Marimuthu",
        "Li Wei Ang",
        "Tze Minn Mak",
        "Sok Kiang Lau",
        "Danielle E. Anderson",
        "Kian Sing Chan",
        "Thean Yen Tan",
        "Tong Yong Ng",
        "Lin Cui",
        "Zubaidah Said",
        "Lalitha Kurupatham",
        "Mark I.Cheng Chen",
        "Monica Chan",
        "Shawn Vasoo",
        "Lin Fa Wang",
        "Boon Huan Tan",
        "Raymond Tzer Pin Lin",
        "Vernon Jian Ming Lee",
        "Yee Sin Leo",
        "David Chien Lye"
    ],
    "related_topics": [
        "Respiratory tract infections",
        "Intensive care",
        "Upper respiratory tract infection"
    ],
    "citation_count": "1,644",
    "reference_count": "17",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3008028633",
        "3002539152",
        "3004318991",
        "3006961006",
        "3000413850",
        "2129542667"
    ]
},{
    "id": "2030966943",
    "title": "CONFIDENCE LIMITS ON PHYLOGENIES: AN APPROACH USING THE BOOTSTRAP.",
    "abstract": "The recently-developed statistical method known as the \"bootstrap\" can be used to place confidence intervals on phylogenies. It involves resampling points from one's own data, with replacement, to create a series of bootstrap samples of the same size as the original data. Each of these is analyzed, and the variation among the resulting estimates taken to indicate the size of the error involved in making estimates from the original data. In the case of phylogenies, it is argued that the proper method of resampling is to keep all of the original species while sampling characters with replacement, under the assumption that the characters have been independently drawn by the systematist and have evolved independently. Majority-rule consensus trees can be used to construct a phylogeny showing all of the inferred monophyletic groups that occurred in a majority of the bootstrap samples. If a group shows up 95% of the time or more, the evidence for it is taken to be statistically significant. Existing computer programs can be used to analyze different bootstrap samples by using weights on the characters, the weight of a character being how many times it was drawn in bootstrap sampling. When all characters are perfectly compatible, as envisioned by Hennig, bootstrap sampling becomes unnecessary; the bootstrap method would show significant evidence for a group if it is defined by three or more characters.",
    "date": "1985",
    "authors": [
        "Joseph Felsenstein"
    ],
    "related_topics": [
        "Resampling",
        "Sampling (statistics)",
        "Computational phylogenetics"
    ],
    "citation_count": "44,427",
    "reference_count": "12",
    "references": [
        "2117897510",
        "2124181495",
        "1976927254",
        "1973967548",
        "2317907906",
        "2114827603",
        "2178606245",
        "92565547",
        "2999635039",
        "2088484367"
    ]
},{
    "id": "2162496804",
    "title": "Severe Acute Respiratory Syndrome Coronavirus as an Agent of Emerging and Reemerging Infection",
    "abstract": "Before the emergence of severe acute respiratory syndrome (SARS) coronavirus (SARS-CoV) in 2003, only 12 other animal or human coronaviruses were known. The discovery of this virus was soon followed by the discovery of the civet and bat SARS-CoV and the human coronaviruses NL63 and HKU1. Surveillance of coronaviruses in many animal species has increased the number on the list of coronaviruses to at least 36. The explosive nature of the first SARS epidemic, the high mortality, its transient reemergence a year later, and economic disruptions led to a rush on research of the epidemiological, clinical, pathological, immunological, virological, and other basic scientific aspects of the virus and the disease. This research resulted in over 4,000 publications, only some of the most representative works of which could be reviewed in this article. The marked increase in the understanding of the virus and the disease within such a short time has allowed the development of diagnostic tests, animal models, antivirals, vaccines, and epidemiological and infection control measures, which could prove to be useful in randomized control trials if SARS should return. The findings that horseshoe bats are the natural reservoir for SARS-CoV-like virus and that civets are the amplification host highlight the importance of wildlife and biosecurity in farms and wet markets, which can serve as the source and amplification centers for emerging infections.",
    "date": "2007",
    "authors": [
        "Vincent C. C. Cheng",
        "Susanna K. P. Lau",
        "Patrick C. Y. Woo",
        "Kwok Yung Yuen"
    ],
    "related_topics": [
        "Coronavirus",
        "Natural reservoir",
        "Virus"
    ],
    "citation_count": "850",
    "reference_count": "432",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2131262274",
        "2129542667",
        "2100820722",
        "2125251240",
        "2147166346",
        "2116586125",
        "1966238900"
    ]
},{
    "id": "2255897570",
    "title": "Severe Acute Respiratory Syndrome (SARS) Coronavirus ORF8 Protein Is Acquired from SARS-Related Coronavirus from Greater Horseshoe Bats through Recombination.",
    "abstract": "Despite the identification of horseshoe bats as the reservoir of severe acute respiratory syndrome (SARS)-related coronaviruses (SARSr-CoVs), the origin of SARS-CoV ORF8, which contains the 29-nucleotide signature deletion among human strains, remains obscure. Although two SARS-related Rhinolophus sinicus bat CoVs (SARSr-Rs-BatCoVs) previously detected in Chinese horseshoe bats (Rhinolophus sinicus) in Yunnan, RsSHC014 and Rs3367, possessed 95% genome identities to human and civet SARSr-CoVs, their ORF8 protein exhibited only 32.2 to 33% amino acid identities to that of human/civet SARSr-CoVs. To elucidate the origin of SARS-CoV ORF8, we sampled 348 bats of various species in Yunnan, among which diverse alphacoronaviruses and betacoronaviruses, including potentially novel CoVs, were identified, with some showing potential interspecies transmission. The genomes of two betacoronaviruses, SARSr-Rf-BatCoV YNLF_31C and YNLF_34C, from greater horseshoe bats (Rhinolophus ferrumequinum), possessed 93% nucleotide identities to human/civet SARSr-CoV genomes. Although these two betacoronaviruses displayed lower similarities than SARSr-Rs-BatCoV RsSHC014 and Rs3367 in S protein to civet SARSr-CoVs, their ORF8 proteins demonstrated exceptionally high (80.4 to 81.3%) amino acid identities to that of human/civet SARSr-CoVs, compared to SARSr-BatCoVs from other horseshoe bats (23.2 to 37.3%). Potential recombination events were identified around ORF8 between SARSr-Rf-BatCoVs and SARSr-Rs-BatCoVs, leading to the generation of civet SARSr-CoVs. The expression of ORF8 subgenomic mRNA suggested that the ORF8 protein may be functional in SARSr-Rf-BatCoVs. The high Ka/Ks ratio among human SARS-CoVs compared to that among SARSr-BatCoVs supported that ORF8 is under strong positive selection during animal-to-human transmission. Molecular clock analysis using ORF1ab showed that SARSr-Rf-BatCoV YNLF_31C and YNLF_34C diverged from civet/human SARSr-CoVs in approximately 1990. SARS-CoV ORF8 originated from SARSr-CoVs of greater horseshoe bats through recombination, which may be important for animal-to-human transmission. IMPORTANCE Although horseshoe bats are the primary reservoir of SARS-related coronaviruses (SARSr-CoVs), it is still unclear how these bat viruses have evolved to cross the species barrier to infect civets and humans. Most human SARS-CoV epidemic strains contain a signature 29-nucleotide deletion in ORF8, compared to civet SARSr-CoVs, suggesting that ORF8 may be important for interspecies transmission. However, the origin of SARS-CoV ORF8 remains obscure. In particular, SARSr-Rs-BatCoVs from Chinese horseshoe bats (Rhinolophus sinicus) exhibited <40% amino acid identities to human/civet SARS-CoV in the ORF8 protein. We detected diverse alphacoronaviruses and betacoronaviruses among various bat species in Yunnan, China, including two SARSr-Rf-BatCoVs from greater horseshoe bats that possessed ORF8 proteins with exceptionally high amino acid identities to that of human/civet SARSr-CoVs. We demonstrated recombination events around ORF8 between SARSr-Rf-BatCoVs and SARSr-Rs-BatCoVs, leading to the generation of civet SARSr-CoVs. Our findings offer insight into the evolutionary origin of SARS-CoV ORF8 protein, which was likely acquired from SARSr-CoVs of greater horseshoe bats through recombination.",
    "date": "2015",
    "authors": [
        "Susanna K.P. Lau",
        "Yun Feng",
        "Honglin Chen",
        "Hayes K.H. Luk",
        "Wei Hong Yang",
        "Kenneth S.M. Li",
        "Yu Zhen Zhang",
        "Yi Huang",
        "Zhi Zhong Song",
        "Wang Ngai Chow",
        "Rachel Y.Y. Fan",
        "Syed Shakeel Ahmed",
        "Hazel C. Yeung",
        "Carol S.F. Lam",
        "Jian Piao Cai",
        "Samson S.Y. Wong",
        "Jasper F.W. Chan",
        "Kwok Yung Yuen",
        "Hai Lin Zhang",
        "Patrick C.Y. Woo"
    ],
    "related_topics": [
        "Civet",
        "Viverridae",
        "Rhinolophus ferrumequinum"
    ],
    "citation_count": "186",
    "reference_count": "69",
    "references": [
        "2166867592",
        "2132260239",
        "2104548316",
        "2025170735",
        "2110835349",
        "1993577573",
        "2112147913",
        "2160011624",
        "2103503670",
        "2115555188"
    ]
},{
    "id": "3010441732",
    "title": "Structural basis for the recognition of SARS-CoV-2 by full-length human ACE2.",
    "abstract": "Angiotensin-converting enzyme 2 (ACE2) is the cellular receptor for severe acute respiratory syndrome-coronavirus (SARS-CoV) and the new coronavirus (SARS-CoV-2) that is causing the serious coronavirus disease 2019 (COVID-19) epidemic. Here, we present cryo-electron microscopy structures of full-length human ACE2 in the presence of the neutral amino acid transporter B0AT1 with or without the receptor binding domain (RBD) of the surface spike glycoprotein (S protein) of SARS-CoV-2, both at an overall resolution of 2.9 angstroms, with a local resolution of 3.5 angstroms at the ACE2-RBD interface. The ACE2-B0AT1 complex is assembled as a dimer of heterodimers, with the collectrin-like domain of ACE2 mediating homodimerization. The RBD is recognized by the extracellular peptidase domain of ACE2 mainly through polar residues. These findings provide important insights into the molecular basis for coronavirus recognition and infection.",
    "date": "2020",
    "authors": [
        "Renhong Yan",
        "Yuanyuan Zhang",
        "Yaning Li",
        "Lu Xia",
        "Yingying Guo",
        "Qiang Zhou"
    ],
    "related_topics": [
        "Coronavirus",
        "Protein domain",
        "Plasma protein binding"
    ],
    "citation_count": "2,533",
    "reference_count": "54",
    "references": [
        "3001897055",
        "3004280078",
        "3007643904",
        "2114622716",
        "2124026197",
        "2132260239",
        "2593511418",
        "3004151654",
        "2104234755",
        "1966238900"
    ]
},{
    "id": "3031532178",
    "title": "COVID-19 outbreak and endoscopy: Considerations in patients encountered in a foregut surgery practice",
    "abstract": "Severe acute respiratory syndrome coronavirus has become a critical challenge to global health. Since the arrival of coronavirus disease 2019 in the United States, several government agencies and professional societies have issued guidelines to healthcare systems and medical providers. Endoscopy is a substantial portion of the practice of many general surgeons in the United States. With upper endoscopy, manipulation of the upper aerodigestive tract can turn the droplets to an aerosolized form and increase the likelihood of transmission and therefore is considered a high-risk procedure. In this article we review some aspects of the coronavirus disease 2019 outbreak that are relevant to practice of surgical endoscopy. The emphasis of this communication is on the mode of transmission, previous experiences during other coronavirus outbreaks and society guidelines. We then highlight the changes that we have made to our practice to incorporate these factors to improve the safety of patients, health care providers, and community as a whole.",
    "date": "2020",
    "authors": [
        "Tanya Olszewski",
        "Andrew D Grubic",
        "Shahin Ayazi",
        "Blair A Jobe"
    ],
    "related_topics": [
        "Surgical endoscopy",
        "Health care",
        "Global health"
    ],
    "citation_count": "4",
    "reference_count": "13",
    "references": [
        "3007497549",
        "3010781325",
        "3023787531",
        "3009834387",
        "3016131164",
        "3011598093",
        "1757215199",
        "1977330440",
        "2061609002",
        "3012881844"
    ]
},{
    "id": "2131988685",
    "title": "Coronavirus Pathogenesis and the Emerging Pathogen Severe Acute Respiratory Syndrome Coronavirus",
    "abstract": "Coronaviruses are a family of enveloped, single-stranded, positive-strand RNA viruses classified within the Nidovirales order. This coronavirus family consists of pathogens of many animal species and of humans, including the recently isolated severe acute respiratory syndrome coronavirus (SARS-CoV). This review is divided into two main parts; the first concerns the animal coronaviruses and their pathogenesis, with an emphasis on the functions of individual viral genes, and the second discusses the newly described human emerging pathogen, SARS-CoV. The coronavirus part covers (i) a description of a group of coronaviruses and the diseases they cause, including the prototype coronavirus, murine hepatitis virus, which is one of the recognized animal models for multiple sclerosis, as well as viruses of veterinary importance that infect the pig, chicken, and cat and a summary of the human viruses; (ii) a short summary of the replication cycle of coronaviruses in cell culture; (iii) the development and application of reverse genetics systems; and (iv) the roles of individual coronavirus proteins in replication and pathogenesis. The SARS-CoV part covers the pathogenesis of SARS, the developing animal models for infection, and the progress in vaccine development and antiviral therapies. The data gathered on the animal coronaviruses continue to be helpful in understanding SARS-CoV.",
    "date": "2005",
    "authors": [
        "Susan R. Weiss",
        "Sonia Navas-Martin"
    ],
    "related_topics": [
        "Coronavirus",
        "Coronaviridae",
        "Nidovirales"
    ],
    "citation_count": "968",
    "reference_count": "384",
    "references": [
        "2132260239",
        "2104548316",
        "2131262274",
        "2129542667",
        "2116586125",
        "1966238900",
        "2169198329",
        "2167384912",
        "2134061616",
        "2163627712"
    ]
},{
    "id": "1974901207",
    "title": "Quantitative mRNA expression profiling of ACE 2, a novel homologue of angiotensin converting enzyme",
    "abstract": "ACE 2, a novel homologue of angiotensin converting enzyme, has recently been identified. This study used QRT-PCR to quantitatively map the transcriptional expression profile of ACE 2 (and the two isoforms of ACE) in 72 human tissues. While confirming that ACE 2 expression is high in renal and cardiovascular tissues, the novel observation has been made that ACE 2 shows comparably high levels of expression in the gastrointestinal system, in particular in ileum, duodenum, jejunum, caecum and colon. Therefore, in probing the functional significance of this novel peptidase, some consideration should be given to a role in gastrointestinal physiology and pathophysiology.",
    "date": "2002",
    "authors": [
        "Dan Harmer",
        "Maureen Gilbert",
        "Richard Borman",
        "Kenneth L Clark"
    ],
    "related_topics": [
        "Angiotensin-converting enzyme",
        "Angiotensin-converting enzyme 2",
        "Gene expression profiling"
    ],
    "citation_count": "723",
    "reference_count": "12",
    "references": [
        "2025672718",
        "2000040025",
        "2161399617",
        "2149146712",
        "2020177273",
        "2014363167",
        "2159994064",
        "2073577195",
        "2160901785",
        "2056435519"
    ]
},{
    "id": "3008352032",
    "title": "Rigidity of the Outer Shell Predicted by a Protein Intrinsic Disorder Model Sheds Light on the COVID-19 (Wuhan-2019-nCoV) Infectivity",
    "abstract": "The world is currently witnessing an outbreak of a new coronavirus spreading quickly across China and affecting at least 24 other countries. With almost 65,000 infected, a worldwide death toll of at least 1370 (as of 14 February 2020), and with the potential to affect up to two-thirds of the world population, COVID-19 is considered by the World Health Organization (WHO) to be a global health emergency. The speed of spread and infectivity of COVID-19 (also known as Wuhan-2019-nCoV) are dramatically exceeding those of the Middle East respiratory syndrome coronavirus (MERS-CoV) and severe acute respiratory syndrome coronavirus (SARS-CoV). In fact, since September 2012, the WHO has been notified of 2494 laboratory-confirmed cases of infection with MERS-CoV, whereas the 2002\u20132003 epidemic of SARS affected 26 countries and resulted in more than 8000 cases. Therefore, although SARS, MERS, and COVID-19 are all the result of coronaviral infections, the causes of the coronaviruses differ dramatically in their transmissibility. It is likely that these differences in infectivity of coronaviruses can be attributed to the differences in the rigidity of their shells which can be evaluated using computational tools for predicting intrinsic disorder predisposition of the corresponding viral proteins.",
    "date": "2020",
    "authors": [
        "Gerard Kian Meng Goh",
        "A. Keith Dunker",
        "James A. Foster",
        "Vladimir N. Uversky"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome coronavirus",
        "Infectivity"
    ],
    "citation_count": "32",
    "reference_count": "9",
    "references": [
        "3011863580",
        "3014910618",
        "3013294882",
        "2067971243",
        "3000129223",
        "2944153764",
        "3015288005",
        "1971101818",
        "3013875346"
    ]
},{
    "id": "3012379316",
    "title": "A Trial of Lopinavir-Ritonavir in Adults Hospitalized with Severe Covid-19.",
    "abstract": "Abstract Background No therapeutics have yet been proven effective for the treatment of severe illness caused by SARS-CoV-2. Methods We conducted a randomized, controlled, open-label trial involvin...",
    "date": "2020",
    "authors": [
        "Bin Cao",
        "Yeming Wang",
        "Danning Wen",
        "Wen Liu",
        "Jingli Wang",
        "Guohui Fan",
        "Lianguo Ruan",
        "Bin Song",
        "Yanping Cai",
        "Ming Wei",
        "Xingwang Li",
        "Jiaan Xia",
        "Nanshan Chen",
        "Jie Xiang",
        "Ting Yu",
        "Tao Bai",
        "Xuelei Xie",
        "Li Zhang",
        "Caihong Li",
        "Ye Yuan",
        "Hua Chen",
        "Huadong Li",
        "Hanping Huang",
        "Shengjing Tu",
        "Fengyun Gong",
        "Ying Liu",
        "Yuan Wei",
        "Chongya Dong",
        "Fei Zhou",
        "Xiaoying Gu",
        "Jiuyang Xu",
        "Zhibo Liu",
        "Yi Zhang",
        "Hui Li",
        "Lianhan Shang",
        "Ke Wang",
        "Kunxia Li",
        "Xia Zhou",
        "Xuan Dong",
        "Zhaohui Qu",
        "Sixia Lu",
        "Xujuan Hu",
        "Shunan Ruan",
        "Shanshan Luo",
        "Jing Wu",
        "Lu Peng",
        "Fang Cheng",
        "Lihong Pan",
        "Jun Zou",
        "Chunmin Jia"
    ],
    "related_topics": [
        "Lopinavir/ritonavir",
        "Lopinavir",
        "Randomized controlled trial"
    ],
    "citation_count": "4,078",
    "reference_count": "23",
    "references": [
        "3001118548",
        "3005079553",
        "3002108456",
        "3009885589",
        "3006961006",
        "3006485704",
        "2791599184",
        "2150120685",
        "2345375456",
        "2102263282"
    ]
},{
    "id": "1984335993",
    "title": "Stability of Middle East respiratory syndrome coronavirus (MERS-CoV) under different environmental conditions",
    "abstract": "The stability of Middle East respiratory syndrome coronavirus (MERS-CoV) was determined at 20\u00b0C--40% relative humidity (RH); 30\u00b0C--30% RH and 30\u00b0C--80% RH. MERS-CoV was more stable at low temperature/low humidity conditions and could still be recovered after 48 hours. During aerosolisation of MERS-CoV, no decrease in stability was observed at 20\u00b0C--40% RH. These data suggest the potential of MERS-CoV to be transmitted via contact or fomite transmission due to prolonged environmental presence.",
    "date": "2012",
    "authors": [
        "N van Doremalen",
        "T Bushmaker",
        "V J Munster"
    ],
    "related_topics": [
        "Middle East respiratory syndrome coronavirus",
        "Relative humidity",
        "Humidity"
    ],
    "citation_count": "469",
    "reference_count": "17",
    "references": [
        "2166867592",
        "2107053896",
        "1703839189",
        "2160011624",
        "2140143765",
        "2119775949",
        "1690366459",
        "2152344953",
        "2064850047",
        "2022439931"
    ]
},{
    "id": "2064850047",
    "title": "The Effects of Temperature and Relative Humidity on the Viability of the SARS Coronavirus",
    "abstract": "The main route of transmission of SARS CoV infection is presumed to be respiratory droplets. However the virus is also detectable in other body fluids and excreta. The stability of the virus at different temperatures and relative humidity on smooth surfaces were studied. The dried virus on smooth surfaces retained its viability for over 5 days at temperatures of 22\u201325\u00b0C and relative humidity of 40\u201350%, that is, typical air-conditioned environments. However, virus viability was rapidly lost (>3 log10) at higher temperatures and higher relative humidity (e.g., 38\u00b0C, and relative humidity of >95%). The better stability of SARS coronavirus at low temperature and low humidity environment may facilitate its transmission in community in subtropical area (such as Hong Kong) during the spring and in air-conditioned environments. It may also explain why some Asian countries in tropical area (such as Malaysia, Indonesia or Thailand) with high temperature and high relative humidity environment did not have major community outbreaks of SARS.",
    "date": "2011",
    "authors": [
        "K. H. Chan",
        "J. S. Malik Peiris",
        "S. Y. Lam",
        "L. L. M. Poon",
        "K. Y. Yuen",
        "W. H. Seto"
    ],
    "related_topics": [
        "Relative humidity",
        "Humidity",
        "Outbreak"
    ],
    "citation_count": "714",
    "reference_count": "23",
    "references": [
        "2132260239",
        "2104548316",
        "2025170735",
        "2129542667",
        "1990049863",
        "2138453842",
        "1993435091",
        "2137144526",
        "2082755732",
        "2154638029"
    ]
},{
    "id": "2406220407",
    "title": "Tracking the Epidemic",
    "abstract": "",
    "date": "2000",
    "authors": [
        "Monica S. Ruiz",
        "Alicia R. Gable",
        "Edward H. Kaplan",
        "Michael A. Stoto",
        "Harvey V. Fineberg",
        "James Trussell"
    ],
    "related_topics": [
        "Tracking (particle physics)",
        "Computer vision",
        "Geography"
    ],
    "citation_count": "6",
    "reference_count": "0",
    "references": []
},{
    "id": "3007189521",
    "title": "Clinical findings in a group of patients infected with the 2019 novel coronavirus (SARS-Cov-2) outside of Wuhan, China: retrospective case series",
    "abstract": "Abstract Objective To study the clinical characteristics of patients in Zhejiang province, China, infected with the 2019 severe acute respiratory syndrome coronavirus 2 (SARS-Cov-2) responsible for coronavirus disease 2019 (covid-2019). Design Retrospective case series. Setting Seven hospitals in Zhejiang province, China. Participants 62 patients admitted to hospital with laboratory confirmed SARS-Cov-2 infection. Data were collected from 10 January 2020 to 26 January 2020. Main outcome measures Clinical data, collected using a standardised case report form, such as temperature, history of exposure, incubation period. If information was not clear, the working group in Hangzhou contacted the doctor responsible for treating the patient for clarification. Results Of the 62 patients studied (median age 41 years), only one was admitted to an intensive care unit, and no patients died during the study. According to research, none of the infected patients in Zhejiang province were ever exposed to the Huanan seafood market, the original source of the virus; all studied cases were infected by human to human transmission. The most common symptoms at onset of illness were fever in 48 (77%) patients, cough in 50 (81%), expectoration in 35 (56%), headache in 21 (34%), myalgia or fatigue in 32 (52%), diarrhoea in 3 (8%), and haemoptysis in 2 (3%). Only two patients (3%) developed shortness of breath on admission. The median time from exposure to onset of illness was 4 days (interquartile range 3-5 days), and from onset of symptoms to first hospital admission was 2 (1-4) days. Conclusion As of early February 2020, compared with patients initially infected with SARS-Cov-2 in Wuhan, the symptoms of patients in Zhejiang province are relatively mild.",
    "date": "2020",
    "authors": [
        "Xiao-Wei physician Xu",
        "Xiao-Xin physician Wu",
        "Xian-Gao physician Jiang",
        "Kai-Jin physician Xu",
        "Ling-Jun physician Ying",
        "Chun-Lian physician Ma",
        "Shi-Bo physician Li",
        "Hua-Ying physician Wang",
        "Sheng physician Zhang",
        "Hai-Nv Gao",
        "Ji-Fang Sheng",
        "Hong-Liu physician Cai",
        "Yun-Qing Qiu",
        "Lan-Juan Li"
    ],
    "related_topics": [
        "Interquartile range",
        "myalgia",
        "Retrospective cohort study"
    ],
    "citation_count": "1,653",
    "reference_count": "14",
    "references": [
        "3001118548",
        "3002108456",
        "3002539152",
        "3004318991",
        "2166867592",
        "2999318660",
        "2999364275",
        "3000771439",
        "2112147913",
        "2150120685"
    ]
},{
    "id": "3020184843",
    "title": "Epidemiology and transmission of COVID-19 in 391 cases and 1286 of their close contacts in Shenzhen, China: a retrospective cohort study.",
    "abstract": "Summary Background Rapid spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in Wuhan, China, prompted heightened surveillance in Shenzhen, China. The resulting data provide a rare opportunity to measure key metrics of disease course, transmission, and the impact of control measures. Methods From Jan 14 to Feb 12, 2020, the Shenzhen Center for Disease Control and Prevention identified 391 SARS-CoV-2 cases and 1286 close contacts. We compared cases identified through symptomatic surveillance and contact tracing, and estimated the time from symptom onset to confirmation, isolation, and admission to hospital. We estimated metrics of disease transmission and analysed factors influencing transmission risk. Findings Cases were older than the general population (mean age 45 years) and balanced between males (n=187) and females (n=204). 356 (91%) of 391 cases had mild or moderate clinical severity at initial assessment. As of Feb 22, 2020, three cases had died and 225 had recovered (median time to recovery 21 days; 95% CI 20\u201322). Cases were isolated on average 4\u00b76 days (95% CI 4\u00b71\u20135\u00b70) after developing symptoms; contact tracing reduced this by 1\u00b79 days (95% CI 1\u00b71\u20132\u00b77). Household contacts and those travelling with a case were at higher risk of infection (odds ratio 6\u00b727 [95% CI 1\u00b749\u201326\u00b733] for household contacts and 7\u00b706 [1\u00b743\u201334\u00b791] for those travelling with a case) than other close contacts. The household secondary attack rate was 11\u00b72% (95% CI 9\u00b71\u201313\u00b78), and children were as likely to be infected as adults (infection rate 7\u00b74% in children Interpretation Our data on cases as well as their infected and uninfected close contacts provide key insights into the epidemiology of SARS-CoV-2. This analysis shows that isolation and contact tracing reduce the time during which cases are infectious in the community, thereby reducing the R. The overall impact of isolation and contact tracing, however, is uncertain and highly dependent on the number of asymptomatic cases. Moreover, children are at a similar risk of infection to the general population, although less likely to have severe symptoms; hence they should be considered in analyses of transmission and control. Funding Emergency Response Program of Harbin Institute of Technology, Emergency Response Program of Peng Cheng Laboratory, US Centers for Disease Control and Prevention.",
    "date": "2020",
    "authors": [
        "Qifang Bi",
        "Yongsheng Wu",
        "Shujiang Mei",
        "Chenfei Ye",
        "Xuan Zou",
        "Zhen Zhang",
        "Xiaojian Liu",
        "Lan Wei",
        "Shaun A Truelove",
        "Tong Zhang",
        "Wei Gao",
        "Cong Cheng",
        "Xiujuan Tang",
        "Xiaoliang Wu",
        "Yu Wu",
        "Binbin Sun",
        "Suli Huang",
        "Yu Sun",
        "Juncen Zhang",
        "Ting Ma",
        "Justin Lessler",
        "Tiejian Feng"
    ],
    "related_topics": [
        "Contact tracing",
        "Transmission risks and rates",
        "Population"
    ],
    "citation_count": "1,033",
    "reference_count": "19",
    "references": [
        "3005079553",
        "3002108456",
        "3003668884",
        "3002539152",
        "3006961006",
        "3010233963",
        "3008985036",
        "3006643024",
        "3004912618",
        "2129542667"
    ]
},{
    "id": "3008294222",
    "title": "Feasibility of controlling COVID-19 outbreaks by isolation of cases and contacts",
    "abstract": "Summary Background Isolation of cases and contact tracing is used to control outbreaks of infectious diseases, and has been used for coronavirus disease 2019 (COVID-19). Whether this strategy will achieve control depends on characteristics of both the pathogen and the response. Here we use a mathematical model to assess if isolation and contact tracing are able to control onwards transmission from imported cases of COVID-19. Methods We developed a stochastic transmission model, parameterised to the COVID-19 outbreak. We used the model to quantify the potential effectiveness of contact tracing and isolation of cases at controlling a severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)-like pathogen. We considered scenarios that varied in the number of initial cases, the basic reproduction number (R0), the delay from symptom onset to isolation, the probability that contacts were traced, the proportion of transmission that occurred before symptom onset, and the proportion of subclinical infections. We assumed isolation prevented all further transmission in the model. Outbreaks were deemed controlled if transmission ended within 12 weeks or before 5000 cases in total. We measured the success of controlling outbreaks using isolation and contact tracing, and quantified the weekly maximum number of cases traced to measure feasibility of public health effort. Findings Simulated outbreaks starting with five initial cases, an R0 of 1\u00b75, and 0% transmission before symptom onset could be controlled even with low contact tracing probability; however, the probability of controlling an outbreak decreased with the number of initial cases, when R0 was 2\u00b75 or 3\u00b75 and with more transmission before symptom onset. Across different initial numbers of cases, the majority of scenarios with an R0 of 1\u00b75 were controllable with less than 50% of contacts successfully traced. To control the majority of outbreaks, for R0 of 2\u00b75 more than 70% of contacts had to be traced, and for an R0 of 3\u00b75 more than 90% of contacts had to be traced. The delay between symptom onset and isolation had the largest role in determining whether an outbreak was controllable when R0 was 1\u00b75. For R0 values of 2\u00b75 or 3\u00b75, if there were 40 initial cases, contact tracing and isolation were only potentially feasible when less than 1% of transmission occurred before symptom onset. Interpretation In most scenarios, highly effective contact tracing and case isolation is enough to control a new outbreak of COVID-19 within 3 months. The probability of control decreases with long delays from symptom onset to isolation, fewer cases ascertained by contact tracing, and increasing transmission before symptoms. This model can be modified to reflect updated transmission characteristics and more specific definitions of outbreak control to assess the potential success of local response efforts. Funding Wellcome Trust, Global Challenges Research Fund, and Health Data Research UK.",
    "date": "2020",
    "authors": [
        "Joel Hellewell",
        "Sam Abbott",
        "Amy Gimma",
        "Nikos I Bosse",
        "Christopher I Jarvis",
        "Timothy W Russell",
        "James D Munday",
        "Adam J Kucharski",
        "W John Edmunds",
        "Fiona Sun",
        "Stefan Flasche",
        "Billy J Quilty",
        "Nicholas Davies",
        "Yang Liu",
        "Samuel Clifford",
        "Petra Klepac",
        "Mark Jit",
        "Charlie Diamond",
        "Hamish Gibbs",
        "Kevin van Zandvoort",
        "Sebastian Funk",
        "Rosalind M Eggo"
    ],
    "related_topics": [
        "Contact tracing",
        "Outbreak",
        "Isolation (health care)"
    ],
    "citation_count": "1,702",
    "reference_count": "30",
    "references": [
        "3001118548",
        "3003668884",
        "3004397688",
        "3002764620",
        "3004912618",
        "3004026249",
        "3005995896",
        "3008590414",
        "3026046290",
        "1990049863"
    ]
},{
    "id": "3009983851",
    "title": "Serial interval of novel coronavirus (COVID-19) infections.",
    "abstract": "Abstract Objective To estimate the serial interval of novel coronavirus (COVID-19) from information on 28 infector-infectee pairs. Methods We collected dates of illness onset for primary cases (infectors) and secondary cases (infectees) from published research articles and case investigation reports. We subjectively ranked the credibility of the data and performed analyses on both the full dataset (n = 28) and a subset of pairs with highest certainty in reporting (n = 18). In addition, we adjust for right truncation of the data as the epidemic is still in its growth phase. Results Accounting for right truncation and analyzing all pairs, we estimated the median serial interval at 4.0 days (95% credible interval [CrI]: 3.1, 4.9). Limiting our data to only the most certain pairs, the median serial interval was estimated at 4.6 days (95% CrI: 3.5, 5.9). Conclusions The serial interval of COVID-19 is close to or shorter than its median incubation period. This suggests that a substantial proportion of secondary transmission may occur prior to illness onset. The COVID-19 serial interval is also shorter than the serial interval of severe acute respiratory syndrome (SARS), indicating that calculations made using the SARS serial interval may introduce bias.",
    "date": "2020",
    "authors": [
        "Hiroshi Nishiura",
        "Natalie M. Linton",
        "Andrei R. Akhmetzhanov"
    ],
    "related_topics": [
        "Serial interval",
        "Credible interval",
        "Truncation (statistics)"
    ],
    "citation_count": "778",
    "reference_count": "9",
    "references": [
        "3003668884",
        "3004239190",
        "3006065484",
        "2147166346",
        "3004658686",
        "3005847234",
        "2140763962",
        "2086446832",
        "2155823264"
    ]
},{
    "id": "3001392146",
    "title": "Pattern of early human-to-human transmission of Wuhan 2019-nCoV",
    "abstract": "On December 31, 2019, the World Health Organization was notified about a cluster of pneumonia of unknown aetiology in the city of Wuhan, China. Chinese authorities later identified a new coronavirus (2019-nCoV) as the causative agent of the outbreak. As of January 23, 2020, 655 cases have been confirmed in China and several other countries. Understanding the transmission characteristics and the potential for sustained human-to-human transmission of 2019-nCoV is critically important for coordinating current screening and containment strategies, and determining whether the outbreak constitutes a public health emergency of international concern (PHEIC). We performed stochastic simulations of early outbreak trajectories that are consistent with the epidemiological findings to date. We found the basic reproduction number, R_0, to be around 2.2 (90% high density interval 1.4--3.8), indicating the potential for sustained human-to-human transmission. Transmission characteristics appear to be of a similar magnitude to severe acute respiratory syndrome-related coronavirus (SARS-CoV) and the 1918 pandemic influenza. These findings underline the importance of heightened screening, surveillance and control efforts, particularly at airports and other travel hubs, in order to prevent further international spread of 2019-nCoV.",
    "date": "2020",
    "authors": [
        "Julien Riou",
        "Christian L. Althaus"
    ],
    "related_topics": [
        "Disease cluster",
        "Outbreak",
        "Transmission (mechanics)"
    ],
    "citation_count": "72",
    "reference_count": "11",
    "references": [
        "3004280078",
        "2107053896",
        "3001971765",
        "3026046290",
        "2069251911",
        "1042757214",
        "2134527559",
        "2998953329",
        "2169080737",
        "3002582459"
    ]
},{
    "id": "3023259384",
    "title": "Cardiac Manifestations of Coronavirus Disease 2019 (COVID-19): A Comprehensive Review",
    "abstract": "Since its origin in China, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection has become a pandemic and spread to 209 countries. As coronavirus disease 2019 (COVID-19) is a very rapidly emerging disease, organ-specific studies related to it have been reported. Apart from respiratory findings, some studies have highlighted inflammatory consequences in the heart, kidney, and/or liver as well. Cardiac involvement in COVID-19 seems to be a result of an inflammatory storm in response to the infection. Moreover, direct viral invasion of cardiomyocytes, as well as a myocardial injury due to oxidative stress, may account for acute cardiac injury in COVID-19. Nevertheless, the mechanism of heart injury in COVID-19 is not clear yet. However, multiple studies that highlight the clinical features, laboratory findings, and prognosis of acute myocardial injury (AMI) in COVID-19-affected individuals have been published. In this review, we have summarized the findings of all those studies as well as the clinical features and management of cardiac injury discussed by some case reports.",
    "date": "2020",
    "authors": [
        "Faryal Tahir",
        "Taha Bin Arif",
        "Jawad Ahmed",
        "Farheen Malik",
        "Muhammad Khalid"
    ],
    "related_topics": [
        "Heart Injury",
        "Disease",
        "Troponin"
    ],
    "citation_count": "16",
    "reference_count": "42",
    "references": [
        "3001118548",
        "3001897055",
        "3005079553",
        "3002108456",
        "3004318991",
        "3012099172",
        "3003217347",
        "3007940623",
        "2903899730",
        "3010338568"
    ]
},{
    "id": "1951724000",
    "title": "Fitting Linear Mixed-Effects Models Using lme4",
    "abstract": "Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.",
    "date": "2015",
    "authors": [
        "Douglas Bates",
        "Martin M\u00e4chler",
        "Benjamin M. Bolker",
        "Steven C. Walker"
    ],
    "related_topics": [
        "Generalized linear mixed model",
        "Deviance (statistics)",
        "Restricted maximum likelihood"
    ],
    "citation_count": "36,705",
    "reference_count": "34",
    "references": [
        "2582743722",
        "2045656233",
        "1981457167",
        "3086315876",
        "1587094587",
        "2097879961",
        "2068047481",
        "2165693128",
        "1520511539",
        "2155382668"
    ]
},{
    "id": "2097360283",
    "title": "Regularization Paths for Generalized Linear Models via Coordinate Descent",
    "abstract": "We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include l(1) (the lasso), l(2) (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.",
    "date": "2010",
    "authors": [
        "Jerome Friedman",
        "Trevor Hastie",
        "Robert Tibshirani"
    ],
    "related_topics": [
        "Elastic net regularization",
        "Generalized iterative scaling",
        "Coordinate descent"
    ],
    "citation_count": "10,695",
    "reference_count": "37",
    "references": [
        "2135046866",
        "2109363337",
        "2122825543",
        "2063978378",
        "2078204800",
        "2138019504",
        "2158940042",
        "2020925091",
        "2074682976",
        "2132555912"
    ]
},{
    "id": "3012284084",
    "title": "Substantial undocumented infection facilitates the rapid dissemination of novel coronavirus (SARS-CoV-2)",
    "abstract": "Estimation of the prevalence and contagiousness of undocumented novel coronavirus [severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2)] infections is critical for understanding the overall prevalence and pandemic potential of this disease. Here, we use observations of reported infection within China, in conjunction with mobility data, a networked dynamic metapopulation model, and Bayesian inference, to infer critical epidemiological characteristics associated with SARS-CoV-2, including the fraction of undocumented infections and their contagiousness. We estimate that 86% of all infections were undocumented [95% credible interval (CI): 82-90%] before the 23 January 2020 travel restrictions. The transmission rate of undocumented infections per person was 55% the transmission rate of documented infections (95% CI: 46-62%), yet, because of their greater numbers, undocumented infections were the source of 79% of the documented cases. These findings explain the rapid geographic spread of SARS-CoV-2 and indicate that containment of this virus will be particularly challenging.",
    "date": "2020",
    "authors": [
        "Ruiyun Li",
        "Sen Pei",
        "Bin Chen",
        "Yimeng Song",
        "Tao Zhang",
        "Wan Yang",
        "Jeffrey Shaman"
    ],
    "related_topics": [
        "Coronavirus",
        "Pandemic",
        "Disease"
    ],
    "citation_count": "2,625",
    "reference_count": "29",
    "references": [
        "3002539152",
        "3003573988",
        "2160337655",
        "3002533507",
        "3004026249",
        "3001971765",
        "3082757469",
        "3035621246",
        "3006320625",
        "2140763962"
    ]
},{
    "id": "2122825543",
    "title": "Regularization and variable selection via the elastic net",
    "abstract": "Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the",
    "date": "2005",
    "authors": [
        "Hui Zou",
        "Trevor Hastie"
    ],
    "related_topics": [
        "Elastic net regularization",
        "Lasso (statistics)",
        "Feature selection"
    ],
    "citation_count": "13,975",
    "reference_count": "32",
    "references": [
        "1554944419",
        "2135046866",
        "2109363337",
        "2063978378",
        "2157795344",
        "2798909945",
        "2143426320",
        "2074682976",
        "1975900269",
        "2138550913"
    ]
},{
    "id": "3004912618",
    "title": "Incubation period of 2019 novel coronavirus (2019-nCoV) infections among travellers from Wuhan, China, 20-28 January 2020.",
    "abstract": "A novel coronavirus (2019-nCoV) is causing an outbreak of viral pneumonia that started in Wuhan, China. Using the travel history and symptom onset of 88 confirmed cases that were detected outside Wuhan in the early outbreak phase, we estimate the mean incubation period to be 6.4 days (95% credible interval: 5.6\u20137.7), ranging from 2.1 to 11.1 days (2.5th to 97.5th percentile). These values should help inform 2019-nCoV case definitions and appropriate quarantine durations.",
    "date": "2020",
    "authors": [
        "Jantien A Backer",
        "Don Klinkenberg",
        "Jacco Wallinga"
    ],
    "related_topics": [
        "Infectious Disease Incubation Period",
        "Incubation period",
        "Outbreak"
    ],
    "citation_count": "1,423",
    "reference_count": "13",
    "references": [
        "3001897055",
        "3003668884",
        "3002539152",
        "3003573988",
        "3004397688",
        "2107053896",
        "3001423274",
        "1990049863",
        "1968393246",
        "1998725525"
    ]
},{
    "id": "3006659024",
    "title": "The psychological impact of quarantine and how to reduce it: rapid review of the evidence.",
    "abstract": "The December, 2019 coronavirus disease outbreak has seen many countries ask people who have potentially come into contact with the infection to isolate themselves at home or in a dedicated quarantine facility. Decisions on how to apply quarantine should be based on the best available evidence. We did a Review of the psychological impact of quarantine using three electronic databases. Of 3166 papers found, 24 are included in this Review. Most reviewed studies reported negative psychological effects including post-traumatic stress symptoms, confusion, and anger. Stressors included longer quarantine duration, infection fears, frustration, boredom, inadequate supplies, inadequate information, financial loss, and stigma. Some researchers have suggested long-lasting effects. In situations where quarantine is deemed necessary, officials should quarantine individuals for no longer than required, provide clear rationale for quarantine and information about protocols, and ensure sufficient supplies are provided. Appeals to altruism by reminding the public about the benefits of quarantine to wider society can be favourable.",
    "date": "2020",
    "authors": [
        "Samantha K Brooks",
        "Rebecca K Webster",
        "Louise E Smith",
        "Lisa Woodland",
        "Simon Wessely",
        "Neil Greenberg",
        "Gideon James Rubin"
    ],
    "related_topics": [
        "Quarantine",
        "Mental health",
        "Boredom"
    ],
    "citation_count": "5,969",
    "reference_count": "42",
    "references": [
        "2336678555",
        "1705041815",
        "3003379403",
        "1586661029",
        "2169337111",
        "2548791536",
        "2775241253",
        "2170812681",
        "2036410023",
        "2109525459"
    ]
},{
    "id": "3009577418",
    "title": "In Vitro Antiviral Activity and Projection of Optimized Dosing Design of Hydroxychloroquine for the Treatment of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2).",
    "abstract": "Background The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) first broke out in 2019 and subsequently spread worldwide. Chloroquine has been sporadically used in treating SARS-CoV-2 infection. Hydroxychloroquine shares the same mechanism of action as chloroquine, but its more tolerable safety profile makes it the preferred drug to treat malaria and autoimmune conditions. We propose that the immunomodulatory effect of hydroxychloroquine also may be useful in controlling the cytokine storm that occurs late phase in critically ill patients with SARS-CoV-2. Currently, there is no evidence to support the use of hydroxychloroquine in SARS-CoV-2 infection. Methods The pharmacological activity of chloroquine and hydroxychloroquine was tested using SARS-CoV-2-infected Vero cells. Physiologically based pharmacokinetic (PBPK) models were implemented for both drugs separately by integrating their in vitro data. Using the PBPK models, hydroxychloroquine concentrations in lung fluid were simulated under 5 different dosing regimens to explore the most effective regimen while considering the drug's safety profile. Results Hydroxychloroquine (EC50 = 0.72 \u03bcM) was found to be more potent than chloroquine (EC50 = 5.47 \u03bcM) in vitro. Based on PBPK models results, a loading dose of 400 mg twice daily of hydroxychloroquine sulfate given orally, followed by a maintenance dose of 200 mg given twice daily for 4 days is recommended for SARS-CoV-2 infection, as it reached 3 times the potency of chloroquine phosphate when given 500 mg twice daily 5 days in advance. Conclusions Hydroxychloroquine was found to be more potent than chloroquine to inhibit SARS-CoV-2 in vitro.",
    "date": "2020",
    "authors": [
        "Xueting Yao",
        "Fei Ye",
        "Miao Zhang",
        "Cheng Cui",
        "Baoying Huang",
        "Peihua Niu",
        "Xu Liu",
        "Li Zhao",
        "Erdan Dong",
        "Chunli Song",
        "Siyan Zhan",
        "Roujian Lu",
        "Haiyan Li",
        "Wenjie Tan",
        "Dongyang Liu"
    ],
    "related_topics": [
        "Hydroxychloroquine Sulfate",
        "Hydroxychloroquine",
        "Chloroquine Phosphate"
    ],
    "citation_count": "2,160",
    "reference_count": "34",
    "references": [
        "3001118548",
        "3001897055",
        "3005212621",
        "3005905966",
        "3004709581",
        "3007829007",
        "2095807050",
        "2100967823",
        "3036925868",
        "2150119943"
    ]
},{
    "id": "3009468976",
    "title": "Early dynamics of transmission and control of COVID-19: a mathematical modelling study.",
    "abstract": "Summary Background An outbreak of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has led to 95\u2008333 confirmed cases as of March 5, 2020. Understanding the early transmission dynamics of the infection and evaluating the effectiveness of control measures is crucial for assessing the potential for sustained transmission to occur in new areas. Combining a mathematical model of severe SARS-CoV-2 transmission with four datasets from within and outside Wuhan, we estimated how transmission in Wuhan varied between December, 2019, and February, 2020. We used these estimates to assess the potential for sustained human-to-human transmission to occur in locations outside Wuhan if cases were introduced. Methods We combined a stochastic transmission model with data on cases of coronavirus disease 2019 (COVID-19) in Wuhan and international cases that originated in Wuhan to estimate how transmission had varied over time during January, 2020, and February, 2020. Based on these estimates, we then calculated the probability that newly introduced cases might generate outbreaks in other areas. To estimate the early dynamics of transmission in Wuhan, we fitted a stochastic transmission dynamic model to multiple publicly available datasets on cases in Wuhan and internationally exported cases from Wuhan. The four datasets we fitted to were: daily number of new internationally exported cases (or lack thereof), by date of onset, as of Jan 26, 2020; daily number of new cases in Wuhan with no market exposure, by date of onset, between Dec 1, 2019, and Jan 1, 2020; daily number of new cases in China, by date of onset, between Dec 29, 2019, and Jan 23, 2020; and proportion of infected passengers on evacuation flights between Jan 29, 2020, and Feb 4, 2020. We used an additional two datasets for comparison with model outputs: daily number of new exported cases from Wuhan (or lack thereof) in countries with high connectivity to Wuhan (ie, top 20 most at-risk countries), by date of confirmation, as of Feb 10, 2020; and data on new confirmed cases reported in Wuhan between Jan 16, 2020, and Feb 11, 2020. Findings We estimated that the median daily reproduction number (Rt) in Wuhan declined from 2\u00b735 (95% CI 1\u00b715\u20134\u00b777) 1 week before travel restrictions were introduced on Jan 23, 2020, to 1\u00b705 (0\u00b741\u20132\u00b739) 1 week after. Based on our estimates of Rt, assuming SARS-like variation, we calculated that in locations with similar transmission potential to Wuhan in early January, once there are at least four independently introduced cases, there is a more than 50% chance the infection will establish within that population. Interpretation Our results show that COVID-19 transmission probably declined in Wuhan during late January, 2020, coinciding with the introduction of travel control measures. As more cases arrive in international locations with similar transmission potential to Wuhan before these control measures, it is likely many chains of transmission will fail to establish initially, but might lead to new outbreaks eventually. Funding Wellcome Trust, Health Data Research UK, Bill & Melinda Gates Foundation, and National Institute for Health Research.",
    "date": "2020",
    "authors": [
        "Adam J Kucharski",
        "Timothy W Russell",
        "Charlie Diamond",
        "Yang Liu",
        "John Edmunds",
        "Sebastian Funk",
        "Rosalind M Eggo",
        "Fiona Sun",
        "Mark Jit",
        "James D Munday",
        "Nicholas Davies",
        "Amy Gimma",
        "Kevin van Zandvoort",
        "Hamish Gibbs",
        "Joel Hellewell",
        "Christopher I Jarvis",
        "Sam Clifford",
        "Billy J Quilty",
        "Nikos I Bosse",
        "Sam Abbott",
        "Petra Klepac",
        "Stefan Flasche"
    ],
    "related_topics": [
        "Population",
        "Transmission (mechanics)",
        "Outbreak"
    ],
    "citation_count": "1,746",
    "reference_count": "25",
    "references": [
        "3003668884",
        "3004239190",
        "78967600",
        "3004026249",
        "3002533591",
        "3026046290",
        "2069251911",
        "2096145431",
        "1042757214",
        "3003773899"
    ]
},{
    "id": "2793008036",
    "title": "Hosts and Sources of Endemic Human Coronaviruses.",
    "abstract": "The four endemic human coronaviruses HCoV-229E, -NL63, -OC43, and -HKU1 contribute a considerable share of upper and lower respiratory tract infections in adults and children. While their clinical representation resembles that of many other agents of the common cold, their evolutionary histories, and host associations could provide important insights into the natural history of past human pandemics. For two of these viruses, we have strong evidence suggesting an origin in major livestock species while primordial associations for all four viruses may have existed with bats and rodents. HCoV-NL63 and -229E may originate from bat reservoirs as assumed for many other coronaviruses, but HCoV-OC43 and -HKU1 seem more likely to have speciated from rodent-associated viruses. HCoV-OC43 is thought to have emerged from ancestors in domestic animals such as cattle or swine. The bovine coronavirus has been suggested to be a possible ancestor, from which HCoV-OC43 may have emerged in the context of a pandemic recorded historically at the end of the 19th century. New data suggest that HCoV-229E may actually be transferred from dromedary camels similar to Middle East respiratory syndrome (MERS) coronavirus. This scenario provides important ecological parallels to the present prepandemic pattern of host associations of the MERS coronavirus.",
    "date": "2017",
    "authors": [
        "Victor M. Corman",
        "Doreen Muth",
        "Daniela Niemeyer",
        "Christian Drosten"
    ],
    "related_topics": [
        "Coronavirus",
        "Middle East respiratory syndrome",
        "Middle East respiratory syndrome coronavirus"
    ],
    "citation_count": "557",
    "reference_count": "122",
    "references": [
        "2166867592",
        "2132260239",
        "1993577573",
        "2775086803",
        "2565805236",
        "2112147913",
        "2160011624",
        "2113457186",
        "2134061616",
        "2576706040"
    ]
},{
    "id": "2894950287",
    "title": "Attenuation of replication by a 29 nucleotide deletion in SARS-coronavirus acquired during the early stages of human-to-human transmission.",
    "abstract": "A 29 nucleotide deletion in open reading frame 8 (ORF8) is the most obvious genetic change in severe acute respiratory syndrome coronavirus (SARS-CoV) during its emergence in humans. In spite of intense study, it remains unclear whether the deletion actually reflects adaptation to humans. Here we engineered full, partially deleted (\u221229\u2009nt), and fully deleted ORF8 into a SARS-CoV infectious cDNA clone, strain Frankfurt-1. Replication of the resulting viruses was compared in primate cell cultures as well as Rhinolophus bat cells made permissive for SARS-CoV replication by lentiviral transduction of the human angiotensin-converting enzyme 2 receptor. Cells from cotton rat, goat, and sheep provided control scenarios that represent host systems in which SARS-CoV is neither endemic nor epidemic. Independent of the cell system, the truncation of ORF8 (29\u2009nt deletion) decreased replication up to 23-fold. The effect was independent of the type I interferon response. The 29\u2009nt deletion in SARS-CoV is a deleterious mutation acquired along the initial human-to-human transmission chain. The resulting loss of fitness may be due to a founder effect, which has rarely been documented in processes of viral emergence. These results have important implications for the retrospective assessment of the threat posed by SARS.",
    "date": "2018",
    "authors": [
        "Doreen Muth",
        "Victor Max Corman",
        "Hanna Roth",
        "Tabea Binger",
        "Ronald Dijkman",
        "Lina Theresa Gottula",
        "Florian Gloza-Rausch",
        "Andrea Balboni",
        "Mara Battilani",
        "Danijela Rihtari\u010d",
        "Ivan Toplak",
        "Ram\u00f3n Seage Ameneiros",
        "Alexander Pfeifer",
        "Volker Thiel",
        "Jan Felix Drexler",
        "Marcel Alexander M\u00fcller",
        "Christian Drosten"
    ],
    "related_topics": [
        "Coronavirus",
        "Viral evolution",
        "Disease reservoir"
    ],
    "citation_count": "302",
    "reference_count": "63",
    "references": [
        "2132260239",
        "1993577573",
        "2127435093",
        "2775086803",
        "2134061616",
        "2046153984",
        "2140338292",
        "2031705962",
        "2101063972",
        "2255897570"
    ]
},{
    "id": "2884280018",
    "title": "The European Virus Archive goes global: A growing resource for research",
    "abstract": "The European Virus Archive (EVA) was created in 2008 with funding from the FP7-EU Infrastructure Programme, in response to the need for a coordinated and readily accessible collection of viruses that could be made available to academia, public health organisations and industry. Within three years, it developed from a consortium of nine European laboratories to encompass associated partners in Africa, Russia, China, Turkey, Germany and Italy. In 2014, the H2020 Research and Innovation Framework Programme (INFRAS projects) provided support for the transformation of the EVA from a European to a global organization (EVAg). The EVAg now operates as a non-profit consortium, with 26 partners and 20 associated partners from 21 EU and non-EU countries. In this paper, we outline the structure, management and goals of the EVAg, to bring to the attention of researchers the wealth of products it can provide and to illustrate how end-users can gain access to these resources. Organisations or individuals who would like to be considered as contributors are invited to contact the EVAg coordinator, Jean-Louis Romette, at jean-louis.romette@univmed.fr.",
    "date": "2018",
    "authors": [
        "J.L. Romette",
        "C.M. Prat",
        "E.A. Gould",
        "X. de Lamballerie",
        "R. Charrel",
        "B. Coutard",
        "A.R. Fooks",
        "M. Bardsley",
        "M. Carroll",
        "C. Drosten",
        "J.F. Drexler",
        "S. G\u00fcnther",
        "B. Klempa",
        "D. Pinschewer",
        "T. Klimkait",
        "T. Avsic-Zupanc",
        "M.R. Capobianchi",
        "A. Dicaro",
        "G. Ippolito",
        "A. Nitsche",
        "M. Koopmans",
        "C. Reusken",
        "A. Gorbalenya",
        "H. Raoul",
        "H. Bourhy",
        "T. Mettenleiter",
        "S. Reiche",
        "C. Batten",
        "C. Sabeta",
        "J.T. Paweska",
        "M. Eropkin",
        "V. Zverev",
        "Z. Hu",
        "S. Mac Cullough",
        "A. Mirazimi",
        "F. Pradel",
        "P. Lieutaud"
    ],
    "related_topics": [
        "Resource (biology)",
        "Biobank",
        "Economic growth"
    ],
    "citation_count": "25",
    "reference_count": "10",
    "references": [
        "1703839189",
        "2384699986",
        "2559123425",
        "2786313719",
        "2426204902",
        "2587777516",
        "2796941210",
        "2621222833",
        "2759052617",
        "2094250116"
    ]
},{
    "id": "2031705962",
    "title": "Ecology, evolution and classification of bat coronaviruses in the aftermath of SARS.",
    "abstract": "In 2002/2003, a novel coronavirus (CoV) caused a pandemic, infecting more than 8000 people, of whom nearly 10% died. This virus, termed severe acute respiratory syndrome-CoV was linked to a zoonotic origin from rhinolophid bats in 2005. Since then, numerous studies have described novel bat CoVs, including close relatives of the newly emerging Middle East respiratory syndrome (MERS)-CoV. In this paper we discuss CoV genomic properties and compare different taxonomic approaches in light of the technical difficulties of obtaining full genomic sequences directly from bat specimens. We first present an overview of the available studies on bat CoVs, with details on their chiropteran hosts, then comparatively analyze the increase in bat CoV studies and novel genomic sequences obtained since the SARS pandemic. We then conduct a comprehensive phylogenetic analysis of the genera Alpha- and Betacoronavirus, to show that bats harbour more CoV diversity than other mammalian hosts and are widely represented in most, but not all parts of the tree of mammalian CoVs. We next discuss preliminary evidence for phylogenetic co-segregation of CoVs and bat hosts encompassing the Betacoronavirus clades b and d, with an emphasis on the sampling bias that exists among bat species and other mammals, then present examples of CoVs infecting different hosts on the one hand and viruses apparently confined to host genera on the other. We also demonstrate a geographic bias within available studies on bat CoVs, and identify a critical lack of information from biodiversity hotspots in Africa, Asia and Latin America. We then present evidence for a zoonotic origin of four of the six known human CoVs (HCoV), three of which likely involved bats, namely SARS-CoV, MERS-CoV and HCoV-229E; compare the available data on CoV pathogenesis in bats to that in other mammalian hosts; and discuss hypotheses on the putative insect origins of CoV ancestors. Finally, we suggest caution with conclusions on the zoonotic potential of bat viruses, based only on genomic sequence data, and emphasize the need to preserve these ecologically highly relevant animals. This paper forms part of a symposium in Antiviral Research on \"from SARS to MERS: 10years of research on highly pathogenic human coronaviruses\".",
    "date": "2013",
    "authors": [
        "Jan Felix Drexler",
        "Victor Max Corman",
        "Christian Drosten"
    ],
    "related_topics": [
        "Betacoronavirus",
        "Alphacoronavirus",
        "Middle East respiratory syndrome"
    ],
    "citation_count": "297",
    "reference_count": "147",
    "references": [
        "2166867592",
        "2146058063",
        "2132260239",
        "2130362098",
        "2129542667",
        "2127435093",
        "2119111857",
        "2112147913",
        "2160011624",
        "2103503670"
    ]
},{
    "id": "2032118018",
    "title": "Primer-directed enzymatic amplification of DNA with a thermostable DNA polymerase",
    "abstract": "A thermostable DNA polymerase was used in an in vitro DNA amplification procedure, the polymerase chain reaction. The enzyme, isolated from Thermus aquaticus, greatly simplifies the procedure and, by enabling the amplification reaction to be performed at higher temperatures, significantly improves the specificity, yield, sensitivity, and length of products that can be amplified. Single-copy genomic sequences were amplified by a factor of more than 10 million with very high specificity, and DNA segments up to 2000 base pairs were readily amplified. In addition, the method was used to amplify and detect a target DNA molecule present only once in a sample of 10(5) cells.",
    "date": "1988",
    "authors": [
        "Randall K. Saiki",
        "David H. Gelfand",
        "Susanne Stoffel",
        "Stephen J. Scharf",
        "Russell Higuchi",
        "Glenn T. Horn",
        "Kary B. Mullis",
        "Henry A. Erlich"
    ],
    "related_topics": [
        "Multiple displacement amplification",
        "Taq polymerase",
        "Hot start PCR"
    ],
    "citation_count": "22,870",
    "reference_count": "18",
    "references": [
        "2144634347",
        "2138270253",
        "2050717506",
        "1558516755",
        "1517480469",
        "1997521650",
        "2071697240",
        "2030903599",
        "1967999707",
        "2012061944"
    ]
},{
    "id": "2035792726",
    "title": "Strand displacement amplification\u2014an isothermal, in vitro DNA amplification technique",
    "abstract": "Strand Displacement Amplification (SDA) is an isothermal, in vitro nucleic acid amplification technique based upon the ability of HincII to nick the unmodified strand of a hemiphosphorothioate form of its recognition site, and the ability of exonuclease deficient klenow (exo- klenow) to extend the 3'-end at the nick and displace the downstream DNA strand. Exponential amplification results from coupling sense and antisense reactions in which strands displaced from a sense reaction serve as target for an antisense reaction and vice versa. In the original design (G. T. Walker, M. C. Little, J. G. Nadeau and D. D. Shank (1992) Proc. Natl. Acad. Sci 89, 392-396), the target DNA sample is first cleaved with a restriction enzyme(s) in order to generate a double-stranded target fragment with defined 5'- and 3'-ends that can then undergo SDA. Although effective, target generation by restriction enzyme cleavage presents a number of practical limitations. We report a new target generation scheme that eliminates the requirement for restriction enzyme cleavage of the target sample prior to amplification. The method exploits the strand displacement activity of exo- klenow to generate target DNA copies with defined 5'- and 3'-ends. The new target generation process occurs at a single temperature (after initial heat denaturation of the double-stranded DNA). The target copies generated by this process are then amplified directly by SDA. The new protocol improves overall amplification efficiency. Amplification efficiency is also enhanced by improved reaction conditions that reduce nonspecific binding of SDA primers. Greater than 10(7)-fold amplification of a genomic sequence from Mycobacterium tuberculosis is achieved in 2 hours at 37 degrees C even in the presence of as much as 10 micrograms of human DNA per 50 microL reaction. The new target generation scheme can also be applied to techniques separate from SDA as a means of conveniently producing double-stranded fragments with 5'- and 3'-sequences modified as desired.",
    "date": "1992",
    "authors": [
        "G T Walker",
        "M S Fraiser",
        "J L Schram",
        "M C Little",
        "J G Nadeau",
        "D P Malinowski"
    ],
    "related_topics": [
        "Nucleic acid amplification technique",
        "Multiple displacement amplification",
        "Klenow fragment"
    ],
    "citation_count": "1,485",
    "reference_count": "6",
    "references": [
        "2062756489",
        "2013923392",
        "2142539585",
        "2078846682",
        "2058317622",
        "1972383778"
    ]
},{
    "id": "2062756489",
    "title": "Isothermal, in vitro amplification of nucleic acids by a multienzyme reaction modeled after retroviral replication.",
    "abstract": "A target nucleic acid sequence can be replicated (amplified) exponentially in vitro under isothermal conditions by using three enzymatic activities essential to retroviral replication: reverse transcriptase, RNase H, and a DNA-dependent RNA polymerase. By mimicking the retroviral strategy of RNA replication by means of cDNA intermediates, this reaction accumulates cDNA and RNA copies of the original target. Product accumulation is exponential with respect to time, indicating that newly synthesized cDNAs and RNAs function as templates for a continuous series of transcription and reverse transcription reactions. Ten million-fold amplification occurs after a 1- to 2-hr incubation, with an initial rate of amplification of 10-fold every 2.5 min. This self-sustained sequence replication system is useful for the detection and nucleotide sequence analysis of rare RNAs and DNAs. The analogy to aspects of retroviral replication is discussed.",
    "date": "1990",
    "authors": [
        "John C. Guatelli",
        "Kristina M. Whitfield",
        "Deborah Y. Kwoh",
        "Kevin J. Barringer",
        "Douglas D. Richman",
        "Thomas R. Gingeras"
    ],
    "related_topics": [
        "Self-Sustained Sequence Replication",
        "Nucleic acid amplification technique",
        "Rapid amplification of cDNA ends"
    ],
    "citation_count": "1,084",
    "reference_count": "22",
    "references": [
        "2050717506",
        "2030017358",
        "1963954954",
        "2074747188",
        "2032790020",
        "2156326901",
        "1994142510",
        "2012174863",
        "1980437255",
        "2090507582"
    ]
},{
    "id": "1990689151",
    "title": "Nucleic acid sequence-based amplification.",
    "abstract": "Nucleic acid sequence-based amplification (NASBA) is a primer-dependent technology that can be used for the continuous amplification of nucleic acids in a single mixture at one temperature.",
    "date": "1991",
    "authors": [
        "Compton J"
    ],
    "related_topics": [
        "Nucleic acid amplification technique",
        "Nucleic acid methods",
        "NASBA"
    ],
    "citation_count": "1,615",
    "reference_count": "0",
    "references": []
},{
    "id": "2142539585",
    "title": "Isothermal in vitro amplification of DNA by a restriction enzyme/DNA polymerase system.",
    "abstract": "Abstract An isothermal in vitro DNA amplification method was developed based upon the following sequence of reaction events. Restriction enzyme cleavage and subsequent heat denaturation of a DNA sample generates two single-stranded target DNA fragments (T1 and T2). Present in excess are two DNA amplification primers (P1 and P2). The 3' end of P1 binds to the 3' end of T1, forming a duplex with 5' overhangs. Likewise, P2 binds to T2. The 5' overhangs of P1 and P2 contain a recognition sequence (5'-GTTGAC-3') for the restriction enzyme HincII. An exonuclease-deficient form of the large fragment of Escherichia coli DNA polymerase I (exo- Klenow polymerase) [Derbyshire, V., Freemont, P. S., Sanderson, M. R., Beese, L., Friedman, J. M., Joyce, C. M. & Steitz, T. A. (1988) Science 240, 199-201] extends the 3' ends of the duplexes using dGTP, dCTP, TTP, and deoxyadenosine 5'-[alpha-thio]triphosphate, which produces hemiphosphorothioate recognition sites on P1.T1 and P2.T2. HincII nicks the unprotected primer strands of the hemiphosphorothioate recognition sites, leaving intact the modified complementary strands. The exo- Klenow polymerase extends the 3' end at the nick on P1.T1 and displaces the downstream strand that is functionally equivalent to T2. Likewise, extension at the nick on P2.T2 results in displacement of a downstream strand functionally equivalent to T1. Nicking and polymerization/displacement steps cycle continuously on P1.T1 and P2.T2 because extension at a nick regenerates a nickable HincII recognition site. Target amplification is exponential because strands displaced from P1.T1 serve as targets for P2 and strands displaced from P2.T2 serve as targets for P1. A 10(6)-fold amplification of a genomic sequence from Mycobacterium tuberculosis or Mycobacterium bovis was achieved in 4 h at 37 degrees C.",
    "date": "1991",
    "authors": [
        "G T Walker",
        "M C Little",
        "J G Nadeau",
        "D D Shank"
    ],
    "related_topics": [
        "Nicking enzyme",
        "DNA polymerase I",
        "Klenow fragment"
    ],
    "citation_count": "1,134",
    "reference_count": "0",
    "references": []
},{
    "id": "2083121396",
    "title": "Betaine can eliminate the base pair composition dependence of DNA melting",
    "abstract": "We show that the amino acid analogue betaine shares with small tetraalkylammonium ions [Melchior, W. B., Jr., & von Hippel, P. H. (1973) Proc. Natl. Acad. Sci. U.S.A. 70, 298-302] the ability to reduce or even eliminate the base pair composition dependence of DNA thermal melting transitions. The \"isostabilizing\" concentration of betaine (at which AT and GC base pairs are equally stable) is approximately 5.2 M. Betaine exerts its isostabilizing effect without appreciably altering the conformation of double-stranded DNA from the B form. The presence of > 5 M betaine also does not greatly change the behavior of DNA as a polyelectrolyte; this lack of effect on electrostatic interactions is expected because betaine exists as a zwitterion near neutral pH. Study of DNA melting transitions in high concentrations of betaine thus allows the experimental separation of compositional and polyelectrolyte effects on DNA melting. As a consequence, betaine solutions can also be used to investigate DNA-protein interactions under isostabilizing (or close to isostabilizing) conditions, which has not been possible using isostabilizing salts. This potential is illustrated by examining the highly salt concentration-dependent interaction of ribonuclease A with DNA in concentrated betaine solutions.",
    "date": "1993",
    "authors": [
        "W A Rees",
        "T D Yager",
        "J Korte",
        "P H von Hippel"
    ],
    "related_topics": [
        "Betaine",
        "Base pair",
        "Polyelectrolyte"
    ],
    "citation_count": "439",
    "reference_count": "37",
    "references": [
        "2009095852",
        "2113368761",
        "1986115510",
        "2032413102",
        "2102834112",
        "1989651677",
        "2005389848",
        "2045514727",
        "1988753748",
        "2026884660"
    ]
},{
    "id": "2082277951",
    "title": "Uniform amplification of a mixture of deoxyribonucleic acids with varying GC content.",
    "abstract": "A PCR method for uniform amplification of a mixture of DNA templates differing in GC content is described using the two enzyme approach (Klentaq1 and Pfu DNA polymerase) and a combination of DMSO and betaine. This method was applied to amplify the CGG repeat region from the fragile X region.",
    "date": "1996",
    "authors": [
        "N Baskaran",
        "R P Kandpal",
        "A K Bhargava",
        "M W Glynn",
        "A Bale",
        "S M Weissman"
    ],
    "related_topics": [
        "Pfu DNA polymerase",
        "GC-content",
        "Polymerase chain reaction"
    ],
    "citation_count": "276",
    "reference_count": "26",
    "references": [
        "2032118018",
        "2167119720",
        "2021243296",
        "2002780348",
        "2083121396",
        "2137180677",
        "2006762876",
        "2159542417",
        "2151639225",
        "2045514727"
    ]
},{
    "id": "1970137322",
    "title": "Molecular staging of prostate cancer with the use of an enhanced reverse transcriptase-PCR assay",
    "abstract": "Objective. Because up to 40 percent of surgically treated patients with prostate cancer are subsequently found to be clinically understaged, a more sensitive staging modality to identify extraprostatic disease prior to surgery is required. Methods. We describe an enhanced reverse transcriptase (RT) polymerase chain reaction (PCR) assay utilizing oligonucleoticie primers specific for the human prostate-specific antigen (PSA). This assay identifies PSA-synthesizing cells from reverse transcribed mRNA. This assay was applied to RNAs extracted from the peripheral blood lymphocytes of 65 patients with clinically localized prostate cancer. In addition, blood from 20 women, 20 young men, 25 age-matched control men under treatment for benign prostatic hyperplasia (BPH), and 18 men with established, untreated metastatic prostate cancer was tested. Results. An RTPCR assay for PSA can recognize one PSA-expressing cell diluted into one hundred thousand lymphocytes. The sensitivity of this assay can be enhanced by the addition of digoxigenin-modified nucleotides to the PCR reaction and this assay was applied to RNAs extracted from the peripheral lymphocyte fraction of 148 prostate cancer patients and controls at this institution. Although no specimen from women or men without cancer was positive in this assay, 14 of 18 metastatic prostate cancer patients were positive (77.8%). Additionally, 25 of 65 (38.5%) patients with clinically localized disease (T1-2b) were positive from blood specimens obtained prior to surgery. Final pathologic results from this group of patients identified a correlation between positivity on this assay and the presence of capsular tumor penetration (sensitivity, 68%; specificity, 84%) as well as a strong correlation with the finding of carcinoma at the surgical margin (sensitivity, 87%; specificity, 76%). Logarithmic regression analysis of the results of the RT-PCR assay indicates its remarkable superiority to digital rectal examination, computed tomography scan, endorectal coil magnetic resonance imaging, PSA, prostate-specific antigen density, or Gleason score for predicting the true pathologic stage of prostate cancer in these surgically treated patients. Conclusions. An RT-PCR assay using PSA primers to detect p7rostate cells in the peripheral circulation of surgical-candidate patients is significantly correlated with capsular penetration and tumor-positive surgical margins. This molecular assay provides a sensitive and specific means to stage correctly apparent localized prostate cancer prior to radical prostatectomy.",
    "date": "1994",
    "authors": [
        "Aaron E. Katz",
        "Carl A. Olsson",
        "Anthony J. Raffo",
        "Cristoforo Cama",
        "Harris Perlman",
        "Eric Seaman",
        "Kathleen M. O'Toole",
        "Don McMahon",
        "Mitchell C. Benson",
        "Ralph Buttyan"
    ],
    "related_topics": [
        "PCA3",
        "Prostate cancer",
        "Prostate-specific antigen"
    ],
    "citation_count": "363",
    "reference_count": "29",
    "references": [
        "2144634347",
        "2134812217",
        "2138270253",
        "2053510778",
        "2138417964",
        "2395925941",
        "2076877296",
        "2002027028",
        "123162698",
        "2057477877"
    ]
},{
    "id": "2056636525",
    "title": "DNA helix destabilization by proline and betaine: possible role in the salinity tolerance process",
    "abstract": "Evidence is provided for the ability of proline, a salinity induced osmoprotectant, to destabilize the double helix and lower the Tm of DNA in a concentration dependent manner. At the reported salinity-adaptive bio-accumulation of 1 M and above, proline could considerably decrease the Tm and partially counteract the effect of sodium chloride and spermidine on DNA stability. On the contrary, several other amino acids tested did not show any such destabilizing effect on DNA helix. Enhanced susceptibility to S1 nuclease and insensitivity to DNase I in presence of increasing proline concentrations have further suggested a clear destabilization of the double helix. Such an effect is somewhat reminiscent of the interaction between betaine, another salinity induced osmolyte, and DNA resulting in decreased Tm values. These interactions may be significant in view of the abundance of such osmolytes in cells under salinity stress-adapted conditions, with many a bacterial mutant accumulating them exhibiting improved tolerance to salinity.",
    "date": "1997",
    "authors": [
        "Chadalavada S.V Rajendrakumar",
        "Tangirala Suryanarayana",
        "Arjula R Reddy"
    ],
    "related_topics": [
        "Osmolyte",
        "Proline",
        "Betaine"
    ],
    "citation_count": "172",
    "reference_count": "27",
    "references": [
        "1832710699",
        "2003744680",
        "2154547290",
        "2083121396",
        "2057033722",
        "1993165949",
        "2071062575",
        "2011281099",
        "1970874044",
        "1597626888"
    ]
},{
    "id": "3000771439",
    "title": "Cross-species transmission of the newly identified coronavirus 2019-nCoV.",
    "abstract": "The current outbreak of viral pneumonia in the city of Wuhan, China, was caused by a novel coronavirus designated 2019-nCoV by the World Health Organization, as determined by sequencing the viral RNA genome. Many initial patients were exposed to wildlife animals at the Huanan seafood wholesale market, where poultry, snake, bats, and other farm animals were also sold. To investigate possible virus reservoir, we have carried out comprehensive sequence analysis and comparison in conjunction with relative synonymous codon usage (RSCU) bias among different animal species based on the 2019-nCoV sequence. Results obtained from our analyses suggest that the 2019-nCoV may appear to be a recombinant virus between the bat coronavirus and an origin-unknown coronavirus. The recombination may occurred within the viral spike glycoprotein, which recognizes a cell surface receptor. Additionally, our findings suggest that 2019-nCoV has most similar genetic information with bat coronovirus and most similar codon usage bias with snake. Taken together, our results suggest that homologous recombination may occur and contribute to the 2019-nCoV cross-species transmission.",
    "date": "2020",
    "authors": [
        "Wei Ji",
        "Wei Wang",
        "Xiaofang Zhao",
        "Junjie Zai",
        "Xingguang Li"
    ],
    "related_topics": [
        "Coronavirus",
        "Codon usage bias",
        "Cross-species transmission"
    ],
    "citation_count": "516",
    "reference_count": "22",
    "references": [
        "2141052558",
        "2160378127",
        "2999318660",
        "1483247593",
        "2172081451",
        "2134061616",
        "2999535351",
        "2163400707",
        "2152528032",
        "1996050058"
    ]
},{
    "id": "1979974453",
    "title": "Accelerated reaction by loop-mediated isothermal amplification using loop primers.",
    "abstract": "Loop-mediated isothermal amplification (LAMP) is a novel nucleic acid amplification method that amplifies DNA with high specificity, efficiency and rapidity under isothermal conditions using a set of four specially designed primers and a DNA polymerase with strand displacement activity. We have developed a method that accelerates the LAMP reaction by using additional primers, termed loop primers. Loop primers hybridize to the stem-loops, except for the loops that are hybridized by the inner primers, and prime strand displacement DNA synthesis. Although both inner and loop primers react via the loops, they do so by different mechanisms. The LAMP method presented here uses loop primers to achieve reaction times of less than half that of the original LAMP method. Since the total time of analysis including detection is less than 1h, this new method should facilitate genetic analysis, including genetic diagnosis in the clinical laboratory.",
    "date": "2002",
    "authors": [
        "K. Nagamine",
        "T. Hase",
        "T. Notomi"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Multiple displacement amplification",
        "Recombinase Polymerase Amplification"
    ],
    "citation_count": "2,006",
    "reference_count": "16",
    "references": [
        "2032118018",
        "2164578725",
        "2105275554",
        "2050717506",
        "1975801865",
        "1520883967",
        "1538518956",
        "2141633648",
        "2035792726",
        "2062756489"
    ]
},{
    "id": "1562219715",
    "title": "Diagnostics for the developing world.",
    "abstract": "Although 'diseases of affluence', such as diabetes and cardiovascular disease, are increasing in developing countries, infectious diseases still impose the greatest health burden. Annually, just under 1 million people die from malaria, 4.3 million from acute respiratory infections, 2.9 million from enteric infections and 5 million from AIDS and tuberculosis. Other sexually transmitted infections and tropical parasitic infections are responsible for hundreds of thousands of deaths and an enormous burden of morbidity. More than 95% of these deaths occur in developing countries. Simple, accurate and stable diagnostic tests are essential to combat these diseases, but are usually unavailable or inaccessible to those who need them.",
    "date": "2004",
    "authors": [
        "David Mabey",
        "Rosanna W. Peeling",
        "Andrew Ustianowski",
        "Mark D. Perkins"
    ],
    "related_topics": [
        "Diseases of affluence",
        "Disease",
        "Acquired immunodeficiency syndrome (AIDS)"
    ],
    "citation_count": "1,004",
    "reference_count": "45",
    "references": [
        "2108361166",
        "2043066204",
        "2121049991",
        "2108215795",
        "2338591221",
        "2115780677",
        "2135192999",
        "2100641815",
        "2124971883",
        "1986532204"
    ]
},{
    "id": "89741002",
    "title": "Visual detection of isothermal nucleic acid amplification using pH-sensitive dyes.",
    "abstract": "Nucleic acid amplification is the basis for many molecular diagnostic assays. In these cases, the amplification product must be detected and analyzed, typically requiring extended workflow time, sophisticated equipment, or both. Here we present a novel method of amplification detection that harnesses the pH change resulting from amplification reactions performed with minimal buffering capacity. In loop-mediated isothermal amplification (LAMP) reactions, we achieved rapid (<30 min) and sensitive (<10 copies) visual detection using pH-sensitive dyes. Additionally, the detection can be performed in real time, enabling high-throughput or quantitative applications. We also demonstrate this visual detection for another isothermal amplification method (strand-displacement amplification), PCR, and reverse transcription LAMP (RT-LAMP) detection of RNA. The colorimetric detection of amplification presented here represents a generally applicable approach for visual detection of nucleic acid amplification, enabling molecular diagnostic tests to be analyzed immediately without the need for specialized and expensive instrumentation.",
    "date": "2015",
    "authors": [
        "Nathan A. Tanner",
        "Yinhua Zhang",
        "Thomas C. Evans"
    ],
    "related_topics": [
        "Nucleic acid amplification technique",
        "Loop-mediated isothermal amplification",
        "Nucleic acid"
    ],
    "citation_count": "283",
    "reference_count": "25",
    "references": [
        "1988929438",
        "2105275554",
        "2065098811",
        "2153350094",
        "1979974453",
        "1975801865",
        "2048255163",
        "2066385972",
        "2082133857",
        "2117240806"
    ]
},{
    "id": "2063533401",
    "title": "Loop-mediated isothermal amplification (LAMP): principle, features, and future prospects",
    "abstract": "Loop-mediated isothermal amplification (LAMP), a newly developed gene amplification method, combines rapidity, simplicity, and high specificity. Several tests have been developed based on this method, and simplicity is maintained throughout all steps, from extraction of nucleic acids to detection of amplification. In the LAMP reaction, samples are amplified at a fixed temperature through a repetition of two types of elongation reactions occurring at the loop regions: self-elongation of templates from the stem loop structure formed at the 3\u2032-terminal and the binding and elongation of new primers to the loop region. The LAMP reaction has a wide range of possible applications, including point-of-care testing, genetic testing in resource-poor settings (such as in developing countries), and rapid testing of food products and environmental samples.",
    "date": "2015",
    "authors": [
        "Tsugunori Notomi",
        "Yasuyoshi Mori",
        "Norihiro Tomita",
        "Hidetoshi Kanda"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Recombinase Polymerase Amplification",
        "Stem-loop"
    ],
    "citation_count": "451",
    "reference_count": "13",
    "references": [
        "2086187432",
        "2105275554",
        "2065098811",
        "1979974453",
        "1975801865",
        "2074305200",
        "2057876450",
        "2019786863",
        "2162859059",
        "2139825940"
    ]
},{
    "id": "1997925861",
    "title": "Loop mediated isothermal amplification (LAMP): a new generation of innovative gene amplification technique; perspectives in clinical diagnosis of infectious diseases.",
    "abstract": "Loop mediated isothermal amplification (LAMP) is a powerful innovative gene amplification technique emerging as a simple rapid diagnostic tool for early detection and identification of microbial diseases. The whole procedure is very simple and rapid wherein the amplification can be completed in less than 1\u2009h under isothermal conditions employing a set of six specially designed primers spanning eight distinct sequences of a target gene, by incubating all the reagents in a single tube. Gene amplification products can be detected by agarose gel electrophoresis as well as by real-time monitoring in an inexpensive turbidimeter. Gene copy number can also be quantified with the help of a standard curve generated from different concentrations of gene copy number plotted against time of positivity with the help of a real-time turbidimeter. Alternatively, gene amplification can be visualised by the naked eye either as turbidity or in the form of a colour change when SYBR Green I, a fluorescent dsDNA intercalating dye, is employed. LAMP does not require a thermal cycler and can be performed simply with a heating block and/or water bath. Considering the advantages of rapid amplification, simple operation and easy detection, LAMP has potential applications for clinical diagnosis as well as surveillance of infectious diseases in developing countries without requiring sophisticated equipment or skilled personnel. Copyright \u00a9 2008 John Wiley & Sons, Ltd.",
    "date": "2008",
    "authors": [
        "Manmohan Parida",
        "Santhosh Sannarangaiah",
        "Paban Kumar Dash",
        "P. V. L. Rao",
        "Kouichi Morita"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Applications of PCR",
        "Thermal cycler"
    ],
    "citation_count": "635",
    "reference_count": "37",
    "references": [
        "2105275554",
        "1979974453",
        "1975801865",
        "2100187217",
        "2149136689",
        "2019786863",
        "2160892791",
        "2101258647",
        "2119867242",
        "1982583549"
    ]
},{
    "id": "2050515639",
    "title": "Tolerance of loop-mediated isothermal amplification to a culture medium and biological substances",
    "abstract": "To simplify the molecular detection of micro-organisms, we evaluated the tolerance of loop-mediated isothermal amplification (LAMP) to a culture medium and some biological substances. The sensitivity of LAMP was less affected by the various components of the clinical samples than was polymerase chain reaction (PCR); therefore, DNA purification from samples could be omitted.",
    "date": "2007",
    "authors": [
        "Hisatoshi Kaneko",
        "Takashi Kawana",
        "Eiko Fukushima",
        "Tatsuo Suzutani"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Recombinase Polymerase Amplification",
        "DNA extraction"
    ],
    "citation_count": "679",
    "reference_count": "13",
    "references": [
        "2105275554",
        "1975801865",
        "2019786863",
        "2141633648",
        "2101258647",
        "2140363623",
        "2147815921",
        "2043238835",
        "1994213074",
        "1546091139"
    ]
},{
    "id": "2141633648",
    "title": "Loop-mediated Isothermal Amplification Reaction Using a Nondenatured Template",
    "abstract": "Loop-mediated isothermal amplification (LAMP) is a novel nucleic acid amplification method that amplifies DNA with high specificity, efficiency, and rapidity under isothermal conditions (1). The LAMP method requires a set of four specially designed primers and a DNA polymerase with strand displacement activity. The amplification products are stem-loop DNA structures with several inverted repeats of the target and cauliflower-like structures with multiple loops, yielding >500 \u03bcg/mL. Although LAMP amplifies DNA under isothermal conditions, the template DNA is heat-denatured. To determine whether LAMP can be performed under isothermal conditions at all steps, we attempted to amplify DNA without using a heat-denatured template. Hepatitis B virus (HBV) DNA that was obtained from a patient was digested with Bam HI and cloned into pBR322 plasmid vector. Plasmid and genomic DNA was prepared using the plasmid Midi reagent set (Qiagen) and EXTRAGEN reagent \u2026",
    "date": "2001",
    "authors": [
        "Kentaro Nagamine",
        "Keiko Watanabe",
        "Kimihiko Ohtsuka",
        "Tetsu Hase",
        "Tsugunori Notomi"
    ],
    "related_topics": [
        "Loop-mediated isothermal amplification",
        "Multiple displacement amplification",
        "Recombinase Polymerase Amplification"
    ],
    "citation_count": "527",
    "reference_count": "8",
    "references": [
        "2164578725",
        "2105275554",
        "2092043066",
        "2142769519",
        "1927282360",
        "2106775861",
        "2082277951",
        "2053738348"
    ]
},{
    "id": "2788073857",
    "title": "World malaria report",
    "abstract": "",
    "date": "2004",
    "authors": [
        "Weltgesundheitsorganisation"
    ],
    "related_topics": [
        "Malaria",
        "Indoor residual spraying",
        "Environmental health"
    ],
    "citation_count": "6,756",
    "reference_count": "3",
    "references": [
        "2093499192",
        "1967452938",
        "44523790"
    ]
},{
    "id": "2133724824",
    "title": "A large focus of naturally acquired Plasmodium knowlesi infections in human beings",
    "abstract": "Background About a fifth of malaria cases in 1999 for the Kapit division of Malaysian Borneo had routinely been identified by microscopy as Plasmodium malariae, although these infections appeared atypical and a nested PCR assay failed to identify P malariae DNA. We aimed to investigate whether such infections could be attributable to a variant form of P malariae or a newly emergent Plasmodium species. Methods We took blood samples from 208 people with malaria in the Kapit division between March, 2000, and November, 2002. The small subunit ribosomal RNA and the circumsporozoite protein genes were sequenced for eight isolates that had been microscopically identified as P malariae. All blood samples were characterised with a genus-specific and species-specific nested PCR assay together with newly designed P knowlesi-specific primers. Findings All DNA sequences were phylogenetically indistinguishable from those of P knowlesi, a malaria parasite of long-tailed macaque monkeys, but were significantly different from other malaria parasite species. By PCR assay, 120 (58%) of 208 people with malaria tested positive for P knowlesi, whereas none was positive for P malariae. P knowlesi parasites in human erythrocytes were difficult to distinguish from P malariae by microscopy. Most of the P knowlesi infections were in adults and we did not note any clustering of cases within communities. P knowlesi infections were successfully treated with chloroquine and primaquine. Interpretation Naturally acquired P knowlesi infections, misdiagnosed by microscopy mainly as P malariae, accounted for over half of all malaria cases in our study. Morphological similarities between P knowlesi and P malariae necessitate the use of molecular methods for correct identification. Further work is needed to determine whether human P knowlesi infections in the Kapit division are acquired from macaque monkeys or whether a host switch to human beings has occurred.",
    "date": "2004",
    "authors": [
        "Balbir Singh",
        "Lee Kim Sung",
        "Asmad Matusop",
        "Anand Radhakrishnan",
        "Sunita S G Shamsul",
        "Janet Cox-Singh",
        "Alan Thomas",
        "David J Conway"
    ],
    "related_topics": [
        "Plasmodium knowlesi",
        "Plasmodium malariae",
        "Malaria"
    ],
    "citation_count": "1,345",
    "reference_count": "29",
    "references": [
        "2097706568",
        "2156434383",
        "1546639740",
        "2102424972",
        "2106258670",
        "2144029515",
        "2163892779",
        "2118210994",
        "2025421232",
        "2038399745"
    ]
}]