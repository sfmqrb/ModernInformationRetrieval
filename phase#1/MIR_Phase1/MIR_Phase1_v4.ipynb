{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b2UsRU4P9JF"
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "<font face=\"B Titr\" size=5>\n",
    "<p></p><p></p>\n",
    "بسمه تعالی\n",
    "<p></p>\n",
    "</font>\n",
    "<p></p>\n",
    "<font>\n",
    "<br>\n",
    "درس بازیابی پیشرفته اطلاعات\n",
    "<br>\n",
    "مدرس: دکتر سلیمانی\n",
    "</font>\n",
    "<p></p>\n",
    "<br>\n",
    "<font>\n",
    "<b>فاز اول پروژه</b>\n",
    "</font>\n",
    "<br>\n",
    "<br>\n",
    "موعد تحویل: ۲۸ اسفند ۱۳۹۹\n",
    "<br>\n",
    "<br>\n",
    "<font size=4.8>\n",
    "دستیاران آموزشی: نیما جمالی، آرمین سعادت، ایمان غلامی\n",
    "</font>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<font>\n",
    "دانشگاه صنعتی شریف\n",
    "<br>\n",
    "دانشکده مهندسی کامپیوتر\n",
    "<br>\n",
    "<br>\n",
    "</font>\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3YoNVsQR3zO"
   },
   "source": [
    "<p></p>\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>مقدمه</b>\n",
    "    </h1>\n",
    "    <p></p>\n",
    "    <p></p>\n",
    "    هدف از فاز اول پروژه، طراحی و پیاده‌سازی سیستم بازیابی اطلاعات برای مجموعه دادگان تعیین شده می‌باشد.<br>\n",
    "    اولین مرحله، پیش‌پردازش مجموعه دادگان است. پس از آن نمایه‌ها با ویژگی‌های خواسته شده پیاده‌سازی می‌شود. در گام بعدی به ذخیره و بازخوانی نمایه‌ها به همراه روش‌های فشرده‌سازی پرداخته می‌شود. پس از آن تکنیک‌های اصلاح پرسمان پیاده‌سازی شده و در نهایت جستجو روی دادگان صورت می‌گیرد. همچنین در بخش آخر با پیاده‌سازی برخی معیارهای ارزیابی، عملکرد سیستم مورد سنجش قرار می‌گیرد.<br><br>\n",
    "     توضیحات مربوط به هر بخش در ادامه آمده است که اهداف، محدودیت‌ها و خواسته‌های آن بخش را مشخص می‌کند.\n",
    "     در هر بخش توابعی مشخص شده است که محتوای آن با کد نوشته شده توسط شما باید پر شود. شما می‌توانید در همین فایل، سیستم بازیابی خود را پیاده‌سازی کنید یا فایل‌های خودتان را ایمپورت کرده و از آن‌ها استفاده کنید. در هر صورت تمامی کدهای لازم را به همراه این نوت‌بوک ارسال کنید. همچنین در نظر داشته باشید که ملاک اصلی نمره‌دهی شما اجرای صحیح توابع مشخص‌شده در این نوت‌بوک می‌باشد. بنابراین از صحت اجرای نوت‌بوک خود اطمینان پیدا کنید.<br><br>\n",
    "     تنها زبان قابل قبول برای پروژه پایتون است. محدودیت استفاده از کتاب‌خانه‌های آماده در هر بخش مشخص شده است. پروژه ۱۱۵ نمره دارد که ۱۵ نمره از آن امتیازی و مربوط به بخش اصلاح پرسمان می‌باشد.\n",
    "    \n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaR5CS_khMQB"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>مجموعه دادگان</b>\n",
    "    </h1>\n",
    "    مجموعه دادگان مورد بررسی در این پروژه از سایت kaggle فراهم شده است. این مجموعه شامل اطلاعات ۶۰۰۰ فیلم سینمایی از سال ۱۹۰۴ تا ۲۰۱۷ است. داده‌ها در قالب فایل csv   دارای ستون‌‌های plot، title، id می‌باشد. id یک شناسه یکتا برای هر فیلم است که برای ارزیابی بهتر عملکرد شما به داده‌ها اضافه شده است و در مجموعه دادگان اصلی وجود نداشته است. همانطور که می‌دانید برای پیاده‌سازی نمایه باید به هر داکیومنت یک شناسه اختصاص بدهید. <b>شناسه مربوط به هر داکیومنت باید id ذکر شده برای آن در مجموعه دادگان باشد.</b> هر فیلم از دو بخش title و plot  تشکیل شده است که از این دو بخش در ساخت نمایه و جستجو استفاده می‌شود. plot خلاصه‌ای از طرح داستان فیلم است.<br>\n",
    "    علاوه بر مجموعه دادگان اصلی، تعدای پرسمان در اختیار شما قرار گرفته است. همچنین جواب مطلوب هر یک از این پرسمان‌ها نیز فراهم شده که طبیعتا زیرمجموعه‌ای از مجموعه دادگان است. شما باید از این پرسمان‌ها و نتیجه مورد انتظار هر کدام برای ارزیابی سامانه خود استفاده کنید.\n",
    "    پرسمان‌ها و شناسه فیلم‌های بازیابی شده مورد انتظار از هر پرسمان در فایل validation.json آمده است. توضیحات بیشتر در رابطه با استفاده از این فایل در بخش ارزیابی آمده است.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxNntHofmHHH"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>پیش‌پردازش و آماده‌سازی داده‌ها (۱۵ نمره)</b>\n",
    "    </h1>\n",
    "    در این بخش ابتدا داده‌ها را از فایل بخوانید. برای آماده‌سازی متن می‌توانید از کتاب‌خانه‌های آماده استفاده کنید. یکی از کتاب‌خانه‌های معروف برای این کار <a href=\"https://www.nltk.org/\">NLTK</a> است اما در انتخاب روش پیاده‌سازی این بخش مختارید. برای این بخش باید تابع ()prepare_text را تکمیل کنید. این تابع یک متن انگلیسی ورودی گرفته و توکن‌‌های مربوط به آن‌را در قالب یک لیست خروجی می‌دهد. متن ورودی در عمل تایتل یا طرح داستان هر فیلم است. دقت کنید که لیست خروجی شامل تعدادی توکن است که عملیات case folding، stemming و lemmatization روی آن‌ها اجرا شده است. در ضمن علائم نگارشی نباید به عنوان توکن در نظر گرفته شود. در کد زیر یک نمونه ورودی و خروجی نمایش داده شده است. با توجه به نحوه پیاده‌سازی انواع بازگردانی به ریشه قابل قبول است.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wrong', 'test']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_text(\"wrong,, test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import brown\n",
    "from collections import defaultdict\n",
    "import nltk.tag\n",
    "import json\n",
    "import os\n",
    "import sys \n",
    "from array import array\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "df_raw = pd.read_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_word_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    \n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    \n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    \n",
    "    return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sajad', 'be', 'fir', 'the', 'her', 'be', 'my', 'her'], [0, 1, 3, 4, 6, 7, 8, 10]]\n"
     ]
    }
   ],
   "source": [
    "def get_position_in_text_prepare_it(raw_text):\n",
    "    \n",
    "    punc_ls = string.punctuation\n",
    "    punc_ls = punc_ls + '–'\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    ls = LancasterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(raw_text)\n",
    "    \n",
    "    arr = [[tokens[i], i] for i in range(len(tokens))]\n",
    "    \n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    pos_arr = []\n",
    "    token_arr = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i][0] in punc_ls:\n",
    "            arr[i][1] = -1\n",
    "            continue\n",
    "        \n",
    "        arr[i][0] = ls.stem(lemmatizer.lemmatize(arr[i][0], pos=get_word_pos(tagged[i][1])))\n",
    "        \n",
    "        pos_arr.append(arr[i][1])\n",
    "        token_arr.append(arr[i][0])\n",
    "    \n",
    "    return [token_arr, pos_arr]\n",
    "\n",
    "print(get_position_in_text_prepare_it('Sajad is _ Fire the , here is my, her'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sajad', 'be', 'fir', 'the', 'her', 'be', 'my', 'her'], [0, 1, 3, 4, 6, 7, 8, 10]]\n"
     ]
    }
   ],
   "source": [
    "def get_position_in_text_prepare_it2(raw_text):\n",
    "    \n",
    "    raw_text = str(raw_text)\n",
    "    \n",
    "    punc_ls = string.punctuation\n",
    "    punc_ls = punc_ls + '–'\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    ls = LancasterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(raw_text)\n",
    "    \n",
    "    arr = [[tokens[i], i] for i in range(len(tokens))]\n",
    "    \n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    pos_arr = []\n",
    "    token_arr = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i][0] in punc_ls:\n",
    "            arr[i][1] = -1\n",
    "            continue\n",
    "        \n",
    "        arr[i][0] = ls.stem(lemmatizer.lemmatize(arr[i][0], pos=get_word_pos(tagged[i][1])))\n",
    "        \n",
    "        pos_arr.append(arr[i][1])\n",
    "        token_arr.append(arr[i][0])\n",
    "    \n",
    "    return [token_arr, pos_arr]\n",
    "\n",
    "print(get_position_in_text_prepare_it('Sajad is _ Fire the , here is my, her'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aa16Puk-if0",
    "outputId": "2e6a2c95-41d5-4146-a27b-5ceba034e291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sajad', 'be', 'fir', 'the', 'her', 'be', 'my', 'her']\n"
     ]
    }
   ],
   "source": [
    "def prepare_text(raw_text):\n",
    "    \n",
    "    punc_ls = string.punctuation\n",
    "    punc_ls = punc_ls + '–'\n",
    "    \n",
    "    tokens = word_tokenize(raw_text)\n",
    "    tokens = list(filter(lambda token: token not in punc_ls, tokens)) \n",
    "\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    ls = LancasterStemmer()\n",
    "    \n",
    "    tokens = [ls.stem(lemmatizer.lemmatize(tokens[i], pos=get_word_pos(tagged[i][1]))) \n",
    "              for i in range(len(tokens))]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "print(prepare_text('Sajad is _ Fire the , here is my, her'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 472 ms, total: 2min 58s\n",
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[the, suburbanit], [0, 1]]</td>\n",
       "      <td>[[the, film, be, about, a, famy, who, mov, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[laugh, gas], [0, 1]]</td>\n",
       "      <td>[[the, plot, be, that, of, a, black, wom, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[a, calamit, elop], [0, 1, 2]]</td>\n",
       "      <td>[[a, young, coupl, decid, to, elop, aft, be, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[the, cal, of, the, wild], [0, 1, 2, 3, 4]]</td>\n",
       "      <td>[[a, whit, girl, flor, lawr, reject, a, propos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[a, lad, from, old, ireland], [0, 1, 2, 3, 4]]</td>\n",
       "      <td>[[an, ir, boy, olcot, emigr, to, americ, to, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            title  \\\n",
       "0   1                      [[the, suburbanit], [0, 1]]   \n",
       "1   2                           [[laugh, gas], [0, 1]]   \n",
       "2   3                  [[a, calamit, elop], [0, 1, 2]]   \n",
       "3   4     [[the, cal, of, the, wild], [0, 1, 2, 3, 4]]   \n",
       "4   5  [[a, lad, from, old, ireland], [0, 1, 2, 3, 4]]   \n",
       "\n",
       "                                                plot  \n",
       "0  [[the, film, be, about, a, famy, who, mov, to,...  \n",
       "1  [[the, plot, be, that, of, a, black, wom, go, ...  \n",
       "2  [[a, young, coupl, decid, to, elop, aft, be, c...  \n",
       "3  [[a, whit, girl, flor, lawr, reject, a, propos...  \n",
       "4  [[an, ir, boy, olcot, emigr, to, americ, to, e...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## un-comment the line below if you want to run the block more than once\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "## data_frame \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.iat[index, 1] = get_position_in_text_prepare_it(str(row['title']))\n",
    "    df.iat[index, 2] = get_position_in_text_prepare_it(str(row['plot']))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVhVEO6VARIa"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>شناسایی و حذف stop-words (۵ نمره)</b>\n",
    "    </h1>\n",
    "    این بخش باید توسط خودتان و بدون استفاده از کد آماده پیاده‌سازی شود. ترم‌های موجود در مجموعه دادگان را بر اساس تکرار آن‌ها مرتب کرده و پرتکرارترین آن‌ها را به عنوان stop-words در نظر بگیرید. اینکه چند ترم را به عنوان stop-words در نظر بگیرید به عهده خودتان است.<br>\n",
    "    با فراخوانی تابع ()get_stop_words لیست stop-words به همراه تعداد تکرار آن‌‌ها خروجی داده می‌شود.<br>\n",
    "    ترم‌های به دست آمده از این بخش نباید در نمایه حضور داشته باشند.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-0YxOUeBGDY",
    "outputId": "b8e3476a-02af-41dc-b4a3-5c637ffd4118",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['the', '147762'],\n",
       "       ['to', '91563'],\n",
       "       ['and', '83116'],\n",
       "       ['a', '79587'],\n",
       "       ['be', '68937']], dtype='<U6')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stop_words():\n",
    "    \n",
    "    n = 50 # number of reported stop_words\n",
    "    dic = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "    \n",
    "        title_terms = row['title'][0]\n",
    "        plot_terms = row['plot'][0]\n",
    "    \n",
    "        for term in title_terms:\n",
    "            dic[term] = dic.get(term, 0) + 1\n",
    "        \n",
    "        for term in plot_terms:\n",
    "            dic[term] = dic.get(term, 0) + 1\n",
    "\n",
    "    dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    n_stop_words = take(n, dic.items())\n",
    "    \n",
    "    n_stop_words = np.array([list(t) for t in n_stop_words])\n",
    "    \n",
    "    return n_stop_words\n",
    "    \n",
    "stop_words = get_stop_words()\n",
    "stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['the', '147762'],\n",
       "       ['to', '91563'],\n",
       "       ['and', '83116'],\n",
       "       ['a', '79587'],\n",
       "       ['be', '68937'],\n",
       "       ['of', '42764'],\n",
       "       ['in', '38841'],\n",
       "       ['his', '34700'],\n",
       "       ['he', '32317'],\n",
       "       [\"'s\", '29813'],\n",
       "       ['her', '28138'],\n",
       "       ['that', '26288'],\n",
       "       ['with', '25083'],\n",
       "       ['on', '23087'],\n",
       "       ['hav', '20296'],\n",
       "       ['him', '18923'],\n",
       "       ['by', '17818'],\n",
       "       ['for', '17628'],\n",
       "       ['she', '17608'],\n",
       "       ['but', '13555']], dtype='<U6')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sw(arr, sw_ls):\n",
    "    arr_f_pos = []\n",
    "    arr_f_token = []\n",
    "    for i in range(len(arr[0])):\n",
    "        if arr[0][i] not in sw_ls:\n",
    "            arr_f_token.append(arr[0][i])\n",
    "            arr_f_pos.append(arr[1][i])\n",
    "            \n",
    "    return [arr_f_token, arr_f_pos]\n",
    "\n",
    "# ls = list(df.iloc[0,2]).copy()\n",
    "# print(delete_sw(ls, stop_words[:,0]))\n",
    "# print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                            title  \\\n",
      "0   1                      [[the, suburbanit], [0, 1]]   \n",
      "1   2                           [[laugh, gas], [0, 1]]   \n",
      "2   3                  [[a, calamit, elop], [0, 1, 2]]   \n",
      "3   4     [[the, cal, of, the, wild], [0, 1, 2, 3, 4]]   \n",
      "4   5  [[a, lad, from, old, ireland], [0, 1, 2, 3, 4]]   \n",
      "\n",
      "                                                plot  \n",
      "0  [[the, film, be, about, a, famy, who, mov, to,...  \n",
      "1  [[the, plot, be, that, of, a, black, wom, go, ...  \n",
      "2  [[a, young, coupl, decid, to, elop, aft, be, c...  \n",
      "3  [[a, whit, girl, flor, lawr, reject, a, propos...  \n",
      "4  [[an, ir, boy, olcot, emigr, to, americ, to, e...  \n",
      "__________________________________________________________________________ \n",
      " new corpus:\n",
      "\n",
      "   id                             title  \\\n",
      "0   1               [[suburbanit], [1]]   \n",
      "1   2            [[laugh, gas], [0, 1]]   \n",
      "2   3         [[calamit, elop], [1, 2]]   \n",
      "3   4             [[cal, wild], [1, 4]]   \n",
      "4   5  [[lad, old, ireland], [1, 3, 4]]   \n",
      "\n",
      "                                                plot  \n",
      "0  [[film, about, famy, mov, suburb, hop, quiet, ...  \n",
      "1  [[plot, black, wom, dent, toothach, giv, laugh...  \n",
      "2  [[young, coupl, decid, elop, catch, midst, rom...  \n",
      "3  [[whit, girl, flor, lawr, reject, propos, ind,...  \n",
      "4  [[ir, boy, olcot, emigr, americ, escap, desp, ...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "delete stop-words from df \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ls_new =  delete_sw(row['title'], stop_words)\n",
    "    df.iat[i, 1] = ls_new.copy()\n",
    "    ls_new =  delete_sw(row['plot'], stop_words)\n",
    "    df.iat[i, 2] = ls_new.copy()\n",
    "\n",
    "print('__________________________________________________________________________','\\n', \"new corpus:\" '\\n')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4Z02BzNHD1z"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>نمایه‌سازی (۱۵ نمره)</b>\n",
    "    </h1>\n",
    "    در این بخش باید برای سامانه positional index بسازید. برای هر ترم باید مشخص باشد که آن ترم در تایتل چه فیلم‌هایی و در چه جایگاهی از تایتل هر فیلم قرار گرفته است. همچنین برای هر ترم باید مشخص باشد که آن ترم در طرح داستان چه فیلم‌هایی و در چه جایگاهی از طرح داستان هر فیلم قرار گرفته است.<br>\n",
    "     برای ارزیابی بهتر و عادلانه‌تر به ویژه برای ارزیابی بخش فشرده‌سازی، از استاندارد بیان شده در قطعه کد زیر برای ذخیره posting list هر ترم در RAM استفاده کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJy4LiraBm8E",
    "outputId": "a740d94d-1896-4a6a-9a28-68b1cb8d32db"
   },
   "outputs": [],
   "source": [
    "def create_positional_index():\n",
    "    \n",
    "    term_dic_pos = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        index = row[\"id\"]\n",
    "        title = row[\"title\"]\n",
    "        plot = row[\"plot\"]\n",
    "        \n",
    "        for i in range(len(title[0])):\n",
    "            term = title[0][i]\n",
    "            \n",
    "            ls = []\n",
    "            ls1 = ls.copy()\n",
    "            ls2 = ls.copy()\n",
    "            \n",
    "            ls.append(ls1)\n",
    "            ls.append(ls2)\n",
    "            \n",
    "            term_dic_pos[term] = term_dic_pos.get(term, ls)\n",
    "            \n",
    "            ls = term_dic_pos[term][0]\n",
    "            \n",
    "            key = False\n",
    "            for doc in ls:\n",
    "                if doc[0] == index:\n",
    "                    doc[1].append(title[1][i])\n",
    "                    key = True\n",
    "                    break\n",
    "                    \n",
    "            if not key:\n",
    "                newDoc = [index, [title[1][i]]]\n",
    "                ls.append(newDoc)\n",
    "\n",
    "        for i in range(len(plot[0])):\n",
    "            term = plot[0][i]\n",
    "            \n",
    "            ls = []\n",
    "            ls1 = ls.copy()\n",
    "            ls2 = ls.copy()\n",
    "            \n",
    "            ls.append(ls1)\n",
    "            ls.append(ls2)\n",
    "            \n",
    "            term_dic_pos[term] = term_dic_pos.get(term, ls)\n",
    "            ls = term_dic_pos[term][1]\n",
    "            \n",
    "            key = False\n",
    "            for doc in ls:\n",
    "                if doc[0] == index:\n",
    "                    doc[1].append(plot[1][i])\n",
    "                    key = True\n",
    "            \n",
    "            if not key:\n",
    "                newDoc = [index, [plot[1][i]]]\n",
    "                ls.append(newDoc)    \n",
    "    \n",
    "    return term_dic_pos\n",
    "\n",
    "pos_index = create_positional_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [[495, [285]],\n",
       "  [499, [123]],\n",
       "  [2681, [104]],\n",
       "  [3198, [240]],\n",
       "  [3435, [631]],\n",
       "  [3469, [141]],\n",
       "  [4043, [148, 251]],\n",
       "  [4630, [298]]]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index[\"ok\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voqMrk4rg1qk"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>پویا‌سازی نمایه (۱۰ نمره)</b>\n",
    "    </h1>\n",
    "    نمایه ایجاد شده باید قابلیت حذف و اضافه تک داکیومنت را داشته باشد.\n",
    "    برای اضافه شدن داکیومنت، به تابع ()add_single_document یک رشته داده می‌شود که اطلاعات مربوط به داکیومنت شامل id و plot و title در آن با کاما جدا شده است. برای حذف داکیومنت نیز id آن به تابع ()remove_single_document داده می‌شود.<br>\n",
    "    تضمین می‌شود که شرط یکتا بودن id داکیومنت‌ها نقض نشود. برای مثال دو داکیومنت با شناسه یکسان به مجموعه اضافه نخواهد شد. البته ممکن است حذف شده و دوباره اضافه شود.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "e1Ej2n3MB6ef"
   },
   "outputs": [],
   "source": [
    "def add_single_documnet(document):\n",
    "    \n",
    "    global df\n",
    "    global df_raw\n",
    "\n",
    "    x = document.split(\",\")\n",
    "    id_ = int(x[0])\n",
    "    \n",
    "    df_raw = df_raw.append({'id': id_, 'title': x[1], 'plot': x[2]}, ignore_index=True)\n",
    "    \n",
    "    title = get_position_in_text_prepare_it(x[1])\n",
    "    plot = get_position_in_text_prepare_it(x[2])\n",
    "    \n",
    "    title = delete_sw(title, stop_words)\n",
    "    plot = delete_sw(plot, stop_words)\n",
    "\n",
    "    df = df.append({'id' : id_, 'title': title, 'plot': plot}, ignore_index=True)\n",
    "        \n",
    "    for term in title[0]:\n",
    "        \n",
    "        ls = []\n",
    "        ls1 = ls.copy()\n",
    "        ls2 = ls.copy()\n",
    "        \n",
    "        ls.append(ls1)\n",
    "        ls.append(ls2)\n",
    "        \n",
    "        pos_index[term] = pos_index.get(term, ls.copy())\n",
    "        \n",
    "        ls = pos_index[term][0]\n",
    "        index = id_\n",
    "        i = title[1][title[0].index(term)]\n",
    "        \n",
    "        key = False\n",
    "        for doc in ls:\n",
    "            if doc[0] == index:\n",
    "                doc[1].append(i)\n",
    "                doc[1].sort()\n",
    "                key = True\n",
    "                \n",
    "        if not key:\n",
    "            newDoc = [index, [i]]\n",
    "            j = 0\n",
    "            for j in range(len(ls)+1):\n",
    "                if j == len(ls):\n",
    "                    break\n",
    "                doc_tmp = ls[j]\n",
    "                if doc_tmp[0] > index:\n",
    "                    break\n",
    "            \n",
    "            ls.insert(j, newDoc)\n",
    "            \n",
    "    for term in plot[0]:\n",
    "        ls = []\n",
    "        ls1 = ls.copy()\n",
    "        ls2 = ls.copy()\n",
    "        \n",
    "        ls.append(ls1)\n",
    "        ls.append(ls2)\n",
    "        \n",
    "        pos_index[term] = pos_index.get(term, ls.copy())\n",
    "        ls = pos_index[term][1]\n",
    "        index = id_\n",
    "        i = plot[1][plot[0].index(term)]\n",
    "\n",
    "        key = False\n",
    "        for doc in ls:\n",
    "            if doc[0] == index:\n",
    "                doc[1].append(i)\n",
    "                doc[1].sort()\n",
    "                key = True\n",
    "                \n",
    "        if not key:\n",
    "            newDoc = [index, [i]]\n",
    "            j = 0\n",
    "            for j in range(len(ls)+1):\n",
    "                if j == len(ls):\n",
    "                    break\n",
    "                doc_tmp = ls[j]\n",
    "                if doc_tmp[0] > index:\n",
    "                    break\n",
    "            \n",
    "            ls.insert(j, newDoc)\n",
    "    \n",
    "    return\n",
    "\n",
    "new_document = \"7000,The Adventures of Sherlock Holmes,The picture begins with Moriarty and Holmes verbally sparring on the steps\"\n",
    "add_single_documnet(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[39, [0]],\n",
       "  [854, [3]],\n",
       "  [1138, [0]],\n",
       "  [1224, [0]],\n",
       "  [1225, [0]],\n",
       "  [1226, [0]],\n",
       "  [1392, [0]],\n",
       "  [5597, [0]]],\n",
       " [[762, [268]],\n",
       "  [858, [0]],\n",
       "  [1138, [302]],\n",
       "  [1224, [0]],\n",
       "  [1225, [120, 140]],\n",
       "  [1335, [2]],\n",
       "  [3235, [22]],\n",
       "  [3417, [13, 60]],\n",
       "  [5597, [5]]]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index['sherlock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DsarzVzhDoMi"
   },
   "outputs": [],
   "source": [
    "def remove_signle_document(document_id):\n",
    "    \"\"\"removes a document from positional index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : int\n",
    "        Id of the document\n",
    "    \"\"\"\n",
    "    \n",
    "    global df\n",
    "    global df_raw\n",
    "        \n",
    "    df.drop(list(df[df['id'] == document_id].index), inplace = True)\n",
    "    df_raw.drop(list(df_raw[df_raw['id'] == document_id].index), inplace = True)\n",
    "    \n",
    "    for term in pos_index:\n",
    "        removed = []\n",
    "        \n",
    "        ls_title = pos_index[term][0]\n",
    "        ls_plot = pos_index[term][1]\n",
    "        for i in range(len(ls_title)):\n",
    "            if ls_title[i][0] == document_id:\n",
    "                removed.append(ls_title[i])\n",
    "        for removed_one in removed:\n",
    "            ls_title.remove(removed_one)\n",
    "\n",
    "        removed = []\n",
    "        for i in range(len(ls_plot)):\n",
    "            if ls_plot[i][0] == document_id:\n",
    "                removed.append(ls_plot[i])\n",
    "        for removed_one in removed:\n",
    "            ls_plot.remove(removed_one)\n",
    "\n",
    "    return\n",
    "  \n",
    "remove_signle_document(7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PBbFcmpXFKD"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>ذخیره و فشرده‌سازی نمایه (۲۰ نمره)</b>\n",
    "    </h1>\n",
    "    در این بخش باید توانایی ذخیره کردن نمایه و بارگذاری مجدد آن را به سامانه اضافه کنید. ذخیره‌سازی به ۳ روش صورت می‌گیرد. بدون فشرده‌سازی، فشرده‌سازی از روش gamma-code و فشرده‌سازی از روش variable-byte. روش‌های فشرده‌سازی باید توسط خودتان پیاده‌سازی شود.\n",
    "    برای ذخیره نمایه در فایل نیز از JSON  استفاده کنید.<br>\n",
    "     بخشی از نمره شما در این قسمت به میزان فشرده‌سازی نمایه اختصاص داده شده است. بنابراین پیاده‌سازی بهینه روش‌های فشرده‌سازی مهم است.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_encoding(ls):\n",
    "\n",
    "    for i in range(len(ls)):\n",
    "        ls[i] += 1\n",
    "    encoded_list = [to_unary(to_bin(gap))+to_bin(gap) for gap in get_gaps(ls)]\n",
    "    return \"\".join(encoded_list)\n",
    "        \n",
    "def gamma_encoding_not_using_gaps(ls): \n",
    "    \n",
    "    for i in range(len(ls)):\n",
    "        ls[i] += 1\n",
    "    encoded_list = [to_unary(to_bin(gap))+to_bin(gap) for gap in ls]\n",
    "    return \"\".join(encoded_list)\n",
    "    \n",
    "def gamma_decoding(gamma):\n",
    "    unary, binary, neck, first_list = \"\", \"\", 0, []\n",
    "    \n",
    "    if gamma == \"\":\n",
    "        return first_list\n",
    "    \n",
    "    while gamma != \"\":\n",
    "        \n",
    "        neck = gamma.find(\"0\")\n",
    "        unary = gamma[:neck]\n",
    "        \n",
    "        if unary==\"\": \n",
    "            first_list.append(1)\n",
    "            gamma = gamma[1:]\n",
    "            \n",
    "        else:\n",
    "            binary = \"1\"+gamma[neck+1:neck+1+neck]\n",
    "            first_list.append(int(binary,2))\n",
    "            gamma  = gamma[neck+1+neck:]\n",
    "            \n",
    "    first_list[0] -= 1\n",
    "    return first_list\n",
    "    \n",
    "def gamma_decoding_not_using_gaps(gamma):\n",
    "    unary, binary, neck, first_list = \"\", \"\", 0, []\n",
    "    \n",
    "    if gamma == \"\":\n",
    "        return first_list\n",
    "    \n",
    "    while gamma != \"\":\n",
    "        \n",
    "        neck = gamma.find(\"0\")\n",
    "        unary = gamma[:neck]\n",
    "        \n",
    "        if unary==\"\": \n",
    "            first_list.append(1)\n",
    "            gamma = gamma[1:]\n",
    "            \n",
    "        else:\n",
    "            binary = \"1\"+gamma[neck+1:neck+1+neck]\n",
    "            first_list.append(int(binary,2))\n",
    "            gamma  = gamma[neck+1+neck:]\n",
    "            \n",
    "    for i in range(len(first_list)):\n",
    "        first_list[i] -= 1\n",
    "    return first_list\n",
    "\n",
    "def remake_initial_list_using_gaps(gaps):\n",
    "    return [sum(gaps[:i]) for i in range(1,len(gaps)+1)]\n",
    "\n",
    "def get_gaps(ls): \n",
    "    if len(ls) == 0:\n",
    "        return []\n",
    "    return [ls[0]]+[ls[i]-ls[i-1] for i in range(1,len(ls))]\n",
    "\n",
    "def to_bin(gap): \n",
    "    if gap == '':\n",
    "        return ''\n",
    "    gap = int(gap)\n",
    "    return bin(gap)[3:]\n",
    "\n",
    "def to_unary(s):\n",
    "    l_gap = len(s)\n",
    "    a = \"\".join([\"1\" for i in range(l_gap)]) + '0'\n",
    "    return a\n",
    "\n",
    "def all_to_one_list(pos):\n",
    "    list_pos = []\n",
    "    for ls in pos:\n",
    "        length = len(ls)\n",
    "        list_pos.append(length)\n",
    "        list_pos.extend(ls.copy())\n",
    "    return list_pos\n",
    "\n",
    "def str2int(string):\n",
    "    if string == \"\":\n",
    "        return \"\"\n",
    "    return int(string, 2)\n",
    "\n",
    "def strbin2hex(string):\n",
    "    if string == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    num = int(string, base=2)\n",
    "    return str(hex(num))[2:]\n",
    "\n",
    "def remake_pos_index_inner(title_doc, title_pos):\n",
    "    final_ls = []\n",
    "    while len(title_pos) != 0:\n",
    "        idx = title_pos.pop(0)\n",
    "        doc_id = title_doc.pop(0)\n",
    "        ls_pos = []\n",
    "        for i in range(idx):\n",
    "            ls_pos.append(title_pos.pop(0))\n",
    "\n",
    "        final_ls.append([doc_id, ls_pos.copy()])\n",
    "    return final_ls.copy()\n",
    "\n",
    "def remake_pos_index(ls_term):\n",
    "    title_doc = ls_term[0]\n",
    "    title_pos = ls_term[1]\n",
    "    \n",
    "    title = remake_pos_index_inner(title_doc, title_pos)\n",
    "    \n",
    "    plot_doc = ls_term[2]\n",
    "    plot_pos = ls_term[3]\n",
    "    \n",
    "    plot = remake_pos_index_inner(plot_doc, plot_pos)\n",
    "    return [title, plot]\n",
    "\n",
    "def convert_int_to_variable_byte(num):\n",
    "    if num == 0:\n",
    "        return '10000000'\n",
    "    base2_num = '1' + str(to_bin(num))\n",
    "    l = len(base2_num)\n",
    "    mod = l % 7\n",
    "    if mod != 0:\n",
    "        base2_num = '0'*(7-mod) + base2_num\n",
    "    i = 0\n",
    "    vb_bit = ''\n",
    "    for i in range(len(base2_num) // 7):\n",
    "        key = '0'\n",
    "        if i == (len(base2_num)) // 7 - 1:\n",
    "            key = '1'\n",
    "        vb_bit = vb_bit + key + base2_num[7*i: 7*(i+1)]\n",
    "    return vb_bit\n",
    "\n",
    "def convert_list_to_vbs(ls):\n",
    "    s = ''\n",
    "    for i in ls:\n",
    "        s += convert_int_to_variable_byte(i)\n",
    "    return s\n",
    "\n",
    "def vb_decoding(s):\n",
    "    key = False\n",
    "    ls = []\n",
    "    x = ''\n",
    "    for i in range(len(s) // 8):\n",
    "        if s[0] == '1':\n",
    "            key = True\n",
    "        tmp = s[0:8]\n",
    "        s = s[8:]\n",
    "        x += tmp[1:8]\n",
    "        if key:\n",
    "            ls.append(int(x, 2))\n",
    "            x = ''\n",
    "            key = False\n",
    "    return ls.copy()\n",
    "\n",
    "def hexstr2bin(s):\n",
    "    scale = 16 \n",
    "    s = str(s)\n",
    "    return bin(int(s, scale))[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN9I4_BD178",
    "outputId": "4a11351f-d214-495e-eb3f-7dc56863cd58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.2145\n"
     ]
    }
   ],
   "source": [
    "def store_index(path, compression_type):\n",
    "    \n",
    "    global pos_index_cp\n",
    "    pos_index_cp = pos_index.copy()\n",
    "    if compression_type == 'no-compression':\n",
    "        with open(path, 'w') as fp:\n",
    "            json_object = json.dump(pos_index, fp)\n",
    "            size_of_file = os.path.getsize(path)\n",
    "    \n",
    "    if compression_type == 'gamma-code':\n",
    "        with open(path, 'w') as fp:\n",
    "            \n",
    "            for term in pos_index:\n",
    "                ls_title = pos_index_cp[term][0].copy()\n",
    "                ls_plot = pos_index_cp[term][1].copy()\n",
    "                \n",
    "                pos = [ls_title[i][1] for i in range(len(ls_title))]\n",
    "                \n",
    "                doc = [ls_title[i][0] for i in range(len(ls_title))]\n",
    "                    \n",
    "                \n",
    "                gamma_title_encoded = gamma_encoding(doc) ## not sorted\n",
    "                list_pos = all_to_one_list(pos)\n",
    "                \n",
    "                title_pos_encoded = gamma_encoding_not_using_gaps(list_pos)\n",
    "                title_compressed = gamma_title_encoded\n",
    "                \n",
    "                pos = [ls_plot[i][1] for i in range(len(ls_plot))]\n",
    "                doc = [ls_plot[i][0] for i in range(len(ls_plot))]\n",
    "                \n",
    "                gamma_plot_encoded = gamma_encoding(doc)\n",
    "                list_pos = all_to_one_list(pos)\n",
    "                plot_pos_encoded = gamma_encoding_not_using_gaps(list_pos)\n",
    "                plot_compressed = gamma_plot_encoded\n",
    "                \n",
    "                q = [strbin2hex('1'+title_compressed), strbin2hex('1'+title_pos_encoded), strbin2hex('1'+plot_compressed)\n",
    "                     , strbin2hex('1'+plot_pos_encoded)]\n",
    "\n",
    "                pos_index_cp[term] = q.copy()\n",
    "\n",
    "            json_object = json.dump(pos_index_cp, fp)\n",
    "            size_of_file = os.path.getsize(path)\n",
    "    \n",
    "    if compression_type == 'variable-byte':\n",
    "        with open(path, 'w') as fp:\n",
    "            \n",
    "            for term in pos_index:\n",
    "                ls_title = pos_index_cp[term][0].copy()\n",
    "                ls_plot = pos_index_cp[term][1].copy()\n",
    "                \n",
    "                pos = [ls_title[i][1] for i in range(len(ls_title))]\n",
    "                doc = [ls_title[i][0] for i in range(len(ls_title))]\n",
    "                doc = get_gaps(doc)\n",
    "                pos = all_to_one_list(pos)\n",
    "                \n",
    "                title_compressed = convert_list_to_vbs(doc)\n",
    "                title_pos_encoded = convert_list_to_vbs(pos)\n",
    "            \n",
    "                pos = [ls_plot[i][1] for i in range(len(ls_plot))]\n",
    "                doc = [ls_plot[i][0] for i in range(len(ls_plot))]\n",
    "                doc = get_gaps(doc)\n",
    "                pos = all_to_one_list(pos)\n",
    "                \n",
    "                plot_compressed = convert_list_to_vbs(doc)\n",
    "                plot_pos_encoded = convert_list_to_vbs(pos)\n",
    "                \n",
    "                q = [strbin2hex('1'+title_compressed), strbin2hex('1'+title_pos_encoded), strbin2hex('1'+plot_compressed)\n",
    "                     , strbin2hex('1'+plot_pos_encoded)]\n",
    "                pos_index_cp[term] = q.copy()\n",
    "                \n",
    "            json_object = json.dump(pos_index_cp, fp)\n",
    "            size_of_file = os.path.getsize(path)\n",
    "    \n",
    "    return round(size_of_file / 1000000, 4)\n",
    "\n",
    "\n",
    "# print(store_index('pos_index_nc.json', \"no-compression\"))\n",
    "print(store_index('pos_index_gamma.json', \"gamma-code\"))\n",
    "# print(store_index('pos_index_vb.json', \"variable-byte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc1 = \"10000,The Shawshank Redemption,Two imprisoned men bond over a number of years\"\n",
    "add_single_documnet(new_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[10000, [1]]], []]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index['shawshank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_signle_document(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "3Dm38ZXHFQVH"
   },
   "outputs": [],
   "source": [
    "pos_index_cp_loaded = {}\n",
    "\n",
    "def load_index(path, compression_type):\n",
    "    \n",
    "    global pos_index_cp_loaded\n",
    "    pos_index_cp_loaded = {}\n",
    "    \n",
    "    if compression_type == 'no-compression':   \n",
    "        with open(path, 'r') as fp:\n",
    "            pos_index_cp_loaded = json.load(fp)\n",
    "            \n",
    "    if compression_type == 'gamma-code':   \n",
    "        with open(path, 'r') as fp:\n",
    "            pos_index_cp_loaded = json.load(fp)\n",
    "            for term in pos_index_cp_loaded.keys():\n",
    "                ls_term = []\n",
    "                for i in range(4):\n",
    "                    x = pos_index_cp_loaded[term][i]\n",
    "                    s = hexstr2bin(x)\n",
    "                    \n",
    "                    if i % 2 == 0:\n",
    "                        ls = gamma_decoding(s)\n",
    "                    else:\n",
    "                        ls = gamma_decoding_not_using_gaps(s)\n",
    "                    \n",
    "                    if i % 2 == 0:\n",
    "                        ls = remake_initial_list_using_gaps(ls)\n",
    "                    ls_term.append(ls.copy())\n",
    "                    \n",
    "                pos_index_term = remake_pos_index(ls_term)\n",
    "                pos_index_cp_loaded[term] = pos_index_term.copy()  \n",
    "                \n",
    "    if compression_type == 'variable-byte':   \n",
    "        with open(path, 'r') as fp:\n",
    "            pos_index_cp_loaded = json.load(fp)\n",
    "            for term in pos_index_cp_loaded.keys():\n",
    "                ls_term = []\n",
    "                for i in range(4):\n",
    "                    x = pos_index_cp_loaded[term][i]\n",
    "                    s = hexstr2bin(x)\n",
    "                    ls = vb_decoding(s)\n",
    "                    if i % 2 == 0:\n",
    "                        ls = remake_initial_list_using_gaps(ls)\n",
    "                    ls_term.append(ls.copy())\n",
    "                pos_index_term = remake_pos_index(ls_term)\n",
    "                pos_index_cp_loaded[term] = pos_index_term.copy()  \n",
    "      \n",
    "    return\n",
    "\n",
    "# load_index('pos_index_nc.json', 'no-compression')\n",
    "load_index(\"pos_index_gamma.json\", \"gamma-code\")\n",
    "# load_index(\"pos_index_vb.json\", \"variable-byte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[647, [0]],\n",
       " [942, [1]],\n",
       " [1113, [0]],\n",
       " [1114, [4]],\n",
       " [1772, [1]],\n",
       " [1773, [1]],\n",
       " [1830, [2]],\n",
       " [1944, [3]],\n",
       " [2969, [0]],\n",
       " [3020, [0]]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index = pos_index_cp_loaded\n",
    "pos_index['grand'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i-iLvu2nh2k"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>اصلاح پرسمان (۱۵ نمره امتیازی)</b>\n",
    "    </h1>\n",
    "    در صورتی که پرسمان ورودی دارای غلط املایی باشد یا به عبارتی لغاتی از آن در لغت‌نامه موجود نباشد، لازم است که با جستجوی لغت‌های احتمالی و انتخاب بهترین لغت به ادامه‌ی جستجو با پرسمان اصلاح شده پرداخته شود. برای اینکار ابتدا باید با روش bigram و معیار jaccard نزدیک‌ترین لغات به لغت با غلط املایی را پیدا کنید. سپس با استفاده از معیار edit distance بهترین لغت را از میان آن‌ها بیابید.<br>\n",
    "    نیازی به ذخیره‌سازی و فشرده‌سازی نمایه بایگرم نیست. همچنین می‌توانید از کد آماده برای محاسبه edit distance استفاده کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_words():\n",
    "    \n",
    "    df_raw_text = pd.read_csv(\"movies.csv\")\n",
    "    \n",
    "    initial_words = set()\n",
    "    \n",
    "    for index, row in df_raw_text.iterrows():\n",
    "        raw_text = str(row['title'])\n",
    "        raw_text = str(row['plot'])\n",
    "        tokens = word_tokenize(raw_text)\n",
    "        tokens = list(filter(lambda token: token not in string.punctuation, tokens))\n",
    "        tokens = [t.lower() for t in tokens]   \n",
    "        for term in tokens:\n",
    "            initial_words.add(term)\n",
    "    omitted = set()\n",
    "    for term in initial_words:\n",
    "        if len(prepare_text(term)) == 0 or prepare_text(term)[0] in stop_words:\n",
    "            omitted.add(term)\n",
    "    initial_words -= omitted\n",
    "    return initial_words\n",
    "\n",
    "initial_words = get_initial_words()\n",
    "all_corpus_words = set(pos_index.keys()).union(initial_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(initial_words).copy()\n",
    "keys.sort()\n",
    "for i in range(len(keys)):\n",
    "    keys[i] = '$' + keys[i] + '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qMZTstsbL1G3"
   },
   "outputs": [],
   "source": [
    "def create_bigram_index():\n",
    "    bigram = {}\n",
    "    # TODO: create bigram index    \n",
    "    for key in keys:\n",
    "        key = '$' + key + '$'\n",
    "        for i in range(len(key) - 1):\n",
    "            bio = key[i:i+2]\n",
    "            if bio in bigram.keys():\n",
    "                bigram[bio].append(key)\n",
    "            else:\n",
    "                bigram[bio] = [key]\n",
    "            \n",
    "    return bigram\n",
    "\n",
    "bigram_index = create_bigram_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chi', 'hi', 'hid', 'hip', 'hit', 'hiv', 'shi', 'thi']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(word, threshold=0.2, ls_last=None):\n",
    "   \n",
    "    if ls_last == None:\n",
    "        ls_last = [word]\n",
    "    ls = []\n",
    "    set_word_bi_char = {word[i:i+2] for i in range(len(word)-1)}\n",
    "    \n",
    "    for key in keys:\n",
    "        set_key_bi_char = {key[i:i+2] for i in range(len(key)-1)}\n",
    "        intersection = set_key_bi_char.intersection(set_word_bi_char)\n",
    "        union = set_key_bi_char.union(set_word_bi_char)\n",
    "        if len(intersection) / len(union) > threshold:\n",
    "            ls.append(key[1:len(key)-1])\n",
    "    \n",
    "    if len(ls) < 4:\n",
    "        return ls_last\n",
    "    return jaccard(word, threshold+0.04, ls)\n",
    "\n",
    "jaccard('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistance(str1, str2, m, n):\n",
    " \n",
    "    if m == 0:\n",
    "        return n\n",
    " \n",
    "    if n == 0:\n",
    "        return m\n",
    " \n",
    "    if str1[m-1] == str2[n-1]:\n",
    "        return editDistance(str1, str2, m-1, n-1)\n",
    " \n",
    "    return 1 + min(editDistance(str1, str2, m, n-1),    \n",
    "                   editDistance(str1, str2, m-1, n),    \n",
    "                   editDistance(str1, str2, m-1, n-1)   \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sL3E8C-nL1yG",
    "outputId": "d4da236e-728c-4419-e80e-e8a36bd4e85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected form : in a murder trial , 12 men act as the jury to decide whether or not the boy is guilty for murdering his father . the lawyers wo n't help the boy as he has a weapon .\n"
     ]
    }
   ],
   "source": [
    "def get_corrected_text(raw_text):\n",
    "    \n",
    "    raw_text = word_tokenize(raw_text)\n",
    "    if len(raw_text) == 0:\n",
    "        return \"\"\n",
    "    raw_text = [t.lower() for t in raw_text]\n",
    "    for i in range(len(raw_text)):\n",
    "        word = raw_text[i]\n",
    "        if word in all_corpus_words or word in stop_words:\n",
    "            raw_text[i] = word\n",
    "            continue\n",
    "        ls = jaccard(word)\n",
    "        max_ = 100\n",
    "        final_word = word\n",
    "        for candidate in ls:\n",
    "            if editDistance(candidate, word, len(candidate), len(word)) < max_:\n",
    "                max_ = editDistance(candidate, word, len(candidate), len(word))\n",
    "                final_word = candidate\n",
    "            \n",
    "        raw_text[i] = final_word\n",
    "    \n",
    "    corrected_text = raw_text\n",
    "    ss = corrected_text[0]\n",
    "    for i in range(1, len(corrected_text)):\n",
    "        ss = ss + \" \" + corrected_text[i] \n",
    "    return ss\n",
    "    \n",
    "print(\"corrected form :\", get_corrected_text(\"In a murder trial, 12 men acte as the juury to decide whether or not the boy is guilty for murdering his father. The lawyers won't help the boy as he has a weapon.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she returns home dru safer his bachelor party'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corrected_text(\"She returns homee drubk afer his bchelor party\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BWhdHJbs1zy"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>جستجو و بازیابی اسناد (۲۵ نمره)</b>\n",
    "    </h1>\n",
    "    در این بخش جستجو ترتیب‌دار در فضای برداری tf-idf به روش <b>lnn-ltn</b> انجام می‌شود. یک پرسمان title و یک پرسمان plot ورودی گرفته شده و هر کدام در بخش مربوطه از اسناد جستجو می‌شوند. امتیاز نهایی هر سند برابر با جمع وزن‌دار امتیاز به دست آمده از جستجو در بخش title و plot است. به این صورت که وزن plot واحد در نظر گرفته شده و وزن تایتل به عنوان ورودی داده می‌شود.<br>\n",
    "    در نهایت اسناد برتر را نمایش دهید. تعداد حداکثر اسناد برتر نیز به عنوان ورودی داده می‌شود.<br><br>\n",
    "    نکته بسیار مهم نحوه نمایش اسناد انتخابی است. برای نمایش هر سند علاوه بر استفاده از شناسه و تیتر، یک هایلایت برای آن درست کنید. به این معنا که کلمات موجود در پرسمان را که باعث انتخاب سند شده‌اند به همراه ۲-۳ ترم قبل و بعد از آن به عنوان هایلایت آن سند نمایش دهید. اینگونه کاربر می‌تواند خیلی سریع دلیل بازیابی اسناد توسط سامانه را متوجه شود. مشابه کاری که سرچ گوگل انجام می‌دهد و ۲-۳ خط مربوطه را زیر وبسایت‌های پیشنهادی نمایش می‌دهد. طبیعتا راه حل بهینه برای این‌کار استفاده از قابلیت‌های نمایه جایگاهی می‌باشد.<br>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [[1225, [87, 422, 442, 456, 492, 510, 547]]]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['id'] == 1225]['plot'])\n",
    "\n",
    "df_raw = pd.read_csv('movies.csv')\n",
    "# df.loc[1224]['plot']\n",
    "\n",
    "pos_index['sexton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_term_frequency_in_unidoc(term, doc_index, part):\n",
    "    \n",
    "    if term not in pos_index.keys():\n",
    "        return 0\n",
    "    \n",
    "    ls = pos_index[term][part]\n",
    "    \n",
    "    for i in range(len(ls)):\n",
    "        if ls[i][0] == doc_index:\n",
    "            return len(ls[i][1])\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_log_term_frequency_in_unidoc(term, doc_index, part):\n",
    "    \n",
    "    tf_d = get_term_frequency_in_unidoc(term, doc_index, part)\n",
    "    if tf_d == 0:\n",
    "        return 0\n",
    "    return 1 + math.log10(tf_d)\n",
    "\n",
    "def get_dic_frequency(term, part):\n",
    "    \n",
    "    if term not in pos_index.keys():\n",
    "        return 0\n",
    "    \n",
    "    ls = pos_index[term][part]\n",
    "    return len(ls)\n",
    "    \n",
    "def get_log_inverted_dic_frequency(term, part):\n",
    "    \n",
    "    d_f = get_dic_frequency(term, part)\n",
    "    \n",
    "    if d_f == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_docs = df.shape[0] ################ nOOOOOt RiightT\n",
    "    \n",
    "    return math.log10(num_docs/d_f)\n",
    "\n",
    "def get_df_idf_unidoc(term, doc_index, part):\n",
    "    return get_log_term_frequency_in_unidoc(term, doc_index, part)*get_log_inverted_dic_frequency(term, part)\n",
    "\n",
    "def query__unidoc_df_idf(query_ls, doc_index, part):\n",
    "\n",
    "    score_vector = np.zeros(len(query_ls))\n",
    "    \n",
    "    for i in range(len(query_ls)):\n",
    "        term = query_ls[i]\n",
    "        score_vector[i] = get_df_idf_unidoc(term, doc_index, part)\n",
    "    \n",
    "    return score_vector\n",
    "\n",
    "def prepare_query(query):\n",
    "    return prepare_text(query)\n",
    "\n",
    "def df_idf_query(query_ls, query):\n",
    "    \n",
    "    score_vector = np.zeros(len(query_ls))\n",
    "    query_ls_repeated = prepare_query(query)\n",
    "    \n",
    "    for i in range(len(query_ls)):\n",
    "        term = query_ls[i]\n",
    "        tf_q = query_ls_repeated.count(term)\n",
    "        \n",
    "        if tf_q == 0:\n",
    "            score_vector[i] = 0\n",
    "            continue\n",
    "            \n",
    "        score_vector[i] = 1 + math.log10(tf_q)\n",
    "    \n",
    "    return score_vector\n",
    "\n",
    "def query_unidoc_score(query, doc_index, part):\n",
    "    \n",
    "    query_ls_repeated = prepare_query(query)\n",
    "    query_ls = list(set(query_ls_repeated))\n",
    "    \n",
    "    nparr =  np.multiply(df_idf_query(query_ls, query), query__unidoc_df_idf(query_ls, doc_index, part))\n",
    "    return math.sqrt(nparr.dot(nparr))\n",
    "\n",
    "def query_unidoc_score_total(query0, query1, doc_index, title_weight=10):\n",
    "    return title_weight * query_unidoc_score(query0, doc_index, 0) + query_unidoc_score(query1, doc_index, 1)\n",
    "\n",
    "def union_valid_docs_query(query):\n",
    "    \n",
    "    union = set()\n",
    "    \n",
    "    query_ls_repeated = prepare_query(query)\n",
    "    query_ls = list(set(query_ls_repeated))\n",
    "    \n",
    "    for term in query_ls:\n",
    "        \n",
    "        if term not in pos_index.keys():\n",
    "            continue\n",
    "        \n",
    "        for doc in pos_index[term][0]:\n",
    "            union.add(doc[0])\n",
    "        \n",
    "        for doc in pos_index[term][1]:    \n",
    "            union.add(doc[0])\n",
    "            \n",
    "    return union\n",
    "\n",
    "def get_all_doc_sorted_score_based_on_query(query0, query1, title_weight):\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    query = ' ' + query0 + ' ' + query1 + ' '\n",
    "    \n",
    "    doc_related = list(union_valid_docs_query(query))\n",
    "        \n",
    "    for doc_index in doc_related:\n",
    "        s_t = query_unidoc_score_total(query0, query1, doc_index, title_weight)\n",
    "        dic[doc_index] = s_t\n",
    "    \n",
    "    return {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "def get_all_doc_id_sorted(query0, query1, title_weight = 10, max_size = 10):\n",
    "    ls = get_related_doc_id(query0, query1, title_weight)\n",
    "        \n",
    "    if len(ls) > max_size:\n",
    "        return ls[:max_size]\n",
    "    else:\n",
    "        return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_is_near(ls, i, dist = 3):\n",
    "    for idx in ls:\n",
    "        if abs(i-int(idx)) <= dist :\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_bold_get_around(string, query, doc_id, part):\n",
    "    \n",
    "    ls_query = prepare_query(query)\n",
    "    ls_query_pos = []\n",
    "    \n",
    "    for q in ls_query:\n",
    "        if q not in pos_index.keys():\n",
    "            continue\n",
    "        for doc in pos_index[q][part]:\n",
    "            if doc[0] == doc_id:\n",
    "                ls_query_pos = ls_query_pos + doc[1].copy()\n",
    "#                 ls_query_pos = doc[1].copy()\n",
    "                break\n",
    "    \n",
    "    final_str = ''\n",
    "    ls_str = word_tokenize(string)\n",
    "    key = False\n",
    "    for i in range(len(ls_str)):\n",
    "        \n",
    "        if not i_is_near(ls_query_pos, i) and part != 0:\n",
    "            if not key:\n",
    "                final_str += '... '\n",
    "                key = True\n",
    "                \n",
    "            continue\n",
    "        \n",
    "        key = False\n",
    "        \n",
    "        token = ls_str[i]\n",
    "        \n",
    "        if i not in ls_query_pos:\n",
    "            final_str += token + ' '\n",
    "            continue\n",
    "        tmp = '<b>' + token + '</b>'\n",
    "        final_str += tmp + ' '\n",
    "        \n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bold_print(ls):\n",
    "    \n",
    "    ls = ls.copy()\n",
    "\n",
    "    for doc in ls:\n",
    "        \n",
    "        doc[0] = '\\033[91m' + str(doc[0]) + '\\033[00m'\n",
    "        doc[1] = doc[1].replace('<b>', '\\033[1m')\n",
    "        doc[1] = doc[1].replace('</b>', '\\033[0m')\n",
    "        doc[2] = doc[2].replace('<b>', '\\033[1m')\n",
    "        doc[2] = doc[2].replace('</b>', '\\033[0m')\n",
    "        \n",
    "        print(doc[0] , \": \", doc[1], '\\n\\n', doc[2], '\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0R2i_O4Gev_",
    "outputId": "7f57be29-eec0-489e-dd61-74d67c923106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m4670\u001b[00m :  12 Angry Men  \n",
      "\n",
      " ... arguments in a \u001b[1mmurder\u001b[0m \u001b[1mtrial\u001b[0m have been presented ... instructions to the \u001b[1mjury\u001b[0m , all of whom are \u001b[1mmen\u001b[0m . In the ... in a hung \u001b[1mjury\u001b[0m which in turn ... question they are \u001b[1mdeciding\u001b[0m is \u001b[1mwhether\u001b[0m the defendant , a teenaged \u001b[1mboy\u001b[0m from a city slum , \u001b[1mmurdered\u001b[0m his \u001b[1mfather\u001b[0m . The \u001b[1mjury\u001b[0m is further instructed that a \u001b[1mguilty\u001b[0m verdict will be ... sentence . The \u001b[1mjury\u001b[0m of twelve retires to the \u001b[1mjury\u001b[0m room , where ... circumstantial and the \u001b[1mboy\u001b[0m deserves a fair ... witnesses to the \u001b[1mmurder\u001b[0m , the fact ... used in the \u001b[1mmurder\u001b[0m is not as ... eleven jurors voted \u001b[1mguilty\u001b[0m unanimously , then ... acquiesce to their \u001b[1mdecision\u001b[0m . However , ... voted `` not \u001b[1mguilty\u001b[0m '' , then ... accused is not \u001b[1mguilty\u001b[0m , but feeling ... further deliberations concerning \u001b[1mwhether\u001b[0m one witness \u001b[1mactually\u001b[0m heard the \u001b[1mmurder\u001b[0m take place , ... to `` not \u001b[1mguilty\u001b[0m . '' Soon ... 11 , questioning \u001b[1mwhether\u001b[0m the defendant would ... and 6 also \u001b[1mdecide\u001b[0m to vote `` not \u001b[1mguilty\u001b[0m '' to tie ... defendant is not \u001b[1mguilty\u001b[0m . The next ... votes are Jurors \u001b[1m12\u001b[0m and 1 when ... that one witness \u001b[1mactually\u001b[0m saw the \u001b[1mboy\u001b[0m flee the scene ... stated that the \u001b[1mboy\u001b[0m had subconscious desires ... the slums ca \u001b[1mn't\u001b[0m be trusted , ... . And do \u001b[1mn't\u001b[0m open your filthy ... who saw the \u001b[1mmurder\u001b[0m from across the ... out , Juror \u001b[1m12\u001b[0m changes his vote back to `` \u001b[1mguilty\u001b[0m '' to make ... she saw the \u001b[1mmurder\u001b[0m , had impressions ... she saw the \u001b[1mmurder\u001b[0m . After he ... out , Jurors \u001b[1m12\u001b[0m , 10 , ... to `` not \u001b[1mguilty\u001b[0m '' . Last ... kill his own \u001b[1mfather\u001b[0m ( it was ... quietly that the \u001b[1mboy\u001b[0m is not his ... while Juror 8 \u001b[1mhelps\u001b[0m the distraught Juror ...  \n",
      "\n",
      "\n",
      "\u001b[91m4754\u001b[00m :  The Devil 's Advocate  \n",
      "\n",
      " ... his client is \u001b[1mguilty\u001b[0m and local reporter ... warns him a \u001b[1mguilty\u001b[0m verdict is inevitable ... a `` not \u001b[1mguilty\u001b[0m '' verdict . ... to assist a \u001b[1mjury\u001b[0m selection . After the \u001b[1mjury\u001b[0m delivers a not \u001b[1mguilty\u001b[0m verdict , the ... is accused of \u001b[1mmurdering\u001b[0m his wife , ... down from the \u001b[1mtrial\u001b[0m to tend to ... law firm 's \u001b[1mactivities\u001b[0m . Kevin tells ... believes Cullen is \u001b[1mguilty\u001b[0m . Despite this ... testimony and the \u001b[1mtrial\u001b[0m . Afterwards , ... is Kevin 's \u001b[1mfather\u001b[0m ; Kevin leaves ... of the Gettys \u001b[1mtrial\u001b[0m . Choosing to ...  \n",
      "\n",
      "\n",
      "\u001b[91m1136\u001b[00m :  Roxie Hart  \n",
      "\n",
      " ... pulled into a \u001b[1mmurder\u001b[0m investigation together with ... 1927 - a \u001b[1mmurder\u001b[0m case involving the ... Casely , was \u001b[1mmurdered\u001b[0m , and his ... arrested for the \u001b[1mmurder\u001b[0m , since a ... gets convicted of \u001b[1mmurder\u001b[0m in Chicago . ... her husband is \u001b[1mguilty\u001b[0m of the \u001b[1mmurder\u001b[0m . Her mugshot ... her the best \u001b[1mlawyer\u001b[0m money could buy ... room . Billy \u001b[1mdecides\u001b[0m they will use ... Finnegan , and \u001b[1mdecides\u001b[0m to \u001b[1mhelp\u001b[0m Roxie out . ... Billy moves her \u001b[1mtrial\u001b[0m further into the ... Roxie still does \u001b[1mn't\u001b[0m trust the legal ... front of the \u001b[1mjury\u001b[0m \u001b[1mhelps\u001b[0m her case tremendously ... is found not \u001b[1mguilty\u001b[0m of the \u001b[1mmurder\u001b[0m , but Amos ... member of the \u001b[1mjury\u001b[0m , stockbroker O'Malley ...  \n",
      "\n",
      "\n",
      "\u001b[91m5514\u001b[00m :  88 Minutes  \n",
      "\n",
      " ... testifies at the \u001b[1mtrial\u001b[0m of suspected serial ... Cates and the \u001b[1mmurder\u001b[0m of her sister ... Upon receiving a \u001b[1mguilty\u001b[0m verdict from the \u001b[1mjury\u001b[0m , Forster taunts ... several similar torture \u001b[1mmurders\u001b[0m occur . Gramm ... questioned by a \u001b[1mlawyer\u001b[0m from the Attorney ... who offers to \u001b[1mhelp\u001b[0m find the perpetrator ... , crying for \u001b[1mhelp\u001b[0m before being \u001b[1mmurdered\u001b[0m . Gramm concludes ... but find her \u001b[1mmurdered\u001b[0m in her apartment ... at Forster 's \u001b[1mtrial\u001b[0m . Special Agent ... , you got \u001b[1m12\u001b[0m hours to live ...  \n",
      "\n",
      "\n",
      "\u001b[91m4971\u001b[00m :  Rules of Engagement  \n",
      "\n",
      " ... Marines . His \u001b[1mact\u001b[0m thereby saves the ... of Hodges ' \u001b[1mmen\u001b[0m die in the ... then orders his \u001b[1mmen\u001b[0m to open fire ... needs a better \u001b[1mlawyer\u001b[0m . But Childers ... to be absolutely \u001b[1mguilty\u001b[0m . Sokal at ... . During the \u001b[1mtrial\u001b[0m , Hodges presents ... up at the \u001b[1mtrial\u001b[0m , arguing that ... While defending his \u001b[1mactions\u001b[0m , Childers loses ... lives of his \u001b[1mmen\u001b[0m to appease the ... interpreted by the \u001b[1mjury\u001b[0m as being prejudiced towards Yemenis \u001b[1mor\u001b[0m having a gung-ho/cowboy ... . After the \u001b[1mtrial\u001b[0m , Hodges visits ... Childers is found \u001b[1mguilty\u001b[0m of the minor ... , but not \u001b[1mguilty\u001b[0m of the more ... an officer and \u001b[1mmurder\u001b[0m . A final ...  \n",
      "\n",
      "\n",
      "\u001b[91m5958\u001b[00m :  True Story  \n",
      "\n",
      " ... have been discovered \u001b[1mmurdered\u001b[0m , is arrested ... to defend his \u001b[1mactions\u001b[0m , but he ... conclusion of the \u001b[1mmurder\u001b[0m \u001b[1mtrial\u001b[0m . Finkel becomes ... . As the \u001b[1mtrial\u001b[0m approaches , Finkel ... that Longo is \u001b[1mguilty\u001b[0m of the \u001b[1mmurders\u001b[0m , and Longo ... plea to not \u001b[1mguilty\u001b[0m . In court ... Longo pleads not \u001b[1mguilty\u001b[0m to two of the \u001b[1mmurders\u001b[0m , but pleads \u001b[1mguilty\u001b[0m to the \u001b[1mmurder\u001b[0m of his wife ... . At the \u001b[1mtrial\u001b[0m , Longo takes ... . As the \u001b[1mjury\u001b[0m deliberates , Jill ... is a narcissistic \u001b[1mmurderer\u001b[0m who will never ... Longo is found \u001b[1mguilty\u001b[0m of all four ... memory of the \u001b[1mmurders\u001b[0m . Finkel angrily ...  \n",
      "\n",
      "\n",
      "\u001b[91m5309\u001b[00m :  The Exorcism of Emily Rose  \n",
      "\n",
      " ... attempted exorcism . \u001b[1mFather\u001b[0m Richard Moore , ... Moore to plead \u001b[1mguilty\u001b[0m to minimize the ... to plead Not \u001b[1mGuilty\u001b[0m . Erin Bruner , an ambitious \u001b[1mlawyer\u001b[0m hoping to use the \u001b[1mtrial\u001b[0m to become a ... . During the \u001b[1mtrial\u001b[0m , Emily ’ ... witnesses . The \u001b[1mtrial\u001b[0m ’ s prosecutor ... Emily ’ s \u001b[1mfather\u001b[0m , Jason , ... Jason and Cartwright \u001b[1mhelp\u001b[0m Moore , Emily ... ends when the \u001b[1mmen\u001b[0m render aid to Emily 's \u001b[1mfather\u001b[0m , injured by ... ascending to Heaven \u001b[1mor\u001b[0m remaining to become ... farm . The \u001b[1mjury\u001b[0m ultimately reach a verdict of \u001b[1mguilty\u001b[0m , but surprise ... it , and \u001b[1mFather\u001b[0m Moore is free ...  \n",
      "\n",
      "\n",
      "\u001b[91m3958\u001b[00m :  Suspect  \n",
      "\n",
      " ... which no explanation \u001b[1mor\u001b[0m context is given ... night of her \u001b[1mmurder\u001b[0m . Kathleen Riley ... arrested for her \u001b[1mmurder\u001b[0m . Riley finds ... member of the \u001b[1mjury\u001b[0m by Riley despite ... details of the \u001b[1mmurder\u001b[0m himself , eventually ... observation of the \u001b[1mtrial\u001b[0m 's suspicious judge ... , which contained \u001b[1mtrial\u001b[0m transcripts from federal ... transcribing . The \u001b[1mtrial\u001b[0m is conducted by ... disbarrable offense of \u001b[1mjury\u001b[0m tampering , although ... who sequesters the \u001b[1mjury\u001b[0m to avoid any ... prosecutor and the \u001b[1mtrial\u001b[0m judge . Riley ... his motive to \u001b[1mmurder\u001b[0m Quinn if she ... . With the \u001b[1mhelp\u001b[0m of Sanger ( ... however , he \u001b[1mmurdered\u001b[0m her . As ...  \n",
      "\n",
      "\n",
      "\u001b[91m2169\u001b[00m :  Rails Into Laramie  \n",
      "\n",
      " ... , where the \u001b[1mmen\u001b[0m are drinking , ... , the other \u001b[1mmen\u001b[0m back away , ... that all the \u001b[1mmen\u001b[0m have been fired ... plan a two-week \u001b[1mtrial\u001b[0m . Shanessy counters ... that no local \u001b[1mjury\u001b[0m will convict Shanessy , offers to \u001b[1mhelp\u001b[0m . A mistrustful ... by Shanessy 's \u001b[1mmen\u001b[0m . In the ... dismissed by crooked \u001b[1mjuries\u001b[0m . He then ... to construct a \u001b[1mjury\u001b[0m out of the ... on the female \u001b[1mjury\u001b[0m , and , ... they find him \u001b[1mguilty\u001b[0m . Jeff thanks ...  \n",
      "\n",
      "\n",
      "\u001b[91m2535\u001b[00m :  Witness for the Prosecution  \n",
      "\n",
      " ... is accused of \u001b[1mmurdering\u001b[0m Mrs Emily French ... end of the \u001b[1mtrial\u001b[0m , she is ... . During the \u001b[1mtrial\u001b[0m in the Old ... lied that the \u001b[1mjury\u001b[0m finds Leonard not \u001b[1mguilty\u001b[0m . However , ... that he had \u001b[1mhelp\u001b[0m in winning the ... her before the \u001b[1mtrial\u001b[0m that `` ... no \u001b[1mjury\u001b[0m would believe an ... knew he was \u001b[1mguilty\u001b[0m because she loves ...  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_related_doc_id(title_query, plot_query, title_weight, max_result_count=10):\n",
    " \n",
    "    q_0 = get_corrected_text(title_query)\n",
    "    q_1 = get_corrected_text(plot_query)\n",
    "    search_a_dic = get_all_doc_sorted_score_based_on_query(q_0, q_1, title_weight)\n",
    "    i=1\n",
    "    ans = []\n",
    "    for key in search_a_dic.keys():\n",
    "        \n",
    "        if i > max_result_count:\n",
    "            break\n",
    "            \n",
    "        doc_id = key\n",
    "        ans.append(doc_id)\n",
    "        i += 1\n",
    "    return ans\n",
    "        \n",
    "\n",
    "def search(title_query, plot_query, title_weight, max_result_count=10):\n",
    "    \n",
    "    q_0 = get_corrected_text(title_query)\n",
    "    q_1 = get_corrected_text(plot_query)\n",
    "    \n",
    "    search_a_dic = get_all_doc_sorted_score_based_on_query(q_0, q_1, title_weight)\n",
    "    i=1\n",
    "    \n",
    "    ans = []\n",
    "    \n",
    "    for key in search_a_dic.keys():\n",
    "        \n",
    "        if i > max_result_count:\n",
    "            break\n",
    "            \n",
    "        doc_id = key\n",
    "        \n",
    "        idx_ls = (list(df_raw[df['id'] == doc_id].index))\n",
    "        title = df_raw.loc[idx_ls[0], 'title']\n",
    "        title = tokenize_and_bold_get_around(title, q_0, doc_id, part=0)\n",
    "    \n",
    "        \n",
    "        highlight = df_raw.loc[idx_ls[0], 'plot']\n",
    "        highlight = tokenize_and_bold_get_around(highlight, q_1, doc_id, part=1)\n",
    "        \n",
    "        \n",
    "        ans.append([doc_id, title, highlight])\n",
    "        i += 1 \n",
    "    \n",
    "    return ans\n",
    "\n",
    "plot_query = \"In a murder trial, 12 men act as the jury to decide whether or not the boy is guilty for murdering his father. The lawyers won't help the boy as he has a weapon.\"\n",
    "title_query = \"\"\n",
    "\n",
    "answer = search(title_query, plot_query, 4, 10)\n",
    "clean_bold_print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crawshaw'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corrected_text('shawshank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10000, 'The Shawshank <b>Redemption</b> ', '... '],\n",
       " [36, 'Civilization ', '... '],\n",
       " [5285, 'Kingdom of Heaven ', '... ']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('redempt', '', 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBig369C6wSC"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>ارزیابی عملکرد سامانه (۱۰ نمره)</b>\n",
    "    </h1>\n",
    "    همانطور که در بخش مربوط به مجموعه دادگان گفته شد، تعدادی پرسمان نمونه به همراه اسناد مورد نظر برای آن‌ها در اختیار شما قرار گرفته است. در هر مورد اطلاعات لازم برای ایجاد یک پرسمان ذکر شده است. مطابق آن‌ها پرسمان خود را ایجاد کنید. نتایج به دست آمده از هر پرسمان را به عنوان predicted results آن پرسمان در نظر بگیرید. همچنین در هر مورد لیستی از شناسه‌ها وجود دارد. این لیست را به عنوان actual results در نظر بگیرید. <br>\n",
    "    معیار‌های زیر را پیاده‌سازی کنید (بدون استفاده از کد آماده) و نتیجه این معیارها را روی مجموعه‌ی actual و predicted گزارش کنید. دقت کنید که به ازای هر پرسمان باید تمام معیارها را در قالب یک جدول گزارش کنید.<br> دقت کنید که ۳ پرسمان آخر فقط برای افرادی که بخش spell correction را پیاده کرد‌ه‌اند نتیجه مطلوب دارد.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPfEVezQIsmb",
    "outputId": "28b08705-5d4f-47e6-baec-3372f3e3293c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision(actual, predicted):\n",
    "    \"\"\"Calculate precision\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    predicted : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Precision score\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: implement precision\n",
    "    actual = set(actual)\n",
    "    predicted = set(predicted)\n",
    "    \n",
    "    precision = len(actual.intersection(predicted)) / len(predicted)\n",
    "    return precision\n",
    "\n",
    "precision([1,2], [1, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "is4nfSw1LQoQ",
    "outputId": "cc2a4388-464b-4d67-cb86-32617e3e526d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(actual, predicted):\n",
    "    \"\"\"Calculate recall\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    predicted : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Recall score\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: implement recall\n",
    "    \n",
    "    actual = set(actual)\n",
    "    predicted = set(predicted)\n",
    "    \n",
    "    recall = len(actual.intersection(predicted)) / len(actual)\n",
    "    return recall\n",
    "\n",
    "recall([1,2], [1, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYHYwRgTLVRA",
    "outputId": "d749daf0-102d-4855-e292-21dcd137d6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1_score(actual, predicted):\n",
    "    \"\"\"Calculate f1_score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    predicted : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        f1_score\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: implement f1_score\n",
    "    if precision(actual, predicted) == 0:\n",
    "        return 0\n",
    "    \n",
    "    f1_score = 2* (precision(actual, predicted)*recall(actual, predicted))/(precision(actual, predicted) + recall(actual, predicted))\n",
    "    return f1_score\n",
    "\n",
    "f1_score([1,2], [1, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZg-_PUPLZ31",
    "outputId": "e85b9efa-3b9b-470e-8b93-f474585da6c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_score(actual, predicted):\n",
    "    \"\"\"Calculate map_score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    predicted : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        map_score\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: implement map_score\n",
    "    sum_ = 0\n",
    "    rel_pre = 0\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] in actual:\n",
    "            rel_pre += 1\n",
    "            sum_ += rel_pre/(i+1)\n",
    "    \n",
    "    if rel_pre == 0:\n",
    "        map_score = 0\n",
    "        return map_score\n",
    "    map_score = sum_/rel_pre\n",
    "    return map_score\n",
    "\n",
    "map_score([1,2], [1, 4, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgOKEbMNLf-r",
    "outputId": "b38f683a-7224-411b-efb4-8fe7ce4eb328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46927872602275644"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ndcg_score(actual, predicted):\n",
    "    \"\"\"Calculate ndcg_score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "\n",
    "    predicted : list\n",
    "        [1st_doc_id, 2nd_doc_id, ...]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        ndcg_score\n",
    "    \"\"\"\n",
    "    \n",
    "    n_ = 0\n",
    "    for i in range(len(actual)):\n",
    "        n_ += 1/math.log2(i+2)\n",
    "    \n",
    "    dcg = 0    \n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] in actual:\n",
    "            dcg += 1/math.log2(i+2)\n",
    "    \n",
    "    ndcg_score = dcg/n_\n",
    "\n",
    "    \n",
    "    return ndcg_score\n",
    "\n",
    "ndcg_score([3, 1,2], [1, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[626, 1812, 111, 3297, 74, 4213, 3296, 4507, 2760, 1655]\n",
      "[5180, 4315]\n",
      "[4643, 4471, 5122, 4836, 3661, 4105, 3760]\n",
      "[4670, 4754, 1136, 5514, 4971, 5958, 5309, 3958, 2169, 2535, 794, 2871]\n",
      "[2851]\n",
      "[5625]\n",
      "[5153]\n"
     ]
    }
   ],
   "source": [
    "with open('validation.json', 'r') as json_file:\n",
    "    test_dic = json.load(json_file)\n",
    "    \n",
    "    ls_score = []\n",
    "    \n",
    "    for i in range(len(test_dic)):\n",
    "        test = test_dic[i]\n",
    "        actual = test['doc_ids']\n",
    "        plot_q = test['plot_query']\n",
    "        title_q = test['title_query']\n",
    "        max_size = test['max_size']\n",
    "        title_weight = test['title_weight']\n",
    "        predicted = get_related_doc_id(title_q, plot_q, title_weight, max_size)\n",
    "        print(predicted)\n",
    "        \n",
    "        ls = [precision(actual, predicted),\n",
    "                recall(actual, predicted),\n",
    "                f1_score(actual, predicted),\n",
    "                map_score(actual, predicted),\n",
    "                ndcg_score(actual, predicted)]\n",
    "        \n",
    "        ls_score.append(ls)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall  f1_score  map  ndcg\n",
       "0        0.9     0.9       0.9  1.0   0.9\n",
       "1        0.5     0.5       0.5  1.0   0.6\n",
       "2        0.9     0.9       0.9  1.0   0.9\n",
       "3        0.6     0.6       0.6  0.8   0.7\n",
       "4        0.0     0.0       0.0  0.0   0.0\n",
       "5        1.0     1.0       1.0  1.0   1.0\n",
       "6        1.0     1.0       1.0  1.0   1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_df = pd.DataFrame(columns=['precision', 'recall', 'f1_score', 'map', 'ndcg'])\n",
    "\n",
    "for ls in ls_score:\n",
    "    tmp = []\n",
    "    for score in ls:\n",
    "        tmp.append(round(score, 1))\n",
    "    s = pd.Series(tmp, index=sc_df.columns)\n",
    "    sc_df = sc_df.append(s, ignore_index=True)\n",
    "sc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.6, 0.6, 0.5888888888888889, 0.5147714448836774)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(precision([1, 2, 3, 4, 5], [6, 1, 5, 8, 4]), recall([1, 2, 3, 4, 5], [6, 1, 5, 8, 4]), f1_score([1, 2, 3, 4, 5], [6, 1, 5, 8, 4]), map_score([1, 2, 3, 4, 5], [6, 1, 5, 8, 4]), ndcg_score([1, 2, 3, 4, 5], [6, 1, 5, 8, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 1.0, 0.7499999999999999, 0.7555555555555555, 0.8854598815714874)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(precision([1, 2, 3], [1, 4, 2, 5, 3]), recall([1, 2, 3], [1, 4, 2, 5, 3]), f1_score([1, 2, 3], [1, 4, 2, 5, 3]), map_score([1, 2, 3], [1, 4, 2, 5, 3]), ndcg_score([1, 2, 3], [1, 4, 2, 5, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = [\n",
    "  {\n",
    "    \"max_size\": 8,\n",
    "    \"plot_query\": \"the Scorpion King leads his army on a campaign to conquer the world.\",\n",
    "    \"title_query\": \"The Mummy Returns\",\n",
    "    \"title_weight\": 1\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 4,\n",
    "    \"plot_query\": \"Jeremy takes John to a wedding for a daughter of the U.S. Secretary of the Treasury\\nJohn and Jeremy become acquainted with the Clearys at their home.\",\n",
    "    \"title_query\": \"\",\n",
    "    \"title_weight\": 1\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 10,\n",
    "    \"plot_query\": \"One of them, later known as The Fallen, defies their sole rule to never destroy planets hosting life by establishing a Sun Harvester on Earth. \",\n",
    "    \"title_query\": \"\",\n",
    "    \"title_weight\": 1\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 11,\n",
    "    \"plot_query\": \"jim and his mother are in a birthday celebration. he finds a mysterious map but a sailor with one leg looks for it too. The pirates want to kill Jim. Silver protects him. Jim frees Silver. As he sails away, Silver promises to hunt treasure with Jim again some day.\",\n",
    "    \"title_query\": \"Treasure Island\",\n",
    "    \"title_weight\": 4\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 2,\n",
    "    \"plot_query\": \"Neo, humanity's only hope of stopping the war and saving Zion, attempts to broker peace between the machines and humans.\",\n",
    "    \"title_query\": \"\",\n",
    "    \"title_weight\": 4\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 8,\n",
    "    \"plot_query\": \"Captain Jean Luc Picard awaken from a nightmare.\\nThe Enterprise arrives in time to assist the crew of the USS Defiant and its captain.\\nThe Enterprise arrives hundreds of years in its past on April 4, 2063, the day before humanity's first encounter with alien life.\",\n",
    "    \"title_query\": \"Star Trek\",\n",
    "    \"title_weight\": 4\n",
    "  },\n",
    "  {\n",
    "    \"max_size\": 13,\n",
    "    \"plot_query\": \"In a murder trial, 12 men act as the jury to decide whether or not the boy is guilty for murdering his father. The lawyers won't help the boy as he has a weapon.\",\n",
    "    \"title_query\": \"\",\n",
    "    \"title_weight\": 4\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> The Mummy Returns</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> the Scorpion King leads his army on a campaign to conquer the world.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Predicted:</b> [5060, 5139, 5550, 4925, 4256, 5192, 1157, 2876]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>1:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>The <b>Mummy</b> <b>Returns</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... BC , the <b>Scorpion</b> <b>King</b> <b>leads</b> his <b>army</b> on a <b>campaign</b> to <b>conquer</b> the <b>world</b> . Seven years later , his <b>army</b> is defeated while ... to hide the <b>Scorpion</b> <b>King</b> 's pyramid and ... warriors . The <b>Army</b> of Anubis sweeps ... Anubis claims the <b>Scorpion</b> <b>King</b> 's soul and his <b>army</b> . In 1933 ... shine on the <b>Scorpion</b> <b>King</b> 's pyramid . ... to defeat the <b>Scorpion</b> <b>King</b> , giving him ... of Anubis 's <b>army</b> to take over the <b>world</b> . The cult , <b>led</b> by Baltus Hafez ... case Anubis 's <b>army</b> rises . Evelyn ... and revives the <b>Army</b> of Anubis . ... Imhotep summoning the <b>Scorpion</b> <b>King</b> and fights him , but the <b>Scorpion</b> <b>King</b> interrupts them , ... battle Anubis 's <b>army</b> of jackal warriors ... Rick and the <b>Scorpion</b> <b>King</b> fight , Baltus ... can kill the <b>Scorpion</b> <b>King</b> . The Medjai defeat Anubis ' <b>army</b> , but find ... Rick sends the <b>Scorpion</b> <b>King</b> and his <b>army</b> back to the ... by killing the <b>Scorpion</b> <b>King</b> with the spear ... a pit that <b>leads</b> to the underworld ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>2:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>The Scorpion King </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... invades the prehistoric <b>world</b> , <b>led</b> by the ruthless ... law , is <b>king</b> for being their ... are hired by <b>King</b> Pheron of the ... , and Nubian <b>King</b> Balthazar , who ... leg with a <b>scorpion</b> blood-laced arrow . ... Memnon and his <b>army</b> slaughtering the entire ... palace , the <b>King</b> on High will become the invincible <b>Scorpion</b> <b>King</b> , and Memnon ... to become the <b>Scorpion</b> <b>King</b> . Furthermore , ... Philos and the <b>army</b> of rebels , ... to become the <b>Scorpion</b> <b>King</b> , Cassandra kills ... of Memnon 's <b>army</b> bow before Mathayus ... is their new <b>king</b> , the <b>Scorpion</b> <b>King</b> . In the ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> Jeremy takes John to a wedding for a daughter of the U.S. Secretary of the Treasury\n",
       "John and Jeremy become acquainted with the Clearys at their home.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Predicted:</b> [5324, 5729, 5700, 3312]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>1:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Wedding Crashers </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>John</b> Beckwith ( Owen Wilson ) and <b>Jeremy</b> Grey ( Vince ... `` crash '' <b>wedding</b> parties to meet ... successful crashes , <b>Jeremy</b> takes <b>John</b> to a <b>wedding</b> for a <b>daughter</b> of the <b>U.S.</b> <b>Secretary</b> of the <b>Treasury</b> , William <b>Cleary</b> ( Christopher Walken ... their sights on <b>Cleary</b> 's other <b>daughters</b> , Gloria ( ... McAdams ) . <b>Jeremy</b> ends up having ... possessive and quickly <b>becomes</b> obsessed with <b>Jeremy</b> , and <b>Jeremy</b> urges <b>John</b> to escape the ... . Meanwhile , <b>John</b> attempts to court ... When Gloria invites <b>Jeremy</b> and <b>John</b> to an extended ... family compound , <b>John</b> overrules <b>Jeremy</b> to accept and ... to Claire . <b>John</b> and <b>Jeremy</b> <b>become</b> <b>acquainted</b> with the <b>Clearys</b> at their <b>home</b> : the <b>Secretary</b> 's wife ( ... ) sexually harasses <b>John</b> ; Gloria 's ... tries to seduce <b>Jeremy</b> during the night ... sexual attention on <b>Jeremy</b> ; and Sack repeatedly injures <b>Jeremy</b> during a game ... At dinner , <b>John</b> spikes Sack 's ... with Claire . <b>John</b> and Claire continue ... trip , where <b>Jeremy</b> is shot in ... he recovers , <b>John</b> and Claire go ... ends up kissing <b>John</b> passionately . Meanwhile ... Gloria tends to <b>Jeremy</b> 's wounds and ... let on . <b>Jeremy</b> realizes that he ... marry Sack , <b>John</b> is interrupted by <b>Jeremy</b> being chased out ... investigated and revealed <b>John</b> and <b>Jeremy</b> 's identities to ... turns away from <b>John</b> and the <b>Secretary</b> tells them to ... following months , <b>John</b> attempts to reach ... see him . <b>John</b> attempts to crash ... Sack . Confronting <b>Jeremy</b> about abandoning him ... he learns that <b>Jeremy</b> has <b>secretly</b> continued his relationship ... . Betrayed , <b>John</b> spirals into depression , crashing <b>weddings</b> alone and <b>becoming</b> nihilistic and suicidal ... Sack plan their <b>wedding</b> , Claire 's doubts grow . <b>Jeremy</b> proposes to Gloria ... tries to ask <b>John</b> to be his ... but a depressed <b>John</b> refuses . <b>John</b> visits <b>Jeremy</b> 's former <b>wedding</b> crashing mentor , ... and rushes to <b>Jeremy</b> 's <b>wedding</b> . <b>John</b> joins the <b>wedding</b> mid-ceremony to <b>Jeremy</b> 's delight , ... appearance , prompting <b>John</b> to profess his ... tries to attack <b>John</b> , but <b>Jeremy</b> intervenes to knock ... out , and <b>John</b> and Claire kiss . After the <b>wedding</b> , the two ... discussing crashing another <b>wedding</b> together . </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>2:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Fire with Fire </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... work , firefighter <b>Jeremy</b> Thomas Coleman and ... Scotch . When <b>Jeremy</b> enters a convenience ... boss . After <b>Jeremy</b> narrowly escapes with ... is arrested and <b>Jeremy</b> identifies him in ... full well that <b>Jeremy</b> is behind the ... mirror by reciting <b>Jeremy</b> 's full name ... the trial , <b>Jeremy</b> is forced to ... program . Although <b>Jeremy</b> finds it difficult ... a result , <b>Jeremy</b> and Talia find ... and Hagan calls <b>Jeremy</b> , threatening to ... or not . <b>Jeremy</b> vows to kill ... protection program . <b>Jeremy</b> travels <b>home</b> to Long Beach ... a gun . <b>Jeremy</b> stakes out one ... Cella to believe <b>Jeremy</b> is behind the killings . <b>Jeremy</b> grows bolder in ... fear , gives <b>Jeremy</b> the location of ... tries to convince <b>Jeremy</b> to abandon his plan . <b>Jeremy</b> locks Talia in ... That night , <b>Jeremy</b> , using his ... meeting . When <b>Jeremy</b> realizes Talia is ... the blaze . <b>Jeremy</b> runs into Hagan ... kills Hagan . <b>Jeremy</b> leaves the building ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> One of them, later known as The Fallen, defies their sole rule to never destroy planets hosting life by establishing a Sun Harvester on Earth. </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Predicted:</b> [5610, 5967, 4836, 5661, 5483, 5120, 3760, 5564, 5594, 5874]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>1:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Transformers : Revenge of the Fallen </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... star-absorbing machines named <b>Sun</b> <b>Harvesters</b> . One of them , <b>later</b> <b>known</b> as The <b>Fallen</b> , <b>defies</b> their <b>sole</b> <b>rule</b> to <b>never</b> <b>destroy</b> <b>planets</b> <b>hosting</b> <b>life</b> by <b>establishing</b> a <b>Sun</b> <b>Harvester</b> on <b>Earth</b> . He is ... before he can <b>harvest</b> the <b>planet</b> 's <b>Sun</b> using the Matrix ... them of the <b>Fallen</b> 's return . ... are still on <b>Earth</b> to hunt the ... . After Bumblebee <b>destroys</b> the rampaging appliances ... Mikaela , who <b>later</b> captures the Decepticon ... master , the <b>Fallen</b> , who orders ... can defeat the <b>Fallen</b> . Sam , ... the world , <b>destroying</b> ships in the ... Paris . The <b>Fallen</b> hijacks <b>Earth</b> 's telecommunications systems ... the Transformers visited <b>Earth</b> eons ago and ... most ancient , <b>known</b> as Seekers , remained on <b>Earth</b> , hiding in ... story of the <b>Fallen</b> . Jetfire and ... Devastator , who <b>destroys</b> one of the ... to reveal the <b>Sun</b> <b>Harvester</b> inside , before ... killed by a <b>destroyer</b> 's railgun called ... restore Sam 's <b>life</b> and the Matrix ... Optimus . The <b>Fallen</b> teleports to their ... and activates the <b>Sun</b> <b>Harvester</b> . Jetfire , ... Optimus knocks the <b>Fallen</b> and Megatron off the pyramid , <b>destroying</b> the <b>Sun</b> <b>Harvester</b> in the process ... and kills the <b>Fallen</b> ; vowing vengeance ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>2:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Independence Day : Resurgence </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... set up the <b>Earth</b> Space Defense ( ... and serves as <b>Earth</b> 's <b>early</b> warning system against ... intact alien city <b>destroyer</b> and discover that ... a wormhole near <b>Earth</b> 's Moon , ... Levinson , is <b>destroyed</b> on the orders ... Security Council . <b>Defying</b> orders , American ... and proceeds to <b>destroy</b> much of the <b>Earth</b> 's <b>planetary</b> defenses before landing ... down toward the <b>Earth</b> 's molten core ... survivors to a <b>planet</b> of refuge from ... she calls `` <b>Harvesters</b> '' , and ... attack on the <b>Harvesters</b> ' <b>planet</b> . In the ... Rain navigate two <b>Harvester</b> fighters to pursue ... about the refugee <b>planet</b> . <b>Knowing</b> the <b>Harvester</b> Queen has become ... to lure the <b>Harvester</b> Queen 's ship ... sacrificing himself but <b>destroying</b> the enemy ship ... However , the <b>Harvester</b> Queen survives by ... but after the <b>Harvester</b> Queen lowers her ... counterattack on the <b>Harvester</b> 's home world ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> Treasure Island</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> jim and his mother are in a birthday celebration. he finds a mysterious map but a sailor with one leg looks for it too. The pirates want to kill Jim. Silver protects him. Jim frees Silver. As he sails away, Silver promises to hunt treasure with Jim again some day.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Predicted:</b> [626, 1812, 111, 3297, 74, 4213, 3296, 4507, 2760, 1655, 2557]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>1:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Treasure</b> <b>Island</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Young <b>Jim</b> Hawkins ( Jackie ... ) and his <b>mother</b> ( Dorothy Peterson ... , during a <b>birthday</b> <b>celebration</b> , the <b>mysterious</b> Billy Bones ( ... drunkenly talks about <b>treasure</b> . Soon after ... of money , <b>Jim</b> finds a <b>map</b> that his friend ... the famous Flint <b>treasure</b> . Squire Trelawney ... voyage to the <b>treasure</b> island and they set <b>sail</b> on Captain Alexander ... one-legged Long John <b>Silver</b> ( Wallace Beery ... Bones had warned <b>Jim</b> about a <b>sailor</b> with one <b>leg</b> , they become ... '' happen to <b>sailors</b> who disapprove of <b>Silver</b> and his cohorts ... the island , <b>Jim</b> overhears <b>Silver</b> plotting to take the <b>treasure</b> and kill Smollett 's men . <b>Jim</b> goes ashore with ... found Flint 's <b>treasure</b> . Meanwhile , ... for safety . <b>Silver</b> 's men then ... give them the <b>treasure</b> <b>map</b> . While the situation <b>looks</b> hopeless , <b>Jim</b> secretly goes back ... at night , <b>sails</b> it to a ... one of the <b>pirates</b> in self-defense . ... the stockade , <b>Silver</b> 's men are there and <b>Silver</b> tells them that ... signed . The <b>pirates</b> <b>want</b> to kill <b>Jim</b> , but <b>Silver</b> <b>protects</b> him . Dr. Livesey comes for <b>Jim</b> , but the ... his word to <b>Silver</b> not to run <b>away</b> . The next <b>day</b> the <b>pirates</b> search for the <b>treasure</b> hold and when ... empty . When <b>some</b> of the <b>pirates</b> mutiny against <b>Silver</b> , Livesey ( ... . Smollett then <b>sails</b> home with the <b>treasure</b> , which Gunn ... , and with <b>Silver</b> as his prisoner ... be hanged , <b>Jim</b> <b>frees</b> <b>Silver</b> . As he <b>sails</b> <b>away</b> , <b>Silver</b> <b>promises</b> to <b>hunt</b> <b>treasure</b> with <b>Jim</b> <b>again</b> <b>some</b> <b>day</b> , as Honest John <b>Silver</b> . </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>2:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Treasure</b> <b>Island</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... young boy called <b>Jim</b> Hawkins lives with his <b>mother</b> in a tiny ... gives Hawkins a <b>treasure</b> <b>map</b> after being visited by two <b>pirates</b> , the second ... inn , and <b>Jim</b> shows Squire Trelawney the <b>map</b> . Trelawney recognizes the <b>map</b> as belonging to ... to discover the <b>pirate</b> 's lost <b>treasure</b> . Trelawney hires ... 's doctor and <b>Jim</b> as the cabin ... by Long John <b>Silver</b> , a one-legged ... a crew . <b>Silver</b> strikes up a friendship with <b>Jim</b> and joins the ... At sea , <b>Jim</b> overhears <b>Silver</b> and the crew ... seamen hired by <b>Silver</b> are Captain Flint ... old crew . <b>Jim</b> reveals the treachery ... Smollett who asks <b>Jim</b> to stay friends with <b>Silver</b> to learn more . Upon reaching <b>Treasure</b> Island , <b>Silver</b> offers to tow ... , one of <b>Silver</b> 's men , ... the plot by <b>Jim</b> , is able ... below decks . <b>Silver</b> cuts the row ... men , taking <b>Jim</b> as a hostage ... the island , <b>Jim</b> escapes and meets ... . Gunn shows <b>Jim</b> the boat he ... Jolly Roger . <b>Silver</b> returns to the ... of men , <b>Silver</b> attempts to parlay ... is rebuffed , <b>Silver</b> calls his men ... fails , but <b>Silver</b> wounds Smollett . Although seemingly <b>protected</b> by the stockade ... morning tide , <b>Silver</b> could move the ... the fort . <b>Jim</b> takes Gunn 's ... rope . The <b>pirate</b> Israel Hands discovers <b>Jim</b> and chases him ... . Hands injures <b>Jim</b> 's arm with ... 's pistol . <b>Jim</b> strikes the Jolly ... . Inside , <b>Jim</b> searches for the ... is Long John <b>Silver</b> . <b>Jim</b> faints on the spot . <b>Silver</b> finds the <b>map</b> on him as ... up . Merry <b>wants</b> <b>Jim</b> dead , but <b>Silver</b> states he <b>wants</b> to trade him for the <b>map</b> , which his ... 's lookout , <b>Silver</b> sees that the ... The men give <b>Silver</b> the black spot ... Livesey for the <b>map</b> . <b>Silver</b> returns with <b>Jim</b> , flaunting the <b>map</b> . The <b>pirates</b> are overjoyed until ... out that the <b>treasure</b> – 700,000 pounds ... there . The <b>pirates</b> turn on <b>Silver</b> , who manages ... rest . Greeting <b>Silver</b> , Gunn reveals ... up Flint 's <b>treasure</b> and has stashed ... Captain Smollett still <b>wants</b> <b>Silver</b> taken back for ... two others take <b>Silver</b> to the Hispaniola ... a chest of <b>treasure</b> . <b>Silver</b> snatches <b>Jim</b> 's pistol and ... boat . He <b>wants</b> Hawkins to steer ... rows , but <b>Jim</b> beaches them instead . <b>Silver</b> orders Hawkins to ... off , but <b>Jim</b> refuses and <b>Silver</b> threatens to shoot him . <b>Silver</b> is unable to ... himself . Seeing <b>Silver</b> struggle , <b>Jim</b> helps him , ... hesitant farewell as <b>Silver</b> rows <b>away</b> with the <b>treasure</b> . </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> Neo, humanity's only hope of stopping the war and saving Zion, attempts to broker peace between the machines and humans.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Predicted:</b> [5180, 4315]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>1:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>The Matrix Revolutions </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Neo</b> and Bane lie ... . Meanwhile , <b>Neo</b> finds his digital ... —a transition zone <b>between</b> the Matrix and the <b>Machine</b> City . In ... whose father tells <b>Neo</b> the subway is ... Merovingian . When <b>Neo</b> tries to board ... informs them of <b>Neo</b> 's confinement . ... him to release <b>Neo</b> . Troubled by visions of the <b>Machine</b> City , <b>Neo</b> visits the Oracle ... and that the <b>war</b> will conclude . After <b>Neo</b> leaves , a ... their defense of <b>Zion</b> , <b>Neo</b> requests a ship ... travel to the <b>Machine</b> City . Motivated ... the Logos . <b>Neo</b> departs , accompanied ... Trinity hostage . <b>Neo</b> realizes that Bane ... . Bane cauterizes <b>Neo</b> 's eyes with ... ; however , <b>Neo</b> discovers an ability ... golden light . <b>Neo</b> kills Bane , ... them to the <b>Machine</b> City . Niobe ... set out for <b>Zion</b> with the Hammer to aid the <b>human</b> defenses against the Sentinels . In <b>Zion</b> , the fatally ... defenses . The <b>humans</b> are forced to ... . Near the <b>Machine</b> City , <b>Neo</b> and Trinity are ... of missiles which <b>Neo</b> <b>attempts</b> to destroy , ... Logos into the <b>Machine</b> City . The ... kills Trinity . <b>Neo</b> enters the <b>Machine</b> City and encounters `` Deus Ex <b>Machina</b> '' , the <b>machine</b> leader . <b>Neo</b> , warning that ... , offers to <b>stop</b> Smith in exchange for <b>peace</b> with <b>Zion</b> . The <b>machine</b> leader agrees , and the Sentinels <b>stop</b> attacking <b>Zion</b> . The <b>Machines</b> provide a connection for <b>Neo</b> to enter the ... his victory against <b>Neo</b> . After a ... assimilated . The <b>machine</b> leader sends a ... of energy into <b>Neo</b> 's body in ... world . Because <b>Neo</b> is connected to ... all , though <b>Neo</b> 's life is ... Sentinels withdraw from <b>Zion</b> , Morpheus and ... embrace , and <b>Neo</b> 's body is ... away by the <b>machines</b> . The Matrix ... agree that the <b>peace</b> will last `` ... and that all <b>humans</b> will be offered ... they will see <b>Neo</b> again . Seraph ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>2:</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Newsies </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>... New Mexico . <b>Attempting</b> to outdo his ... `` Spot '' <b>Conlon</b> is reluctant to ... arrested , Spot <b>Conlon</b> arrives with the ... reassigned as a <b>war</b> correspondent and can ... . The boys <b>attempt</b> to rescue Jack ... steps in to <b>save</b> them , knowing ... </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Title:</b> Star Trek</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Plot:</b> Captain Jean Luc Picard awaken from a nightmare.\n",
       "The Enterprise arrives in time to assist the crew of the USS Defiant and its captain.\n",
       "The Enterprise arrives hundreds of years in its past on April 4, 2063, the day before humanity's first encounter with alien life.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-57fd87db3c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"<div><b>Title:</b> {test['title_query']}</div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"<div><b>Plot:</b> {test['plot_query']}</div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot_query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"<div><b>Predicted:</b> {predicted}</div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-3e8e5cf6ee02>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(title_query, plot_query, title_weight, max_result_count)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mq_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corrected_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msearch_a_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_doc_sorted_score_based_on_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-096dc6a93db4>\u001b[0m in \u001b[0;36mget_all_doc_sorted_score_based_on_query\u001b[0;34m(query0, query1, title_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_related\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_unidoc_score_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-096dc6a93db4>\u001b[0m in \u001b[0;36mquery_unidoc_score_total\u001b[0;34m(query0, query1, doc_index, title_weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquery_unidoc_score_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtitle_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mquery_unidoc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery_unidoc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munion_valid_docs_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-096dc6a93db4>\u001b[0m in \u001b[0;36mquery_unidoc_score\u001b[0;34m(query, doc_index, part)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquery_unidoc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mquery_ls_repeated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mquery_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_ls_repeated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-096dc6a93db4>\u001b[0m in \u001b[0;36mprepare_query\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_idf_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-748d25e416cb>\u001b[0m in \u001b[0;36mprepare_text\u001b[0;34m(raw_text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpunc_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_ls\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'–'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-python-env/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/my-python-env/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/my-python-env/lib/python3.8/site-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "res = []\n",
    "for test in test_case:\n",
    "    display(HTML(f\"<div><b>Title:</b> {test['title_query']}</div>\"))\n",
    "    display(HTML(f\"<div><b>Plot:</b> {test['plot_query']}</div>\"))\n",
    "    res = search(test['title_query'], test['plot_query'], test['title_weight'], test['max_size'])\n",
    "    predicted = [x[0] for x in res]\n",
    "    display(HTML(f\"<div><b>Predicted:</b> {predicted}</div>\"))\n",
    "    for i, x in enumerate(res[:2]):\n",
    "        display(HTML(f\"<div><b>{i+1}:</b></div>\"))\n",
    "        display(HTML(f\"<div>{x[1]}</div>\"))\n",
    "        display(HTML(f\"<div>{x[2]}</div><br>\"))\n",
    "    display(HTML(f\"<hr>\"))\n",
    "    res.append(predicted)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHVlw0kVBUW4"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>نکات پایانی</b>\n",
    "    </h1>\n",
    "    \n",
    "\n",
    "1.   سیستم را بهینه پیاده‌سازی کنید تا در زمان کمتری بارگذاری و نمایه‌سازی  انجام شود.\n",
    "2.   تمام قطعه‌ کدهای بالا باید توسط شما تکمیل شود. نوت‌بوک نهایی باید بدون خطا اجرا شود. اگر تمام کدهای استفاده شده در همین فایل نیست،‌ حتما آن‌ها را نیز به همراه نوت‌بوک در کوئرا آپلود کنید.\n",
    "3.    اسم توابع و نحوه ورودی گرفتن و خروجی دادن آن‌ها را تغییر ندهید. بقیه اجزای توابع صرفا برای شهود بیشتر شما نوشته شده‌اند و نیازی به نگه‌داری آن‌ها نیست.\n",
    "4.   در صورت امکان استفاده از کد آماده مشخصا این مورد برای بخش مربوطه ذکر شده است. اگر چیزی در این مورد ذکر نشده نمی‌توانید از کد آماده استفاده کنید.\n",
    "5.    فایل داده‌ها را در کوئرا آپلود نکنید.\n",
    "6.    فایل زیپ نهایی و فایل نوت‌بوک حتما به فرمت StudentNumber_phase1 نامگذاری شود.\n",
    "\n",
    "\n",
    "<b>سالم و موفق باشید.</b>\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIR_Phase1_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
